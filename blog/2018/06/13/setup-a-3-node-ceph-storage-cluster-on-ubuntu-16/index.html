
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Setup a 3 Node Ceph Storage Cluster on Ubuntu 16 - Ruan Bekker's Blog</title>
  <meta name="author" content="Ruan">

  
  <meta name="description" content="For some time now, I wanted to do a setup of Ceph, and I finally got the time to do it. This setup was done on Ubuntu 16.04 What is Ceph Ceph is a &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- font awesome --!>
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  <!-- samwize.com/2012/09/24/octopress-table-stylesheet --!>
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />

  
  <link rel="canonical" href="https://blog.ruanbekker.com/blog/2018/06/13/setup-a-3-node-ceph-storage-cluster-on-ubuntu-16/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Ruan Bekker's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-105336110-1']);
    _gaq.push(['_setDomainName','ruanbekker.com']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


  <!-- Fathom - simple website analytics - https://github.com/usefathom/fathom -->
<script>
(function(f, a, t, h, o, m){
	a[h]=a[h]||function(){
		(a[h].q=a[h].q||[]).push(arguments)
	};
	o=f.createElement('script'),
	m=f.getElementsByTagName('script')[0];
	o.async=1; o.src=t; o.id='fathom-script';
	m.parentNode.insertBefore(o,m)
})(document, window, '//fh-blog-ruanbekker-com.home.ruan.dev/tracker.js', 'fathom');
fathom('set', 'siteId', 'MWBHH');
fathom('trackPageview');
</script>
<!-- / Fathom -->

  <!-- Twitter cards # www.brianbunke.com/blog/2017/09/06/twitter-cards-on-jekyll -->
<meta name="twitter:site"    content="@ruanbekker">
<meta name="twitter:creator" content="@">
<meta name="twitter:title"   content="Setup a 3 Node Ceph Storage Cluster on Ubuntu 16">


<meta name="twitter:description" content="">



<meta name="twitter:card"  content="summary">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/567298/69000657-c093e780-08db-11ea-8464-bcd3023e9923.png">

<!-- end of Twitter cards -->

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Ruan Bekker's Blog</a></h1>
  
    <h2>From a Curious mind to Posts on Github</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://blog.ruanbekker.com/search/" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="blog.ruanbekker.com">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/categories/aws/">AWS</a></li>
  <li><a href="/blog/categories/docker/">Docker</a></li>
  <li><a href="/blog/categories/devops/">DevOps</a></li>
  <li><a href="/blog/categories/python/">Python</a></li>
  <li><a target="_blank" href="https://sysadmins.co.za">My Sysadmins Blog</a></li>
  <li><a href="https://ruan.dev/">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Setup a 3 Node Ceph Storage Cluster on Ubuntu 16</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-06-13T18:22:06-04:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>6:22 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p><img src="https://ceph.com/wp-content/uploads/2016/07/Ceph_Logo_Standard_RGB_120411_fa.png" alt="" /></p>

<p>For some time now, I wanted to do a setup of Ceph, and I finally got the time to do it. This setup was done on Ubuntu 16.04</p>

<script id="mNCC" language="javascript">
    medianet_width = "728";
    medianet_height = "90";
    medianet_crid = "218284798";
    medianet_versionId = "3111299"; 
  </script>


<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>


<h2>What is Ceph</h2>

<p>Ceph is a storage platform that implements object storage on a single distributed computer cluster and provides interfaces for object, block and file-level storage.</p>

<ul>
<li>Object Storage:</li>
</ul>


<p>Ceph provides seemless access to objects via native language bindings or via the REST interface, RadosGW and also compatible for applications written for S3 and Swift.</p>

<ul>
<li>Block Storage:</li>
</ul>


<p>Ceph&rsquo;s Rados Block Device (RBD) provides access to block device images that are replicated and striped across the storage cluster.</p>

<ul>
<li>File System:</li>
</ul>


<p>Ceph provides a network file system (CephFS) that aims for high performance.</p>

<h2>Our Setup</h2>

<p>We will have 4 nodes. 1 Admin node where we will deploy our cluster with, and 3 nodes that will hold the data:</p>

<ul>
<li>ceph-admin (10.0.8.2)</li>
<li>ceph-node1 (10.0.8.3)</li>
<li>ceph-node2 (10.0.8.4)</li>
<li>ceph-node3 (10.0.8.5)</li>
</ul>


<h2>Host Entries</h2>

<p>If you don&rsquo;t have dns for your servers, setup the <code>/etc/hosts</code> file so that the names can resolves to the ip addresses:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>10.0.8.2 ceph-admin
</span><span class='line'>10.0.8.3 ceph-node1
</span><span class='line'>10.0.8.4 ceph-node2
</span><span class='line'>10.0.8.5 ceph-node3
</span></code></pre></td></tr></table></div></figure>


<h2>User Accounts and Passwordless SSH</h2>

<p>Setup the <code>ceph-system</code> user accounts on all the servers:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>useradd -d /home/ceph-system -s /bin/bash -m ceph-system
</span><span class='line'><span class="nv">$ </span>passwd ceph-system
</span></code></pre></td></tr></table></div></figure>


<p>Setup the created user part of the sudoers that is able to issue sudo commands without a pssword:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">&quot;ceph-system ALL = (root) NOPASSWD:ALL&quot;</span> <span class="p">|</span> sudo tee /etc/sudoers.d/ceph-system
</span><span class='line'><span class="nv">$ </span>chmod <span class="m">0440</span> /etc/sudoers.d/ceph-system
</span></code></pre></td></tr></table></div></figure>


<p>Switch user to <code>ceph-system</code> and generate SSH keys and copy the keys from the <code>ceph-admin</code> server to the ceph-nodes:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo su - ceph-system
</span><span class='line'><span class="nv">$ </span>ssh-keygen -t rsa -f ~/.ssh/id_rsa -P <span class="s2">&quot;&quot;</span>
</span><span class='line'><span class="nv">$ </span>ssh-copy-id ceph-system@ceph-node1
</span><span class='line'><span class="nv">$ </span>ssh-copy-id ceph-system@ceph-node2
</span><span class='line'><span class="nv">$ </span>ssh-copy-id ceph-system@ceph-node3
</span><span class='line'><span class="nv">$ </span>ssh-copy-id ceph-system@ceph-admin
</span></code></pre></td></tr></table></div></figure>


<h2>Pre-Requisite Software:</h2>

<p>Install Python and Ceph Deploy on each node:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo apt-get install python -y
</span><span class='line'><span class="nv">$ </span>sudo apt install ceph-deploy -y
</span></code></pre></td></tr></table></div></figure>


<p>Note: Please skip this section if you have additional disks on your servers.</p>

<p>The instances that im using to test this setup only has one disk, so I will be creating loop block devices using allocated files. This is not recommended as when the disk fails, all the (files/block device images) will be gone with that. But since im demonstrating this, I will create the block devices from a file:</p>

<p>I will be creating a 12GB file on each node</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo mkdir /raw-disks
</span><span class='line'><span class="nv">$ </span>sudo dd <span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>/raw-disks/rd0 <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>12288
</span></code></pre></td></tr></table></div></figure>


<p>The use losetup to create the loop0 block device:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo losetup /dev/loop0 /raw-disks/rd0
</span></code></pre></td></tr></table></div></figure>


<p>As you can see the loop device is showing when listing the block devices:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>lsblk
</span><span class='line'>NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
</span><span class='line'>loop0       7:0    <span class="m">0</span>   12G  <span class="m">0</span> loop
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h2>Install Ceph</h2>

<p>Now let&rsquo;s install ceph using ceph-deploy to all our nodes:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo apt update <span class="o">&amp;&amp;</span> sudo apt upgrade -y
</span><span class='line'><span class="nv">$ </span>ceph-deploy install ceph-admin ceph-node1 ceph-node2 ceph-node3
</span></code></pre></td></tr></table></div></figure>


<p>The version I was running at the time:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph --version
</span><span class='line'>ceph version 10.2.9
</span></code></pre></td></tr></table></div></figure>


<h2>Initialize Ceph</h2>

<p>Initialize the Cluster with 3 Monitors:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy new ceph-node1 ceph-node2 ceph-node3
</span></code></pre></td></tr></table></div></figure>


<p>Add the initial monitors and gather the keys from the previous command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy mon create-initial
</span></code></pre></td></tr></table></div></figure>


<p>At this point, we should be able to scan the block devices on our nodes:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy disk list ceph-node3
</span><span class='line'><span class="o">[</span>ceph-node3<span class="o">][</span>INFO  <span class="o">]</span> Running <span class="nb">command</span>: sudo /usr/sbin/ceph-disk list
</span><span class='line'><span class="o">[</span>ceph-node3<span class="o">][</span>DEBUG <span class="o">]</span> /dev/loop0 other
</span></code></pre></td></tr></table></div></figure>


<h2>Prepare the Disks:</h2>

<p>First we will zap the block devices and then prepare to create the partitions:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy disk zap ceph-node1:/dev/loop0 ceph-node2:/dev/loop0 ceph-node3:/dev/loop0
</span><span class='line'><span class="nv">$ </span>ceph-deploy osd prepare ceph-node1:/dev/loop0 ceph-node2:/dev/loop0 ceph-node3:/dev/loop0
</span><span class='line'><span class="o">[</span>ceph_deploy.osd<span class="o">][</span>DEBUG <span class="o">]</span> Host ceph-node1 is now ready <span class="k">for</span> osd use.
</span><span class='line'><span class="o">[</span>ceph_deploy.osd<span class="o">][</span>DEBUG <span class="o">]</span> Host ceph-node2 is now ready <span class="k">for</span> osd use.
</span><span class='line'><span class="o">[</span>ceph_deploy.osd<span class="o">][</span>DEBUG <span class="o">]</span> Host ceph-node3 is now ready <span class="k">for</span> osd use.
</span></code></pre></td></tr></table></div></figure>


<p>When you scan the nodes for their disks, you will notice that the partitions has been created:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy disk list ceph-node1
</span><span class='line'><span class="o">[</span>ceph-node1<span class="o">][</span>DEBUG <span class="o">]</span> /dev/loop0p2 ceph journal, <span class="k">for</span> /dev/loop0p1
</span><span class='line'><span class="o">[</span>ceph-node1<span class="o">][</span>DEBUG <span class="o">]</span> /dev/loop0p1 ceph data, active, cluster ceph, osd.0, journal /dev/loop0p2
</span></code></pre></td></tr></table></div></figure>


<p>Now let&rsquo;s activate the OSD&rsquo;s by using the data partitions:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy osd activate ceph-node1:/dev/loop0p1 ceph-node2:/dev/loop0p1 ceph-node3:/dev/loop0p1
</span></code></pre></td></tr></table></div></figure>


<h2>Redistribute Keys:</h2>

<p>Copy the configuration files and admin key to your admin node and ceph data nodes:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy admin ceph-admin ceph-node1 ceph-node2 ceph-node3
</span></code></pre></td></tr></table></div></figure>


<p>If you would like to add more OSD&rsquo;s (not tested):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph-deploy disk zap ceph-node1:/dev/loop1 ceph-node2:/dev/loop1 ceph-node3:/dev/loop1
</span><span class='line'><span class="nv">$ </span>ceph-deploy osd prepare ceph-node1:/dev/loop1 ceph-node2:/dev/loop1 ceph-node3:/dev/loop1
</span><span class='line'><span class="nv">$ </span>ceph-deploy osd activate ceph-node2:/dev/loop1p1:/dev/loop1p2 ceph-node2:/dev/loop1p1:/dev/loop1p2 ceph-node3:/dev/loop1p1:/dev/loop1p2
</span><span class='line'><span class="nv">$ </span>ceph-deploy admin ceph-node1 ceph-node2 ceph-node3
</span></code></pre></td></tr></table></div></figure>


<h2>Ceph Status:</h2>

<p>Have a look at your cluster status:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo ceph -s
</span><span class='line'>    cluster 8d704c8a-ac19-4454-a89f-89a5d5b7d94d
</span><span class='line'>     health HEALTH_OK
</span><span class='line'>     monmap e1: <span class="m">3</span> mons at <span class="o">{</span>ceph-node1<span class="o">=</span>10.0.8.3:6789/0,ceph-node2<span class="o">=</span>10.0.8.4:6789/0,ceph-node3<span class="o">=</span>10.0.8.5:6789/0<span class="o">}</span>
</span><span class='line'>            election epoch 10, quorum 0,1,2 ceph-node2,ceph-node3,ceph-node1
</span><span class='line'>     osdmap e14: <span class="m">3</span> osds: <span class="m">3</span> up, <span class="m">3</span> in
</span><span class='line'>            flags sortbitwise,require_jewel_osds
</span><span class='line'>      pgmap v29: <span class="m">64</span> pgs, <span class="m">1</span> pools, <span class="m">0</span> bytes data, <span class="m">0</span> objects
</span><span class='line'>            <span class="m">100</span> MB used, <span class="m">18298</span> MB / <span class="m">18398</span> MB avail
</span><span class='line'>                  <span class="m">64</span> active+clean
</span></code></pre></td></tr></table></div></figure>


<p>Everything looks good. Also change the permissions on this file, on all the nodes in order to execute the ceph, rados commands:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo chmod +r /etc/ceph/ceph.client.admin.keyring
</span></code></pre></td></tr></table></div></figure>


<h2>Storage Pools:</h2>

<p>List your pool in your Ceph Cluster:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rados lspools
</span><span class='line'>rbd
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s create a new storage pool called <code>mypool</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph osd pool create mypool <span class="m">32</span> <span class="m">32</span>
</span><span class='line'>pool <span class="s1">&#39;mypool&#39;</span> created
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s the list the storage pools again:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rados lspools
</span><span class='line'>rbd
</span><span class='line'>mypool
</span></code></pre></td></tr></table></div></figure>


<p>You can also use the ceph command to list the pools:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph osd pool ls
</span><span class='line'>rbd
</span><span class='line'>mypool
</span></code></pre></td></tr></table></div></figure>


<p>Create a Block Device Image:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rbd create --size <span class="m">1024</span> mypool/disk1 --image-feature layering
</span></code></pre></td></tr></table></div></figure>


<p>List the Block Device Images under your Pool:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rbd list mypool
</span><span class='line'>disk1
</span></code></pre></td></tr></table></div></figure>


<p>Retrieve information from your image:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rbd info mypool/disk1
</span><span class='line'>rbd image <span class="s1">&#39;disk1&#39;</span>:
</span><span class='line'>        size <span class="m">1024</span> MB in <span class="m">256</span> objects
</span><span class='line'>        order <span class="m">22</span> <span class="o">(</span><span class="m">4096</span> kB objects<span class="o">)</span>
</span><span class='line'>        block_name_prefix: rbd_data.1021643c9869
</span><span class='line'>        format: 2
</span><span class='line'>        features: layering
</span><span class='line'>        flags:
</span><span class='line'>        create_timestamp: Thu Jun  <span class="m">7</span> 23:48:23 2018
</span></code></pre></td></tr></table></div></figure>


<p>Create a local mapping of the image to a block device:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo rbd map mypool/disk1
</span><span class='line'>/dev/rbd0
</span></code></pre></td></tr></table></div></figure>


<p>Now we have a block device available at <code>/dev/rbd0</code>. Go ahead and mount it to <code>/mnt</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo mount /dev/rbd0 /mnt
</span></code></pre></td></tr></table></div></figure>


<p>We can then see it when we list our mounted disk partitions:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>df -h
</span><span class='line'>Filesystem      Size  Used Avail Use% Mounted on
</span><span class='line'>/dev/sda1        19G   13G  5.2G  72% /
</span><span class='line'>/dev/rbd0       976M  1.3M  908M   1% /mnt
</span></code></pre></td></tr></table></div></figure>


<p>We can also resize the disk on the fly, let&rsquo;s resize it from 1GB to 2GB:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rbd resize mypool/disk1 --size 2048
</span><span class='line'>Resizing image: 100% complete...done.
</span></code></pre></td></tr></table></div></figure>


<p>To grow the space we can use resize2fs for ext4 partitions and xfs_growfs for xfs partitions:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>sudo resize2fs /dev/rbd0
</span><span class='line'>resize2fs 1.42.13 <span class="o">(</span>17-May-2015<span class="o">)</span>
</span><span class='line'>Filesystem at /dev/rbd0 is mounted on /mnt<span class="p">;</span> on-line resizing required
</span><span class='line'><span class="nv">old_desc_blocks</span> <span class="o">=</span> 1, <span class="nv">new_desc_blocks</span> <span class="o">=</span> 1
</span><span class='line'>The filesystem on /dev/rbd0 is now <span class="m">524288</span> <span class="o">(</span>4k<span class="o">)</span> blocks long.
</span></code></pre></td></tr></table></div></figure>


<p>When we look at our mounted partitions, you will notice that the size of our mounted partition has been increased in size:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>df -h
</span><span class='line'>Filesystem      Size  Used Avail Use% Mounted on
</span><span class='line'>/dev/sda1        19G   13G  5.2G   72% /
</span><span class='line'>/dev/rbd0       2.0G  1.5M  1.9G   1% /mnt
</span></code></pre></td></tr></table></div></figure>


<h2>Object Storage RadosGW</h2>

<p>Let&rsquo;s create a new pool where we will store our objects:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>ceph osd pool create object-pool <span class="m">32</span> 32
</span><span class='line'>pool <span class="s1">&#39;object-pool&#39;</span> created
</span></code></pre></td></tr></table></div></figure>


<p>We will now create a local file, push the file to our object storage service, then delete our local file, download the file as a file with a different name, and read the contents:</p>

<p>Create the local file:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">&quot;ok&quot;</span> &gt; test.txt
</span></code></pre></td></tr></table></div></figure>


<p>Push the local file to our pool in our object storage:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rados put objects/data/test.txt ./test.txt --pool object-pool
</span></code></pre></td></tr></table></div></figure>


<p>List the pool (note that this can be executed from any node):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ $ </span>rados ls --pool object-pool
</span><span class='line'>objects/data/test.txt
</span></code></pre></td></tr></table></div></figure>


<p>Delete the local file, download the file from our object storage and read the contents:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rm -rf test.txt
</span><span class='line'>
</span><span class='line'><span class="nv">$ </span>rados get objects/data/test.txt ./newfile.txt --pool object-pool
</span><span class='line'>
</span><span class='line'><span class="nv">$ </span>cat ./newfile.txt
</span><span class='line'>ok
</span></code></pre></td></tr></table></div></figure>


<p>View the disk space from our storage-pool:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>rados df --pool object-pool
</span><span class='line'>pool name                 KB      objects       clones     degraded      unfound           rd        rd KB           wr        wr KB
</span><span class='line'>object-pool                <span class="m">1</span>            <span class="m">1</span>            <span class="m">0</span>            <span class="m">0</span>            <span class="m">0</span>            <span class="m">0</span>            <span class="m">0</span>            <span class="m">1</span>            1
</span><span class='line'>  total used          <span class="m">261144</span>           37
</span><span class='line'>  total avail       18579372
</span><span class='line'>  total space       18840516
</span></code></pre></td></tr></table></div></figure>


<h2>Resources:</h2>

<ul>
<li><a href="https://stackoverflow.com/questions/39589696/ceph-too-many-pgs-per-osd-all-you-need-to-know">https://stackoverflow.com/questions/39589696/ceph-too-many-pgs-per-osd-all-you-need-to-know</a></li>
<li><a href="https://github.com/lucj/swarm-rexray-ceph">https://github.com/lucj/swarm-rexray-ceph</a></li>
<li><a href="http://docs.ceph.com/docs/mimic/rbd/">http://docs.ceph.com/docs/mimic/rbd/</a></li>
<li><a href="http://docs.ceph.com/docs/mimic/radosgw/">http://docs.ceph.com/docs/mimic/radosgw/</a></li>
</ul>


<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Ruan</span></span>

      




<time class='entry-date' datetime='2018-06-13T18:22:06-04:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>6:22 pm</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/ceph/'>ceph</a>, <a class='category' href='/blog/categories/storage/'>storage</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="https://blog.ruanbekker.com/blog/2018/06/13/setup-a-3-node-ceph-storage-cluster-on-ubuntu-16/" data-via="ruanbekker" data-counturl="https://blog.ruanbekker.com/blog/2018/06/13/setup-a-3-node-ceph-storage-cluster-on-ubuntu-16/" >Tweet</a>
  
  
  
</div>

    
    <!-- https://www.undefinednull.com/2013/10/15/octopress-blog-tweaks-adding-author-information-section-below-each-posts/ -->
    <div class="about">
     <span class="about-image">
          <img src="/images/author.png" alt="Ruan Bekker">
     </span>
     <span class="about-desc">
          <span>My name is <a href="https://ruan.dev">Ruan</a>, i'm a DevOps Engineer from Cape Town, South Africa. I'm
          passionate about AWS, OpenSource, Containers, Linux, Automation and sharing my findings with the world.
          More info about me on my website, <a href="https://ruan.dev">ruan.dev</a>.</span>
          <br/>
          <hr/>
          <a href="https://twitter.com/ruanbekker" class="twitter-follow-button" data-show-count="false" data-size="large">Follow @ruanbekker</a>
     </span>
</div>

    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2018/06/09/hello-world-programs-in-different-languages/" title="Previous Post: Hello World Programs in Different Languages">&laquo; Hello World Programs in Different Languages</a>
      
      
        <a class="basic-alignment right" href="/blog/2018/06/14/deploy-docker-swarm-using-ansible/" title="Next Post: Deploy Docker Swarm using Ansible">Deploy Docker Swarm using Ansible &raquo;</a>
      
    </p>
  </footer>
</article>
<!-- google advertisements
    <script data-ad-client="ca-pub-1100086574264181" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- old
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-1543437721119411",
        enable_page_level_ads: true
      });
    </script>
    -->

 
-->


  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Subscribe</h1>
  <!-- Begin MailChimp Signup Form -->
  <div id="mc_embed_signup">
  <form action="https://sysadmins.us15.list-manage.com/subscribe/post?u=3dfcff447b6ee598231eeb658&amp;id=3542f323a9" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
      <div class="indicates-required"><span class="asterisk"></span></div>
      <div class="mc-field-group">
	<label for="mce-EMAIL">Email Address:  <span class="asterisk"></span>
        </label>
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL">
        </div>
	<div id="mce-responses" class="clear">
	  <div class="response" id="mce-error-response" style="display:none"></div>
	  <div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
      <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_3dfcff447b6ee598231eeb658_3542f323a9" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
  </form>
</div>
<!--End mc_embed_signup-->
</section>

<section>
  <h1>Slack</h1>
  Join me on <a href="http://linux-hackers.slack.com">Slack</a>
</section>

<section>
  <h1>Twitter</h1>
  Follow me on Twitter: <a href="https://twitter.com/ruanbekker">@ruanbekker</a>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2020/10/26/upload-public-ssh-keys-using-ansible/">Upload Public SSH Keys Using Ansible</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/10/26/easy-ad-hoc-vpns-with-sshuttle/">Easy Ad-Hoc VPNs With Sshuttle</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/10/26/use-a-ssh-jump-host-with-ansible/">Use a SSH Jump Host With Ansible</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/10/23/basic-ping-role-with-ansible-in-a-playbook/">Basic Ping Role With Ansible in a Playbook</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/10/08/using-the-libvirt-provisioner-with-terraform-for-kvm/">Using the Libvirt Provisioner With Terraform for KVM</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Store</h1>
  <ul id=""></ul>
  <p></p>
  <strong>Check out my Store</strong>: Have a look at my latest cheatsheets in PDF format.
  <p></p>
  <a href="https://ruan.dev/store/elasticsearch-cheatsheet/?source=blog.ruanbekker.com"><img src="https://user-images.githubusercontent.com/567298/97010485-c2334a00-1545-11eb-9e1d-2333e5148da1.png" width="290" height="900"></a>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2020 - Ruan -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>



  <li>
    <a href="https://twitter.com/ruanbekker">
      <i class="fa fa-twitter"></i> Twitter
    </a>
  </li>



  <li>
    <a href="https://github.com/ruanbekker">
      <i class="fa fa-github"></i> GitHub
    </a>
  </li>



  <li>
    <a href="https://sysadmins.co.za">
      <i class="fa fa-bars"></i> My HowTo Blog
    </a>
  </li>


</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'blog-ruanbekker';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'https://blog.ruanbekker.com/blog/2018/06/13/setup-a-3-node-ceph-storage-cluster-on-ubuntu-16/';
        var disqus_url = 'https://blog.ruanbekker.com/blog/2018/06/13/setup-a-3-node-ceph-storage-cluster-on-ubuntu-16/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





      <script data-ad-client="ca-pub-1100086574264181" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- old
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-1543437721119411",
        enable_page_level_ads: true
      });
    </script>
    -->


</body>
</html>
