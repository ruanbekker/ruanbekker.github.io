<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ansible | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/ansible/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2020-10-23T13:40:34+00:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Basic Ping Role With Ansible in a Playbook]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/10/23/basic-ping-role-with-ansible-in-a-playbook/"/>
    <updated>2020-10-23T13:13:16+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/10/23/basic-ping-role-with-ansible-in-a-playbook</id>
    <content type="html"><![CDATA[<p>This is a short post on how to create a basic role to reference the ping module in Ansible.</p>

<h2>Directory Structure</h2>

<p>This is our directory strucuture:</p>

<pre><code>$ tree .
.
├── inventory.ini
├── playbooks
│   └── myplaybook.yml
└── roles
    └── ping
        └── tasks
            └── main.yml

4 directories, 3 files
</code></pre>

<p>Create the directories:</p>

<pre><code>$ mkdir -p playbooks
$ mkdir -p roles/ping/tasks
</code></pre>

<p>Our <code>inventory.ini</code> includes the hosts that we will be using, and in this case I will be defining a group named <code>rpifleet</code> with all the host nested under that group and I&rsquo;m using the user <code>pi</code> and my private ssh key <code>~/.ssh/id_rsa</code>:</p>

<pre><code>$ cat inventory.ini
[rpifleet]
rpi-01 ansible_host=rpi-01.local ansible_user=pi ansible_ssh_private_key_file=~/.ssh/id_rsa ansible_python_interpreter=/usr/bin/python3
rpi-02 ansible_host=rpi-02.local ansible_user=pi ansible_ssh_private_key_file=~/.ssh/id_rsa ansible_python_interpreter=/usr/bin/python3
[rpifleet:vars]
ansible_ssh_common_args='-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
</code></pre>

<p>Next our role is a basic role that will reference our ping module, so from our main playbook we will reference the role that we are defining:</p>

<pre><code>$ cat roles/ping/tasks/main.yml
---
- name: Test Ping
  action: ping
</code></pre>

<p>Now that we have defined our <code>ping</code> role, we need to include it into our playbook:</p>

<pre><code>$ cat playbooks/myplaybook.yml
---
- name: ping raspberry pi fleet
  hosts: rpifleet
  roles:
    - { role: ../roles/ping }
</code></pre>

<p>You will see due to my playbooks directory being non-default, I defined the path to the role directory.</p>

<h2>Install Ansible</h2>

<p>Next we need to install ansible:</p>

<pre><code>$ pip install ansible
</code></pre>

<h2>Run the Ansible Playbook</h2>

<p>Now run the playbook which will ping the nodes using ssh. Using the ping module is useful when testing the connection to your nodes:</p>

<pre><code>$ ansible-playbook -i inventory.ini playbooks/myplaybook.yml

PLAY [ping raspberry pi fleet] *****************************************************

TASK [Gathering Facts] *************************************************************
ok: [rpi-02]
ok: [rpi-01]

TASK [../roles/ping : Test Ping] ***************************************************
ok: [rpi-02]
ok: [rpi-01]

PLAY RECAP *************************************************************************
rpi-01                     : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
rpi-02                     : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
</code></pre>

<h2>Thank You</h2>

<p>Thanks for reading</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using the Libvirt Provisioner With Terraform for KVM]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/10/08/using-the-libvirt-provisioner-with-terraform-for-kvm/"/>
    <updated>2020-10-08T00:06:21+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/10/08/using-the-libvirt-provisioner-with-terraform-for-kvm</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/95402415-e836d880-090f-11eb-8977-d1e2f842ef34.png" alt="terraform-ansible-kvm" /></p>

<p>In this post we will use the <a href="https://github.com/dmacvicar/terraform-provider-libvirt">libvirt provisioner</a> with Terraform to deploy a KVM Virtual Machine on a Remote KVM Host using SSH and use Ansible to deploy Nginx on our VM.</p>

<p>In my <a href="https://blog.ruanbekker.com/blog/2020/10/07/setup-a-kvm-host-for-virtualization-on-oneprovider/">previous post</a> I demonstrated how I provisioned my KVM Host and created a dedicated user for Terraform to authenticate to our KVM host to provision VMs.</p>

<p>Once you have KVM installed and your SSH access is sorted, we can start by installing our dependencies.</p>

<h2>Install our Dependencies</h2>

<p>First we will install Terraform:</p>

<pre><code>$ wget https://releases.hashicorp.com/terraform/0.13.3/terraform_0.13.3_linux_amd64.zip
$ unzip terraform_0.13.3_linux_amd64.zip
$ sudo mv terraform /usr/local/bin/terraform
</code></pre>

<p>Then we will install Ansible:</p>

<pre><code>$ virtualenv -p python3 .venv
$ source .venv/bin/activate
$ pip install ansible
</code></pre>

<p>Now in order to use the libvirt provisioner, we need to install it where we will run our Terraform deployment:</p>

<pre><code>$ cd /tmp/
$ mkdir -p ~/.local/share/terraform/plugins/registry.terraform.io/dmacvicar/libvirt/0.6.2/linux_amd64
$ wget https://github.com/dmacvicar/terraform-provider-libvirt/releases/download/v0.6.2/terraform-provider-libvirt-0.6.2+git.1585292411.8cbe9ad0.Ubuntu_18.04.amd64.tar.gz
$ tar -xvf terraform-provider-libvirt-0.6.2+git.1585292411.8cbe9ad0.Ubuntu_18.04.amd64.tar.gz
$ mv ./terraform-provider-libvirt  ~/.local/share/terraform/plugins/registry.terraform.io/dmacvicar/libvirt/0.6.2/linux_amd64/
</code></pre>

<p>Our ssh config for our KVM host in <code>~/.ssh/config</code>:</p>

<pre><code>Host *
    Port 22
    StrictHostKeyChecking no
    UserKnownHostsFile /dev/null

Host ams-kvm-remote-host
    HostName ams-kvm.mydomain.com
    User deploys
    IdentityFile ~/.ssh/deploys.pem
</code></pre>

<h2>Terraform all the things</h2>

<p>Create a workspace directory for our demonstration:</p>

<pre><code>$ mkdir -p ~/workspace/terraform-kvm-example/
$ cd ~/workspace/terraform-kvm-example/
</code></pre>

<p>First let&rsquo;s create our <code>providers.tf</code>:</p>

<pre><code>terraform {
  required_providers {
    libvirt = {
      source  = "dmacvicar/libvirt"
      version = "0.6.2"
    }
  }
}
</code></pre>

<p>Then our <code>variables.tf</code>, just double check where you need to change values to suite your environment:</p>

<pre><code>variable "libvirt_disk_path" {
  description = "path for libvirt pool"
  default     = "/opt/kvm/pool1"
}

variable "ubuntu_18_img_url" {
  description = "ubuntu 18.04 image"
  default     = "http://cloud-images.ubuntu.com/releases/bionic/release-20191008/ubuntu-18.04-server-cloudimg-amd64.img"
}

variable "vm_hostname" {
  description = "vm hostname"
  default     = "terraform-kvm-ansible"
}

variable "ssh_username" {
  description = "the ssh user to use"
  default     = "ubuntu"
}

variable "ssh_private_key" {
  description = "the private key to use"
  default     = "~/.ssh/id_rsa"
}
</code></pre>

<p>Create the <code>main.tf</code>, you will notice that we are using ssh to connect to KVM, and because the private range of our VM&rsquo;s are not routable via the internet, I&rsquo;m using a bastion host to reach them.</p>

<p>The bastion host (ssh config from the pre-requirements section) is the KVM host and you will see that ansible is also using that host as a jump box, to get to the VM. I am also using cloud-init to bootstrap the node with SSH, etc.</p>

<p>The reason why I&rsquo;m using remote-exec before the ansible deployment, is to ensure that we can establish a command via SSH before Ansible starts.</p>

<pre><code>provider "libvirt" {
  uri = "qemu+ssh://deploys@ams-kvm-remote-host/system"
}

resource "libvirt_pool" "ubuntu" {
  name = "ubuntu"
  type = "dir"
  path = var.libvirt_disk_path
}

resource "libvirt_volume" "ubuntu-qcow2" {
  name = "ubuntu-qcow2"
  pool = libvirt_pool.ubuntu.name
  source = var.ubuntu_18_img_url
  format = "qcow2"
}

data "template_file" "user_data" {
  template = file("${path.module}/config/cloud_init.yml")
}

data "template_file" "network_config" {
  template = file("${path.module}/config/network_config.yml")
}

resource "libvirt_cloudinit_disk" "commoninit" {
  name           = "commoninit.iso"
  user_data      = data.template_file.user_data.rendered
  network_config = data.template_file.network_config.rendered
  pool           = libvirt_pool.ubuntu.name
}

resource "libvirt_domain" "domain-ubuntu" {
  name   = var.vm_hostname
  memory = "512"
  vcpu   = 1

  cloudinit = libvirt_cloudinit_disk.commoninit.id

  network_interface {
    network_name   = "default"
    wait_for_lease = true
    hostname       = var.vm_hostname
  }

  console {
    type        = "pty"
    target_port = "0"
    target_type = "serial"
  }

  console {
    type        = "pty"
    target_type = "virtio"
    target_port = "1"
  }

  disk {
    volume_id = libvirt_volume.ubuntu-qcow2.id
  }

  graphics {
    type        = "spice"
    listen_type = "address"
    autoport    = true
  }

  provisioner "remote-exec" {
    inline = [
      "echo 'Hello World'"
    ]

    connection {
      type                = "ssh"
      user                = var.ssh_username
      host                = libvirt_domain.domain-ubuntu.network_interface[0].addresses[0]
      private_key         = file(var.ssh_private_key)
      bastion_host        = "ams-kvm-remote-host"
      bastion_user        = "deploys"
      bastion_private_key = file("~/.ssh/deploys.pem")
      timeout             = "2m"
    }
  }

  provisioner "local-exec" {
    command = &lt;&lt;EOT
      echo "[nginx]" &gt; nginx.ini
      echo "${libvirt_domain.domain-ubuntu.network_interface[0].addresses[0]}" &gt;&gt; nginx.ini
      echo "[nginx:vars]" &gt;&gt; nginx.ini
      echo "ansible_ssh_common_args='-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ProxyCommand=\"ssh -W %h:%p -q ams-kvm-remote-host\"'" &gt;&gt; nginx.ini
      ansible-playbook -u ${var.ssh_username} --private-key ${var.ssh_private_key} -i nginx.ini ansible/playbook.yml
      EOT
  }
}
</code></pre>

<p>As I&rsquo;ve mentioned, Im using cloud-init, so lets setup the network config and cloud init under the <code>config/</code> directory:</p>

<pre><code>$ mkdir config
</code></pre>

<p>And our <code>config/cloud_init.yml</code>, just make sure that you configure your public ssh key for ssh access in the config:</p>

<pre><code>#cloud-config
# vim: syntax=yaml
# examples:
# https://cloudinit.readthedocs.io/en/latest/topics/examples.html
bootcmd:
  - echo 192.168.0.1 gw.homedns.xyz &gt;&gt; /etc/hosts
runcmd:
 - [ ls, -l, / ]
 - [ sh, -xc, "echo $(date) ': hello world!'" ]
ssh_pwauth: true
disable_root: false
chpasswd:
  list: |
     root:password
  expire: false
users:
  - name: ubuntu
    sudo: ALL=(ALL) NOPASSWD:ALL
    groups: users, admin
    home: /home/ubuntu
    shell: /bin/bash
    lock_passwd: false
    ssh-authorized-keys:
      - ssh-rsa AAAA ...your-public-ssh-key-goes-here... user@host
final_message: "The system is finally up, after $UPTIME seconds"
</code></pre>

<p>And our network config, in <code>config/network_config.yml</code>:</p>

<pre><code>version: 2
ethernets:
  ens3:
    dhcp4: true
</code></pre>

<p>Now we will create our Ansible playbook, to deploy nginx to our VM, create the ansible directory:</p>

<pre><code>$ mkdir ansible
</code></pre>

<p>Then create the <code>ansible/playbook.yml</code>:</p>

<pre><code>---
# https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_module.html
# https://docs.ansible.com/ansible/latest/collections/ansible/builtin/systemd_module.html#examples
- hosts: nginx
  become: yes
  become_user: root
  become_method: sudo
  tasks:
    - name: Install nginx
      apt:
        name: nginx
        state: latest
        update_cache: yes

    - name: Enable service nginx and ensure it is not masked
      systemd:
        name: nginx
        enabled: yes
        masked: no

    - name: ensure nginx is started
      systemd:
        state: started
        name: nginx
</code></pre>

<p>This is optional, but I&rsquo;m using a <code>ansible.cfg</code> file to define my defaults:</p>

<pre><code>[defaults]
host_key_checking = False
ansible_port = 22
ansible_user = ubuntu
ansible_ssh_private_key_file = ~/.ssh/id_rsa
ansible_python_interpreter = /usr/bin/python3
</code></pre>

<p>And lastly, our <code>outputs.tf</code> which will display our IP address of our VM:</p>

<pre><code>output "ip" {
  value = libvirt_domain.domain-ubuntu.network_interface[0].addresses[0]
}

output "url" {
  value = "http://${libvirt_domain.domain-ubuntu.network_interface[0].addresses[0]}"
}
</code></pre>

<h2>Deploy our Terraform Deployment</h2>

<p>It&rsquo;s time to deploy a KVM instance with Terraform and deploy Nginx to our VM with Ansible using the local-exec provisioner.</p>

<p>Initialize terraform to download all the plugins:</p>

<pre><code>$ terraform init

Initializing the backend...

Initializing provider plugins...
- Finding latest version of hashicorp/template...
- Finding dmacvicar/libvirt versions matching "0.6.2"...
- Installing hashicorp/template v2.1.2...
- Installed hashicorp/template v2.1.2 (signed by HashiCorp)
- Installing dmacvicar/libvirt v0.6.2...
- Installed dmacvicar/libvirt v0.6.2 (unauthenticated)

The following providers do not have any version constraints in configuration,
so the latest version was installed.

To prevent automatic upgrades to new major versions that may contain breaking
changes, we recommend adding version constraints in a required_providers block
in your configuration, with the constraint strings suggested below.

* hashicorp/template: version = "~&gt; 2.1.2"

Terraform has been successfully initialized!
</code></pre>

<p>Run a plan, to see what will be done:</p>

<pre><code>$ terraform plan

...
Plan: 4 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + ip  = (known after apply)
  + url = (known after apply)
...
</code></pre>

<p>And run a apply to run our deployment:</p>

<pre><code>$ terraform apply -auto-approve
...
libvirt_domain.domain-ubuntu (local-exec): PLAY RECAP *********************************************************************
libvirt_domain.domain-ubuntu (local-exec): 192.168.122.213            : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
libvirt_domain.domain-ubuntu: Creation complete after 2m24s [id=c96def6e-0361-441c-9e1f-5ba5f3fa5aec]

Apply complete! Resources: 4 added, 0 changed, 0 destroyed.

Outputs:

ip = 192.168.122.213
url = http://192.168.122.213
</code></pre>

<p>You can always get the output afterwards using show or output:</p>

<pre><code>$ terraform show -json | jq -r '.values.outputs.ip.value'
192.168.122.213

$ terraform output -json ip | jq -r '.'
192.168.122.213
</code></pre>

<h2>Test our VM</h2>

<p>Hop onto the KVM host, and test out nginx:</p>

<pre><code>$ curl -I http://192.168.122.213
HTTP/1.1 200 OK
Server: nginx/1.14.0 (Ubuntu)
Date: Thu, 08 Oct 2020 00:37:43 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Thu, 08 Oct 2020 00:33:04 GMT
Connection: keep-alive
ETag: "5f7e5e40-264"
Accept-Ranges: bytes
</code></pre>

<iframe src="https://giphy.com/embed/3ohzdIuqJoo8QdKlnW" width="480" height="222" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>


<p><a href="https://giphy.com/gifs/reactionseditor-yes-awesome-3ohzdIuqJoo8QdKlnW">via GIPHY</a></p>


<h2>Thank You</h2>

<p><a href="https://saythanks.io/to/ruan.ru.bekker@gmail.com"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a></p>

<p>Thanks for reading, check out my <strong><a href="" rel="nofollow" target="_blank">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker" rel="nofollow" target="_blank">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Save Output to Local File With Ansible]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/01/24/save-output-to-local-file-with-ansible/"/>
    <updated>2020-01-24T19:56:01+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/01/24/save-output-to-local-file-with-ansible</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/55700285-f3cdda00-59ce-11e9-9c00-a05b9d469e23.png" alt="" /></p>

<p>This playbook demonstrates how you can redirect shell output to a local file</p>

<h2>Inventory</h2>

<p>Our <code>inventory.ini</code> file:</p>

<pre><code>[localhost]
localhost
</code></pre>

<h2>The Script</h2>

<p>Our script: <code>/tmp/foo</code></p>

<pre><code class="bash">#!/usr/bin/env bash
echo "foo"
echo "bar"
</code></pre>

<p>Apply executable permissions:</p>

<pre><code>$ chmod +x /tmp/foo
</code></pre>

<h2>Playbook</h2>

<p>Our playbook: <code>debug.yml</code></p>

<pre><code class="yaml">---
- hosts: localhost
  tasks:
    - shell: /tmp/foo
      register: foo_result
      ignore_errors: True
    - local_action: copy content= dest=file
</code></pre>

<h2>Running</h2>

<p>Running the Ansible Playbook:</p>

<pre><code>$ ansible-playbook -i inventory.ini debug.yml

PLAY [localhost] ********************************************************************************************************************************************************************

TASK [shell] ************************************************************************************************************************************************************************
changed: [localhost]

TASK [copy] *************************************************************************************************************************************************************************
changed: [localhost -&gt; localhost]

PLAY RECAP **************************************************************************************************************************************************************************
localhost                  : ok=2    changed=2    unreachable=0    failed=0
</code></pre>

<p>View the local saved file:</p>

<pre><code>$ cat file
foo
bar
</code></pre>

<h2>Read More</h2>

<p>For more content on <a href="https://blog.ruanbekker.com/blog/categories/ansible/">Ansible</a> check out my <a href="https://blog.ruanbekker.com/blog/categories/ansible/">Ansible</a> category</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Environment Variables With Ansible]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/01/24/environment-variables-with-ansible/"/>
    <updated>2020-01-24T19:28:16+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/01/24/environment-variables-with-ansible</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/55700285-f3cdda00-59ce-11e9-9c00-a05b9d469e23.png" alt="" /></p>

<p>This is a quick post on how to use environment variables in ansible</p>

<h2>Inventory</h2>

<p>Our <code>inventory.ini</code> file looks like this:</p>

<pre><code>[localhost]
localhost
</code></pre>

<h2>Across Tasks</h2>

<p>You can set environment variables across tasks, and let your tasks inherit the variables:</p>

<pre><code class="yaml">- hosts: localhost
  vars:
    var_mysecret: secret123

  tasks:
    - name: echo my env var
      environment:
        MYNAME: ""
      shell: "echo hello $MYNAME &gt; /tmp/bla.txt"
      args:
        creates: /tmp/bla.txt
</code></pre>

<p>When we run the task:</p>

<pre><code class="bash">$ ansible-playbook -i inventory.ini -u ruan task.yml
</code></pre>

<p>Check the output:</p>

<pre><code class="bash">$ cat /tmp/bla.txt
hello secret123
</code></pre>

<h2>Environment Variables Per Task</h2>

<p>You can set environment variables per task:</p>

<pre><code class="yaml">- hosts: dev
  tasks:
    - name: echo my env var
      environment:
        MYNAME: "RUAN"
      shell: "echo hello $MYNAME &gt; /tmp/bla2.txt"
      args:
        creates: /tmp/bla2.txt
</code></pre>

<p>Running the task:</p>

<pre><code>$ ansible-playbook -i inventory.ini -u ruan task.yml
</code></pre>

<p>Checking the output:</p>

<pre><code>$ cat /tmp/bla2.txt
hello RUAN
</code></pre>

<h2>Read More</h2>

<p>Read more on environment variables in ansible in their <a href="https://docs.ansible.com/ansible/latest/plugins/lookup/env.html">documentation</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Install Elasticsearch With Ansible Tutorial]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/04/06/install-elasticsearch-with-ansible-tutorial/"/>
    <updated>2019-04-06T15:45:09-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/04/06/install-elasticsearch-with-ansible-tutorial</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/55700285-f3cdda00-59ce-11e9-9c00-a05b9d469e23.png" alt="" /></p>

<p>In this tutorial we will install a elasticsearch cluster with ansible (well rather a node)</p>

<p>Our inventory:</p>

<pre><code>$ cat inventory.ini
[newes]
esnewnode

[newes:vars]
ansible_python_interpreter=/usr/bin/python3
</code></pre>

<p>Our playbook to bootstrap our nodes with Python:</p>

<pre><code>$ cat bootstrap-python.yml
---
- hosts: newes
  gather_facts: False

  tasks:
  - name: install python
    raw: test -e /usr/bin/python || ( apt update &amp;&amp; apt install python -y )
</code></pre>

<p>Our playbook to provision users:</p>

<pre><code>$ cat provision-users.yml
---
# Provisions User on Nodes
# Setup Passwordless SSH from Jumpbox
# Install Packages using APT
- name: bootstrap python
  hosts: newes
  roles:
    - bootstrap-python

- name: setup pre-requisites
  hosts: newes
  roles:
    - create-sudo-user
    - install-modules
    - configure-hosts-file

#- name: setup ruan user on the nodes
#  become: yes
#  become_user: ruan
#  hosts: admin
#  roles:
#    - configure-admin

- name: copy public key to nodes
  become: yes
  become_user: ruan
  hosts: newes
  roles:
    - copy-keys

- name: install elasticsearch
  hosts: newes
  roles:
    - elasticsearch
</code></pre>

<p>Our roles that will be included in our playbooks from above:</p>

<pre><code>$ cat roles/create-sudo-user/tasks/main.yml
---
- name: Create Sudo User
  user: name=ruan
        groups=sudo
        shell=/bin/bash
        generate_ssh_key=no
        state=present

- name: Set Passwordless SSH Access for ruan user
  copy: src=sudoers
        dest=/etc/sudoers.d
        mode=0440
</code></pre>

<p>Sudoers file for the create sudo role:</p>

<pre><code>$ cat roles/create-sudo-user/files/sudoers
ruan ALL=(ALL) NOPASSWD:ALL
</code></pre>

<p>The role to install all the apt packages:</p>

<pre><code>$ cat roles/install-modules/tasks/main.yml
---
- name: Install Packages
  apt: name= state=latest update_cache=yes
  with_items:
    - apt-transport-https
    - ntp
    - python
    - tcpdump
    - wget
    - openssl
    - curl
</code></pre>

<p>Role to configure hosts file:</p>

<pre><code>$ cat roles/configure-hosts-file/tasks/main.yml
---
- name: Configure Hosts File
  lineinfile: path=/etc/hosts regexp='.*$' line=" " state=present
  when: hostvars[item].ansible_default_ipv4.address is defined
  with_items: ""
</code></pre>

<p>The role to copy the ssh keys:</p>

<pre><code>$ cat roles/copy-keys/tasks/main.yml
---
- name: Copy Public Key to Other Hosts
  become: true
  become_user: ruan
  copy:
    src: /tmp/id_rsa.pub
    dest: /tmp/id_rsa.pub
    mode: 0644
- name: Append Public key in authorized_keys file
  authorized_key:
    user: ruan
    state: present
    key: ""
</code></pre>

<p>The role to install elasticsearch:</p>

<pre><code>$ cat roles/elasticsearch/tasks/main.yml
---
- name: get apt repo key
  apt_key:
    url: https://artifacts.elastic.co/GPG-KEY-elasticsearch
    state: present

- name: install apt repo
  apt_repository:
    repo: deb https://artifacts.elastic.co/packages/6.x/apt stable main
    state: present
    filename: elastic-6.x.list
    update_cache: yes

- name: install java
  apt:
    name: openjdk-8-jre
    state: present
    update_cache: yes

- name: install elasticsearch
  apt:
    name: elasticsearch
    state: present
    update_cache: yes

- name: reload systemd config
  systemd: daemon_reload=yes

- name: enable service elasticsearch and ensure it is not masked
  systemd:
    name: elasticsearch
    enabled: yes
    masked: no

- name: ensure elasticsearch is running
  systemd: state=started name=elasticsearch
</code></pre>

<h2>Deploy Elasticsearch</h2>

<p>Bootstrap python then deploy elasticsearch:</p>

<pre><code>$ ansible-playbook -i inventory.ini -u root bootstrap-python.yml
$ ansible-playbook -i inventory.ini -u root provision-users.yml
</code></pre>

<p>Test out elasticsearch:</p>

<pre><code>$ curl http://127.0.0.1:9200/
{
  "name" : "Z52AEZ7",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "fUiYVjsSQpCbo9QKEiuvaA",
  "version" : {
    "number" : "6.3.0",
    "build_flavor" : "default",
    "build_type" : "deb",
    "build_hash" : "424e937",
    "build_date" : "2018-06-11T23:38:03.357887Z",
    "build_snapshot" : false,
    "lucene_version" : "7.3.1",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  },
  "tagline" : "You Know, for Search"
}
</code></pre>
]]></content>
  </entry>
  
</feed>
