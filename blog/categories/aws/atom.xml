<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2019-06-11T08:20:42-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setup a Logstash Server for Amazon Elasticsearch Service and Auth With IAM]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/06/04/setup-a-logstash-server-for-amazon-elasticsearch-service-and-auth-with-iam/"/>
    <updated>2019-06-04T17:46:27-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/06/04/setup-a-logstash-server-for-amazon-elasticsearch-service-and-auth-with-iam</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/59209960-ca872100-8bac-11e9-8672-8c6af502afe0.png" alt="logstash" /></p>

<p>As many of you might know, when you deploy a ELK stack on Amazon Web Services, you only get E and K in the ELK stack, which is Elasticsearch and Kibana. Here we will be dealing with Logstash on EC2.</p>

<h2>What will we be doing</h2>

<p>In this tutorial we will setup a Logstash Server on EC2, setup a IAM Role and Autenticate Requests to Elasticsearch with an IAM Role, setup Nginx so that logstash can ship logs to Elasticsearch.</p>

<p>I am not fond of working with access key&rsquo;s and secret keys, and if I can stay away from handling secret information the better. So instead of creating a access key and secret key for logstash, we will instead create a IAM Policy that will allow the actions to Elasticsearch, associate that policy to an IAM Role, set EC2 as a trusted entity and strap that IAM Role to the EC2 Instance.</p>

<p>Then we will allow the IAM Role ARN to the Elasticsearch Policy, then when Logstash makes requests against Elasticsearch, it will use the IAM Role to assume temporary credentials to authenticate. That way we don&rsquo;t have to deal with keys. But I mean you can create access keys if that is your preferred method, I&rsquo;m just not a big fan of keeping secret keys.</p>

<p>The benefit of authenticating with IAM, allows you to remove a reverse proxy that is another hop to the path of your target.</p>

<h2>Create the IAM Policy:</h2>

<p>Create a IAM Policy that will allow actions to Elasticsearch:</p>

<pre><code>{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "es:ESHttpHead",
                "es:ESHttpPost",
                "es:ESHttpGet",
                "es:ESHttpPut"
            ],
            "Resource": "arn:aws:es:eu-west-1:0123456789012:domain/my-es-domain"
        }
    ]
}
</code></pre>

<p>Create Role logstash-system-es with &ldquo;ec2.amazonaws.com&rdquo; as trusted entity in trust the relationship and associate the above policy to the role.</p>

<h2>Authorize your Role in Elasticsearch Policy</h2>

<p>Head over to your Elasticsearch Domain and configure your Elasticsearch Policy to include your IAM Role to grant requests to your Domain:</p>

<pre><code>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": [
          "arn:aws:iam::0123456789012:role/logstash-system-es"
        ]
      },
      "Action": "es:*",
      "Resource": "arn:aws:es:eu-west-1:0123456789012:domain/my-es-domain/*"
    }
  ]
}
</code></pre>

<h2>Install Logstash on EC2</h2>

<p>I will be using Ubuntu Server 18. Update the repositories and install dependencies:</p>

<pre><code>$ apt update &amp;&amp; apt upgrade -y
$ apt install build-essential apt-transport-https -y
$ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
$ echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list
$ apt update
</code></pre>

<p>As logstash requires Java, install the the Java OpenJDK Runtime Environment:</p>

<pre><code>$ apt install default-jre -y
</code></pre>

<p>Verify that Java is installed:</p>

<pre><code>$ java -version
openjdk version "11.0.3" 2019-04-16
OpenJDK Runtime Environment (build 11.0.3+7-Ubuntu-1ubuntu218.04.1)
OpenJDK 64-Bit Server VM (build 11.0.3+7-Ubuntu-1ubuntu218.04.1, mixed mode, sharing)
</code></pre>

<p>Now, install logstash and enable the service on boot:</p>

<pre><code>$ apt install logstash -y
$ systemctl enable logstash.service
$ service logstash stop
</code></pre>

<h2>Install the Amazon ES Logstash Output Plugin</h2>

<p>For us to be able to authenticate using IAM, we should use the Amazon-ES Logstash Output Plugin. Update and install the plugin:</p>

<pre><code>$ /usr/share/logstash/bin/logstash-plugin update
$ /usr/share/logstash/bin/logstash-plugin install logstash-output-amazon_es
</code></pre>

<h2>Configure Logstash</h2>

<p>I like to split up my configuration in 3 parts, (input, filter, output).</p>

<p>Let&rsquo;s create the input configuration: <code>/etc/logstash/conf.d/10-input.conf</code></p>

<pre><code>input {
  file {
    path =&gt; "/var/log/nginx/access.log"
    start_position =&gt; "beginning"
  }
}
</code></pre>

<p>Our filter configuration: <code>/etc/logstash/conf.d/20-filter.conf</code></p>

<pre><code>filter {
  grok {
    match =&gt; { "message" =&gt; "%{HTTPD_COMMONLOG}" }
  }
  mutate {
    add_field =&gt; {
      "custom_field1" =&gt; "hello from: %{host}"
    }
  }
}
</code></pre>

<p>And lastly, our output configuration: <code>/etc/logstash/conf.d/30-outputs.conf</code>:</p>

<pre><code>output {
  amazon_es {
      hosts =&gt; ["my-es-domain.abcdef.eu-west-1.es.amazonaws.com"]
      index =&gt; "new-logstash-%{+YYYY.MM.dd}"
      region =&gt; "eu-west-1"
      aws_access_key_id =&gt; ''
      aws_secret_access_key =&gt; ''
  }
}
</code></pre>

<p>Note that the <code>aws_</code> directives has been left empty as that seems to be the way it needs to be set when using roles. Authentication will be assumed via the Role which is associated to the EC2 Instance.</p>

<p>If you are using access keys, you can populate them there.</p>

<h2>Start Logstash</h2>

<p>Start logstash:</p>

<pre><code>$ service logstash start
</code></pre>

<p>Tail the logs to see if logstash starts up correctly, it should look more or less like this:</p>

<pre><code>$ tail -f /var/log/logstash/logstash-plain.log

[2019-06-04T16:38:12,087][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=&gt;"6.8.0"}
[2019-06-04T16:38:14,480][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=&gt;"main", "pipeline.workers"=&gt;2, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;50}
[2019-06-04T16:38:15,226][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=&gt;{:removed=&gt;[], :added=&gt;[https://search-my-es-domain-xx.eu-west-1.es.amazonaws.com:443/]}}
[2019-06-04T16:38:15,234][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;https://search-my-es-domain-xx.eu-west-1.es.amazonaws.com:443/, :path=&gt;"/"}
</code></pre>

<h2>Install Nginx</h2>

<p>As you noticed, I have specified <code>/var/log/nginx/access.log</code> as my input file for logstash, as we will test logstash by shipping nginx access logs to Elasticsearch Service.</p>

<p>Install Nginx:</p>

<pre><code>$ apt install nginx -y
</code></pre>

<p>Start the service:</p>

<pre><code>$ systemctl restart nginx 
$ systemctl enable nginx
</code></pre>

<p>Make a GET request on your Nginx Web Server and inspect the log on Kibana, where it should look like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/58917559-4dc8f280-8727-11e9-9e9d-7950217abe34.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Snippet: Create Custom CloudWatch Metrics With Python]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/03/28/snippet-create-custom-cloudwatch-metrics-with-python/"/>
    <updated>2019-03-28T08:05:28-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/03/28/snippet-create-custom-cloudwatch-metrics-with-python</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53865781-a984c200-3ff8-11e9-9ffa-ccad62ac08f6.png" alt="" /></p>

<p>A quick post on how create custom CloudWatch Metrics using Python on AWS.</p>

<p>After you produced the metrics into CloudWatch, you will be able to see them when navigating to:</p>

<ul>
<li>CloudWatch / Metrics / Custom Namespaces / statusdash/ec2client</li>
</ul>


<p>When selecting:</p>

<pre><code>Select Metric: SomeKey1, SomeKey2
Select MetricName HttpResponseTime
</code></pre>

<p>And should look like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/53865426-d4224b00-3ff7-11e9-8bd5-bd04dfdd9f43.png" alt="" /></p>

<h2>The Script:</h2>

<p>The python script that will be using boto3 to talk to AWS:</p>

<pre><code class="python">import boto3
import random
cloudwatch = boto3.Session(region_name='eu-west-1').client('cloudwatch')
response = cloudwatch.put_metric_data(
MetricData = [
    {
        'MetricName': 'HttpResponseTime',
        'Dimensions': [
            {
                'Name': 'Server',
                'Value': 'app.example.com'
            },
            {
                'Name': 'Client',
                'Value': 'Client-ABC'
            },
        ],
        'Unit': 'Milliseconds',
        'Value': random.randint(20, 50)
    },
],
Namespace = 'statusdash/ec2client'
)
print response
</code></pre>

<h2>Resources:</h2>

<p><a href="https://stackify.com/custom-metrics-aws-lambda/">https://stackify.com/custom-metrics-aws-lambda/</a>
<a href="https://www.syntouch.nl/custom-cloudwatch-metrics-in-python-yes-we-can/">https://www.syntouch.nl/custom-cloudwatch-metrics-in-python-yes-we-can/</a> &lt;- psutil
<a href="https://aws.amazon.com/blogs/devops/new-how-to-better-monitor-your-custom-application-metrics-using-amazon-cloudwatch-agent/">https://aws.amazon.com/blogs/devops/new-how-to-better-monitor-your-custom-application-metrics-using-amazon-cloudwatch-agent/</a>
<a href="https://medium.com/@mrdoro/aws-lambda-as-the-website-monitoring-tool-184b09202ae2">https://medium.com/@mrdoro/aws-lambda-as-the-website-monitoring-tool-184b09202ae2</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Tag All Your AWS IAM Users With Python]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/02/25/how-to-tag-all-your-aws-iam-users-with-python/"/>
    <updated>2019-02-25T06:44:55-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/02/25/how-to-tag-all-your-aws-iam-users-with-python</id>
    <content type="html"><![CDATA[<p>Let&rsquo;s say that all your IAM users are named in <code>name.surname</code> and your system accounts are named as <code>my-system-account</code> and you find yourself in a position that you need to tag all your IAM users based on Human/System account type.</p>

<script src="//ap.lijit.com/www/delivery/fpi.js?z=601358&width=300&height=250"></script>


<p>With AWS and Python&rsquo;s Boto library, it makes things easy. We would list all our users, loop through each one and tag them with the predefined tag values that we chose.</p>

<h2>Batch Tagging AWS IAM Users with Python</h2>

<p>This script wil tag all users with the tag: Name, Email, Environment and Account_Type.</p>

<pre><code class="python">import boto3

iam = boto3.Session(profile_name='test', region_name='eu-west-1').client('iam')
paginator = iam.get_paginator('list_users')

iam_environment = 'test'

unstructed_users = []
userlist = []
taggable_users = []
already_tagged_users = []
email_address_domain = '@example.com'

# generate tag list based on account type
def tag_template(username, environment):
    if '.' in username:
        account_type = 'human'
    email = username
    else:
        account_type = 'system'
    email = 'system-admin'

    template = [
        {'Key': 'Name','Value': username.lower()}, 
        {'Key': 'Email', 'Value': email.lower() + email_address_domain}, 
        {'Key': 'Environment','Value': environment}, 
        {'Key': 'Account_Type','Value': account_type}
    ]

    return template

# generate userlist
for response in paginator.paginate():
    unstructed_users.append(response['Users'])

for iteration in range(len(unstructed_users)):
    for userobj in range(len(unstructed_users[iteration])):
        userlist.append((unstructed_users[iteration][userobj]['UserName']))

# generate taggable userlist:
for user in userlist:
    tag_response = iam.list_user_tags(UserName=user)
    if len(tag_response['Tags']) == 0:
        taggable_users.append(user)
    else:
        already_tagged_users.append(user)

# tag users from taggable_list
for tag_user in taggable_users:
    user_template = tag_template(tag_user, iam_environment)
    print(tag_user, user_template)
    response = iam.tag_user(UserName=tag_user, Tags=user_template)

# print lists
print('Userlists: {}'.format(userlist))
print('Taggable Users: {}'.format(taggable_users))
print('Already Tagged Users: {}'.format(already_tagged_users))
</code></pre>

<p>After it completes, your IAM users should be tagged in the following format:</p>

<pre><code>Name: john.doe
Email: john.doe@example.com
Environment: test
Account_Type: human

or:

Name: system-account
Email: system-admin@example.com
Environment: test
Account-Type: system
</code></pre>

<h2>Thank You</h2>

<p>Please feel free to show support by, <strong>sharing</strong> this post, making a <strong>donation</strong>, <strong>subscribing</strong> or <strong>reach out to me</strong> if you want me to demo and write up on any specific tech topic.</p>

<center>
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick" />
<input type="hidden" name="hosted_button_id" value="W7CBGYTCWGANQ" />
<input type="image" src="https://user-images.githubusercontent.com/567298/49853901-461c3700-fdf1-11e8-9d80-8a424a3173af.png" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
<img alt="" border="0" src="https://www.paypal.com/en_ZA/i/scr/pixel.gif" width="1" height="1" />
</form>
</center>


<p><br></p>

<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parallel Processing on AWS Lambda With Python Using Multiprocessing]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/02/19/parallel-processing-on-aws-lambda-with-python-using-multiprocessing/"/>
    <updated>2019-02-19T09:39:47-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/02/19/parallel-processing-on-aws-lambda-with-python-using-multiprocessing</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53020033-c51b9480-345e-11e9-9625-b73062e2464a.png" alt="" /></p>

<p>If you are trying to use <code>multiprocessing.Queue</code> or <code>multiprocessing.Pool</code> on AWS Lambda, you are probably getting the exception:</p>

<pre><code>[Errno 38] Function not implemented: OSError

    sl = self._semlock = _multiprocessing.SemLock(kind, value, maxvalue)
OSError: [Errno 38] Function not implemented
</code></pre>

<p>The reason for that is due to the Lambda execution environment not having support on shared memory for processes, therefore you canâ€™t use <code>multiprocessing.Queue</code> or <code>multiprocessing.Pool</code>.</p>

<p>As a workaround, Lambda does support the usage of <code>multiprocessing.Pipe</code> instead of Queue.</p>

<h2>Parallel Processing on Lambda Example</h2>

<p>Below is a very basic example on how you would achieve the task of executing parallel processing on AWS Lambda for Python:</p>

<pre><code class="python">import time
import multiprocessing

region_maps = {
        "eu-west-1": {
            "dynamodb":"dynamodb.eu-west-1.amazonaws.com"
        },
        "us-east-1": {
            "dynamodb":"dynamodb.us-east-1.amazonaws.com"
        },
        "us-east-2": {
            "dynamodb": "dynamodb.us-east-2.amazonaws.com"
        }
    }

def multiprocessing_func(region):
    time.sleep(1)
    endpoint = region_maps[region]['dynamodb']
    print('endpoint for {} is {}'.format(region, endpoint))

def lambda_handler(event, context):
    starttime = time.time()
    processes = []
    regions = ['us-east-1', 'us-east-2', 'eu-west-1']
    for region in regions:
        p = multiprocessing.Process(target=multiprocessing_func, args=(region,))
        processes.append(p)
        p.start()

    for process in processes:
        process.join()

    output = 'That took {} seconds'.format(time.time() - starttime)
    print(output)
    return output
</code></pre>

<p>The output when the function gets invoked:</p>

<pre><code>pid: 30913 - endpoint for us-east-1 is dynamodb.us-east-1.amazonaws.com
pid: 30914 - endpoint for us-east-2 is dynamodb.us-east-2.amazonaws.com
pid: 30915 - endpoint for eu-west-1 is dynamodb.eu-west-1.amazonaws.com
That took 1.014902114868164 seconds
</code></pre>

<h2>Thank You</h2>

<p>Please feel free to show support by, <strong>sharing</strong> this post, making a <strong>donation</strong>, <strong>subscribing</strong> or <strong>reach out to me</strong> if you want me to demo and write up on any specific tech topic.</p>

<center>
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick" />
<input type="hidden" name="hosted_button_id" value="W7CBGYTCWGANQ" />
<input type="image" src="https://user-images.githubusercontent.com/567298/49853901-461c3700-fdf1-11e8-9d80-8a424a3173af.png" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
<img alt="" border="0" src="https://www.paypal.com/en_ZA/i/scr/pixel.gif" width="1" height="1" />
</form>
</center>


<p><br></p>

<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The AWS CLI Cheatsheet for Bash]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/02/07/the-aws-cli-cheatsheet-for-bash/"/>
    <updated>2019-02-07T03:24:12-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/02/07/the-aws-cli-cheatsheet-for-bash</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/30043398/52399083-cdb9b580-2ac3-11e9-8c8a-79fcb811de18.png" alt="" /></p>

<p>This is a post for all the AWS CLI oneliners that I stumble upon. Note that they will be updated over time.</p>

<h2>RDS</h2>

<p>Describe All RDS DB Instances:</p>

<pre><code class="bash">$ aws --profile prod rds describe-db-instances --query 'DBInstances[*].[DBInstanceArn,DBInstanceIdentifier,DBInstanceClass,Endpoint]'
</code></pre>

<p>Describe a RDS DB Instance with a dbname:</p>

<pre><code class="bash">$ aws --profile prod rds describe-db-instances --query 'DBInstances[?DBInstanceIdentifier==`db-staging`].[DBInstanceArn,DBInstanceIdentifier,DBInstanceClass,Endpoint]'
[
    [
        "arn:aws:rds:eu-west-1:&lt;customer_id&gt;:db:db-staging",
        "db-staging",
        "db.t2.micro",
        {
            "HostedZoneId": "ASKDJSAKDJBA",
            "Port": 5432,
            "Address": "db-staging.asdkjahsd.eu-west-1.rds.amazonaws.com"
        }
    ]
]
</code></pre>

<p>List all RDS DB Instances and limit output:</p>

<pre><code class="bash">$ aws --profile prod rds describe-db-instances --query 'DBInstances[*].[DBInstanceArn,DBInstanceIdentifier,DBInstanceClass,Endpoint]'
[
    [
        "arn:aws:rds:eu-west-1:&lt;customer_id&gt;:db:db-name",
        "db-name",
        "db.t2.micro",
        {
            "HostedZoneId": "ABCDEFGHILKL",
            "Port": 5432,
            "Address": "db-name.abcdefg.eu-west-1.rds.amazonaws.com"
        }
    ],
</code></pre>

<p>List all RDS DB Instances that has backups enabled, and limit output:</p>

<pre><code class="bash">$ aws --profile prod rds describe-db-instances --query 'DBInstances[?BackupRetentionPeriod&gt;`0`].[DBInstanceArn,DBInstanceIdentifier,DBInstanceClass,Endpoint]'
[
    [
        "arn:aws:rds:eu-west-1:&lt;customer_id&gt;:db:db-name",
        "db-name",
        "db.t2.micro",
        {
            "HostedZoneId": "ABCDEFGHILKL",
            "Port": 5432,
            "Address": "db-name.abcdefg.eu-west-1.rds.amazonaws.com"
        }
    ],
</code></pre>

<p>Describe DB Snapshots for DB Instance Name:</p>

<pre><code class="bash">$ aws --profile prod rds describe-db-snapshots --db-instance-identifier db --query 'DBSnapshots[?DBInstanceIdentifier==`db`].[DBInstanceIdentifier,DBSnapshotIdentifier,SnapshotCreateTime,Status]'
[
    [
        "db",
        "rds:db-2018-05-16-04-08",
        "2018-05-16T04:08:53.696Z",
        "available"
    ],
</code></pre>

<p>Events for the last 24 Hours:</p>

<pre><code class="bash">$ aws --profile prod rds describe-events --source-identifier "rds:db-2018-05-16-04-08" --source-type db-snapshot --duration 1440 --query 'Events[*]'
[
    {
        "EventCategories": [
            "creation"
        ],
        "SourceType": "db-snapshot",
        "SourceArn": "arn:aws:rds:eu-west-1:&lt;customer_id&gt;:snapshot:rds:db-2018-05-16-04-08",
        "Date": "2018-05-16T04:08:40.264Z",
        "Message": "Creating automated snapshot",
        "SourceIdentifier": "rds:db-2018-05-16-04-08"
    },
    {
        "EventCategories": [
            "creation"
        ],
        "SourceType": "db-snapshot",
        "SourceArn": "arn:aws:rds:eu-west-1:&lt;customer_id&gt;:snapshot:rds:db-2018-05-16-04-08",
        "Date": "2018-05-16T04:32:04.047Z",
        "Message": "Automated snapshot created",
        "SourceIdentifier": "rds:db-2018-05-16-04-08"
    }
]
</code></pre>

<p>List Public RDS Instances:</p>

<pre><code class="bash">$ aws --profile prod rds describe-db-instances --query 'DBInstances[?PubliclyAccessible==`true`].[DBInstanceIdentifier,Endpoint.Address]'

[
  [
    "name",
    "name.abcdef.eu-west-1.rds.amazonaws.com"
  ]
]
</code></pre>

<h2>SSM Parameter Store:</h2>

<p>List all parameters by path:</p>

<pre><code class="bash">$ aws --profile prod ssm get-parameters-by-path --path '/service-a/team-a/my-app-name/' | jq '.Parameters[]' | jq -r '.Name'
/service-a/team-a/my-app-name/db_hostname
/service-a/team-a/my-app-name/db_username
/service-a/team-a/my-app-name/db_password
</code></pre>

<p>Get a value from a parameter:</p>

<pre><code class="bash">$ aws --profile prod ssm get-parameters --names '/service-a/team-a/my-app-name/db_username' --with-decryption | jq '.Parameters[]' | jq -r '.Value'
my_db_user
</code></pre>

<h2>Thank You</h2>

<p>Please feel free to show support by, <strong>sharing</strong> this post, making a <strong>donation</strong>, <strong>subscribing</strong> or <strong>reach out to me</strong> if you want me to demo and write up on any specific tech topic.</p>

<center>
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick" />
<input type="hidden" name="hosted_button_id" value="W7CBGYTCWGANQ" />
<input type="image" src="https://user-images.githubusercontent.com/567298/49853901-461c3700-fdf1-11e8-9d80-8a424a3173af.png" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
<img alt="" border="0" src="https://www.paypal.com/en_ZA/i/scr/pixel.gif" width="1" height="1" />
</form>
</center>


<p><br></p>

<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>

]]></content>
  </entry>
  
</feed>
