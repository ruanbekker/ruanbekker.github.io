<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2022-04-16T20:04:07-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Provision a AWS EC2 Instance With Terraform]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/04/16/provision-a-aws-ec2-instance-with-terraform/"/>
    <updated>2022-04-16T19:04:08-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/04/16/provision-a-aws-ec2-instance-with-terraform</id>
    <content type="html"><![CDATA[<p>In this tutorial I will demonstrate how to use Terraform (a Infrastructure as Code Tool), to provision a AWS EC2 Instance and the source code that we will be using in this tutorial will be published to my <a href="https://github.com/ruanbekker/terraformfiles/tree/master/aws-ec2-instance">terraformfiles github repository</a>.</p>

<h2>Requirements</h2>

<p>To follow along this tutorial, you will need an AWS Account and Terraform installed</p>

<h2>Terraform</h2>

<p>To install Terraform for your operating system, you can follow <a href="https://learn.hashicorp.com/tutorials/terraform/install-cli">Terraform Installation Documentation</a>, I am using Mac OSx, so for me it will be:</p>

<pre><code class="bash">brew tap hashicorp/tap
brew install hashicorp/tap/terraform
</code></pre>

<p>To verify the installation, we can run <code>terraform version</code> and my output shows:</p>

<pre><code>Terraform v1.1.8
on darwin_amd64
</code></pre>

<h2>Terraform Project Structure</h2>

<p>Create the directory:</p>

<pre><code class="bash">mkdir terraform-aws-ec2
cd terraform-aws-ec2
</code></pre>

<p>Create the following files: <code>main.tf</code>, <code>providers.tf</code>, <code>variables.tf</code>, <code>outputs.tf</code>, <code>locals.tf</code> and <code>terraform.tfvars</code>:</p>

<pre><code class="bash">touch main.tf providers.tf variables.tf outputs.tf locals.tf terraform.tfvars
</code></pre>

<h2>Define Terraform Configuration Code</h2>

<p>First we need to define the aws provider, which we will do in <code>providers.tf</code>:</p>

<pre><code>terraform {
  required_providers {
    aws = {
      version = "~&gt; 3.27"
      source = "hashicorp/aws"
    }
  }
}

provider "aws" {
  region  = "eu-west-1"
  profile = "default"
  shared_credentials_file = "~/.aws/credentials"
}
</code></pre>

<p>You will notice that I am defining my profile name <code>default</code> from the <code>~/.aws/credentials</code> credential provider in order for terraform to authenticate with AWS.</p>

<p>Next I am defining the <code>main.tf</code> which will be the file where we define our aws resources:</p>

<pre><code>data "aws_ami" "latest_ubuntu" {
  most_recent = true
  owners = ["099720109477"]

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-*-server-*"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }

  filter {
    name   = "root-device-type"
    values = ["ebs"]
  }

  filter {
    name   = "architecture"
    values = ["x86_64"]
  }

}

data "aws_iam_policy_document" "assume_role_policy" {
  statement {
    actions = ["sts:AssumeRole"]
    principals {
      type        = "Service"
      identifiers = ["ec2.amazonaws.com"]
    }
  }
}

data "aws_iam_policy" "ec2_read_only_access" {
  arn = "arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess"
}

resource "aws_iam_role" "ec2_access_role" {
  name               = "${local.project_name}-ec2-role"
  assume_role_policy = data.aws_iam_policy_document.assume_role_policy.json
}

resource "aws_iam_policy_attachment" "readonly_role_policy_attach" {
  name       = "${local.project_name}-ec2-role-attachment"
  roles      = [aws_iam_role.ec2_access_role.name]
  policy_arn = data.aws_iam_policy.ec2_read_only_access.arn
}

resource "aws_iam_instance_profile" "instance_profile" {
  name  = "${local.project_name}-ec2-instance-profile"
  role = aws_iam_role.ec2_access_role.name
}

resource "aws_security_group" "ec2" {
    name        = "${local.project_name}-ec2-sg"
    description = "${local.project_name}-ec2-sg"
    vpc_id      = var.vpc_id

    tags = merge(
      var.default_tags,
      {
       Name = "${local.project_name}-ec2-sg"
      },
    )
}

resource "aws_security_group_rule" "ssh" {
    description       = "allows public ssh access to ec2"
    security_group_id = aws_security_group.ec2.id
    type              = "ingress"
    protocol          = "tcp"
    from_port         = 22
    to_port           = 22
    cidr_blocks       = ["0.0.0.0/0"]
}

resource "aws_security_group_rule" "egress" {
    description       = "allows egress"
    security_group_id = aws_security_group.ec2.id
    type              = "egress"
    protocol          = "-1"
    from_port         = 0
    to_port           = 0
    cidr_blocks       = ["0.0.0.0/0"]
}

resource "aws_instance" "ec2" {
  ami                         = data.aws_ami.latest_ubuntu.id
  instance_type               = var.instance_type
  subnet_id                   = var.subnet_id
  key_name                    = var.ssh_keyname
  vpc_security_group_ids      = [aws_security_group.ec2.id]
  associate_public_ip_address = true
  monitoring                  = true
  iam_instance_profile        = aws_iam_instance_profile.instance_profile.name

  lifecycle {
    ignore_changes            = [subnet_id, ami]
  }

  root_block_device {
      volume_type           = "gp2"
      volume_size           = var.ebs_root_size_in_gb
      encrypted             = false
      delete_on_termination = true
  }

  tags = merge(
    var.default_tags,
    {
     Name = "${local.project_name}"
    },
  )

}
</code></pre>

<p>A couple of things are defined here:</p>

<ul>
<li>A data resource to fetch the latest Ubuntu 20.04 AMI</li>
<li>The IAM Role and Policy that we will use to associate to our EC2 Instance Profile</li>
<li>The EC2 Security Group</li>
<li>The EC2 Instance</li>
<li>The VPC ID and Subnet ID are required variables which we will set in <code>terraform.tfvars</code></li>
</ul>


<p>The next file will be our <code>variables.tf</code> file where we will define all our variable definitions:</p>

<pre><code>variable "default_tags" {
  default = {
    Environment = "test"
    Owner       = "ruan.bekker"
    Project     = "terraform-blogpost"
    CostCenter  = "engineering"
    ManagedBy   = "terraform"
  }
}

variable "aws_region" {
  type        = string
  default     = "eu-west-1"
  description = "the region to use in aws"
}

variable "vpc_id" {
  type        = string
  description = "the vpc to use"
}

variable "ssh_keyname" {
  type        = string
  description = "ssh key to use"
}

variable "subnet_id" {
  type        = string
  description = "the subnet id where the ec2 instance needs to be placed in"
}

variable "instance_type" {
  type        = string
  default     = "t3.nano"
  description = "the instance type to use"
}

variable "project_id" {
  type        = string
  default     = "terraform-blogpost"
  description = "the project name"
}

variable "ebs_root_size_in_gb" {
  type        = number
  default     = 10
  description = "the size in GB for the root disk"
}

variable "environment_name" {
   type    = string
   default = "dev"
   description = "the environment this resource will go to (assumption being made theres one account)"
}
</code></pre>

<p>The next file is our <code>locals.tf</code> which just concatenates our project id and environment name:</p>

<pre><code>locals {
  project_name = "${var.project_id}-${var.environment_name}"
}
</code></pre>

<p>Then our <code>outputs.tf</code> for the values that terraform should output:</p>

<pre><code>output "id" {
  description = "The ec2 instance id"
  value       = aws_instance.ec2.id
  sensitive   = false
}

output "ip" {
  description = "The ec2 instance public ip address"
  value       = aws_instance.ec2.public_ip
  sensitive   = false
}

output "subnet_id" {
  description = "the subnet id which will be used"
  value       = var.subnet_id
  sensitive   = false
}
</code></pre>

<p>Then lastly our <code>terraform.tfvars</code>, which you will need to supply your own values to match your AWS Account:</p>

<pre><code># required
vpc_id = "vpc-063d7xxxxxxxxxxxx"
ssh_keyname = "ireland-key"
subnet_id = "subnet-04b3xxxxxxxxxxxxx"
</code></pre>

<h2>Deploy EC2 Instance</h2>

<p>Now that all our configuration is in place, we need to intialize terraform by downloading the providers:</p>

<pre><code class="bash">terraform init
</code></pre>

<p>Once the terraform init has completed, we can run a <code>terraform plan</code> which will show us what terraform will do. Since the <code>terraform.tfvars</code> are the default file for variables, we don&rsquo;t have to specify the name of the file, but since I want to be excplicit, I will include it (should you want to change the file name):</p>

<pre><code class="bash">terraform plan -var-file="terraform.tfvars"
</code></pre>

<p>Now it&rsquo;s a good time to review what terraform wants to action by viewing the plan output, once you are happy you can deploy the changes by running a <code>terraform apply</code>:</p>

<pre><code class="bash">terraform apply -var-file="terraform.tfvars"
</code></pre>

<p>Optional: You can override variables by either updating the <code>terraform.tfvars</code> or you can append them with terraform apply <code>-var-file="terraform.tfvars" -var="ssh_key=default_key"</code>, a successful output should show something like this:</p>

<pre><code class="bash">Outputs:
id = "i-0dgacxxxxxxxxxxxx"
ip = "18.26.xxx.92"
subnet = "subnet-04b3xxxxxxxxxxxxx"
</code></pre>

<h2>Access your EC2 Instance</h2>

<p>You can access the instance by SSH'ing to the IP that was returned by the output as well as the SSH key name that you provided, or you can make use of the <code>terraform output</code> to access the output value:</p>

<pre><code class="bash">ssh -i ~/.ssh/id_rsa ubuntu@$(terraform output -raw ip)
</code></pre>

<h2>Cleanup</h2>

<p>To delete the infrastructure that Terraform provisioned:</p>

<pre><code class="bash">terraform destroy
</code></pre>

<h2>Thank You</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong>, read my <strong><a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS EC2 Linux - Warning: Setlocale: LC_CTYPE: Cannot Change Locale UTF-8]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/08/02/aws-ec2-linux-warning-setlocale-lc-ctype-cannot-change-locale-utf-8/"/>
    <updated>2021-08-02T02:40:53-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/08/02/aws-ec2-linux-warning-setlocale-lc-ctype-cannot-change-locale-utf-8</id>
    <content type="html"><![CDATA[<p>On Amazon Linux EC2 Instances, I noticed the following error when SSH onto them:</p>

<pre><code>-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
</code></pre>

<p>To resolve, add the following to the <code>/etc/environment</code> file:</p>

<pre><code>$ cat /etc/environment
LANG=en_US.utf-8
LC_ALL=en_US.utf-8
</code></pre>

<p>Logout and log back in and it should be resolved.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Difference With ECS Task and Execution IAM Roles on AWS]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/07/31/difference-with-ecs-task-and-execution-iam-roles-on-aws/"/>
    <updated>2021-07-31T03:37:34-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/07/31/difference-with-ecs-task-and-execution-iam-roles-on-aws</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ruanbekker-header-photo.png" alt="" /></p>

<p>In this post we will look at what the difference is between the <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task-iam-roles.html">AWS ECS Task Execution IAM Role</a> and the <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task-iam-roles.html">IAM Role for Tasks</a> and give a example policy to demonstrate.</p>

<h2>ECS Task Execution Role</h2>

<p>The ECS Execution Role is used by the ecs-agent which runs on ECS and is responsible for:
- Pulling down docker images from ECR
- Fetching the SSM Parameters from SSM for your Task (Secrets and LogConfigurations)
- Writing Logs to CloudWatch</p>

<p>The IAM Role has been configured that the Trusted Identity is ecs so only ECS is allowed to assume credentials from the IAM Policy that is associated to the Role.</p>

<p>The trusted identity in the IAM Role to be ecs:</p>

<pre><code class="json">{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": "ecs-tasks.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
</code></pre>

<p>and the policy will look like this more or less for a example service, I am demonstrating my-dev-service:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ecr:GetAuthorizationToken",
                "ecr:BatchCheckLayerAvailability",
                "ecr:GetDownloadUrlForLayer",
                "ecr:BatchGetImage",
                "logs:CreateLogStream",
                "logs:PutLogEvents"
            ],
            "Resource": "*"
        },
        {
            "Sid": "SSMGetParameters",
            "Effect": "Allow",
            "Action": [
                "ssm:GetParameter"
            ],
            "Resource": "arn:aws:ssm:eu-west-1:*:parameter/my-service/dev/*"
        },
        {
            "Sid": "KMSDecryptParametersWithKey",
            "Effect": "Allow",
            "Action": [
                "kms:GetPublicKey",
                "kms:Decrypt",
                "kms:GenerateDataKey",
                "kms:DescribeKey"
            ],
            "Resource": "*"
        }
    ]
}
</code></pre>

<p>In the ECS Task Definition the role arn is specified as <code>"executionRoleArn"</code> in:</p>

<pre><code class="json">{
  "family": "my-dev-service",
  "executionRoleArn":"arn:aws:iam::000000000000:role/ecs-exec-role",
  "taskRoleArn":"arn:aws:iam::000000000000:role/ecs-task-role",
  "containerDefinitions": []
}
</code></pre>

<h2>ECS Task Role</h2>

<p>The ECS Task Role is used by the service that is deployed to ECS, so this will be your application requiring access to SQS as an example</p>

<p>Same as before, we set the trusted identity in the IAM Role to be ecs:</p>

<pre><code class="json">{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": "ecs-tasks.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
</code></pre>

<p>So only the ECS tasks using the role is allowed to assume credentials from the IAM Role, and the policy associated to the role, can look something like this:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowDevSQS",
            "Effect": "Allow",
            "Action": [
                "sqs:GetQueueUrl",
                "sqs:ReceiveMessage",
                "sqs:SendMessage",
                "sqs:ChangeMessageVisibility"
            ],
            "Resource": [
                "arn:aws:sqs:eu-west-1:000000000000:dev-pending-queue",
                "arn:aws:sqs:eu-west-1:000000000000:dev-confirmed-queue"
            ]
        }
    ]
}
</code></pre>

<p>The role arn will be specified in <code>"taskRoleArn"</code> from the following in the ECS Task Definition:</p>

<pre><code class="json">{
  "family": "my-dev-service",
  "executionRoleArn":"arn:aws:iam::000000000000:role/ecs-exec-role",
  "taskRoleArn":"arn:aws:iam::000000000000:role/ecs-task-role",
  "containerDefinitions": []
}
</code></pre>

<h2>Application Code</h2>

<p>In your application you don’t need to reference any aws access keys as the role will assume credentials for you by the SDK, with python a short example will be:</p>

<pre><code class="python">import boto3
sqs = boto3.Session(region_name='eu-west-1').client('sqs')
</code></pre>

<h2>Thanks</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH Using AWS SSM Session Manager]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/03/10/ssh-using-aws-ssm-session-manager/"/>
    <updated>2021-03-10T00:52:54-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/03/10/ssh-using-aws-ssm-session-manager</id>
    <content type="html"><![CDATA[<p>You can use SSM Session Manager to connect to your EC2 instances, as long as your EC2 instance has the associated IAM Role which includes the AmazonSSMManagedInstanceCore managed policy.</p>

<h2>AWS EC2 Console</h2>

<p>Head over to &ldquo;Connect&rdquo; and select &ldquo;Session Manager&rdquo;:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103775580-e8da2a80-5036-11eb-9e00-0fd9b4d9d467.png" alt="image" /></p>

<p>You should get a shell:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103775597-f2639280-5036-11eb-8101-768f1c81108a.png" alt="image" /></p>

<h2>AWS CLI</h2>

<p>You can also use the CLI:</p>

<pre><code>aws --profile prod ssm start-session --target i-0ebba722b102179b6
</code></pre>

<p>If you get this error:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103775625-ff808180-5036-11eb-88dc-be8fde3586ad.png" alt="image" /></p>

<p>Head over to:</p>

<p><a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html">https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html</a></p>

<p>Install the session manager plugin, for Mac:</p>

<pre><code>$ curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/mac/sessionmanager-bundle.zip" -o "sessionmanager-bundle.zip"
$ unzip sessionmanager-bundle.zip
$ sudo ./sessionmanager-bundle/install -i /usr/local/sessionmanagerplugin -b /usr/local/bin/session-manager-plugin
$ rm -rf sessionmanager-bundle
</code></pre>

<p>After installation:</p>

<pre><code>$ aws --profile prod ssm start-session --target i-0ebba722b102179b6
Starting session with SessionId: ruan.bekker-0b07cbbe261885ad3

sh-4.2$ sudo su - ec2-user
Last login: Wed Jan  6 12:55:03 UTC 2021 on pts/0
[ec2-user@ip-172-31-23-246 ~]$
</code></pre>

<p>Note: when you are using ssm session manager you don’t require security groups or a direct routable network to your instance.</p>

<h2>Bash Functions FTW</h2>

<p>You can implement this into a bash function:</p>

<pre><code>$ cat ~/.functions.aws
aws-ssh(){
  instance_name=${1}
  instance_id=$(aws --profile prod ec2 describe-instances --filter "Name=tag:Name,Values=${instance_name}" --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" --output text)
  aws --profile prod ssm start-session --target ${instance_id}
}

$ aws-ssh ssm-session-manager-ssh-test2
Starting session with SessionId: ruan.bekker-04daf56c5f3668790
sh-4.2$
</code></pre>

<p>If you have your own SSH key, you can use this ~/.ssh/config:</p>

<pre><code># AWS SSM Session Manager
Host i-*
    ProxyCommand sh -c "aws --profile prod ssm start-session --target %h --document-name AWS-StartSSHSession --parameters 'portNumber=%p'"
</code></pre>

<pre><code>$ ssh -i ~/.ssh/infra.pem ec2-user@i-0ebba722b102179b6
Warning: Permanently added 'i-0ebba722b102179b6' (ECDSA) to the list of known hosts.
Last login: Wed Jan  6 13:04:03 2021

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
[ec2-user@ip-172-31-23-246 ~]$
</code></pre>

<h2>Related:</h2>

<ul>
<li><a href="https://aws.amazon.com/blogs/mt/amazon-ec2-instance-port-forwarding-with-aws-systems-manager/">https://aws.amazon.com/blogs/mt/amazon-ec2-instance-port-forwarding-with-aws-systems-manager/</a></li>
<li><a href="https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/">https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/</a></li>
</ul>


<h2>Thanks</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running SSH Commands on AWS EC2 Instances With Python]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/11/02/running-ssh-commands-on-aws-ec2-instances-with-python/"/>
    <updated>2020-11-02T09:55:43+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/11/02/running-ssh-commands-on-aws-ec2-instances-with-python</id>
    <content type="html"><![CDATA[<p>In this quick post I will demonstrate how to discover a EC2 Instance&rsquo;s Private IP Address using the AWS API by using Tags then use Paramiko in Python to SSH to the EC2 instance and run SSH commands on the target instance.</p>

<p>Install the required dependencies:</p>

<pre><code>$ virtualenv -p python3 .venv
$ source .venve/bin/activate
$ pip install boto3 paramiko
</code></pre>

<p>I have my development profile for aws configured under <code>dev</code> as can seen below:</p>

<pre><code>$ aws --profile dev configure list
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                      dev           manual    --profile
access_key     ****************xxxx      assume-role
secret_key     ****************xxxx      assume-role
    region                eu-west-1      config-file    ~/.aws/config
</code></pre>

<p>First we need to discover the private ip address from the api by referencing tags, and in this example we will use the <code>Name</code> tag:</p>

<pre><code>import boto3
ec2 = boto3.Session(profile_name='dev', region_name='eu-west-1').client('ec2')

target_instances = ec2.describe_instances(
    Filters=[{'Name':'tag:Name','Values':['my-demo-ec2-instance']}]
)

ec2_instances = []
for each_instance in target_instances['Reservations']:
    for found_instance in each_instance['Instances']:
        ec2_instances.append(found_instance['PrivateIpAddress'])

# ec2_instances
# ['172.31.2.89']
</code></pre>

<p>So we are instantiating a ec2 instance with our configured dev profile, then we describe all our instances using the tag key <code>Name</code> and value <code>my-demo-ec2-instance</code> and then access the private ip address and append it to our <code>ec2_instances</code> list.</p>

<p>Next we want to define the commands that we want to run on the target ec2 instance:</p>

<pre><code>commands = [
    "echo hi",
    "whoami",
    "hostname"
]
</code></pre>

<p>In my case I only have 1 ec2 instance with the name <code>my-demo-ec2-instance</code>, but if you have more you can just loop through the list and perform the actions.</p>

<p>Next we want to establish the SSH connection:</p>

<pre><code>k = paramiko.RSAKey.from_private_key_file("/Users/ruan/.ssh/id_rsa")
c = paramiko.SSHClient()
c.set_missing_host_key_policy(paramiko.AutoAddPolicy())
c.connect(hostname=ec2_instances[0], username="ruan", pkey=k, allow_agent=False, look_for_keys=False)
</code></pre>

<p>Once our SSH connection has established, we can loop through our commands and execute them:</p>

<pre><code>for command in commands:
    print("running command: {}".format(command))
    stdin , stdout, stderr = c.exec_command(command)
    print(stdout.read())
    print(stderr.read())
</code></pre>

<p>Which will output the folling:</p>

<pre><code>running command: echo hi
b'hi\n'
b''
running command: whoami
b'ruan\n'
b''
running command: hostname
b'ip-172-31-2-89\n'
b''
</code></pre>

<p>And then close the SSH connection:</p>

<pre><code>c.close()
</code></pre>

<p>And the full script will look like this:</p>

<pre><code class="python">import boto3
ssh_username = "ruan"
ssh_key_file = "/Users/ruan/.ssh/id_rsa"

ec2 = boto3.Session(profile_name='dev', region_name='eu-west-1').client('ec2')

target_instances = ec2.describe_instances(
    Filters=[{'Name':'tag:Name','Values':['my-demo-ec2-instance']}]
)

ec2_instances = []
for each_instance in target_instances['Reservations']:
    for found_instance in each_instance['Instances']:
        ec2_instances.append(found_instance['PrivateIpAddress'])

commands = [
    "echo hi",
    "whoami",
    "hostname"
]

k = paramiko.RSAKey.from_private_key_file(ssh_key_file)
c = paramiko.SSHClient()
c.set_missing_host_key_policy(paramiko.AutoAddPolicy())
c.connect(hostname=ec2_instances[0], username=ssh_username, pkey=k, allow_agent=False, look_for_keys=False)

for command in commands:
    print("running command: {}".format(command))
    stdin , stdout, stderr = c.exec_command(command)
    print(stdout.read())
    print(stderr.read())

c.close()
</code></pre>
]]></content>
  </entry>
  
</feed>
