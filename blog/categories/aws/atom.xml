<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2017-09-16T17:56:09-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Nginx Reverse Proxy for Elasticsearch and Kibana 5 on AWS]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/16/nginx-reverse-proxy-for-elasticsearch-and-kibana-5-on-aws/"/>
    <updated>2017-09-16T17:24:32-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/16/nginx-reverse-proxy-for-elasticsearch-and-kibana-5-on-aws</id>
    <content type="html"><![CDATA[<p>As up untill today, there&rsquo;s currently no VPC Support for Amazon&rsquo;s Elasticsearch Service.</p>

<p>So for scenarios where you would like to allow private network traffic to Elasticsearch is impossible straight out of the box as Amazon&rsquo;s Elasticsearch Services, only sees Public Internet Traffic.</p>

<p>We will setup 2 configs, one for Kibana and one for Elasticsearch, each one having its own FQDN:</p>

<ul>
<li>Kibana: <code>http://kibana.domain.com</code></li>
<li>Elasticsearch: <code>http://elasticsearch.domain.com</code></li>
</ul>


<h2>Workaround:</h2>

<p>There&rsquo;s a couple of workarounds, which includes:</p>

<ul>
<li>Nginx Reverse Proxy</li>
<li>NAT Gateway</li>
<li>Allow IAM Users/Roles</li>
</ul>


<p>Today we will tackle the Nginx Reverse Proxy Route.</p>

<p>The benefit of this, would be to associate an EIP to the Nginx EC2 Instnace, then whitelist your EIP with Elasticsearch, so the only traffic that will be accepted will be the traffic that is coming from the Nginx Instance. We will also apply an additional layer of security, in this case we will use HTTP Basic Authentication, then also authorize network sources on a Security Group level.</p>

<h2>Installing Nginx:</h2>

<p>In this case I am using Ubuntu 16.04, so we will need to install <code>nginx</code> and <code>apache2-utils</code> for creating the Basic HTTP Auth accounts.</p>

<pre><code class="bash">$ apt update &amp;&amp; apt upgrade -y
$ apt install nginx apache2-utils -y
</code></pre>

<h2>Configure Nginx:</h2>

<p>Our main config: <code>/etc/nginx/nginx.conf</code>:</p>

<pre><code class="bash /etc/nginx/nginx.conf">user www-data;
worker_processes auto;
pid /run/nginx.pid;
error_log /var/log/nginx/error.log;

events {
    worker_connections 1024;
}

http {

    # Basic Settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_names_hash_bucket_size 128;

    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging Settings
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # Gzip Settings
    gzip on;
    gzip_disable "msie6";

    # Elasticsearch and Kibana Configs
    include /etc/nginx/conf.d/elasticsearch.conf;
    include /etc/nginx/conf.d/kibana.conf;
}
</code></pre>

<p>Our <code>/etc/nginx/conf.d/elasticsearch.conf</code> configuration:</p>

<pre><code class="bash /etc/nginx/conf.d/elasticsearch.conf">server {

  listen 80;
  server_name elasticsearch.domain.com;

  # error logging
  error_log /var/log/nginx/elasticsearch_error.log;

  # authentication: elasticsearch
  auth_basic "Elasticsearch Auth";
  auth_basic_user_file /etc/nginx/.secrets_elasticsearch;

  location / {

    proxy_http_version 1.1;
    proxy_set_header Host https://search-elasticsearch-name.eu-west-1.es.amazonaws.com;
    proxy_set_header X-Real-IP &lt;ELASTIC-IP&gt;;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header Authorization "";

    proxy_pass https://search-elasticsearch-name.eu-west-1.es.amazonaws.com/;
    proxy_redirect https://search-elasticsearch-name.eu-west-1.es.amazonaws.com/ http://&lt;ELASTIC-IP&gt;/;

  }

  # ELB Health Checks
  location /status {
    root /usr/share/nginx/html/;
  }

}
</code></pre>

<p>Our <code>/etc/nginx/conf.d/kibana.conf</code> configuration:</p>

<pre><code class="bash /etc/nginx/conf.d/kibana.conf">server {

  listen 80;
  server_name kibana.domain.com;

  # error logging
  error_log /var/log/nginx/kibana_error.log;

  # authentication: kibana
  auth_basic "Kibana Auth";
  auth_basic_user_file /etc/nginx/.secrets_kibana;

  location / {

    proxy_http_version 1.1;
    proxy_set_header Host https://search.elasticsearch-name.eu-west-1.es.amazonaws.com;
    proxy_set_header X-Real-IP &lt;ELASTIC-IP&gt;;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header Authorization "";

    proxy_pass https://search.elasticsearch-name.eu-west-1.es.amazonaws.com/_plugin/kibana/;
    proxy_redirect https://search.elasticsearch-name.eu-west-1.es.amazonaws.com/_plugin/kibana/ http://&lt;ELASTIC-IP&gt;/kibana/;

  }

      location ~ (/app/kibana|/app/timelion|/bundles|/es_admin|/plugins|/api|/ui|/elasticsearch) {
         proxy_pass              https://search.elasticsearch-name.eu-west-1.es.amazonaws.com;
         proxy_set_header        Host $host;
         proxy_set_header        X-Real-IP $remote_addr;
         proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
         proxy_set_header        X-Forwarded-Proto $scheme;
         proxy_set_header        X-Forwarded-Host $http_host;
         proxy_set_header    Authorization  "";
    }
}
</code></pre>

<p>Once you have replaced the elasticsearch endpoint and your EPI values, we can go ahead and create the auth accounts.</p>

<h2>Create User Accounts for HTTP Basic Auth</h2>

<p>Create the 2 accounts for authentication on kibana and elasticsearch:</p>

<pre><code class="bash">$ htpasswd -c /etc/nginx/.secrets_elasticsearch elasticsearch-admin
$ htpasswd -c /etc/nginx/.secrets_kibana kibana-admin
</code></pre>

<h2>Restart Nginx:</h2>

<p>Restart and enable Nginx on boot:</p>

<pre><code class="bash">$ systemctl enable nginx
$ systemctl restart nginx
</code></pre>

<p>Once your Nginx Service is running, you should be able to access Kibana and Elasticsearch using the credentials that you created.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.nginx.com/blog/tcp-load-balancing-udp-load-balancing-nginx-tips-tricks/">https://www.nginx.com/blog/tcp-load-balancing-udp-load-balancing-nginx-tips-tricks/</a></li>
<li><a href="https://www.elastic.co/blog/playing-http-tricks-nginx">https://www.elastic.co/blog/playing-http-tricks-nginx</a></li>
<li><a href="https://sysadmins.co.za/aws-access-kibana-5-behind-elb-via-nginx-reverse-proxy-on-custom-dns/">https://sysadmins.co.za/aws-access-kibana-5-behind-elb-via-nginx-reverse-proxy-on-custom-dns/</a></li>
</ul>


<center>
<script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script> 
</center>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS: IAM S3 Policy for Cyberduck to Allow Listing Buckets and Access to One Bucket]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/15/aws-iam-s3-policy-for-cyberduck-to-allow-listing-buckets-and-access-to-one-bucket/"/>
    <updated>2017-09-15T11:18:17-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/15/aws-iam-s3-policy-for-cyberduck-to-allow-listing-buckets-and-access-to-one-bucket</id>
    <content type="html"><![CDATA[<p>When using Cyberduck to access S3, and a account has restrictive policies, you may find error <code>Listing Directory: /</code> failed.</p>

<p>If you have restrictive IAM Policies in your account, this may be due to the fact that <code>S3:ListMyBuckets</code> is not allowed.</p>

<p>In this post we want to allow a user to list all buckets, so that Cyberduck can do the initial list after configuration / launch, and we would like to give the user access to their designated bucket.</p>

<h2>Creating the IAM Policy:</h2>

<p>We will create this IAM Policy and associate the policy to the user&rsquo;s account:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "Stmt1480515305000",
            "Effect": "Allow",
            "Action": [
                "s3:ListAllMyBuckets",
                "s3:GetBucketLocation"
            ],
            "Resource": [
                "arn:aws:s3:::*"
            ]
        },
        {
            "Sid": "Stmt1480515305002",
            "Effect": "Allow",
            "Action": [
                "s3:List*",
                "s3:GetObject",
                "s3:PutObject",
                "s3:DeleteObject"
            ],
            "Resource": [
                "arn:aws:s3:::allowed-bucket",
                "arn:aws:s3:::allowed-bucket/*"
            ]
        }
    ]
}
</code></pre>

<p>So here we should be able to list the buckets:</p>

<pre><code class="bash">$ aws --profile cyberduck s3 ls /
2017-06-08 08:27:01 allowed-bucket
2017-05-21 13:39:21 private-bucket
2016-12-21 08:23:45 confidential-bucket
2017-08-10 14:18:19 test-bucket
2016-08-03 12:38:29 datalake-bucket
</code></pre>

<p>Able to list inside the bucket, as well as Get, Put etc.</p>

<pre><code class="bash">$ aws --profile cyberduck s3 ls allowed-bucket/
                           PRE data/
</code></pre>

<p>Unable to list the buckets content which is expected, as we did not mention in the policy:</p>

<pre><code class="bash">$ aws --profile cyberduck s3 ls confidential-bucket/

An error occurred (AccessDenied) when calling the ListObjects operation: Access Denied
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://aws.amazon.com/blogs/security/writing-iam-policies-how-to-grant-access-to-an-amazon-s3-bucket/">https://aws.amazon.com/blogs/security/writing-iam-policies-how-to-grant-access-to-an-amazon-s3-bucket/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Python for Image Analysis With Amazons Rekognition Service]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/11/using-python-for-image-analysis-with-amazons-rekognition-service/"/>
    <updated>2017-09-11T10:20:28-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/11/using-python-for-image-analysis-with-amazons-rekognition-service</id>
    <content type="html"><![CDATA[<p>Amazon&rsquo;s Rekognition Service, which falls under their Artificial Intelligence tier, makes it easy to add image analysis to your applications.</p>

<p>Today we will use Rekognition to analyze an image, to determine the percentage of detection that the service analyzes. We will be using the Python SDK to do this.</p>

<h2>Getting a Random Image:</h2>

<p>So, I got this drunk guy on the couch, which I thought we could use to analyze.</p>

<p>Image Used:
- <a href="http://imgur.com/a/CHnSu">http://imgur.com/a/CHnSu</a></p>

<blockquote class="imgur-embed-pub" lang="en" data-id="a/CHnSu"><a href="//imgur.com/CHnSu"></a></blockquote>


<script async src="//s.imgur.com/min/embed.js" charset="utf-8"></script>


<h2>Our Python Code:</h2>

<p>Our code will use boto3 to use rekognition from Amazon Web Services, detects the image, and prints out the values.</p>

<p>Note that I am not specifying any credentials, as my credentials is configured in my local credential provider, where boto will pick it up from.</p>

<pre><code class="python">import boto3

BUCKET = "rekognition-bucket"
KEY = "images/image-02.jpg"

def detect_labels(bucket, key, max_labels=10, min_confidence=90, region="eu-west-1", profile_name="aws"):
    rekognition = boto3.client("rekognition")
    response = rekognition.detect_labels(
        Image={
        "S3Object": {
        "Bucket": BUCKET,
        "Name": KEY,
    }
        },
        MaxLabels=max_labels,
        MinConfidence=min_confidence,
    )
    return response['Labels']


for label in detect_labels(BUCKET, KEY):
    print("{Name} - {Confidence}%".format(**label))
</code></pre>

<h2>Running the App:</h2>

<p>Running our Python App, will result in the following:</p>

<pre><code class="bash">$ python rekog.py 
People - 98.9893875122%
Person - 98.9893951416%
Human - 98.9505844116%
Alcohol - 98.573425293%
Beer - 98.573425293%
Beer Bottle - 98.573425293%
Beverage - 98.573425293%
Bottle - 98.573425293%
Drink - 98.573425293%
Couch - 98.4713821411%
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://aws.amazon.com/rekognition/">https://aws.amazon.com/rekognition/</a></li>
<li><a href="https://gist.github.com/alexcasalboni/0f21a1889f09760f8981b643326730ff">https://gist.github.com/alexcasalboni/0f21a1889f09760f8981b643326730ff</a></li>
</ul>


<center>
        <script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script>
</center>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Secure Your Access to Kibana 5 and Elasticsearch 5 With Nginx for AWS]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/08/31/secure-your-access-to-kibana-5-and-elasticsearch-5-with-nginx-for-aws/"/>
    <updated>2017-08-31T10:40:09-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/08/31/secure-your-access-to-kibana-5-and-elasticsearch-5-with-nginx-for-aws</id>
    <content type="html"><![CDATA[<p>As until now, AWS does not offer VPC Support for Elasticsearch, so this make things a bit difficult authorizing Private IP Ranges.</p>

<p>One workaround would be to setup a Nginx Reverse Proxy on AWS within the your Private VPC, associate a EIP on your Nginx EC2 Instance, then authorize your EIP on your Elasticsearch IP Access Policy.</p>

<h2>Our Setup:</h2>

<p>In this setup, we will have an Internal ELB (Elastic Load Balancer), which we will associate 1 or more EC2 Nginx Instances behind the ELB, then setup our Nginx to Revere Proxy our connections through to our Elasticsearch Endpoint.</p>

<p>We will also setup Basic HTTP Authentication for our <code>/</code> elasticsearch endpoint, and our <code>/kibana</code> endpoint. But we will keep the authentication seperate from each other, so that credentials for ES and Kibana is not the same, but depending on your use case, you can allow both endpoints to reference the same credential file.</p>

<h2>Install Nginx</h2>

<p>Depending on your Linux Distribution, the package manager may differ, I am using Amazon Linux:</p>

<pre><code class="bash Install Nginx">$ sudo yum update -y
$ sudo yum install nginx httpd-tools -y
</code></pre>

<h2>Configure Nginx:</h2>

<p>Remove the default configuration and replace the <code>nginx.conf</code> with the following:</p>

<pre><code class="bash Remove Default Nginx Config">$ sudo rm -r /etc/nginx/nginx.conf
</code></pre>

<p>Main Nginx Configuration:</p>

<pre><code class="bash /etc/nginx/nginx.conf">user nginx;
worker_processes auto;
pid /run/nginx.pid;
error_log /var/log/nginx/error.log;

events {
    worker_connections 1024;
}

http {

    # Basic Settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_names_hash_bucket_size 128;

    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging Settings
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # Gzip Settings
    gzip on;
    gzip_disable "msie6";

    # Elasticsearch Config
    include /etc/nginx/conf.d/elasticsearch.conf;
}
</code></pre>

<p>The Reverse Proxy Configuration:</p>

<pre><code class="bash /etc/nginx/conf.d/elasticsearch.conf">server {

  listen 80;
  server_name elk.mydomain.com;

  # error logging
  error_log /var/log/nginx/elasticsearch_error.log;

  # authentication: server wide
  #auth_basic "Auth";
  #auth_basic_user_file /etc/nginx/.secrets;

  location / {

    # authentication: elasticsearch
    auth_basic "Elasticsearch Auth";
    auth_basic_user_file /etc/nginx/.secrets_elasticsearch;

    proxy_http_version 1.1;
    proxy_set_header Host https://search.eu-west-1.es.amazonaws.com;
    proxy_set_header X-Real-IP {NGINX-EIP};
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header Authorization "";

    proxy_pass https://search.eu-west-1.es.amazonaws.com/;
    proxy_redirect https://search.eu-west-1.es.amazonaws.com/ http://{NGINX-EIP}/;

  }

  location /kibana {

    # authentication: kibana
    auth_basic "Kibana Auth";
    auth_basic_user_file /etc/nginx/.secrets_kibana;

    proxy_http_version 1.1;
    proxy_set_header Host https://search.eu-west-1.es.amazonaws.com;
    proxy_set_header X-Real-IP {NGINX-EIP};
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header Authorization "";

    proxy_pass https://search.eu-west-1.es.amazonaws.com/_plugin/kibana/;
    proxy_redirect https://search.eu-west-1.es.amazonaws.com/_plugin/kibana/ http://{NGINX_EIP}/kibana/;

  }

  # elb checks
  location /status {
    root /usr/share/nginx/html/;
  }

}
</code></pre>

<h2>Setup Authentication:</h2>

<p>Setup the authentication for elasticsearch and kibana:</p>

<pre><code class="bash Create Auth for Kibana and Elasticsearch">$ sudo htpasswd -c /etc/nginx/.secrets_elasticsearch admin
$ sudo htpasswd -c /etc/nginx/.secrets_kibana admin
</code></pre>

<h2>Restart Nginx and Enable on Startup</h2>

<p>Restart the nginx process and enable the process on boot:</p>

<pre><code class="bash Restart Nginx">$ sudo /etc/init.d/nginx restart
$ sudo chkconfig nginx on
</code></pre>

<h2>Configure ELB:</h2>

<p>Create a New Internal ELB, set the Backend Instances on Port 80, and the healthcheck should point to <code>/status/index.html</code> as this location block does not require authentication and our ELB will be able to get a 200 reponse if all is good.
Next you can configure your Route 53 Hosted Zone, <code>elk.mydomain.com</code> to map to your ELB.</p>

<h2>End Result</h2>

<p>Now you should be able to access Elasticsearch on <code>http://elk.mydomain.com/</code> and Kibana on <code>http://elk.mydomain.com/kibana</code> after authenticating.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Change IAM Username With AWS CLI]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/08/28/change-iam-username-with-aws-cli/"/>
    <updated>2017-08-28T18:27:21-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/08/28/change-iam-username-with-aws-cli</id>
    <content type="html"><![CDATA[<p>You may find yourself in a position where you need to rename more than one IAM Username, and one way of doing this is using the AWS CLI tools to rename the username.</p>

<p>The benefit of this is that the user&rsquo;s access keys remains the same, any policies associated to the user, will stay on the user after the username gets renamed.</p>

<p>The only thing that changes, is ofcourse the username that the user will use when logging onto the AWS Management Console:</p>

<h2>Details of our User:</h2>

<p>We will change the IAM User <code>peter</code> to <code>peter.franklin</code>. Currently Peter&rsquo;s ACCESS_KEY will be <code>AKIA123456ABCDEF1234</code> which is configured with the profile name <code>peter</code>.</p>

<p>Lets first get details of our user before changing it:</p>

<pre><code class="bash ">$ aws --profile admin iam get-user --user-name peter
{
    "User": {
        "UserName": "peter",
        "PasswordLastUsed": "2017-08-28T13:17:22Z",
        "CreateDate": "2017-08-28T13:11:25Z",
        "UserId": "ABCDEFGHIJKLMNOPQRST",
        "Path": "/",
        "Arn": "arn:aws:iam::123456789012:user/peter"
    }
}
</code></pre>

<h2>Rename the IAM User</h2>

<p>Update user peter to peter.franklin:</p>

<pre><code class="bash Rename the IAM User">$ aws --profile aws iam update-user --user-name peter --new-user-name peter.franklin
</code></pre>

<p>Describe peter&rsquo;s new username:</p>

<pre><code class="bash">$ aws --profile aws iam get-user --user-name peter.franklin
{
    "User": {
        "UserName": "peter.franklin",
        "PasswordLastUsed": "2017-08-28T13:23:18Z",
        "CreateDate": "2017-08-28T13:11:25Z",
        "UserId": "ABCDEFGHIJKLNMOPQRST",
        "Path": "/",
        "Arn": "arn:aws:iam::123456789012:user/peter.franklin"
    }
}
</code></pre>

<p>Verify that access keys are the same:</p>

<pre><code class="bash">$ aws --profile aws iam list-access-keys --user-name peter.franklin
{
    "AccessKeyMetadata": [
        {
            "UserName": "peter.franklin",
            "Status": "Active",
            "CreateDate": "2017-08-28T13:11:27Z",
            "AccessKeyId": "AKIA123456ABCDEF1234"
        }
    ]
}
</code></pre>

<p>At this momemnt we can see that Peter&rsquo;s AccessKeyId is still the same, which means he does not have to update his credentials on his end.</p>

<h2>Some Useful CLI Commands:</h2>

<p>Get only the Access Key for a User:</p>

<pre><code class="bash">$ aws --profile admin iam list-access-keys --user-name peter.franklin | jq -r '.[][].AccessKeyId'
AKIA123456ABCDEF1234
</code></pre>

<h2>Determine when the AccessKey was last used, and for which Service:</h2>

<p>For auditing, or verifying if a AccessKeyId is being used, we can call the <code>get-access-key-last-used</code>, which will give us the last time the key was used, and also see for which service in question.</p>

<p>Let Peter create a DynamoDB Table:</p>

<pre><code class="bash">$ aws --profile peter dynamodb \
create-table --table-name test01 \
--attribute-definitions "AttributeName=username,AttributeType=S" \
--key-schema "AttributeName=username,KeyType=HASH" \
--provisioned-throughput "ReadCapacityUnits=1,WriteCapacityUnits=1"
</code></pre>

<pre><code class="json">{
    "TableDescription": {
        "TableArn": "arn:aws:dynamodb:eu-west-1:123456789012:table/test01",
        "AttributeDefinitions": [
            {
                "AttributeName": "username",
                "AttributeType": "S"
            }
        ],
        "ProvisionedThroughput": {
            "NumberOfDecreasesToday": 0,
            "WriteCapacityUnits": 1,
            "ReadCapacityUnits": 1
        },
        "TableSizeBytes": 0,
        "TableName": "test01",
        "TableStatus": "CREATING",
        "KeySchema": [
            {
                "KeyType": "HASH",
                "AttributeName": "username"
            }
        ],
        "ItemCount": 0,
        "CreationDateTime": 1503928537.671
    }
}
</code></pre>

<p>Get Detail on LastUsedDate:</p>

<pre><code class="bash">$ aws --profile admin iam get-access-key-last-used  --access-key $(aws --profile aws iam list-access-keys --user-name peter.franklin | jq -r '.[][].AccessKeyId') | jq -r '.[]'
peter.franklin
{
  "Region": "eu-west-1",
  "ServiceName": "dynamodb",
  "LastUsedDate": "2017-08-28T13:55:00Z"
}
</code></pre>

<p>Only getting the LastUsedDate of the AccessKeyId:</p>

<pre><code class="bash">$ aws --profile admin iam get-access-key-last-used  --access-key $(aws --profile aws iam list-access-keys --user-name peter.franklin | jq -r '.[][].AccessKeyId') | jq '.AccessKeyLastUsed.LastUsedDate'
"2017-08-28T13:55:00Z"
</code></pre>

<h2>Resources:</h2>

<ul>
<li><ul>
<li><a href="http://docs.aws.amazon.com/cli/latest/reference/iam/update-user.html?shortFooter=true">http://docs.aws.amazon.com/cli/latest/reference/iam/update-user.html?shortFooter=true</a></li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
