<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2021-11-03T01:21:28-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS EC2 Linux - Warning: Setlocale: LC_CTYPE: Cannot Change Locale UTF-8]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/08/02/aws-ec2-linux-warning-setlocale-lc-ctype-cannot-change-locale-utf-8/"/>
    <updated>2021-08-02T02:40:53-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/08/02/aws-ec2-linux-warning-setlocale-lc-ctype-cannot-change-locale-utf-8</id>
    <content type="html"><![CDATA[<p>On Amazon Linux EC2 Instances, I noticed the following error when SSH onto them:</p>

<pre><code>-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
</code></pre>

<p>To resolve, add the following to the <code>/etc/environment</code> file:</p>

<pre><code>$ cat /etc/environment
LANG=en_US.utf-8
LC_ALL=en_US.utf-8
</code></pre>

<p>Logout and log back in and it should be resolved.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Difference With ECS Task and Execution IAM Roles on AWS]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/07/31/difference-with-ecs-task-and-execution-iam-roles-on-aws/"/>
    <updated>2021-07-31T03:37:34-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/07/31/difference-with-ecs-task-and-execution-iam-roles-on-aws</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ruanbekker-header-photo.png" alt="" /></p>

<p>In this post we will look at what the difference is between the <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task-iam-roles.html">AWS ECS Task Execution IAM Role</a> and the <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task-iam-roles.html">IAM Role for Tasks</a> and give a example policy to demonstrate.</p>

<h2>ECS Task Execution Role</h2>

<p>The ECS Execution Role is used by the ecs-agent which runs on ECS and is responsible for:
- Pulling down docker images from ECR
- Fetching the SSM Parameters from SSM for your Task (Secrets and LogConfigurations)
- Writing Logs to CloudWatch</p>

<p>The IAM Role has been configured that the Trusted Identity is ecs so only ECS is allowed to assume credentials from the IAM Policy that is associated to the Role.</p>

<p>The trusted identity in the IAM Role to be ecs:</p>

<pre><code class="json">{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": "ecs-tasks.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
</code></pre>

<p>and the policy will look like this more or less for a example service, I am demonstrating my-dev-service:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ecr:GetAuthorizationToken",
                "ecr:BatchCheckLayerAvailability",
                "ecr:GetDownloadUrlForLayer",
                "ecr:BatchGetImage",
                "logs:CreateLogStream",
                "logs:PutLogEvents"
            ],
            "Resource": "*"
        },
        {
            "Sid": "SSMGetParameters",
            "Effect": "Allow",
            "Action": [
                "ssm:GetParameter"
            ],
            "Resource": "arn:aws:ssm:eu-west-1:*:parameter/my-service/dev/*"
        },
        {
            "Sid": "KMSDecryptParametersWithKey",
            "Effect": "Allow",
            "Action": [
                "kms:GetPublicKey",
                "kms:Decrypt",
                "kms:GenerateDataKey",
                "kms:DescribeKey"
            ],
            "Resource": "*"
        }
    ]
}
</code></pre>

<p>In the ECS Task Definition the role arn is specified as <code>"executionRoleArn"</code> in:</p>

<pre><code class="json">{
  "family": "my-dev-service",
  "executionRoleArn":"arn:aws:iam::000000000000:role/ecs-exec-role",
  "taskRoleArn":"arn:aws:iam::000000000000:role/ecs-task-role",
  "containerDefinitions": []
}
</code></pre>

<h2>ECS Task Role</h2>

<p>The ECS Task Role is used by the service that is deployed to ECS, so this will be your application requiring access to SQS as an example</p>

<p>Same as before, we set the trusted identity in the IAM Role to be ecs:</p>

<pre><code class="json">{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": "ecs-tasks.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
</code></pre>

<p>So only the ECS tasks using the role is allowed to assume credentials from the IAM Role, and the policy associated to the role, can look something like this:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowDevSQS",
            "Effect": "Allow",
            "Action": [
                "sqs:GetQueueUrl",
                "sqs:ReceiveMessage",
                "sqs:SendMessage",
                "sqs:ChangeMessageVisibility"
            ],
            "Resource": [
                "arn:aws:sqs:eu-west-1:000000000000:dev-pending-queue",
                "arn:aws:sqs:eu-west-1:000000000000:dev-confirmed-queue"
            ]
        }
    ]
}
</code></pre>

<p>The role arn will be specified in <code>"taskRoleArn"</code> from the following in the ECS Task Definition:</p>

<pre><code class="json">{
  "family": "my-dev-service",
  "executionRoleArn":"arn:aws:iam::000000000000:role/ecs-exec-role",
  "taskRoleArn":"arn:aws:iam::000000000000:role/ecs-task-role",
  "containerDefinitions": []
}
</code></pre>

<h2>Application Code</h2>

<p>In your application you don’t need to reference any aws access keys as the role will assume credentials for you by the SDK, with python a short example will be:</p>

<pre><code class="python">import boto3
sqs = boto3.Session(region_name='eu-west-1').client('sqs')
</code></pre>

<h2>Thanks</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH Using AWS SSM Session Manager]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/03/10/ssh-using-aws-ssm-session-manager/"/>
    <updated>2021-03-10T00:52:54-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/03/10/ssh-using-aws-ssm-session-manager</id>
    <content type="html"><![CDATA[<p>You can use SSM Session Manager to connect to your EC2 instances, as long as your EC2 instance has the associated IAM Role which includes the AmazonSSMManagedInstanceCore managed policy.</p>

<h2>AWS EC2 Console</h2>

<p>Head over to &ldquo;Connect&rdquo; and select &ldquo;Session Manager&rdquo;:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103775580-e8da2a80-5036-11eb-9e00-0fd9b4d9d467.png" alt="image" /></p>

<p>You should get a shell:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103775597-f2639280-5036-11eb-8101-768f1c81108a.png" alt="image" /></p>

<h2>AWS CLI</h2>

<p>You can also use the CLI:</p>

<pre><code>aws --profile prod ssm start-session --target i-0ebba722b102179b6
</code></pre>

<p>If you get this error:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103775625-ff808180-5036-11eb-88dc-be8fde3586ad.png" alt="image" /></p>

<p>Head over to:</p>

<p><a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html">https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html</a></p>

<p>Install the session manager plugin, for Mac:</p>

<pre><code>$ curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/mac/sessionmanager-bundle.zip" -o "sessionmanager-bundle.zip"
$ unzip sessionmanager-bundle.zip
$ sudo ./sessionmanager-bundle/install -i /usr/local/sessionmanagerplugin -b /usr/local/bin/session-manager-plugin
$ rm -rf sessionmanager-bundle
</code></pre>

<p>After installation:</p>

<pre><code>$ aws --profile prod ssm start-session --target i-0ebba722b102179b6
Starting session with SessionId: ruan.bekker-0b07cbbe261885ad3

sh-4.2$ sudo su - ec2-user
Last login: Wed Jan  6 12:55:03 UTC 2021 on pts/0
[ec2-user@ip-172-31-23-246 ~]$
</code></pre>

<p>Note: when you are using ssm session manager you don’t require security groups or a direct routable network to your instance.</p>

<h2>Bash Functions FTW</h2>

<p>You can implement this into a bash function:</p>

<pre><code>$ cat ~/.functions.aws
aws-ssh(){
  instance_name=${1}
  instance_id=$(aws --profile prod ec2 describe-instances --filter "Name=tag:Name,Values=${instance_name}" --query "Reservations[].Instances[?State.Name == 'running'].InstanceId[]" --output text)
  aws --profile prod ssm start-session --target ${instance_id}
}

$ aws-ssh ssm-session-manager-ssh-test2
Starting session with SessionId: ruan.bekker-04daf56c5f3668790
sh-4.2$
</code></pre>

<p>If you have your own SSH key, you can use this ~/.ssh/config:</p>

<pre><code># AWS SSM Session Manager
Host i-*
    ProxyCommand sh -c "aws --profile prod ssm start-session --target %h --document-name AWS-StartSSHSession --parameters 'portNumber=%p'"
</code></pre>

<pre><code>$ ssh -i ~/.ssh/infra.pem ec2-user@i-0ebba722b102179b6
Warning: Permanently added 'i-0ebba722b102179b6' (ECDSA) to the list of known hosts.
Last login: Wed Jan  6 13:04:03 2021

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
[ec2-user@ip-172-31-23-246 ~]$
</code></pre>

<h2>Related:</h2>

<ul>
<li><a href="https://aws.amazon.com/blogs/mt/amazon-ec2-instance-port-forwarding-with-aws-systems-manager/">https://aws.amazon.com/blogs/mt/amazon-ec2-instance-port-forwarding-with-aws-systems-manager/</a></li>
<li><a href="https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/">https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/</a></li>
</ul>


<h2>Thanks</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running SSH Commands on AWS EC2 Instances With Python]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/11/02/running-ssh-commands-on-aws-ec2-instances-with-python/"/>
    <updated>2020-11-02T09:55:43+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/11/02/running-ssh-commands-on-aws-ec2-instances-with-python</id>
    <content type="html"><![CDATA[<p>In this quick post I will demonstrate how to discover a EC2 Instance&rsquo;s Private IP Address using the AWS API by using Tags then use Paramiko in Python to SSH to the EC2 instance and run SSH commands on the target instance.</p>

<p>Install the required dependencies:</p>

<pre><code>$ virtualenv -p python3 .venv
$ source .venve/bin/activate
$ pip install boto3 paramiko
</code></pre>

<p>I have my development profile for aws configured under <code>dev</code> as can seen below:</p>

<pre><code>$ aws --profile dev configure list
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                      dev           manual    --profile
access_key     ****************xxxx      assume-role
secret_key     ****************xxxx      assume-role
    region                eu-west-1      config-file    ~/.aws/config
</code></pre>

<p>First we need to discover the private ip address from the api by referencing tags, and in this example we will use the <code>Name</code> tag:</p>

<pre><code>import boto3
ec2 = boto3.Session(profile_name='dev', region_name='eu-west-1').client('ec2')

target_instances = ec2.describe_instances(
    Filters=[{'Name':'tag:Name','Values':['my-demo-ec2-instance']}]
)

ec2_instances = []
for each_instance in target_instances['Reservations']:
    for found_instance in each_instance['Instances']:
        ec2_instances.append(found_instance['PrivateIpAddress'])

# ec2_instances
# ['172.31.2.89']
</code></pre>

<p>So we are instantiating a ec2 instance with our configured dev profile, then we describe all our instances using the tag key <code>Name</code> and value <code>my-demo-ec2-instance</code> and then access the private ip address and append it to our <code>ec2_instances</code> list.</p>

<p>Next we want to define the commands that we want to run on the target ec2 instance:</p>

<pre><code>commands = [
    "echo hi",
    "whoami",
    "hostname"
]
</code></pre>

<p>In my case I only have 1 ec2 instance with the name <code>my-demo-ec2-instance</code>, but if you have more you can just loop through the list and perform the actions.</p>

<p>Next we want to establish the SSH connection:</p>

<pre><code>k = paramiko.RSAKey.from_private_key_file("/Users/ruan/.ssh/id_rsa")
c = paramiko.SSHClient()
c.set_missing_host_key_policy(paramiko.AutoAddPolicy())
c.connect(hostname=ec2_instances[0], username="ruan", pkey=k, allow_agent=False, look_for_keys=False)
</code></pre>

<p>Once our SSH connection has established, we can loop through our commands and execute them:</p>

<pre><code>for command in commands:
    print("running command: {}".format(command))
    stdin , stdout, stderr = c.exec_command(command)
    print(stdout.read())
    print(stderr.read())
</code></pre>

<p>Which will output the folling:</p>

<pre><code>running command: echo hi
b'hi\n'
b''
running command: whoami
b'ruan\n'
b''
running command: hostname
b'ip-172-31-2-89\n'
b''
</code></pre>

<p>And then close the SSH connection:</p>

<pre><code>c.close()
</code></pre>

<p>And the full script will look like this:</p>

<pre><code class="python">import boto3
ssh_username = "ruan"
ssh_key_file = "/Users/ruan/.ssh/id_rsa"

ec2 = boto3.Session(profile_name='dev', region_name='eu-west-1').client('ec2')

target_instances = ec2.describe_instances(
    Filters=[{'Name':'tag:Name','Values':['my-demo-ec2-instance']}]
)

ec2_instances = []
for each_instance in target_instances['Reservations']:
    for found_instance in each_instance['Instances']:
        ec2_instances.append(found_instance['PrivateIpAddress'])

commands = [
    "echo hi",
    "whoami",
    "hostname"
]

k = paramiko.RSAKey.from_private_key_file(ssh_key_file)
c = paramiko.SSHClient()
c.set_missing_host_key_policy(paramiko.AutoAddPolicy())
c.connect(hostname=ec2_instances[0], username=ssh_username, pkey=k, allow_agent=False, look_for_keys=False)

for command in commands:
    print("running command: {}".format(command))
    stdin , stdout, stderr = c.exec_command(command)
    print(stdout.read())
    print(stderr.read())

c.close()
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Run Localstack as a Service Container for AWS Mock Services on Drone CI]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/04/run-localstack-as-a-service-container-for-aws-mock-services-on-drone-ci/"/>
    <updated>2020-02-04T23:43:30+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/04/run-localstack-as-a-service-container-for-aws-mock-services-on-drone-ci</id>
    <content type="html"><![CDATA[<p>In this tutorial we will setup a basic pipeline in drone to make use of service containers, we will provision localstack so that we can provision AWS mock services.</p>

<p>We will create a kinesis stream on localstack, when the service is up, we will create a stream, put 100 records in the stream, read them from the stream and delete the kinesis stream.</p>

<h2>Gitea and Drone Stack</h2>

<p>If you don’t have the stack setup, have a look at <a href="https://blog.ruanbekker.com/blog/2020/02/04/setup-gitea-and-drone-on-docker-2020-edition/">this post</a> where I go into detail on how to get that setup.</p>

<h2>Create the Drone Config</h2>

<p>In gitea, I have created a new git repository and created my drone config as <code>.drone.yml</code> with this pipeline config:</p>

<pre><code>---
kind: pipeline
type: docker
name: localstack

platform:
  os: linux
  arch: amd64

steps:
  - name: wait-for-localstack
    image: busybox
    commands:
      - sleep 10

  - name: list-kinesis-streams
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis list-streams

  - name: create-kinesis-streams
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis create-stream --stream-name mystream --shard-count 1

  - name: describe-kinesis-streams
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis describe-stream --stream-name mystream

  - name: put-record-into-kinesis
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - for record in $$(seq 1 100); do aws --endpoint-url=http://localstack:4568 kinesis put-record --stream-name mystream --partition-key 123 --data testdata_$$record ; done

  - name: get-record-from-kinesis
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - SHARD_ITERATOR=$$(aws --endpoint-url=http://localstack:4568 kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name mystream --query 'ShardIterator' --output text)
      - for each in $$(aws --endpoint-url=http://localstack:4568 kinesis get-records --shard-iterator $$SHARD_ITERATOR | jq -cr '.Records[].Data'); do echo $each | base64 -d ; echo "" ; done

  - name: delete-kinesis-stream
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis delete-stream --stream-name mystream

services:
  - name: localstack
    image: localstack/localstack
    privileged: true
    environment:
      DOCKER_HOST: unix:///var/run/docker.sock
    volumes:
      - name: docker-socket
        path: /var/run/docker.sock
      - name: localstack-vol
        path: /tmp/localstack
    ports:
      - 8080

volumes:
- name: localstack-vol
  temp: {}
- name: docker-socket
  host:
    path: /var/run/docker.sock
</code></pre>

<p>To explain what we are doing, we are bringing up localstack as a service container, then using the aws cli tools we point to the localstack kinesis endpoint, creating a kinesis stream, put 100 records to the stream, then we read from the stream and delete thereafter.</p>

<h2>Trigger the Pipeline</h2>

<p>Then I head to drone activate my new git repository and select the repository as &ldquo;Trusted&rdquo;. I commited a dummy file to trigger the pipeline and it should look like this:</p>

<p><img width="893" alt="image" src="https://user-images.githubusercontent.com/567298/73788817-63a32180-47a6-11ea-96c7-6abba7af2b27.png"></p>

<p>List Streams:</p>

<p><img width="974" alt="image" src="https://user-images.githubusercontent.com/567298/73788860-73bb0100-47a6-11ea-9c80-f2b8bfc18d53.png"></p>

<p>Put Records:</p>

<p><img width="896" alt="image" src="https://user-images.githubusercontent.com/567298/73788895-87666780-47a6-11ea-8d90-2c454ec9174a.png"></p>

<p>Delete Stream:</p>

<p><img width="924" alt="image" src="https://user-images.githubusercontent.com/567298/73788988-aebd3480-47a6-11ea-85d9-9ed7424c648b.png"></p>
]]></content>
  </entry>
  
</feed>
