<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2017-12-14T09:43:20-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Delete Old Items With Amazons DynamoDB TTL Feature]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/22/delete-old-items-with-amazons-dynamodb-ttl-feature/"/>
    <updated>2017-11-22T17:47:31-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/22/delete-old-items-with-amazons-dynamodb-ttl-feature</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/dynamodb.png" alt="" /></p>

<p>As you may know a DynamoDB Table&rsquo;s Partition Splits on 2 factors, Read/Write Capacity Units and when Storage goes over 10GB.</p>

<h2>Automatically Deleting Old Data in DynamoDB:</h2>

<p>With the TTL Feature in DynamoDB, we can enable TTL on a Attribute on our Table, the attributes value needs to have an epoc time value, more specifically, when the current time is the same as the value of on of the items attribute value, that item will be expired, which will be deleted.</p>

<h2>What we will be doing:</h2>

<ul>
<li>Use Boto3 in Python</li>
<li>Create DynamoDB Table: &lsquo;session-table&rsquo;</li>
<li>Set TTL Attribute on &lsquo;ExpirationTime&rsquo;, so whenever the epoch time is equals to the AttributeValue it will delete the item</li>
<li>Do one PUT Item with 48 Hours expiry Date from the Write</li>
<li>Do 240 PUT Items with 24 Hours expiry Date from the Write</li>
<li>Verify after 24 hours if only one item is in our table.</li>
</ul>


<h2>Pre-Requisites:</h2>

<p>Install the AWS CLI, Boto3 and configure your credentials, so that boto3 can read from your credential provider:</p>

<pre><code class="bash">$ pip install awscli
$ pip install boto3
$ aws configure
AWS Access Key ID [****************XYZ]: 
AWS Secret Access Key [****************xyz]: 
Default region name [eu-west-1]: 
Default output format [json]: 
</code></pre>

<h2>Create the Table:</h2>

<pre><code class="python">$ python

import boto3
session = boto3.Session(region_name='eu-west-1', profile_name='default')
dynamodb = session.resource('dynamodb')
table = dynamodb.create_table(
    TableName='session-table',
    KeySchema=[
        {
            'AttributeName': 'sessionid', 
            'KeyType': 'HASH'
        }
    ], 
    AttributeDefinitions=[
        {
            'AttributeName': 'sessionid', 
            'AttributeType': 'S'
        } 
    ], 
    ProvisionedThroughput={
        'ReadCapacityUnits': 2, 
        'WriteCapacityUnits': 2
    }
)
</code></pre>

<p>From the Console, enable TTL and set the TTL Attribute on <code>ExpirationTime</code></p>

<h2>Write Data to DynamoDB</h2>

<p>We have 2 functions that will write the current epoch time to the <code>CreationTime</code> attribute and <code>ExpirationTime</code> will have the current time plus the 24 hours in seconds, which will be used for the 240 items that will be written using the for loop and the other function with the 48 hours of seconds, which will be a single write item.</p>

<p>Then we will just write random data to the session data attribute:</p>

<pre><code class="python">import boto3
import time
import random
from uuid import uuid4

names = ['james', 'john', 'steve', 'peter', 'frank', 'steven', 'jonathan', 'stephen', 'will', 'adam', 'william']
retailer = ['shoprite', 'edgars', 'pnp', 'bestbuy', 'ok', 'grocer-a', 'amazon', 'seveneleven', 'shop-a']

session = boto3.Session(region_name='eu-west-1', profile_name='dev')
ddb = session.resource('dynamodb')
client = ddb.Table('session-table')

def current_time():
    int(time.time())

def current_time():
    return int(time.time())

def expiration_time():
    return int(time.time()) + 86400

def 48h_expiration_time():
    return int(time.time()) + 172800

# expiry on 48 hours
client.put_item(
    Item={
        'sessionid': str(uuid4()),
        'CreationTime': current_time(),
        'ExpirationTime': 48h_expiration_time(),
        'SessionData': {
            'Name': random.choice(names),
            'Retailer': random.choice(retailer),
            'TimeOfTransaction': current_time(),
            'Amount': random.randint(100,9000)
        }
    }
)

# expiry on 24 hours
for x in xrange(240):
    time.sleep(1)
    client.put_item(
        Item={
            'sessionid': str(uuid4()),
            'CreationTime': current_time(),
            'ExpirationTime': expiration_time(),
            'SessionData': {
                'Name': random.choice(names),
                'Retailer': random.choice(retailer),
                'TimeOfTransaction': current_time(),
                'Amount': random.randint(100,9000)
            }
        }
    )
</code></pre>

<h2>Verify:</h2>

<p>Verify after 24 hours if the item with the 48 hour expiration time is still in our table:</p>

<pre><code class="python">client.get_item( Key={'sessionid': '69c2a472-f70e-4d72-b25f-e27573696b0c'} )['Item']

{
    u'ExpirationTime': Decimal('1510672221'),
    u'CreationTime': Decimal('1510585821'),
    u'sessionid': u'69c2a472-f70e-4d72-b25f-e27573696b0c',
    u'SessionData': {
        u'Amount': Decimal('3553'),
        u'Retailer': u'amazon',
        u'TimeOfTransaction': Decimal('1510585821'),
        u'Name': u'steve'
    }
}
</code></pre>

<p>Which we can see is still there, when doing a GET item on one of our 24 hour expired items, we can see that its no longer there:</p>

<pre><code class="python">client.get_item( Key={'sessionid': '70b9fc8c-19c4-49d3-bf63-046e992335af'} )['Item']

Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
KeyError: 'Item'
</code></pre>

<p>Doing a SCAN operation, we should see one item:</p>

<pre><code class="python">import json
r = client.scan(TableName='session-table', Limit=10, Select='COUNT', ReturnConsumedCapacity='TOTAL')

print(json.dumps(r, indent=4))
{
    "Count": 1,
    "ScannedCount": 1,
    "ConsumedCapacity": {
        "CapacityUnits": 0.5,
        "TableName": "session-table"
    },
    "ResponseMetadata": {
        "RetryAttempts": 0,
        "HTTPStatusCode": 200,
        "RequestId": "",
        "HTTPHeaders": {
            "x-amzn-requestid": "",
            "content-length": "107",
            "server": "Server",
            "connection": "keep-alive",
            "x-amz-crc32": "2228370918",
            "date": "Tue, 14 Nov 2017 12:02:31 GMT",
            "content-type": "application/x-amz-json-1.0"
        }
    }
}
</code></pre>

<p>So we can confirm that the TTL feature expires the data based on the epoch value we provide our item.</p>

<h2>Delete the Table:</h2>

<pre><code class="python">client.delete(TableName='session-table')
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://sysadmins.co.za/interfacing-amazon-dynamodb-with-python-using-boto3/">https://sysadmins.co.za/interfacing-amazon-dynamodb-with-python-using-boto3/</a></li>
<li><a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html">http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing Elastalert for Elasticsearch on Amazon Linux]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/07/installing-elastalert-for-elasticsearch-on-amazon-linux/"/>
    <updated>2017-11-07T07:53:33-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/07/installing-elastalert-for-elasticsearch-on-amazon-linux</id>
    <content type="html"><![CDATA[<p>Elastalert, a service for Alerting with Elasticsearch:</p>

<ul>
<li><a href="https://github.com/Yelp/elastalert">https://github.com/Yelp/elastalert</a></li>
</ul>


<h2>Setting up Elastalert</h2>

<p>We will setup Elastalert for Elasticsearch on Amazon Linux which is a RHEL Based Distribution.</p>

<p>Setting up dependencies</p>

<pre><code class="bash">$ sudo su
# yum update -y
# yum install git python-devel lib-devel libevent-devel bzip2-devel openssl-devel ncurses-devel zlib zlib-devel xz-devel gcc -y
# yum install python-setuptools -y
# easy_install pip
# pip install virtualenv
# virtualenv .venv
# source .venv/bin/activate
# pip install pip --upgrade
# pip install setuptools --upgrade
</code></pre>

<p>Clone Elastalert Repository and Install Dependencies:</p>

<pre><code class="bash">$ git clone https://github.com/Yelp/elastalert
$ cd elastalert/
$ pip install -r requirements.txt
</code></pre>

<p>Configs:</p>

<pre><code class="bash">$ cp config.yaml.example config.yaml
$ vim config.yaml
$ vim example_rules/example_frequency.yaml
</code></pre>

<p>After opening the config, populate the configuration where needed.</p>

<p>Installation of elastalert:</p>

<pre><code class="bash">$ python setup.py install
$ elastalert-create-index
</code></pre>

<p>Running elastalert:</p>

<pre><code class="bash">$ python -m elastalert.elastalert --verbose --rule example_frequency.yaml
INFO:elastalert:Starting up
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Script to Decrypt Encrypted Data With AWS KMS]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/10/20/python-script-to-decrypt-encrypted-data-with-aws-kms/"/>
    <updated>2017-10-20T04:54:51-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/10/20/python-script-to-decrypt-encrypted-data-with-aws-kms</id>
    <content type="html"><![CDATA[<p>Quick script to decrypt data that was encrypted with your KMS key:</p>

<h2>The Script:</h2>

<p>The script requires the encrypted scring as an argument:</p>

<pre><code class="python">#!/usr/bin/env python

import boto3
import sys
from base64 import b64decode

try:
    encrypted_value = sys.argv[1]
except IndexError:
    print("Usage: {} {}".format(sys.argv[0], 'the-encrypted-string'))
    exit(1)

session = boto3.Session(
        region_name='eu-west-1',
        profile_name='default'
    )

kms = session.client('kms')

response = kms.decrypt(CiphertextBlob=b64decode(encrypted_value))['Plaintext']
print("Decrypted Value: {}".format(response))
</code></pre>

<p>Change the permissions so that the file is executable:</p>

<pre><code class="bash">$ chmod +x decrypt.py
</code></pre>

<h2>Usage:</h2>

<pre><code class="bash">$ ./decrypt.py asdlaskjdasidausd09q3uoijad09ujd38u309
Decrypted Value: thisIsMyDecryptedValue
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using the AWS CLI Tools to Grab CloudWatch Metrics for Elasticsearch]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/22/using-the-aws-cli-tools-to-grab-cloudwatch-metrics-for-elasticsearch/"/>
    <updated>2017-09-22T18:06:23-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/22/using-the-aws-cli-tools-to-grab-cloudwatch-metrics-for-elasticsearch</id>
    <content type="html"><![CDATA[<p>Using the AWS CLI Tools to get CloudWatch Metrics for Elasticsearch.</p>

<h2>Elasticsearch:</h2>

<p>List the JVM Memory Pressure Metric:</p>

<pre><code class="bash">$ aws cloudwatch list-metrics --namespace AWS/ES --metric-name JVMMemoryPressure
{
    "Metrics": [
        {
            "Namespace": "AWS/ES",
            "Dimensions": [
                {
                    "Name": "DomainName",
                    "Value": "elasticsearch-cluster"
                },
                {
                    "Name": "ClientId",
                    "Value": "123456789012"
                }
            ],
            "MetricName": "JVMMemoryPressure"
        }
    ]
}
</code></pre>

<h2>Metric: JVMMemoryPressure</h2>

<p>Getting Metrics for JVMMemoryPressure, every 10 Minutes for Max Statistic:</p>

<pre><code class="bash">$ aws cloudwatch get-metric-statistics --namespace AWS/ES --dimensions Name=DomainName,Value=elasticsearch-cluster Name=ClientId,Value=123456789012 --metric-name JVMMemoryPressure --start-time 2017-09-08T04:00:00 --end-time 2017-09-08T05:00:00 --period 600 --statistics Maximum
{
    "Datapoints": [
        {
            "Timestamp": "2017-09-08T04:40:00Z",
            "Maximum": 58.7,
            "Unit": "Percent"
        },
        {
            "Timestamp": "2017-09-08T04:00:00Z",
            "Maximum": 58.5,
            "Unit": "Percent"
        },
        {
            "Timestamp": "2017-09-08T04:30:00Z",
            "Maximum": 58.7,
            "Unit": "Percent"
        },
        {
            "Timestamp": "2017-09-08T04:20:00Z",
            "Maximum": 58.5,
            "Unit": "Percent"
        },
        {
            "Timestamp": "2017-09-08T04:50:00Z",
            "Maximum": 58.7,
            "Unit": "Percent"
        },
        {
            "Timestamp": "2017-09-08T04:10:00Z",
            "Maximum": 58.5,
            "Unit": "Percent"
        }
    ],
    "Label": "JVMMemoryPressure"
}
</code></pre>

<h2>Metric: WriteIOPS</h2>

<p>Getting Metrics for WriteIOPS, Every 10 Minutes for Max Statistic:</p>

<pre><code class="bash">$ aws cloudwatch get-metric-statistics --namespace AWS/ES --dimensions Name=DomainName,Value=elasticsearch-cluster Name=ClientId,Value=123456789012 --metric-name WriteIOPS --start-time 2017-09-08T04:00:00 --end-time 2017-09-08T05:00:00 --period 600 --statistics Maximum
{
    "Datapoints": [
        {
            "Timestamp": "2017-09-08T04:30:00Z",
            "Maximum": 0.5266666666666666,
            "Unit": "Count/Second"
        },
        {
            "Timestamp": "2017-09-08T04:00:00Z",
            "Maximum": 0.0,
            "Unit": "Count/Second"
        },
        {
            "Timestamp": "2017-09-08T04:40:00Z",
            "Maximum": 0.09666666666666666,
            "Unit": "Count/Second"
        },
        {
            "Timestamp": "2017-09-08T04:10:00Z",
            "Maximum": 0.0,
            "Unit": "Count/Second"
        },
        {
            "Timestamp": "2017-09-08T04:50:00Z",
            "Maximum": 0.07,
            "Unit": "Count/Second"
        },
        {
            "Timestamp": "2017-09-08T04:20:00Z",
            "Maximum": 0.0,
            "Unit": "Count/Second"
        }
    ],
    "Label": "WriteIOPS"
}
</code></pre>

<h2>Metric: FreeStorageSpace</h2>

<p>Getting Metrics for FreeStorageSpace in Megabytes:</p>

<pre><code class="bash">$ aws cloudwatch get-metric-statistics --namespace AWS/ES --dimensions Name=DomainName,Value=elasticsearch-cluster Name=ClientId,Value=123456789012 --metric-name FreeStorageSpace --start-time 2017-09-11T05:00:00 --end-time 2017-09-11T06:00:00 --period 600 --statistics Minimum --unit Megabytes
{
    "Datapoints": [
        {
            "Timestamp": "2017-09-11T05:50:00Z",
            "Minimum": 25510.438,
            "Unit": "Megabytes"
        },
        {
            "Timestamp": "2017-09-11T05:10:00Z",
            "Minimum": 25573.032,
            "Unit": "Megabytes"
        },
        {
            "Timestamp": "2017-09-11T05:20:00Z",
            "Minimum": 25554.051,
            "Unit": "Megabytes"
        },
        {
            "Timestamp": "2017-09-11T05:30:00Z",
            "Minimum": 25540.957,
            "Unit": "Megabytes"
        },
        {
            "Timestamp": "2017-09-11T05:40:00Z",
            "Minimum": 25525.473,
            "Unit": "Megabytes"
        },
        {
            "Timestamp": "2017-09-11T05:00:00Z",
            "Minimum": 25584.383,
            "Unit": "Megabytes"
        }
    ],
    "Label": "FreeStorageSpace"
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a Postfix Relay Server That Uses SES to Relay Outbound Mail]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/16/setup-a-postfix-relay-server-that-uses-ses-to-relay-outbound-mail/"/>
    <updated>2017-09-16T18:01:49-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/16/setup-a-postfix-relay-server-that-uses-ses-to-relay-outbound-mail</id>
    <content type="html"><![CDATA[<p>We will setup a Postfix Relay Servcer which our clients will use to send out mail, the Postfix server will use Amazon&rsquo;s SES Service to send out mail, which we will configure as a relay host in Postfix.</p>

<h2>Setup EC2 Instance to Relay through AWS SES:</h2>

<p>Install Postfix and SASL:</p>

<pre><code class="bash">$ apt install postfix mailutils libsasl2-2 sasl2-bin libsasl2-modules -y
</code></pre>

<p>Section we need to configure in <code>/etc/nginx/main.cf</code>:</p>

<pre><code class="bash">relayhost = [email-smtp.eu-west-1.amazonaws.com]:587
smtp_use_tls = yes
smtp_sasl_auth_enable = yes
smtp_sasl_security_options =
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt
</code></pre>

<p>Populate SASL Passwd:</p>

<pre><code class="bash">$ cat /etc/postfix/sasl_passwd
</code></pre>

<p>Postmap the changes:</p>

<pre><code class="bash">$ postmap /etc/postfix/sasl_passwd
</code></pre>

<p>Restart Postfix:</p>

<pre><code>$ sudo /etc/init.d/postfix restart
</code></pre>

<p>Test the Mail Flow:</p>

<pre><code>$ echo test | mail -r ruan@ruanbekker.com -s 'ses test mail ' ruan@ruanbekker.com &amp;&amp; tail -f /var/log/mail.log

Jul 18 11:29:06 ip-10-1-4-250 postfix/smtp[5056]: 9FDCB469AA: to=&lt;ruan@ruanbekker.com&gt;, relay=email-smtp.eu-west-1.amazonaws.com[52.10.20.30]:587, delay=0.29, delays=0.02/0.03/0.12/0.13, dsn=2.0.0, status=sent (250 Ok 0234567d557572f2-76f56252-0a00-4d94-af87-38bd213914d2-000000)
Jul 18 11:29:06 ip-10-1-4-250 postfix/qmgr[4392]: 9FDCB469AA: removed
</code></pre>

<p>If your output looks more or less like the snippet from above, your mail should be working fine.</p>

<center>
<script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script> 
</center>

]]></content>
  </entry>
  
</feed>
