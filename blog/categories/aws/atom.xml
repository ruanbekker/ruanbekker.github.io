<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2019-11-17T01:20:24+02:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Deploy a Webapp on a AWS EKS Kubernetes Cluster]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster/"/>
    <updated>2019-11-17T00:21:19+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/68999897-f59a3d00-08cf-11ea-83c7-8624e6048106.png" alt="kubernetes-eks-deploy-webapp" /></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <a href="https://github.com/ruanbekker"><img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /></a></p>

<p><a href="https://twitter.com/ruanbekker?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @ruanbekker</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>In our previous post, <a href="https://blog.ruanbekker.com/blog/2019/11/16/how-to-setup-a-aws-eks-kubernetes-cluster/">Part 1 - Setup a EKS Cluster</a> we went through the steps on how to Setup a EKS Cluster.</p>

<h2>What are we doing today</h2>

<p>In this post, we will deploy a sample web application to EKS and access our application using a ELB that EKS provides us.</p>

<h2>Deployment Manifests</h2>

<p>We will have two manifests that we will deploy to Kubernetes, a deployment manifest that will hold the information about our application and a service manifest that will hold the information about the service load balancer.</p>

<p>The deployment manifest, you will notice that we are specifying that we want 3 containers, we are using labels so that our service and deployment can find each other and we are using a basic http web application that will listen on port 8000 inside the container:</p>

<pre><code class="bash">$ cat deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-hostname-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: ruanbekker/hostname
          ports:
          - name: http
            containerPort: 8000
</code></pre>

<p>The service manifest, you will notice that we are specifying <code>type: LoadBalancer</code> in our service manifest, this will tell EKS to provision a ELB for your application so that we can access our application from the internet.</p>

<p>You will see that the selector is specifying <code>my-app</code> which we also provided in our deployment.yml so that our service know where to find our backend application. We are also stating that the service is listening on port 80, and will forward its traffic to our deployment on port 8000:</p>

<pre><code class="bash">$ cat service.yml
apiVersion: v1
kind: Service
metadata:
  name: my-hostname-app-service
  labels:
    app: my-app
spec:
  ports:
  - port: 80
    targetPort: 8000
  selector:
    app: my-app
  type: LoadBalancer
</code></pre>

<h2>Deployment Time</h2>

<p>Deploy our application:</p>

<pre><code class="bash">$ kubectl apply -f deployment.yml
deployment.apps/my-hostname-app created
</code></pre>

<p>Deploy our service:</p>

<pre><code class="bash">$ kubectl apply -f service.yml
service/my-hostname-app-service created
</code></pre>

<p>Now when we look at our deployment, we should see that 3 replicas of our application is running:</p>

<pre><code class="bash">$ kubectl get deployments
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
my-hostname-app   3/3     3            3           4m38s
</code></pre>

<p>To see the pods of that deployment, look at the pods:</p>

<pre><code class="bash">$ kubectl get pods
NAME                               READY   STATUS    RESTARTS   AGE
my-hostname-app-5dcd48dfc5-2j8zm   1/1     Running   0          24s
my-hostname-app-5dcd48dfc5-58vkc   1/1     Running   0          24s
my-hostname-app-5dcd48dfc5-cmjwj   1/1     Running   0          24s
</code></pre>

<p>As we have more than one service in our EKS cluster, we can specify the labels that we have applied on our manifests to filter what we want to see (<code>app: my-app</code>):</p>

<pre><code class="bash">$ kubectl get service --selector app=my-app
NAME                      TYPE           CLUSTER-IP       EXTERNAL-IP                                                              PORT(S)        AGE
my-hostname-app-service   LoadBalancer   10.100.114.166   a460661ce089b11ea97cd06dd7513db6-669054126.eu-west-1.elb.amazonaws.com   80:30648/TCP   2m29s
</code></pre>

<p>As we can see EKS provisioned a ELB for us, and we can access the application by making a HTTP request:</p>

<pre><code class="bash">$ curl -i http://a460661ce089b11ea97cd06dd7513db6-669054126.eu-west-1.elb.amazonaws.com
HTTP/1.1 200 OK
Date: Sat, 16 Nov 2019 18:05:27 GMT
Content-Length: 43
Content-Type: text/plain; charset=utf-8

Hostname: my-hostname-app-5dcd48dfc5-2j8zm
</code></pre>

<h2>Scaling our Deployment</h2>

<p>Let&rsquo;s scale our deployment to 5 replicas:</p>

<pre><code class="bash">$ kubectl scale deployment/my-hostname-app --replicas 5
deployment.extensions/my-hostname-app scaled
</code></pre>

<p>After all the pods has been deployed, you should be able to see the 5 out of 5 pods that we provisioned, should be running:</p>

<pre><code class="bash">$ kubectl get deployments
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
my-hostname-app   5/5     5            5           5m7s
</code></pre>

<p>We can then also see the pods that our deployment is referencing:</p>

<pre><code class="bash">$ kubectl get pods
NAME                               READY   STATUS    RESTARTS   AGE
my-hostname-app-5dcd48dfc5-2j8zm   1/1     Running   0          6m8s
my-hostname-app-5dcd48dfc5-58vkc   1/1     Running   0          6m8s
my-hostname-app-5dcd48dfc5-cmjwj   1/1     Running   0          6m8s
my-hostname-app-5dcd48dfc5-m4xcq   1/1     Running   0          67s
my-hostname-app-5dcd48dfc5-zf6xl   1/1     Running   0          68s
</code></pre>

<h2>Further Reading on Kubernetes</h2>

<p>This is one amazing resource that covers a lot of kubernetes topics and will help you throughout your EKS journey:</p>

<ul>
<li><a href="https://eksworkshop.com/introduction/">EKSWorkshop</a></li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/worker.html">Worker Nodes Documentation</a></li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/eks-guestbook.html">Guestbook Kubernetes Sample Application</a></li>
</ul>


<h2>Thank You</h2>

<p>Let me know what you think. If you liked my content, feel free to checkout my content on <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<center><script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script></center>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Setup a AWS EKS Kubernetes Cluster]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/11/16/how-to-setup-a-aws-eks-kubernetes-cluster/"/>
    <updated>2019-11-16T22:31:36+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/11/16/how-to-setup-a-aws-eks-kubernetes-cluster</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/68999066-b8c84900-08c3-11ea-9669-5c859590296c.png" alt="kubernetes-eks-aws-cluster" /></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <a href="https://github.com/ruanbekker"><img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /></a></p>

<p><a href="https://twitter.com/ruanbekker?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @ruanbekker</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>This will be a tutorial split up in two posts, where I will show you how to provision a EKS Cluster (Elastic Kubernetes Service) on AWS and in the <a href="https://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster/">next post</a>, how to deploy a web application to your cluster (<a href="https://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster/">Part2 - Deploy a Web App to EKS</a>.)</p>

<h2>And then came EKS</h2>

<p>As some of you may know, I&rsquo;m a massive AWS fan boy, and since AWS released their managed Kubernetes service, I was quite excited to test it out. A couple of months passed and I got the opportunity to test out on-the-job as we moved to Kubernetes.</p>

<p>A couple of moths has passed, and serving multiple production workloads on EKS, and I am really impressed with the service.</p>

<p>Amazon provides a vanilla Kubernetes version, they manage the master nodes and they have a extra component called the cloud controller that runs on the master nodes, which is the aws native component that talks to other aws services (as far as I can recall)</p>

<h2>What are we doing today</h2>

<p>We will cover this in this post:</p>

<table>
<thead>
<tr>
<th> <strong>Topic</strong>                                                    </th>
</tr>
</thead>
<tbody>
<tr>
<td> Deploy a EKS Cluster                                         </td>
</tr>
<tr>
<td> View the resources to see what was provisioned on AWS        </td>
</tr>
<tr>
<td> Interact with Kubernetes using kubectl                       </td>
</tr>
<tr>
<td> Terminate a Node and verify that the ASG replaces the node   </td>
</tr>
<tr>
<td> Scale down your worker nodes                                 </td>
</tr>
<tr>
<td> Run a pod on your cluster                                    </td>
</tr>
</tbody>
</table>


<p>In the <a href="https://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster/">next post</a> we will deploy a web service to our EKS cluster.</p>

<h2>Install Pre-Requirements</h2>

<p>We require <code>awscli</code>, <code>eksctl</code> and <code>kubectl</code> before we continue. I will be installing this on MacOS, but you can have a look at the following links if you are using a different operating system:</p>

<ul>
<li><a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html">Install awscli</a></li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html">Install eksctl</a></li>
<li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Install kubectl</a></li>
</ul>


<p>Install awscli:</p>

<pre><code class="bash">$ pip install awscli
</code></pre>

<p>Install kubectl:</p>

<pre><code>$ brew update
$ brew install kubernetes-cli
</code></pre>

<p>Install eksctl:</p>

<pre><code>$ brew tap weaveworks/tap
$ brew install weaveworks/tap/eksctl
</code></pre>

<h2>Deploy EKS</h2>

<p>Create a SSH key if you would like to SSH to your worker nodes:</p>

<pre><code>$ ssh-keygen -b 2048 -f ~/.ssh/eks -t rsa -q -N ""
</code></pre>

<p>Import your public key to EC2:</p>

<pre><code>$ aws --profile dev --region eu-west-1 ec2 import-key-pair --key-name "eks" --public-key-material file://~/.ssh/eks.pub
</code></pre>

<p>Provision your cluster using eksctl. This will deploy two cloudformation stacks, one for the kubernetes cluster, and one for the node group.</p>

<p>I am creating a kubernetes cluster with 3 nodes of instance type (t2.small) and using version 1.14:</p>

<pre><code class="bash">$ eksctl --profile dev --region eu-west-1 create cluster --name my-eks-cluster --version 1.14 --nodes 3 --node-type t2.small --ssh-public-key eks

[ℹ]  eksctl version 0.9.0
[ℹ]  using region eu-west-1
[ℹ]  setting availability zones to [eu-west-1a eu-west-1b eu-west-1c]
[ℹ]  subnets for eu-west-1a - public:192.168.0.0/19 private:192.168.96.0/19
[ℹ]  subnets for eu-west-1b - public:192.168.32.0/19 private:192.168.128.0/19
[ℹ]  subnets for eu-west-1c - public:192.168.64.0/19 private:192.168.160.0/19
[ℹ]  nodegroup "ng-f27f560e" will use "ami-059c6874350e63ca9" [AmazonLinux2/1.14]
[ℹ]  using Kubernetes version 1.14
[ℹ]  creating EKS cluster "my-eks-cluster" in "eu-west-1" region
[ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup
[ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=eu-west-1 --cluster=my-eks-cluster'
[ℹ]  CloudWatch logging will not be enabled for cluster "my-eks-cluster" in "eu-west-1"
[ℹ]  you can enable it with 'eksctl utils update-cluster-logging --region=eu-west-1 --cluster=my-eks-cluster'
[ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "my-eks-cluster" in "eu-west-1"
[ℹ]  2 sequential tasks: { create cluster control plane "my-eks-cluster", create nodegroup "ng-f27f560e" }
[ℹ]  building cluster stack "eksctl-my-eks-cluster-cluster"
[ℹ]  deploying stack "eksctl-my-eks-cluster-cluster"
[ℹ]  building nodegroup stack "eksctl-my-eks-cluster-nodegroup-ng-f27f560e"
[ℹ]  --nodes-min=3 was set automatically for nodegroup ng-f27f560e
[ℹ]  --nodes-max=3 was set automatically for nodegroup ng-f27f560e
[ℹ]  deploying stack "eksctl-my-eks-cluster-nodegroup-ng-f27f560e"
[+]  all EKS cluster resources for "my-eks-cluster" have been created
[+]  saved kubeconfig as "/Users/ruan/.kube/config"
[ℹ]  adding identity "arn:aws:iam::000000000000:role/eksctl-my-eks-cluster-nodegroup-n-NodeInstanceRole-SNVIW5C3J3SM" to auth ConfigMap
[ℹ]  nodegroup "ng-f27f560e" has 0 node(s)
[ℹ]  waiting for at least 3 node(s) to become ready in "ng-f27f560e"
[ℹ]  nodegroup "ng-f27f560e" has 3 node(s)
[ℹ]  node "ip-192-168-42-186.eu-west-1.compute.internal" is ready
[ℹ]  node "ip-192-168-75-87.eu-west-1.compute.internal" is ready
[ℹ]  node "ip-192-168-8-167.eu-west-1.compute.internal" is ready
[ℹ]  kubectl command should work with "/Users/ruan/.kube/config", try 'kubectl get nodes'
[+]  EKS cluster "my-eks-cluster" in "eu-west-1" region is ready
</code></pre>

<p>Now that our EKS cluster has been provisioned, let&rsquo;s browse through our AWS Management Console to understand what was provisioned.</p>

<h2>View the Provisioned Resources</h2>

<p>If we have a look at the Cloudformation stacks, we can see the two stacks that I mentioned previously:</p>

<p><img width="1057" alt="image" src="https://user-images.githubusercontent.com/567298/68996480-58c1aa80-08a3-11ea-95c1-0fcf0bc1863b.png"></p>

<p>Navigating to our EC2 Instances dashboard, we can see the three worker nodes that we provisioned. Remember that AWS manages the master nodes and we cant see them.</p>

<p><img width="1106" alt="image" src="https://user-images.githubusercontent.com/567298/68996520-ea311c80-08a3-11ea-8ea3-e9e481e4ba6f.png"></p>

<p>We have a ASG (Auto Scaling Group) associated with our worker nodes, nodegroup. We can make use of autoscaling and also have desired state, so we will test this out later where we will delete a worker node and verify if it gets replaced:</p>

<p><img width="1113" alt="image" src="https://user-images.githubusercontent.com/567298/68996551-2e242180-08a4-11ea-8df6-7b962b9aa03a.png"></p>

<h2>Navigate using Kubectl:</h2>

<p>Eksctl already applied the kubeconfig to <code>~/.kube/config</code>, so we can start using kubectl. Let&rsquo;s start by viewing the nodes:</p>

<pre><code>$ kubectl get nodes
NAME                                           STATUS   ROLES    AGE     VERSION
ip-192-168-42-186.eu-west-1.compute.internal   Ready    &lt;none&gt;   8m50s   v1.14.7-eks-1861c5
ip-192-168-75-87.eu-west-1.compute.internal    Ready    &lt;none&gt;   8m55s   v1.14.7-eks-1861c5
ip-192-168-8-167.eu-west-1.compute.internal    Ready    &lt;none&gt;   8m54s   v1.14.7-eks-1861c5
</code></pre>

<p>Viewing our pods from our <code>kube-system</code> namespace (we dont have any pods in our default namespace at the moment):</p>

<pre><code>$ kubectl get pods --namespace kube-system
NAME                       READY   STATUS    RESTARTS   AGE
aws-node-btfbk             1/1     Running   0          11m
aws-node-c6ktk             1/1     Running   0          11m
aws-node-wf8mc             1/1     Running   0          11m
coredns-759d6fc95f-ljxzf   1/1     Running   0          17m
coredns-759d6fc95f-s6lg6   1/1     Running   0          17m
kube-proxy-db46b           1/1     Running   0          11m
kube-proxy-ft4mc           1/1     Running   0          11m
kube-proxy-s5q2w           1/1     Running   0          11m
</code></pre>

<p>And our services from all our namespaces:</p>

<pre><code>$ kubectl get services --all-namespaces
NAMESPACE     NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE
default       kubernetes   ClusterIP   10.100.0.1    &lt;none&gt;        443/TCP         19m
kube-system   kube-dns     ClusterIP   10.100.0.10   &lt;none&gt;        53/UDP,53/TCP   19m
</code></pre>

<h2>Testing the ASG</h2>

<p>Let&rsquo;s view our current nodes in our cluster, then select the first node, delete it and verify if the ASG replaces that node.</p>

<p>First, view the nodes and select one node&rsquo;s address:</p>

<pre><code>$ kubectl get nodes
NAME                                           STATUS   ROLES    AGE   VERSION
ip-192-168-42-186.eu-west-1.compute.internal   Ready    &lt;none&gt;   37m   v1.14.7-eks-1861c5
ip-192-168-75-87.eu-west-1.compute.internal    Ready    &lt;none&gt;   37m   v1.14.7-eks-1861c5
ip-192-168-8-167.eu-west-1.compute.internal    Ready    &lt;none&gt;   37m   v1.14.7-eks-1861c5
</code></pre>

<p>Use the awscli to lookup the EC2 instance id, as we will need this id to delete the node:</p>

<pre><code>$ aws --profile dev ec2 describe-instances --query 'Reservations[*].Instances[?PrivateDnsName==`ip-192-168-42-186.eu-west-1.compute.internal`].[InstanceId][]' --output text
i-0d016de17a46d5178
</code></pre>

<p>Now that we have the EC2 instance id, delete the node:</p>

<pre><code>$ aws --profile dev ec2 terminate-instances --instance-id i-0d016de17a46d51782
{
    "TerminatingInstances": [
        {
            "CurrentState": {
                "Code": 32,
                "Name": "shutting-down"
            },
            "InstanceId": "i-0d016de17a46d5178",
            "PreviousState": {
                "Code": 16,
                "Name": "running"
            }
        }
    ]
}
</code></pre>

<p>Now that we have deleted the EC2 instance, view the nodes and you will see the node has been terminated:</p>

<pre><code>$ kubectl get nodes
NAME                                          STATUS   ROLES    AGE   VERSION
ip-192-168-75-87.eu-west-1.compute.internal   Ready    &lt;none&gt;   41m   v1.14.7-eks-1861c5
ip-192-168-8-167.eu-west-1.compute.internal   Ready    &lt;none&gt;   41m   v1.14.7-eks-1861c5
</code></pre>

<p>Allow about a minute so that the ASG can replace the node, and when you list again you will see that the ASG replaced the node :</p>

<pre><code>$ kubectl get nodes
NAME                                          STATUS   ROLES    AGE   VERSION
ip-192-168-42-61.eu-west-1.compute.internal   Ready    &lt;none&gt;   50s   v1.14.7-eks-1861c5
ip-192-168-75-87.eu-west-1.compute.internal   Ready    &lt;none&gt;   42m   v1.14.7-eks-1861c5
ip-192-168-8-167.eu-west-1.compute.internal   Ready    &lt;none&gt;   42m   v1.14.7-eks-1861c5
</code></pre>

<h2>Run a Pod</h2>

<p>Run a busybox pod on your EKS cluster:</p>

<pre><code>$ kubectl run --rm -it --generator run-pod/v1 my-busybox-pod --image busybox -- /bin/sh
</code></pre>

<p>You will be dropped into a shell:</p>

<pre><code>/ # busybox | head -1
BusyBox v1.31.1 (2019-10-28 18:40:01 UTC) multi-call binary.
</code></pre>

<p>And exit the shell:</p>

<pre><code>/ # exit
Session ended, resume using 'kubectl attach my-busybox-pod -c my-busybox-pod -i -t' command when the pod is running
pod "my-busybox-pod" deleted
</code></pre>

<h2>Scaling Nodes</h2>

<p>While I will not be covering auto-scaling in this post, we can manually scale the worker node count. Let&rsquo;s scale it down to 1 node.</p>

<p>First we need to get the EKS cluster name:</p>

<pre><code>$ eksctl --profile dev --region eu-west-1 get clusters
NAME        REGION
my-eks-cluster  eu-west-1
</code></pre>

<p>Then we need the node group id:</p>

<pre><code>$ eksctl --profile dev --region eu-west-1 get nodegroup --cluster my-eks-cluster
CLUSTER     NODEGROUP   CREATED         MIN SIZE    MAX SIZE    DESIRED CAPACITY    INSTANCE TYPE   IMAGE ID
my-eks-cluster  ng-f27f560e 2019-11-16T16:55:41Z    3       3       3           t2.small    ami-059c6874350e63ca9
</code></pre>

<p>Now that we have the node group id, we can scale the node count:</p>

<pre><code>$ eksctl --profile dev --region eu-west-1 scale nodegroup --cluster my-eks-cluster --nodes 1 ng-f27f560e

[ℹ]  scaling nodegroup stack "eksctl-my-eks-cluster-nodegroup-ng-f27f560e" in cluster eksctl-my-eks-cluster-cluster
[ℹ]  scaling nodegroup, desired capacity from 3 to 1, min size from 3 to 1
</code></pre>

<p>Now when we use kubectl to view the nodes, we will see we only have 1 worker node:</p>

<pre><code>$ kubectl get nodes
NAME                                          STATUS   ROLES    AGE   VERSION
ip-192-168-8-167.eu-west-1.compute.internal   Ready    &lt;none&gt;   73m   v1.14.7-eks-1861c5
</code></pre>

<h2>Clean Up</h2>

<p>If you want to follow along deploying a web application to your EKS cluster before we terminate the cluster, have a look at <a href="https://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster/">Part 2 - EKS Tutorial</a> before continuing.</p>

<p>Once you are ready to terminate your EKS cluster, you can go ahead and terminate the cluster:</p>

<pre><code>$ eksctl --profile dev --region eu-west-1 delete cluster --name my-eks-cluster

[ℹ]  eksctl version 0.9.0
[ℹ]  using region eu-west-1
[ℹ]  deleting EKS cluster "my-eks-cluster"
[+]  kubeconfig has been updated
[ℹ]  cleaning up LoadBalancer services
[ℹ]  2 sequential tasks: { delete nodegroup "ng-f27f560e", delete cluster control plane "my-eks-cluster" [async] }
[ℹ]  will delete stack "eksctl-my-eks-cluster-nodegroup-ng-f27f560e"
[ℹ]  waiting for stack "eksctl-my-eks-cluster-nodegroup-ng-f27f560e" to get deleted
[ℹ]  will delete stack "eksctl-my-eks-cluster-cluster"
[+]  all cluster resources were deleted
</code></pre>

<h2>Further Reading on Kubernetes</h2>

<p>This is one amazing resource that covers a lot of kubernetes topics and will help you throughout your EKS journey:
- <a href="https://eksworkshop.com/introduction/">EKSWorkshop</a></p>

<h2>Thank You</h2>

<p>Let me know what you think. If you liked my content, feel free to checkout my content on <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<center><script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script></center>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing AWS Lambda Functions Locally on Docker With LambCi]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/11/14/testing-aws-lambda-functions-locally-on-docker-with-lambci/"/>
    <updated>2019-11-14T23:57:10+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/11/14/testing-aws-lambda-functions-locally-on-docker-with-lambci</id>
    <content type="html"><![CDATA[<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <a href="https://github.com/ruanbekker"><img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /></a></p>

<p><a href="https://twitter.com/ruanbekker?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @ruanbekker</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>I discovered a Docker image called <strong>LambCi</strong> that allows you to test lambda functions locally on docker and wanted to share with you how it works.</p>

<h2>Python Lambda Function</h2>

<p>We will create a basic lambda function to demonstrate how it works.</p>

<pre><code>$ mkdir task
$ cat &gt; task/lambda_function.py &lt;&lt; EOF
import json

def lambda_handler(event, context):
    if event:

        try:
            event['name']
            name = event['name']
            output_string = 'My name is {}'.format(name.capitalize())

        except KeyError:
            output_string = 'A name was not defined in the event payload'

    return output_string
EOF
</code></pre>

<p>Now that we&rsquo;ve created the function, run the docker container with the parameters of the functions handler method and the event parameters:</p>

<pre><code>$ docker run --rm -v "$PWD/task":/var/task lambci/lambda:python3.7 lambda_function.lambda_handler '{"name": "ruan"}'
START RequestId: 70025895-1233-1362-8006-c2784b5d80b6 Version: $LATEST
END RequestId: 70025895-1233-1362-8006-c2784b5d80b6
REPORT RequestId: 70025895-1233-1362-8006-c2784b5d80b6  Duration: 7.51 ms   Billed Duration: 100 ms Memory Size: 1536 MB    Max Memory Used: 23 MB
"My name is Ruan"
</code></pre>

<p>And another call:</p>

<pre><code>$ docker run --rm -v "$PWD/task":/var/task lambci/lambda:python3.7 lambda_function.lambda_handler '{"nam": "ruan"}'
START RequestId: f7ab2e97-05db-1184-a009-11b92638534f Version: $LATEST
END RequestId: f7ab2e97-05db-1184-a009-11b92638534f
REPORT RequestId: f7ab2e97-05db-1184-a009-11b92638534f  Duration: 5.32 ms   Billed Duration: 100 ms Memory Size: 1536 MB    Max Memory Used: 23 MB
"A name was not defined in the event payload"
</code></pre>

<p>Checkout the dockerhub page for more info:
- <a href="https://hub.docker.com/r/lambci/lambda/">https://hub.docker.com/r/lambci/lambda/</a></p>

<h2>Thank You</h2>

<p>Let me know what you think. If you liked my content, feel free to checkout my content on <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<center><script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script></center>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Expire Objects in AWS S3 Automatically After 30 Days]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/09/12/expire-objects-in-aws-s3-automatically-after-30-days/"/>
    <updated>2019-09-12T22:37:11+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/09/12/expire-objects-in-aws-s3-automatically-after-30-days</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/aws-logo.png" alt="" /></p>

<p>In AWS S3 you can make use of lifecycle policies to manage the lifetime of your objects stored in S3.</p>

<p>In this tutorial, I will show you how to delete objects automatically from S3 after 30 days.</p>

<h2>Navigate to your Bucket</h2>

<p>Head over to your AWS S3 bucket where you want to delete objects after they have been stored for 30 days:</p>

<p><img width="1039" alt="0400F9CB-9223-4FDF-8FA5-D0BC1FA8EB71" src="https://user-images.githubusercontent.com/567298/64819546-c3f2b600-d5ae-11e9-93ba-13777e9b02b0.png"></p>

<h2>Lifecycle Policies</h2>

<p>Select &ldquo;Management&rdquo; and click on &ldquo;Add lifecycle rule&rdquo;:</p>

<p><img width="701" alt="9BB26C7C-F251-45C4-AE44-A34459BD0F4B" src="https://user-images.githubusercontent.com/567298/64819628-f00e3700-d5ae-11e9-9740-8aa3608163a7.png"></p>

<p>Set a rule name of choice and you have the option to provide a prefix if you want to delete objects based on a specific prefix. I will leave this blank as I want to delete objects in the root level of the bucket. Head to next on the following section:</p>

<p><img width="700" alt="AEF8B151-3FA8-454F-AC71-778A531BD1EE" src="https://user-images.githubusercontent.com/567298/64819785-58f5af00-d5af-11e9-8485-fb0dca3a02ac.png"></p>

<p>From the &ldquo;Transitions&rdquo; section, configure the transition section, by selecting to expire the current version of the object after 30 days:</p>

<p><img width="701" alt="2B395671-A4C0-4E5A-82E7-00EE6579DB5A" src="https://user-images.githubusercontent.com/567298/64819851-7c205e80-d5af-11e9-98d7-7e1dd09bcfef.png"></p>

<p>Review the configuration:</p>

<p><img width="705" alt="F7F8E800-62FF-4156-B506-5FB9BCC148E0" src="https://user-images.githubusercontent.com/567298/64819869-893d4d80-d5af-11e9-8034-8a2e3a8939f8.png"></p>

<p>When you select &ldquo;Save&rdquo;, you should be returned to the following section:</p>

<p><img width="1041" alt="8421EBCE-9503-4259-92AA-DB66C6F532AF" src="https://user-images.githubusercontent.com/567298/64819895-99edc380-d5af-11e9-84b4-7f4cc69cfd2e.png"></p>

<h2>Housecleaning on your S3 Bucket</h2>

<p>Now 30 days after you created objects on AWS S3, they will be deleted.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS S3 KMS and Python for Secrets Management]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/09/04/aws-s3-kms-and-python-for-secrets-management/"/>
    <updated>2019-09-04T19:58:45+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/09/04/aws-s3-kms-and-python-for-secrets-management</id>
    <content type="html"><![CDATA[<p><img src="https://miro.medium.com/max/2400/1*9PSzVZDHjr321CpxJHcxPQ.png" alt="" /></p>

<p>So your application need to store secrets and you are looking for a home for them. In this tutorial we will see how we can use Python, S3 and KMS to build our own solution for managing secrets.</p>

<p>There is SSM and Secrets Manager that probably does a better job, but my mind got curious :D</p>

<h2>High Level Goal</h2>

<p>From a High-Level we want to store secrets encrypted on S3 with KMS, namespaced with <strong>team/application/environment/value</strong> in json format so that our application receives the json dictionary of configured key/value pairs.</p>

<p>We can leverage <strong>IAM</strong> to delegate permissions on the namespacing that we decide on, for my example the namespace will look like this on S3:</p>

<pre><code>s3://s3bucket/secrets/engineering/app1/production/appconfig.json
</code></pre>

<p>We will apply <strong>IAM</strong> permissions for our user to only <strong>Put</strong> and <strong>Get</strong> on <code>secrets/engineering*</code>. So with this idea we can apply IAM permissions on groups for different departments, or even let users manage their own secrets such as:</p>

<pre><code>s3://s3bucket/secrets/personal/user.name/app/appconfig.json
</code></pre>

<p>After the object has been downloaded from S3 and decrypted using KMS, the value of the object will look like this:</p>

<pre><code>{u'surname': u'bekker', u'name': u'ruan', u'job_title': u'systems-development-engineer'}
</code></pre>

<h2>Requirements</h2>

<p>We will create the following resources on AWS:</p>

<ul>
<li>KMS Key</li>
<li>S3 Bucket</li>
<li>IAM User</li>
<li>IAM Policy</li>
<li>Python Dependencies: Boto3</li>
</ul>


<h2>Provision AWS Resources</h2>

<p><img src="https://miro.medium.com/max/2728/1*Lq9xaUXuNo2Nb8kQakYdsg.png" alt="" /></p>

<p>First we will create our <strong>S3 Bucket</strong>,  head over to <a href="https://s3.console.aws.amazon.com/s3/home?region=eu-west-1">Amazon S3</a> create a new s3 bucket, make sure that the bucket is <strong>NOT</strong> public, by using the default configuration, you should be good.</p>

<p>Once your S3 Bucket is provisioned, head over to <a href="https://console.aws.amazon.com/iam/home#/users">Amazon IAM</a> and create a IAM User, enable programmatic access, and keep your access key and secret key safe. For now we will not apply any permissions as we will come back to this step.</p>

<p>Head over to <a href="https://eu-west-1.console.aws.amazon.com/kms/home?region=eu-west-1#/kms/home">Amazon KMS</a> and create a KMS Key, we will define the <strong>key administrator</strong>, which will be my user (ruan.bekker in this case) with more privileged permissions:</p>

<p><img src="https://miro.medium.com/max/5120/1*EUPWbCQ8nsfbBWHQI6srYw.png" alt="" /></p>

<p>and then we will define the <strong>key usage permissions</strong> (app.user in this case), which will be the user that we provisioned from the previous step, this will be the user that will encrypt and decrypt the data:</p>

<p><img src="https://miro.medium.com/max/5120/1*5xA5H0qpJ1FYTG1hUjy_Tw.png" alt="" /></p>

<p>Next, review the policy generated from the previous selected sections:</p>

<p><img src="https://miro.medium.com/max/5120/1*bLDVPFaZUDQ4EyWjACYRUw.png" alt="" /></p>

<p>Once you select finish, you will be returned to the section where your KMS Key information will be displayed, keep note of your <strong>KMS Key Alias</strong>, as we will need it later:</p>

<p><img src="https://miro.medium.com/max/5120/1*aooUMS0OyEd5hopnOUrcmA.png" alt="" /></p>

<h2>Create a IAM Policy for our App User</h2>

<p>Next we will create the IAM Policy for the user that will encrypt/decrypt and store data in S3</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "S3PutAndGetAccess",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:GetObject"
            ],
            "Resource": "arn:aws:s3:::arn:aws:s3:::s3-bucket-name/secrets/engineering*"
        },
        {
            "Sid": "KMSDecryptAndEncryptAccess",
            "Effect": "Allow",
            "Action": [
                "kms:Decrypt",
                "kms:Encrypt"
            ],
            "Resource": "arn:aws:kms:eu-west-1:123456789012:key/xxxx-xxxx-xxxx-xxxx-xxxx"
        }
    ]
}
</code></pre>

<p>After the policy has been saved, associate the policy to the IAM User</p>

<h2>Encrypt and Put to S3</h2>

<p>Now we will use Python to define the data that we want to <strong>store in S3</strong>, we will then <strong>encrypt</strong> the data with <strong>KMS</strong>, use base64 to <strong>encode</strong> the ciphertext and push the encrypted value to <strong>S3</strong>, with Server Side Encryption enabled, which we will also use our KMS key.</p>

<p>Install boto3 in Python:</p>

<pre><code class="bash">$ pip install boto3
</code></pre>

<p>Enter the Python REPL and import the required packages, we will also save the access key and secret key as variables so that we can use it with boto3. You can also save it to the <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html">credential provider</a> and utilise the profile name:</p>

<pre><code class="python">&gt;&gt;&gt; import boto3
&gt;&gt;&gt; import json
&gt;&gt;&gt; import base64
&gt;&gt;&gt; aws_access_key_id='redacted'
&gt;&gt;&gt; aws_secret_access_key='redacted'
</code></pre>

<p>Next define the data that we want to <strong>encrypt and store</strong> in S3:</p>

<pre><code class="python">&gt;&gt;&gt; mydata = {
    "name": "ruan",
    "surname": "bekker",
    "job_title": "systems-development-engineer"
}
</code></pre>

<p>Next we will use KMS to encrypt the data and use base64 to encode the ciphertext:</p>

<pre><code class="python">&gt;&gt;&gt; kms = boto3.Session(
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key
).client('kms')
&gt;&gt;&gt; ciphertext = kms.encrypt(
    KeyId='alias/secrets-key',
    Plaintext=json.dumps(mydata)
)
&gt;&gt;&gt; encoded_ciphertext = base64.b64encode(ciphertext["CiphertextBlob"])
# preview the data
&gt;&gt;&gt; encoded_ciphertext
'AQICAHiKOz...42720nCleoI26UW7P89lPdwvV8Q=='
</code></pre>

<p>Next we will use S3 to push the encrypted data onto S3 in our name spaced key: <strong>secrets/engineering/app1/production/appconfig.json</strong></p>

<pre><code class="python">&gt;&gt;&gt; s3 = boto3.Session(
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name='eu-west-1'
).client('s3')
&gt;&gt;&gt; response = s3.put_object(
    Body=encoded_ciphertext,
    Bucket='ruan-secret-store',
    Key='secrets/engineering/app1/production/appconfig.json',
    ServerSideEncryption='aws:kms',
    SSEKMSKeyId='alias/secrets-key'
)
</code></pre>

<p>Now our object is stored in S3, encrypted with KMS and ServerSideEncryption Enabled.</p>

<p>You can try to download the object and decode the base64 encoded file and you will find that its complete garbage as its encrypted.</p>

<p>Next we will use S3 to Get the object and use KMS to decrypt and use base64 to decode after the object has been decrypted:</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.get_object(
    Bucket='ruan-secret-store',
    Key='secrets/engineering/app1/production/appconfig.json'
)
&gt;&gt;&gt; encoded_ciphertext = response['Body'].read()
&gt;&gt;&gt; encoded_ciphertext
'AQICAHiKOz...42720nCleoI26UW7P89lPdwvV8Q=='
</code></pre>

<p>Now let’s decode the result with base64:</p>

<pre><code class="python">&gt;&gt;&gt; decoded_ciphertext = base64.b64decode(encoded_ciphertext)
&gt;&gt;&gt; plaintext = kms.decrypt(CiphertextBlob=bytes(decoded_ciphertext))
</code></pre>

<p>Now we need to deserialize the JSON as it’s in string format:</p>

<pre><code>&gt;&gt;&gt; json.loads(plaintext["Plaintext"])
{u'surname': u'bekker', u'name': u'ruan', u'job_title': u'systems-development-engineer'}
</code></pre>

<h2>Using it in a Application</h2>

<p>Let’s say you are using <strong>Docker</strong> and you want to bootstrap your application configs to your environment that you are retrieving from S3.</p>

<p>We will use a <code>get_secrets.py</code> python script that will read the data into memory, decrypt and write the values in plaintext to disk, then we will use the <code>boot.sh</code> script to read the values into the environment and remove the temp file that was written to disk, then start the application since we have the values stored in our environment.</p>

<p>Our <strong>&ldquo;application&rdquo;</strong> in this example will just be a line of echo to return the values for demonstration.</p>

<p>The <code>get_secrets.py</code> file:</p>

<pre><code class="python">import boto3
import json
import base64

aws_access_key_id='redacted'
aws_secret_access_key='redacted'

kms = boto3.Session(aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key).client('kms')
s3 = boto3.Session(aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, region_name='eu-west-1').client('s3')

response = s3.get_object(Bucket='ruan-secret-store', Key='secrets/engineering/app1/production/appconfig.json')
encoded_ciphertext = response['Body'].read()

decoded_ciphertext = base64.b64decode(encoded_ciphertext)
plaintext = kms.decrypt(CiphertextBlob=bytes(decoded_ciphertext))
values = json.loads(plaintext["Plaintext"])

with open('envs.tmp', 'w') as f:
    for key in values.keys():
        f.write("{}={}".format(key.upper(), values[key]) + "\n")
</code></pre>

<p>And our <code>boot.sh</code> script:</p>

<pre><code class="bash">#!/usr/bin/env bash
source ./envs.tmp
rm -rf ./envs.tmp
echo "Hello, my name is ${NAME} ${SURNAME}, and I am a ${JOB_TITLE}"
</code></pre>

<p>Running that will produce:</p>

<pre><code>$ bash boot.sh
Hello, my name is ruan bekker, and I am a systems-development-engineer
</code></pre>

<h2>Thank You</h2>

<p>And there we have a simple and effective way of encrypting/decrypting data using S3, KMS and Python at a ridiculously cheap cost, its almost free.</p>

<p>If you liked my content, feel free to checkout my content on <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>
]]></content>
  </entry>
  
</feed>
