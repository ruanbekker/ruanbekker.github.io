<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Caching | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/caching/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2019-02-09T16:36:35-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Building a Raspberry Pi Nginx Image With Caching on Alpine for Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm/"/>
    <updated>2018-10-23T17:00:02-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm</id>
    <content type="html"><![CDATA[<p>In this guide, we will be creating a nginx reverse proxy with the ability to cache static content using a alpine image.</p>

<p>We will then push the image to gitlab&rsquo;s private registry, and then run the service on docker swarm.</p>

<h2>Create the backend service:</h2>

<p>We will upstream to our blog using ghost, which you can deploy using:</p>

<pre><code class="bash">$ docker service create --name blog --network docknet rbekker87/armhf-ghost:2.0.3
</code></pre>

<h2>Current File Structure:</h2>

<p>Our file structure for the assets we need to build the reverse proxy:</p>

<pre><code>$ find .
./conf.d
./conf.d/blog.conf
./Dockerfile
./nginx.conf
</code></pre>

<ul>
<li><code>Dockerfile</code></li>
</ul>


<pre><code>FROM hypriot/rpi-alpine-scratch
MAINTAINER Ruan Bekker

RUN apk update &amp;&amp; \
    apk add nginx &amp;&amp; \
    rm -rf /etc/nginx/nginx.conf &amp;&amp; \
    chown -R nginx:nginx /var/lib/nginx &amp;&amp; \
    rm -rf /var/cache/apk/*

ADD nginx.conf /etc/nginx/
ADD conf.d/blog.conf /etc/nginx/conf.d/

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
</code></pre>

<ul>
<li><code>nginx.conf</code></li>
</ul>


<pre><code>user nginx;
worker_processes 1;

events {
    worker_connections 1024;
    }

error_log  /var/log/nginx/nginx_error.log warn;

http {

    sendfile          on;
    tcp_nodelay       on;

    gzip              on;
    gzip_http_version 1.0;
    gzip_proxied      any;
    gzip_min_length   500;
    gzip_disable      "MSIE [1-6]\.";
    gzip_types        text/plain text/xml text/css
                      text/comma-separated-values
                      text/javascript
                      application/x-javascript
                      application/atom+xml;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;
    error_log   /var/log/nginx/error.log;

    proxy_cache_path /var/cache/nginx/ levels=1:2 keys_zone=nginx_cache:5m max_size=128m inactive=60m;

    keepalive_timeout  60;
    server_tokens      off;

    include /etc/nginx/conf.d/*.conf;

}
</code></pre>

<p>Hostname resolution to our Ghost Blog Service: In our swarm we have a service called blog which is associated to the docknet network, so the dns resolution will resolve to the vip of the service. As seen in the figure below:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
nq42a6jfwx3d        blog                replicated          1/1                 rbekker87/armhf-ghost:2.0.3
</code></pre>

<ul>
<li><code>conf.d/blog.conf</code></li>
</ul>


<pre><code>upstream ghost_blog {
    server blog:2368;
    }

server {
    listen 80;
    server_name blog.yourdomain.com;

    access_log  /var/log/nginx/blog_access.log  main;
    error_log   /var/log/nginx/blog_error.log;

    location / {

        proxy_cache                 nginx_cache;
        add_header                  X-Proxy-Cache $upstream_cache_status;
        proxy_ignore_headers        Cache-Control;
        proxy_cache_valid any       10m;
        proxy_cache_use_stale       error timeout http_500 http_502 http_503 http_504;

        proxy_pass                  http://ghost_blog;
        proxy_redirect              off;

        proxy_set_header            Host $host;
        proxy_set_header            X-Real-IP $remote_addr;
        proxy_set_header            X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header            X-Forwarded-Host $server_name;
    }
}
</code></pre>

<h2>Building the Image and Pushing to Gitlab</h2>

<p>I&rsquo;m using Gitlab in this demonstration, but you can use the registry of your choice:</p>

<pre><code>$ docker login registry.gitlab.com
$ docker build -t registry.gitlab.com/user/docker/arm-nginx:caching .
$ docker tag registry.gitlab.com/user/docker/arm-nginx:caching registry.gitlab.com/user/docker/arm-nginx:caching
$ docker push registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<h2>Deploy</h2>

<p>Create the Nginx Reverse Proxy Service on Docker Swarm:</p>

<pre><code>$ docker service create --name nginx_proxy \
--network docknet \
--publish 80:80 \
--replicas 1 \
--with-registry-auth registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<p>Listing our Services:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
je7x21l7egoh        nginx_proxy         replicated          1/1                 registry.gitlab.com/user/docker/arm-nginx:caching   *:80-&gt;80/tcp
nq42a6jfwx3d        blog                replicated          1/1                 rbekker87/armhf-ghost:2.0.3
</code></pre>

<p>Once you access your proxy on port 80, you should see your Ghost Blog Homepage like below:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/ghost-blog-main.png" alt="" /></p>

<p>Have a look at the <a href="https://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/">benchmark performance</a> when using Nginx with caching enabled</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/r/rbekker87/armhf-ghost/">https://hub.docker.com/r/rbekker87/armhf-ghost/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx Caching Performance for Static Content on Docker Swarm With RaspberryPi]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/"/>
    <updated>2018-10-23T16:41:41-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/nginx-logo.png" alt="" /></p>

<h2>The Environment:</h2>

<p>I had my Ghost Blog listening on port 2368 and exposing port 80 on Docker so that the port translation directs port 80 traffic to port 2368 on Ghost directly.</p>

<p>Alex responded on my tweet and introduced Nginx Caching:</p>

<ul>
<li><a href="https://twitter.com/alexellisuk/status/882347698636165121">https://twitter.com/alexellisuk/status/882347698636165121</a></li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/tweet-alexellis-04072017.png" alt="" /></p>

<p>With this approach benchmarking results was not so great in terms of requests per second, and as this hostname will be only used for a blog, its a great idea to cache the content, this was achieved with the help from Alex&rsquo;s blog: <a href="https://blog.alexellis.io/save-and-boost-with-nginx/">blog.alexellis.io/save-and-boost-with-nginx/</a></p>

<h2>How Nginx was Configured:</h2>

<p>I have a <a href="http://rbkr.ddns.net/building-nginx-on-alpine-image-for-docker-swarm-with-caching-enabled-config/">blogpost</a> on how I setup Nginx on an Alpine Image, where I setup caching and proxy-pass the connections through to my ghost blog.</p>

<h2>Benchmarking: Before Nginx with Caching was Implemented:</h2>

<p>When doing an apache benchmark I got <b>9.31 requests per second</b> performing the test on my LAN:</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://rbkr.ddns.net/

This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking rbkr.ddns.net (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   53.725 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2863000 bytes
HTML transferred:       2735000 bytes
Requests per second:    9.31 [#/sec] (mean)
Time per request:       1074.501 [ms] (mean)
Time per request:       107.450 [ms] (mean, across all concurrent requests)
Transfer rate:          52.04 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    2   0.5      2       6
Processing:   685 1068  68.7   1057    1306
Waiting:      683 1067  68.6   1056    1306
Total:        689 1070  68.7   1058    1312

Percentage of the requests served within a certain time (ms)
  50%   1058
  66%   1088
  75%   1102
  80%   1110
  90%   1163
  95%   1218
  98%   1240
  99%   1247
 100%   1312 (longest request)
</code></pre>

<h2>Benchmarking: After Nginx Caching was Implemented:</h2>

<p>After Nginx Caching was Implemented, I got <b>1067.73 requests per second</b> using apache benchmark over a LAN connection! Absolutely awesome!</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://blog.pistack.co.za/
This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking blog.pistack.co.za (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:        nginx
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   0.468 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2880500 bytes
HTML transferred:       2735000 bytes
Requests per second:    1067.73 [#/sec] (mean)
Time per request:       9.366 [ms] (mean)
Time per request:       0.937 [ms] (mean, across all concurrent requests)
Transfer rate:          6007.05 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        3    4   1.4      4      10
Processing:     3    5   1.6      4      10
Waiting:        2    4   1.6      4      10
Total:          6    9   2.7      8      17

Percentage of the requests served within a certain time (ms)
  50%      8
  66%      8
  75%      9
  80%      9
  90%     15
  95%     15
  98%     15
  99%     16
 100%     17 (longest request)
</code></pre>

<h2>Resources:</h2>

<p>Thanks to Alex Ellis for the suggestion on this, and definitely have a look at <a href="https://blog.alexellis.io/tag/nginx/">blog.alexellis.io</a> as he has some epic content on his blog!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Give Your Database a Break and Use Memcached to Return Frequently Accessed Data]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/09/01/give-your-database-a-break-and-use-memcached-to-return-frequently-accessed-data/"/>
    <updated>2018-09-01T17:05:10-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/09/01/give-your-database-a-break-and-use-memcached-to-return-frequently-accessed-data</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/memcached-logo.png" alt="" /></p>

<p>So let&rsquo;s take this scenario:</p>

<p>Your database is getting hammered with requests and building up some load over time and we would like to place a caching layer in front of our database that will return data from the caching layer, to reduce some traffic to our database and also improve our performance for our application.</p>

<h2>The Scenario:</h2>

<p>Our scenario will be very simple for this demonstration:</p>

<ul>
<li>Database will be using SQLite with product information (product_name, product_description)</li>
<li>Caching Layer will be Memcached</li>
<li>Our Client will be written in Python, which checks if the product name is in cache, if not a <code>GET_MISS</code> will be returned, then the data will be fetched from the database, returns it to the client and save it to the cache</li>
<li>Next time the item will be read, a <code>GET_HIT</code> will be received, then the item will be delivered to the client directly from the cache</li>
</ul>


<h2>SQL Database:</h2>

<p>As mentioned we will be using sqlite for demonstration.</p>

<p>Create the table, populate some very basic data:</p>

<pre><code class="sql">$ sqlite3 db.sql -header -column
import sqlite3 as sql
SQLite version 3.16.0 2016-11-04 19:09:39
Enter ".help" for usage hints.

sqlite&gt; create table products (product_name STRING(32), product_description STRING(32));
sqlite&gt; insert into products values('apple', 'fruit called apple');
sqlite&gt; insert into products values('guitar', 'musical instrument');
</code></pre>

<p>Read all the data from the table:</p>

<pre><code class="sql">sqlite&gt; select * from products;
product_name  product_description
------------  -------------------
apple         fruit called apple
guitar        musical instrument
sqlite&gt; .exit
</code></pre>

<h2>Run a Memcached Container:</h2>

<p>We will use docker to run a memcached container on our workstation:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 rbekker87/memcached:alpine
</code></pre>

<h2>Our Application Code:</h2>

<p>I will use <a href="https://pymemcache.readthedocs.io/en/latest/getting_started.html">pymemcache</a> as our client library. Install:</p>

<pre><code class="bash">$ virtualenv .venv &amp;&amp; source .venv/bin/activate
$ pip install pymemcache
</code></pre>

<p>Our Application Code which will be in Python</p>

<pre><code class="python">import sqlite3 as sql
from pymemcache.client import base

product_name = 'guitar'

client = base.Client(('localhost', 11211))
result = client.get(product_name)

def query_db(product_name):
    db_connection = sql.connect('db.sql')
    c = db_connection.cursor()
    try:
        c.execute('select product_description from products where product_name = "{k}"'.format(k=product_name))
        data = c.fetchone()[0]
        db_connection.close()
    except:
        data = 'invalid'
    return data

if result is None:
    print("got a miss, need to get the data from db")
    result = query_db(product_name)
    if result == 'invalid':
        print("requested data does not exist in db")
    else:
        print("returning data to client from db")
        print("=&gt; Product: {p}, Description: {d}".format(p=product_name, d=result))
        print("setting the data to memcache")
        client.set(product_name, result)

else:
    print("got the data directly from memcache")
    print("=&gt; Product: {p}, Description: {d}".format(p=product_name, d=result))
</code></pre>

<p>Explanation:</p>

<ul>
<li>We have a function that takes a argument of the product name, that makes the call to the database and returns the description of that product</li>
<li>We will make a get operation to memcached, if nothing is returned, then we know the item does not exists in our cache,</li>
<li>Then we will call our function to get the data from the database and return it directly to our client, and</li>
<li>Save it to the cache in memcached so the next time the same product is queried, it will be delivered directly from the cache</li>
</ul>


<h2>The Demo:</h2>

<p>Our Product Name is <code>guitar</code>, lets call the product, which will be the first time so memcached wont have the item in its cache:</p>

<pre><code class="bash">$ python app.py
got a miss, need to get the data from db
returning data to client from db
=&gt; Product: guitar, Description: musical instrument
setting the data to memcache
</code></pre>

<p>Now from the output, we can see that the item was delivered from the database and saved to the cache, lets call that same product and observe the behavior:</p>

<pre><code class="bash">$ python app.py
got the data directly from memcache
=&gt; Product: guitar, Description: musical instrument
</code></pre>

<p>When our cache instance gets rebooted we will lose our data that is in the cache, but since the source of truth will be in our database, data will be re-added to the cache as they are requested. That is one good reason not to rely on a cache service to be your primary data source.</p>

<p>What if the product we request is not in our cache or database, let&rsquo;s say the product <code>tree</code></p>

<pre><code class="bash">$ python app.py
got a miss, need to get the data from db
requested data does not exist in db
</code></pre>

<p>This was a really simple scenario, but when working with masses amount of data, you can benefit from a lot of performance using caching.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://realpython.com/python-memcache-efficient-caching/">https://realpython.com/python-memcache-efficient-caching/</a></li>
<li><a href="https://github.com/ruanbekker/dockerhub-sources/tree/master/memcached/alpine">https://github.com/ruanbekker/dockerhub-sources/tree/master/memcached/alpine</a></li>
<li><a href="https://pymemcache.readthedocs.io/en/latest/getting_started.html#basic-usage">https://pymemcache.readthedocs.io/en/latest/getting_started.html#basic-usage</a></li>
<li><a href="https://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html">https://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dockerizing a Memcached Server for Docker on Alpine]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/09/01/dockerizing-a-memcached-server-for-docker-on-alpine/"/>
    <updated>2018-09-01T16:01:09-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/09/01/dockerizing-a-memcached-server-for-docker-on-alpine</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/memcached-logo.png" alt="" /></p>

<p>This post I will demostrate how to dockerize a memcached server on Alpine and how to create a boot script that allows you to pass environment variables through to the application.</p>

<h2>What is Memcached</h2>

<p>Memcached is a multi-threaded, in-memory key/value store for small chunks of arbitrary data (strings, objects) from results of database calls, API calls, etc. More on <a href="https://memcached.org/about">Memcached</a></p>

<h2>The Dockerfile:</h2>

<p>Our Dockerfile will consist of a simple install of memcached and add a boot script that we will start it from:</p>

<pre><code class="docker">FROM alpine:3.7

COPY boot.sh /boot.sh
RUN apk --no-cache add memcached &amp;&amp; chmod +x /boot.sh

USER memcached
CMD ["/boot.sh"]
</code></pre>

<h2>The Boot Script:</h2>

<p>As you can see we have set defaults so when the user does not specify any environment variables, that it will inherit the default values</p>

<pre><code class="bash">#!/bin/sh

/usr/bin/memcached \
  --user=${MEMCACHED_USER:-memcached} \
  --listen=${MEMCACHED_HOST:-0.0.0.0} \
  --port=${MEMCACHED_PORT:-11211} \
  --memory-limit=${MEMCACHED_MEMUSAGE:-64} \
  --conn-limit=${MEMCACHED_MAXCONN:-1024} \
  --threads=${MEMCACHED_THREADS:-4} \
  --max-reqs-per-event=${MEMCACHED_REQUESTS_PER_EVENT:-20} \
  --verbose
</code></pre>

<h2>Build and Deploy:</h2>

<p>Build the image, if you just want to run the container you can use my public image in the next step:</p>

<pre><code class="bash">$ docker build -t local/memcached:0.1 .
</code></pre>

<p>Run the Memcached Container:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 -e MEMCACHED_MEMUSAGE=32 local/memcached:0.1
</code></pre>

<p>Or my Public Image from Docker Hub:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 -e MEMCACHED_MEMUSAGE=32 rbekker87/memcached:alpine
</code></pre>

<h2>Check out the Stats:</h2>

<p>Pass the command <code>stats</code> through the exposed port:</p>

<pre><code>$ echo -e "stats" | nc localhost 11211                                                               
STAT pid 8
STAT uptime 2
STAT time 1535833177
STAT version 1.5.6
STAT libevent 2.1.8-stable
STAT pointer_size 64
STAT rusage_user 0.030000
STAT rusage_system 0.000000
STAT max_connections 1024
STAT curr_connections 1
STAT total_connections 2
STAT rejected_connections 0
STAT connection_structures 2
STAT reserved_fds 20
STAT cmd_get 0
STAT cmd_set 0
STAT cmd_flush 0
STAT cmd_touch 0
STAT get_hits 0
STAT get_misses 0
STAT get_expired 0
STAT get_flushed 0
STAT delete_misses 0
STAT delete_hits 0
STAT incr_misses 0
STAT incr_hits 0
STAT decr_misses 0
STAT decr_hits 0
STAT cas_misses 0
STAT cas_hits 0
STAT cas_badval 0
STAT touch_hits 0
STAT touch_misses 0
STAT auth_cmds 0
STAT auth_errors 0
STAT bytes_read 6
STAT bytes_written 0
STAT limit_maxbytes 33554432
STAT accepting_conns 1
STAT listen_disabled_num 0
STAT time_in_listen_disabled_us 0
STAT threads 4
STAT conn_yields 0
STAT hash_power_level 16
STAT hash_bytes 524288
STAT hash_is_expanding 0
STAT slab_reassign_rescues 0
STAT slab_reassign_chunk_rescues 0
STAT slab_reassign_evictions_nomem 0
STAT slab_reassign_inline_reclaim 0
STAT slab_reassign_busy_items 0
STAT slab_reassign_busy_deletes 0
STAT slab_reassign_running 0
STAT slabs_moved 0
STAT lru_crawler_running 0
STAT lru_crawler_starts 255
STAT lru_maintainer_juggles 155
STAT malloc_fails 0
STAT log_worker_dropped 0
STAT log_worker_written 0
STAT log_watcher_skipped 0
STAT log_watcher_sent 0
STAT bytes 0
STAT curr_items 0
STAT total_items 0
STAT slab_global_page_pool 0
STAT expired_unfetched 0
STAT evicted_unfetched 0
STAT evicted_active 0
STAT evictions 0
STAT reclaimed 0
STAT crawler_reclaimed 0
STAT crawler_items_checked 0
STAT lrutail_reflocked 0
STAT moves_to_cold 0
STAT moves_to_warm 0
STAT moves_within_lru 0
STAT direct_reclaims 0
STAT lru_bumps_dropped 0
END
</code></pre>

<p>Some descriptions:</p>

<p><code>evictions</code> - when items are evicted from the cache
<code>total_items</code> - the number of items the server has stored since it was started
<code>current_items</code> - the number of items in the cache
<code>bytes</code> - the current number of bytes used to store items
<code>limit_maxbytes</code> - the number of bytes the server is allowed to use for storage
<code>get_misses</code> - the number of times a item has been requested, but not found
<code>get_hits</code> - the number of times a item has been served from the cache</p>

<p>To get specific stats, like evictions:</p>

<pre><code class="bash">$ echo -e "stats" | nc localhost 11211 | grep -w evictions   
STAT evictions 0
</code></pre>

<p>When you see evictions value increases, this essentially means that memcache had to remove the oldest items from memory for new or more frequent used items. If this number remains high, consider increasing your memory allocated to memcache.</p>

<p>Slab Stats: returns information about each of the slabs created by memcached during runtime:</p>

<pre><code class="bash">$ echo -e "stats slabs" | nc localhost 11211                 
STAT active_slabs 0
STAT total_malloced 0
</code></pre>

<p><code>active_slabs</code> - Total number of slab classes allocated.
<code>total_malloced</code> - Total amount of memory allocated to slab pages.</p>

<p>For detailed description about statistics, have a look at their github resource:
- <a href="https://github.com/memcached/memcached/blob/master/doc/protocol.txt">https://github.com/memcached/memcached/blob/master/doc/protocol.txt</a></p>

<h2>Resources:</h2>

<ul>
<li><a href="https://memcached.org/">https://memcached.org/</a></li>
<li><a href="https://blog.serverdensity.com/monitor-memcached/">https://blog.serverdensity.com/monitor-memcached/</a></li>
<li><a href="https://wiki.mikejung.biz/Memcached">https://wiki.mikejung.biz/Memcached</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving Performance From Your Lambda Function From the Use of Global Variables]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/27/improving-performance-from-your-lambda-function-from-the-use-of-global-variables/"/>
    <updated>2018-08-27T08:30:30-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/27/improving-performance-from-your-lambda-function-from-the-use-of-global-variables</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/aws-logo.png" alt="" /></p>

<p>When using Lambda and DynamoDB, you can use global variables to gain performance when your data from DynamoDB does not get updated that often, and you would like to use caching to prevent a API call to DynamoDB everytime your Lambda Function gets invoked.</p>

<p>You can use external services like Redis or Memcached when you would like to verify that each invocation is as true as your source of truth which will be DynamoDB. Then your application logic can work with caching.</p>

<p>But in this case we just want a simple piece of code that can keep the state for the remaining time that the function is running on that underlying container. I am not 100% sure, but I have seen that the data can be cached for up to 60 minutes. This can be a total mess when your data gets updated regularly, then I would set all my calls in functions, as the global variables keeps their state for some time.</p>

<script id="mNCC" language="javascript">
    medianet_width = "728";
    medianet_height = "90";
    medianet_crid = "218284798";
    medianet_versionId = "3111299"; 
  </script>


<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>


<h2>Example Function:</h2>

<p>This function gets data from DynamoDB, iterates through a small dataset (10 Items), and appends each group name to my list which is the value of my <code>groups</code> key inside my dictionary.</p>

<p>Due to my global variable <code>mydata</code>, you will see that the first invocation will result in a API call to DynamoDB as the length of my <code>mydata["groups"]</code> being 0, the second invocation, the data will exist inside my global variable, therefore I am returning the data directly from my variable.</p>

<pre><code class="python">import boto3, json

client = boto3.resource('dynamodb', region_name='eu-west-1')
tbl = client.Table('my-dynamo-table')

mydata = {}
mydata["groups"] = []

def lambda_handler(event, context):
    if len(mydata["groups"]) == 0:
        # data is not cached, make call to dynamo
        data = tbl.scan()
        group_data = data['Items']

        for group in group_data:
            mydata["groups"].append(group['name'])
        return mydata

    else:
        # return cached content
        return mydata
</code></pre>

<h2>Results of my Invocations:</h2>

<p>The first call that I made:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/lambda-caching-miss.png" alt="" /></p>

<p>The second call that I made:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/lambda-caching-hit.png" alt="" /></p>

<p>If you need a small layer of caching that can improve your latency, this can be used. But if you need your data to be accurate from every call, rather looking into a different approach and external caching services.</p>

<h2>Resources:</h2>

<p><em>Take advantage of Execution Context reuse to improve the performance of your function.</em>:</p>

<p>&ldquo;Make sure any externalized configuration or dependencies that your code retrieves are stored and referenced locally after initial execution. Limit the re-initialization of variables/objects on every invocation. Instead use static initialization/constructor, global/static variables and singletons. Keep alive and reuse connections (HTTP, database, etc.) that were established during a previous invocation.&rdquo;</p>

<ul>
<li><a href="https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html">https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html</a></li>
<li><a href="https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/">https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
