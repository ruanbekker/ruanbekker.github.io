<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Caching | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/caching/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-09-01T17:03:00-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Dockerizing a Memcached Server for Docker on Alpine]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/09/01/dockerizing-a-memcached-server-for-docker-on-alpine/"/>
    <updated>2018-09-01T16:01:09-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/09/01/dockerizing-a-memcached-server-for-docker-on-alpine</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/memcached-logo.png" alt="" /></p>

<p>This post I will demostrate how to dockerize a memcached server on Alpine and how to create a boot script that allows you to pass environment variables through to the application.</p>

<h2>What is Memcached</h2>

<p>Memcached is a multi-threaded, in-memory key/value store for small chunks of arbitrary data (strings, objects) from results of database calls, API calls, etc. More on <a href="https://memcached.org/about">Memcached</a></p>

<h2>The Dockerfile:</h2>

<p>Our Dockerfile will consist of a simple install of memcached and add a boot script that we will start it from:</p>

<pre><code class="docker">FROM alpine:3.7

COPY boot.sh /boot.sh
RUN apk --no-cache add memcached &amp;&amp; chmod +x /boot.sh

USER memcached
CMD ["/boot.sh"]
</code></pre>

<h2>The Boot Script:</h2>

<p>As you can see we have set defaults so when the user does not specify any environment variables, that it will inherit the default values</p>

<pre><code class="bash">#!/bin/sh

/usr/bin/memcached \
  --user=${MEMCACHED_USER:-memcached} \
  --listen=${MEMCACHED_HOST:-0.0.0.0} \
  --port=${MEMCACHED_PORT:-11211} \
  --memory-limit=${MEMCACHED_MEMUSAGE:-64} \
  --conn-limit=${MEMCACHED_MAXCONN:-1024} \
  --threads=${MEMCACHED_THREADS:-4} \
  --max-reqs-per-event=${MEMCACHED_REQUESTS_PER_EVENT:-20} \
  --verbose
</code></pre>

<h2>Build and Deploy:</h2>

<p>Build the image, if you just want to run the container you can use my public image in the next step:</p>

<pre><code class="bash">$ docker build -t local/memcached:0.1 .
</code></pre>

<p>Run the Memcached Container:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 -e MEMCACHED_MEMUSAGE=32 local/memcached:0.1
</code></pre>

<p>Or my Public Image from Docker Hub:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 -e MEMCACHED_MEMUSAGE=32 rbekker87/memcached:alpine
</code></pre>

<h2>Check out the Stats:</h2>

<p>Pass the command <code>stats</code> through the exposed port:</p>

<pre><code>$ echo -e "stats" | nc localhost 11211                                                               
STAT pid 8
STAT uptime 2
STAT time 1535833177
STAT version 1.5.6
STAT libevent 2.1.8-stable
STAT pointer_size 64
STAT rusage_user 0.030000
STAT rusage_system 0.000000
STAT max_connections 1024
STAT curr_connections 1
STAT total_connections 2
STAT rejected_connections 0
STAT connection_structures 2
STAT reserved_fds 20
STAT cmd_get 0
STAT cmd_set 0
STAT cmd_flush 0
STAT cmd_touch 0
STAT get_hits 0
STAT get_misses 0
STAT get_expired 0
STAT get_flushed 0
STAT delete_misses 0
STAT delete_hits 0
STAT incr_misses 0
STAT incr_hits 0
STAT decr_misses 0
STAT decr_hits 0
STAT cas_misses 0
STAT cas_hits 0
STAT cas_badval 0
STAT touch_hits 0
STAT touch_misses 0
STAT auth_cmds 0
STAT auth_errors 0
STAT bytes_read 6
STAT bytes_written 0
STAT limit_maxbytes 33554432
STAT accepting_conns 1
STAT listen_disabled_num 0
STAT time_in_listen_disabled_us 0
STAT threads 4
STAT conn_yields 0
STAT hash_power_level 16
STAT hash_bytes 524288
STAT hash_is_expanding 0
STAT slab_reassign_rescues 0
STAT slab_reassign_chunk_rescues 0
STAT slab_reassign_evictions_nomem 0
STAT slab_reassign_inline_reclaim 0
STAT slab_reassign_busy_items 0
STAT slab_reassign_busy_deletes 0
STAT slab_reassign_running 0
STAT slabs_moved 0
STAT lru_crawler_running 0
STAT lru_crawler_starts 255
STAT lru_maintainer_juggles 155
STAT malloc_fails 0
STAT log_worker_dropped 0
STAT log_worker_written 0
STAT log_watcher_skipped 0
STAT log_watcher_sent 0
STAT bytes 0
STAT curr_items 0
STAT total_items 0
STAT slab_global_page_pool 0
STAT expired_unfetched 0
STAT evicted_unfetched 0
STAT evicted_active 0
STAT evictions 0
STAT reclaimed 0
STAT crawler_reclaimed 0
STAT crawler_items_checked 0
STAT lrutail_reflocked 0
STAT moves_to_cold 0
STAT moves_to_warm 0
STAT moves_within_lru 0
STAT direct_reclaims 0
STAT lru_bumps_dropped 0
END
</code></pre>

<p>Some descriptions:</p>

<p><code>evictions</code> - when items are evicted from the cache
<code>total_items</code> - the number of items the server has stored since it was started
<code>current_items</code> - the number of items in the cache
<code>bytes</code> - the current number of bytes used to store items
<code>limit_maxbytes</code> - the number of bytes the server is allowed to use for storage
<code>get_misses</code> - the number of times a item has been requested, but not found
<code>get_hits</code> - the number of times a item has been served from the cache</p>

<p>To get specific stats, like evictions:</p>

<pre><code class="bash">$ echo -e "stats" | nc localhost 11211 | grep -w evictions   
STAT evictions 0
</code></pre>

<p>When you see evictions value increases, this essentially means that memcache had to remove the oldest items from memory for new or more frequent used items. If this number remains high, consider increasing your memory allocated to memcache.</p>

<p>Slab Stats: returns information about each of the slabs created by memcached during runtime:</p>

<pre><code class="bash">$ echo -e "stats slabs" | nc localhost 11211                 
STAT active_slabs 0
STAT total_malloced 0
</code></pre>

<p><code>active_slabs</code> - Total number of slab classes allocated.
<code>total_malloced</code> - Total amount of memory allocated to slab pages.</p>

<p>For detailed description about statistics, have a look at their github resource:
- <a href="https://github.com/memcached/memcached/blob/master/doc/protocol.txt">https://github.com/memcached/memcached/blob/master/doc/protocol.txt</a></p>

<h2>Resources:</h2>

<ul>
<li><a href="https://memcached.org/">https://memcached.org/</a></li>
<li><a href="https://blog.serverdensity.com/monitor-memcached/">https://blog.serverdensity.com/monitor-memcached/</a></li>
<li><a href="https://wiki.mikejung.biz/Memcached">https://wiki.mikejung.biz/Memcached</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving Performance From Your Lambda Function From the Use of Global Variables]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/27/improving-performance-from-your-lambda-function-from-the-use-of-global-variables/"/>
    <updated>2018-08-27T08:30:30-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/27/improving-performance-from-your-lambda-function-from-the-use-of-global-variables</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/aws-logo.png" alt="" /></p>

<p>When using Lambda and DynamoDB, you can use global variables to gain performance when your data from DynamoDB does not get updated that often, and you would like to use caching to prevent a API call to DynamoDB everytime your Lambda Function gets invoked.</p>

<p>You can use external services like Redis or Memcached when you would like to verify that each invocation is as true as your source of truth which will be DynamoDB. Then your application logic can work with caching.</p>

<p>But in this case we just want a simple piece of code that can keep the state for the remaining time that the function is running on that underlying container. I am not 100% sure, but I have seen that the data can be cached for up to 60 minutes. This can be a total mess when your data gets updated regularly, then I would set all my calls in functions, as the global variables keeps their state for some time.</p>

<h2>Example Function:</h2>

<p>This function gets data from DynamoDB, iterates through a small dataset (10 Items), and appends each group name to my list which is the value of my <code>groups</code> key inside my dictionary.</p>

<p>Due to my global variable <code>mydata</code>, you will see that the first invocation will result in a API call to DynamoDB as the length of my <code>mydata["groups"]</code> being 0, the second invocation, the data will exist inside my global variable, therefore I am returning the data directly from my variable.</p>

<pre><code class="python">import boto3, json

client = boto3.resource('dynamodb', region_name='eu-west-1')
tbl = client.Table('my-dynamo-table')

mydata = {}
mydata["groups"] = []

def lambda_handler(event, context):
    if len(mydata["groups"]) == 0:
        # data is not cached, make call to dynamo
        data = tbl.scan()
        group_data = data['Items']

        for group in group_data:
            mydata["groups"].append(group['name'])
        return mydata

    else:
        # return cached content
        return mydata
</code></pre>

<h2>Results of my Invocations:</h2>

<p>The first call that I made:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/lambda-caching-miss.png" alt="" /></p>

<p>The second call that I made:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/lambda-caching-hit.png" alt="" /></p>

<p>If you need a small layer of caching that can improve your latency, this can be used. But if you need your data to be accurate from every call, rather looking into a different approach and external caching services.</p>

<h2>Resources:</h2>

<p><em>Take advantage of Execution Context reuse to improve the performance of your function.</em>:</p>

<p>&ldquo;Make sure any externalized configuration or dependencies that your code retrieves are stored and referenced locally after initial execution. Limit the re-initialization of variables/objects on every invocation. Instead use static initialization/constructor, global/static variables and singletons. Keep alive and reuse connections (HTTP, database, etc.) that were established during a previous invocation.&rdquo;</p>

<ul>
<li><a href="https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html">https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html</a></li>
<li><a href="https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/">https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
