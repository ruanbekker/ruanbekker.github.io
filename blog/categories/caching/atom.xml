<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Caching | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/caching/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2022-05-27T06:55:51-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Increase Performance With Your Ghost Blog on Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/06/08/build-a-ghost-blog-with-nginx-cache-on-docker/"/>
    <updated>2020-06-08T23:28:07+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/06/08/build-a-ghost-blog-with-nginx-cache-on-docker</id>
    <content type="html"><![CDATA[<p><img src="https://img.sysadmins.co.za/wngib2.png" alt="nginx-blog-ghost-caching" /></p>

<p>Nginx Caching + Ghost == Great Performance.</p>

<p>In this post we will build a nginx reverse proxy with caching enabled for our static content such as images, which will be our frontend and therefore we will have port 80 exposed, and run our ghost blog as our backend, which we will proxy traffic through from our nginx container.</p>

<h2>But why would you want caching?</h2>

<p>Returning data from memory is a lot faster than returning data from disk, and in this case where a request is being made against nginx, then it proxy passes the request to ghost, gets the data that you requested and returns the data to the client.</p>

<p>So for items that rarely changes like images, we can benefit from caching, so the images can be returned from the nginx service, where the first request will be made to ghost and then it will be loaded into nginx cache, so then the next time when you request the same image it will be returned from cache instead of making that same request to ghost again.</p>

<h2>Caching Info</h2>

<p>For this demonstration once we define the size of our chache which will be 500MB and we specify that if an object has not been accessed for 24 hours, we can expire the object from the cache.</p>

<h2>Nginx</h2>

<p>We will build our nginx container by adding our custom nginx config to our dockerfile.</p>

<p>Our <code>Dockerfile</code> will look like the following:</p>

<pre><code>ROM nginx:stable
ADD nginx.conf /etc/nginx/nginx.conf
</code></pre>

<p>Our <code>nginx.conf</code> configuration file:</p>

<pre><code>events {
  worker_connections  1024;
}

http {
  default_type       text/html;
  access_log         /dev/stdout;
  sendfile           on;
  keepalive_timeout  65;

  #proxy_cache_path /tmp/ghostcache levels=1:2 keys_zone=ghostcache:500m max_size=2g inactive=30d;
  proxy_cache_path /tmp/ghostcache levels=1:2 keys_zone=ghostcache:60m max_size=500m inactive=24h;
  proxy_cache_key "$scheme$request_method$host$request_uri";
  proxy_cache_methods GET HEAD;

  server {
    listen 80;

    location / {
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $http_host;
        proxy_pass http://ghost:2368;
    }

    location ~* \.(?:css|js|ico)$ {
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $http_host;
        proxy_pass http://ghost:2368;
        access_log off;
    }

    location ^~ /content/images/ {
        proxy_cache ghostcache;
        proxy_cache_valid 60m;
        proxy_cache_valid 404 1m;
        proxy_ignore_headers Set-Cookie;
        proxy_hide_header Set-Cookie;
        proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;
        proxy_ignore_headers Cache-Control;
        add_header X-Cache-Status $upstream_cache_status;

        proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_pass http://ghost:2368;
        access_log off;
    }
  }
}
</code></pre>

<p>Then our <code>docker-compose.yml</code> where we will add our nginx and ghost container to run together:</p>

<pre><code>version: '3.4'

services:
  ghost:
    image: ghost:3.15.1
    container_name: 'ghost'
    environment:
      - NODE_ENV=production
      - url=http://localhost:80
    networks:
      - ghost
    volumes:
      - ghost_content:/var/lib/ghost/content/data

  proxy:
    build: .
    container_name: 'proxy'
    depends_on:
      - ghost
    ports:
      - 80:80
    networks:
      - ghost

networks:
  ghost: {}

volumes:
  ghost_content: {}
</code></pre>

<p>To boot our stack:</p>

<pre><code>$ docker-compose up
</code></pre>

<h2>Test Caching</h2>

<p>Once your containers are in a running state, open your browsers devloper tools and look at the networking tab, then access your ghost blog on <code>http://localhost:80/</code>, the first time a image is opened you should see the cache shows <code>MISS</code> when you refresh again you should see a <code>HIT</code>, which means that the object is being returned from your cache.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Cache Data With Python Flask]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/02/14/how-to-cache-data-with-python-flask/"/>
    <updated>2019-02-14T06:37:30-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/02/14/how-to-cache-data-with-python-flask</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/52816968-216f6480-30ab-11e9-9d19-6418ba51563b.png" alt="" /></p>

<p>If you depending on a external source to return static data you can implement <code>cachetools</code> to cache data from preventing the overhead to make the request everytime you make a request to Flask.</p>

<p>This is useful when your upstream data does not change often. This is configurable with <code>maxsize</code> and <code>ttl</code> so whenever the first one&rsquo;s threshold is met, the application will fetch new data whenever the request has been made to your application.</p>

<h2>Example</h2>

<p>Let&rsquo;s build a basic flask application that will return the data from our <code>data.txt</code> file to the client:</p>

<pre><code class="python">from flask import Flask
from cachetools import cached, TTLCache

app = Flask(__name__)
cache = TTLCache(maxsize=100, ttl=60)

@cached(cache)
def read_data():
    data = open('data.txt', 'r').read()
    return data

@app.route('/')
def main():
    get_data = read_data()
    return get_data

if __name__ == '__main__':
    app.run()
</code></pre>

<p>Create the local file with some data:</p>

<pre><code class="bash">$ touch data.txt
$ echo "version1" &gt; data.txt
</code></pre>

<p>Start the server:</p>

<pre><code class="bash">$ python app.py
</code></pre>

<p>Make the request:</p>

<pre><code class="bash">$ curl http://localhost:5000/
version1
</code></pre>

<p>Change the data inside the file:</p>

<pre><code class="bash">$ echo "version2" &gt; data.txt
</code></pre>

<p>Make the request again:</p>

<pre><code class="bash">$ curl http://localhost:5000/
version1
</code></pre>

<p>As the ttl is set to 60, wait for 60 seconds so that the item kan expire from the cache and try again:</p>

<pre><code class="bash">$ curl http://localhost:5000/
version2
</code></pre>

<p>As you can see the cache expired and a new request has been made to read the file again and load it in cache, and then return to the client.</p>

<h2>Thank You</h2>

<p>Please feel free to show support by, <strong>sharing</strong> this post, making a <strong>donation</strong>, <strong>subscribing</strong> or <strong>reach out to me</strong> if you want me to demo and write up on any specific tech topic.</p>

<center>
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick" />
<input type="hidden" name="hosted_button_id" value="W7CBGYTCWGANQ" />
<input type="image" src="https://user-images.githubusercontent.com/567298/49853901-461c3700-fdf1-11e8-9d80-8a424a3173af.png" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
<img alt="" border="0" src="https://www.paypal.com/en_ZA/i/scr/pixel.gif" width="1" height="1" />
</form>
</center>


<p><br></p>

<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a Raspberry Pi Nginx Image With Caching on Alpine for Docker Swarm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm/"/>
    <updated>2018-10-23T17:00:02-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm</id>
    <content type="html"><![CDATA[<p>In this guide, we will be creating a nginx reverse proxy with the ability to cache static content using a alpine image.</p>

<p>We will then push the image to gitlab&rsquo;s private registry, and then run the service on docker swarm.</p>

<h2>Create the backend service:</h2>

<p>We will upstream to our blog using ghost, which you can deploy using:</p>

<pre><code class="bash">$ docker service create --name blog --network docknet rbekker87/armhf-ghost:2.0.3
</code></pre>

<h2>Current File Structure:</h2>

<p>Our file structure for the assets we need to build the reverse proxy:</p>

<pre><code>$ find .
./conf.d
./conf.d/blog.conf
./Dockerfile
./nginx.conf
</code></pre>

<ul>
<li><code>Dockerfile</code></li>
</ul>


<pre><code>FROM hypriot/rpi-alpine-scratch
MAINTAINER Ruan Bekker

RUN apk update &amp;&amp; \
    apk add nginx &amp;&amp; \
    rm -rf /etc/nginx/nginx.conf &amp;&amp; \
    chown -R nginx:nginx /var/lib/nginx &amp;&amp; \
    rm -rf /var/cache/apk/*

ADD nginx.conf /etc/nginx/
ADD conf.d/blog.conf /etc/nginx/conf.d/

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
</code></pre>

<ul>
<li><code>nginx.conf</code></li>
</ul>


<pre><code>user nginx;
worker_processes 1;

events {
    worker_connections 1024;
    }

error_log  /var/log/nginx/nginx_error.log warn;

http {

    sendfile          on;
    tcp_nodelay       on;

    gzip              on;
    gzip_http_version 1.0;
    gzip_proxied      any;
    gzip_min_length   500;
    gzip_disable      "MSIE [1-6]\.";
    gzip_types        text/plain text/xml text/css
                      text/comma-separated-values
                      text/javascript
                      application/x-javascript
                      application/atom+xml;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;
    error_log   /var/log/nginx/error.log;

    proxy_cache_path /var/cache/nginx/ levels=1:2 keys_zone=nginx_cache:5m max_size=128m inactive=60m;

    keepalive_timeout  60;
    server_tokens      off;

    include /etc/nginx/conf.d/*.conf;

}
</code></pre>

<p>Hostname resolution to our Ghost Blog Service: In our swarm we have a service called blog which is associated to the docknet network, so the dns resolution will resolve to the vip of the service. As seen in the figure below:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
nq42a6jfwx3d        blog                replicated          1/1                 rbekker87/armhf-ghost:2.0.3
</code></pre>

<ul>
<li><code>conf.d/blog.conf</code></li>
</ul>


<pre><code>upstream ghost_blog {
    server blog:2368;
    }

server {
    listen 80;
    server_name blog.yourdomain.com;

    access_log  /var/log/nginx/blog_access.log  main;
    error_log   /var/log/nginx/blog_error.log;

    location / {

        proxy_cache                 nginx_cache;
        add_header                  X-Proxy-Cache $upstream_cache_status;
        proxy_ignore_headers        Cache-Control;
        proxy_cache_valid any       10m;
        proxy_cache_use_stale       error timeout http_500 http_502 http_503 http_504;

        proxy_pass                  http://ghost_blog;
        proxy_redirect              off;

        proxy_set_header            Host $host;
        proxy_set_header            X-Real-IP $remote_addr;
        proxy_set_header            X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header            X-Forwarded-Host $server_name;
    }
}
</code></pre>

<h2>Building the Image and Pushing to Gitlab</h2>

<p>I&rsquo;m using Gitlab in this demonstration, but you can use the registry of your choice:</p>

<pre><code>$ docker login registry.gitlab.com
$ docker build -t registry.gitlab.com/user/docker/arm-nginx:caching .
$ docker tag registry.gitlab.com/user/docker/arm-nginx:caching registry.gitlab.com/user/docker/arm-nginx:caching
$ docker push registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<h2>Deploy</h2>

<p>Create the Nginx Reverse Proxy Service on Docker Swarm:</p>

<pre><code>$ docker service create --name nginx_proxy \
--network docknet \
--publish 80:80 \
--replicas 1 \
--with-registry-auth registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<p>Listing our Services:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
je7x21l7egoh        nginx_proxy         replicated          1/1                 registry.gitlab.com/user/docker/arm-nginx:caching   *:80-&gt;80/tcp
nq42a6jfwx3d        blog                replicated          1/1                 rbekker87/armhf-ghost:2.0.3
</code></pre>

<p>Once you access your proxy on port 80, you should see your Ghost Blog Homepage like below:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/ghost-blog-main.png" alt="" /></p>

<p>Have a look at the <a href="https://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/">benchmark performance</a> when using Nginx with caching enabled</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/r/rbekker87/armhf-ghost/">https://hub.docker.com/r/rbekker87/armhf-ghost/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx Caching Performance for Static Content on Docker Swarm With RaspberryPi]]></title>
    <link href="https://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/"/>
    <updated>2018-10-23T16:41:41-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/nginx-logo.png" alt="" /></p>

<h2>The Environment:</h2>

<p>I had my Ghost Blog listening on port 2368 and exposing port 80 on Docker so that the port translation directs port 80 traffic to port 2368 on Ghost directly.</p>

<p>Alex responded on my tweet and introduced Nginx Caching:</p>

<ul>
<li><a href="https://twitter.com/alexellisuk/status/882347698636165121">https://twitter.com/alexellisuk/status/882347698636165121</a></li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/tweet-alexellis-04072017.png" alt="" /></p>

<p>With this approach benchmarking results was not so great in terms of requests per second, and as this hostname will be only used for a blog, its a great idea to cache the content, this was achieved with the help from Alex&rsquo;s blog: <a href="https://blog.alexellis.io/save-and-boost-with-nginx/">blog.alexellis.io/save-and-boost-with-nginx/</a></p>

<h2>How Nginx was Configured:</h2>

<p>I have a <a href="http://rbkr.ddns.net/building-nginx-on-alpine-image-for-docker-swarm-with-caching-enabled-config/">blogpost</a> on how I setup Nginx on an Alpine Image, where I setup caching and proxy-pass the connections through to my ghost blog.</p>

<h2>Benchmarking: Before Nginx with Caching was Implemented:</h2>

<p>When doing an apache benchmark I got <b>9.31 requests per second</b> performing the test on my LAN:</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://rbkr.ddns.net/

This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking rbkr.ddns.net (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   53.725 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2863000 bytes
HTML transferred:       2735000 bytes
Requests per second:    9.31 [#/sec] (mean)
Time per request:       1074.501 [ms] (mean)
Time per request:       107.450 [ms] (mean, across all concurrent requests)
Transfer rate:          52.04 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    2   0.5      2       6
Processing:   685 1068  68.7   1057    1306
Waiting:      683 1067  68.6   1056    1306
Total:        689 1070  68.7   1058    1312

Percentage of the requests served within a certain time (ms)
  50%   1058
  66%   1088
  75%   1102
  80%   1110
  90%   1163
  95%   1218
  98%   1240
  99%   1247
 100%   1312 (longest request)
</code></pre>

<h2>Benchmarking: After Nginx Caching was Implemented:</h2>

<p>After Nginx Caching was Implemented, I got <b>1067.73 requests per second</b> using apache benchmark over a LAN connection! Absolutely awesome!</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://blog.pistack.co.za/
This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking blog.pistack.co.za (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:        nginx
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   0.468 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2880500 bytes
HTML transferred:       2735000 bytes
Requests per second:    1067.73 [#/sec] (mean)
Time per request:       9.366 [ms] (mean)
Time per request:       0.937 [ms] (mean, across all concurrent requests)
Transfer rate:          6007.05 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        3    4   1.4      4      10
Processing:     3    5   1.6      4      10
Waiting:        2    4   1.6      4      10
Total:          6    9   2.7      8      17

Percentage of the requests served within a certain time (ms)
  50%      8
  66%      8
  75%      9
  80%      9
  90%     15
  95%     15
  98%     15
  99%     16
 100%     17 (longest request)
</code></pre>

<h2>Resources:</h2>

<p>Thanks to Alex Ellis for the suggestion on this, and definitely have a look at <a href="https://blog.alexellis.io/tag/nginx/">blog.alexellis.io</a> as he has some epic content on his blog!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Give Your Database a Break and Use Memcached to Return Frequently Accessed Data]]></title>
    <link href="https://blog.ruanbekker.com/blog/2018/09/01/give-your-database-a-break-and-use-memcached-to-return-frequently-accessed-data/"/>
    <updated>2018-09-01T17:05:10-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2018/09/01/give-your-database-a-break-and-use-memcached-to-return-frequently-accessed-data</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/memcached-logo.png" alt="" /></p>

<p>So let&rsquo;s take this scenario:</p>

<p>Your database is getting hammered with requests and building up some load over time and we would like to place a caching layer in front of our database that will return data from the caching layer, to reduce some traffic to our database and also improve our performance for our application.</p>

<h2>The Scenario:</h2>

<p>Our scenario will be very simple for this demonstration:</p>

<ul>
<li>Database will be using SQLite with product information (product_name, product_description)</li>
<li>Caching Layer will be Memcached</li>
<li>Our Client will be written in Python, which checks if the product name is in cache, if not a <code>GET_MISS</code> will be returned, then the data will be fetched from the database, returns it to the client and save it to the cache</li>
<li>Next time the item will be read, a <code>GET_HIT</code> will be received, then the item will be delivered to the client directly from the cache</li>
</ul>


<h2>SQL Database:</h2>

<p>As mentioned we will be using sqlite for demonstration.</p>

<p>Create the table, populate some very basic data:</p>

<pre><code class="sql">$ sqlite3 db.sql -header -column
import sqlite3 as sql
SQLite version 3.16.0 2016-11-04 19:09:39
Enter ".help" for usage hints.

sqlite&gt; create table products (product_name STRING(32), product_description STRING(32));
sqlite&gt; insert into products values('apple', 'fruit called apple');
sqlite&gt; insert into products values('guitar', 'musical instrument');
</code></pre>

<p>Read all the data from the table:</p>

<pre><code class="sql">sqlite&gt; select * from products;
product_name  product_description
------------  -------------------
apple         fruit called apple
guitar        musical instrument
sqlite&gt; .exit
</code></pre>

<h2>Run a Memcached Container:</h2>

<p>We will use docker to run a memcached container on our workstation:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 rbekker87/memcached:alpine
</code></pre>

<h2>Our Application Code:</h2>

<p>I will use <a href="https://pymemcache.readthedocs.io/en/latest/getting_started.html">pymemcache</a> as our client library. Install:</p>

<pre><code class="bash">$ virtualenv .venv &amp;&amp; source .venv/bin/activate
$ pip install pymemcache
</code></pre>

<p>Our Application Code which will be in Python</p>

<pre><code class="python">import sqlite3 as sql
from pymemcache.client import base

product_name = 'guitar'

client = base.Client(('localhost', 11211))
result = client.get(product_name)

def query_db(product_name):
    db_connection = sql.connect('db.sql')
    c = db_connection.cursor()
    try:
        c.execute('select product_description from products where product_name = "{k}"'.format(k=product_name))
        data = c.fetchone()[0]
        db_connection.close()
    except:
        data = 'invalid'
    return data

if result is None:
    print("got a miss, need to get the data from db")
    result = query_db(product_name)
    if result == 'invalid':
        print("requested data does not exist in db")
    else:
        print("returning data to client from db")
        print("=&gt; Product: {p}, Description: {d}".format(p=product_name, d=result))
        print("setting the data to memcache")
        client.set(product_name, result)

else:
    print("got the data directly from memcache")
    print("=&gt; Product: {p}, Description: {d}".format(p=product_name, d=result))
</code></pre>

<p>Explanation:</p>

<ul>
<li>We have a function that takes a argument of the product name, that makes the call to the database and returns the description of that product</li>
<li>We will make a get operation to memcached, if nothing is returned, then we know the item does not exists in our cache,</li>
<li>Then we will call our function to get the data from the database and return it directly to our client, and</li>
<li>Save it to the cache in memcached so the next time the same product is queried, it will be delivered directly from the cache</li>
</ul>


<h2>The Demo:</h2>

<p>Our Product Name is <code>guitar</code>, lets call the product, which will be the first time so memcached wont have the item in its cache:</p>

<pre><code class="bash">$ python app.py
got a miss, need to get the data from db
returning data to client from db
=&gt; Product: guitar, Description: musical instrument
setting the data to memcache
</code></pre>

<p>Now from the output, we can see that the item was delivered from the database and saved to the cache, lets call that same product and observe the behavior:</p>

<pre><code class="bash">$ python app.py
got the data directly from memcache
=&gt; Product: guitar, Description: musical instrument
</code></pre>

<p>When our cache instance gets rebooted we will lose our data that is in the cache, but since the source of truth will be in our database, data will be re-added to the cache as they are requested. That is one good reason not to rely on a cache service to be your primary data source.</p>

<p>What if the product we request is not in our cache or database, let&rsquo;s say the product <code>tree</code></p>

<pre><code class="bash">$ python app.py
got a miss, need to get the data from db
requested data does not exist in db
</code></pre>

<p>This was a really simple scenario, but when working with masses amount of data, you can benefit from a lot of performance using caching.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://realpython.com/python-memcache-efficient-caching/">https://realpython.com/python-memcache-efficient-caching/</a></li>
<li><a href="https://github.com/ruanbekker/dockerhub-sources/tree/master/memcached/alpine">https://github.com/ruanbekker/dockerhub-sources/tree/master/memcached/alpine</a></li>
<li><a href="https://pymemcache.readthedocs.io/en/latest/getting_started.html#basic-usage">https://pymemcache.readthedocs.io/en/latest/getting_started.html#basic-usage</a></li>
<li><a href="https://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html">https://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
