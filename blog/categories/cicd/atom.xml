<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cicd | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/cicd/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2021-08-15T17:47:25-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Install Concourse CI V6 on Ubuntu 20.04]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/04/06/install-concourse-ci-v6-on-ubuntu-20-dot-04/"/>
    <updated>2021-04-06T17:56:38-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/04/06/install-concourse-ci-v6-on-ubuntu-20-dot-04</id>
    <content type="html"><![CDATA[<p><img src="https://i.snag.gy/gzkdu9.jpg?nocache=1511644783495" alt="" /></p>

<p>Concourse is a Pipeline Based Continious Integration system written in Go</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://concourse-ci.org/">https://concourse-ci.org/</a></li>
<li><a href="https://github.com/concourse/concourse">https://github.com/concourse/concourse</a></li>
<li><a href="https://github.com/starkandwayne/concourse-tutorial">https://github.com/starkandwayne/concourse-tutorial</a></li>
</ul>


<h2>Older Version</h2>

<p>An older version is available:</p>

<ul>
<li><a href="https://blog.ruanbekker.com/blog/2017/11/07/setup-a-concourse-ci-server-on-ubuntu-16/">Setup Concourse CI v4 on Ubuntu 16.04</a></li>
</ul>


<h2>What is Concourse CI:</h2>

<p>Concourse CI is a Continious Integration Platform. Concourse enables you to construct pipelines with a yaml configuration that can consist out of 3 core concepts, tasks, resources, and jobs that compose them. For more information about this have a look at their <a href="https://concourse.ci/concepts.html">docs</a></p>

<h2>What will we be doing today</h2>

<p>We will setup a Concourse CI Server v6.7.6 (web and worker) on Ubuntu 20.04 and run the traditional <code>Hello, World</code> pipeline</p>

<h2>Setup the Server:</h2>

<p>Concourse needs <code>PostgresSQL</code> server:</p>

<pre><code class="bash">$ apt update &amp;&amp; apt upgrade -y
$ apt install postgresql postgresql-contrib -y
$ systemctl enable postgresql
</code></pre>

<p>Create the Database and User for Concourse on Postgres:</p>

<pre><code class="bash">$ sudo -u postgres createuser concourse
$ sudo -u postgres createdb --owner=concourse atc
</code></pre>

<p>Download the Concourse and Fly Cli Binaries:</p>

<pre><code class="bash">$ wget https://github.com/concourse/concourse/releases/download/v6.7.6/concourse-6.7.6-linux-amd64.tgz
$ wget https://github.com/concourse/concourse/releases/download/v6.7.6/fly-6.7.6-linux-amd64.tgz
$ tar -xvf concourse-6.7.6-linux-amd64.tgz -C /usr/local/
$ tar -xvf fly-6.7.6-linux-amd64.tgz
$ mv fly /usr/bin/fly
$ rm -rf concourse-6.7.6-linux-amd64.tgz fly-6.7.6-linux-amd64.tgz
</code></pre>

<p>Create the Encryption Keys:</p>

<pre><code class="bash">$ mkdir /etc/concourse
$ ssh-keygen -t rsa -q -N '' -f /etc/concourse/tsa_host_key
$ ssh-keygen -t rsa -q -N '' -f /etc/concourse/worker_key
$ ssh-keygen -t rsa -q -N '' -f /etc/concourse/session_signing_key
$ cp /etc/concourse/worker_key.pub /etc/concourse/authorized_worker_keys
</code></pre>

<p>Concourse Web Process Configuration:</p>

<pre><code class="bash">$ cat /etc/concourse/web_environment

PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/concourse/bin
CONCOURSE_ADD_LOCAL_USER=ruan:pass
CONCOURSE_SESSION_SIGNING_KEY=/etc/concourse/session_signing_key
CONCOURSE_TSA_HOST_KEY=/etc/concourse/tsa_host_key
CONCOURSE_TSA_AUTHORIZED_KEYS=/etc/concourse/authorized_worker_keys
CONCOURSE_POSTGRES_HOST=127.0.0.1
CONCOURSE_POSTGRES_USER=concourse
CONCOURSE_POSTGRES_PASSWORD=concourse
CONCOURSE_POSTGRES_DATABASE=atc
CONCOURSE_MAIN_TEAM_LOCAL_USER=ruan
CONCOURSE_EXTERNAL_URL=http://10.20.30.40:8080 # replace this with your ip address
</code></pre>

<p>Concourse Worker Process Configuration:</p>

<pre><code class="bash">$ cat /etc/concourse/worker_environment

PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/concourse/bin
CONCOURSE_WORK_DIR=/var/lib/concourse
CONCOURSE_TSA_HOST=127.0.0.1:2222
CONCOURSE_TSA_PUBLIC_KEY=/etc/concourse/tsa_host_key.pub
CONCOURSE_TSA_WORKER_PRIVATE_KEY=/etc/concourse/worker_key
CONCOURSE_GARDEN_DNS_SERVER=8.8.8.8
</code></pre>

<p>Create a Concourse user:</p>

<pre><code class="bash">$ mkdir /var/lib/concourse
$ sudo adduser --system --group concourse
$ sudo chown -R concourse:concourse /etc/concourse /var/lib/concourse
$ sudo chmod 600 /etc/concourse/*_environment
</code></pre>

<p>Create SystemD Unit Files, first for the Web Service:</p>

<pre><code class="bash">$ cat /etc/systemd/system/concourse-web.service

[Unit]
Description=Concourse CI web process (ATC and TSA)
After=postgresql.service

[Service]
User=concourse
Restart=on-failure
EnvironmentFile=/etc/concourse/web_environment
ExecStart=/usr/bin/concourse web

[Install]
WantedBy=multi-user.target
</code></pre>

<p>Then the SystemD Unit File for the Worker Service:</p>

<pre><code class="bash">$ cat /etc/systemd/system/concourse-worker.service

[Unit]
Description=Concourse CI worker process
After=concourse-web.service

[Service]
User=root
Restart=on-failure
EnvironmentFile=/etc/concourse/worker_environment
ExecStart=/usr/bin/concourse worker

[Install]
WantedBy=multi-user.target
</code></pre>

<p>Create a postgres password for the concourse user:</p>

<pre><code class="bash">$ cd /home/concourse/
$ sudo -u concourse psql atc
atc=&gt; ALTER USER concourse WITH PASSWORD 'concourse';
atc=&gt; \q
</code></pre>

<p>Start and Enable the Services:</p>

<pre><code class="bash">$ systemctl start concourse-web concourse-worker
$ systemctl enable concourse-web concourse-worker postgresql
$ systemctl status concourse-web concourse-worker

$ systemctl is-active concourse-worker concourse-web
active
active
</code></pre>

<p>The listening ports should more or less look like the following:</p>

<pre><code class="bash">$ netstat -tulpn

Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 127.0.0.1:7777          0.0.0.0:*               LISTEN      4530/concourse
tcp        0      0 127.0.0.1:7788          0.0.0.0:*               LISTEN      4530/concourse
tcp        0      0 127.0.0.1:8079          0.0.0.0:*               LISTEN      4525/concourse
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1283/sshd
tcp        0      0 127.0.0.1:5432          0.0.0.0:*               LISTEN      4047/postgres
tcp6       0      0 :::36159                :::*                    LISTEN      4525/concourse
tcp6       0      0 :::46829                :::*                    LISTEN      4525/concourse
tcp6       0      0 :::2222                 :::*                    LISTEN      4525/concourse
tcp6       0      0 :::8080                 :::*                    LISTEN      4525/concourse
tcp6       0      0 :::22                   :::*                    LISTEN      1283/sshd
udp        0      0 0.0.0.0:68              0.0.0.0:*                           918/dhclient
udp        0      0 0.0.0.0:42165           0.0.0.0:*                           4530/concourse
</code></pre>

<h2>Client Side:</h2>

<p>I will be using a the Fly cli from a Mac, so first we need to download the fly-cli for Mac:</p>

<pre><code class="bash">$ wget https://github.com/concourse/concourse/releases/download/v6.7.6/fly-6.7.6-darwin-amd64.tgz
$ tar -xvf fly-6.7.6-darwin-amd64.tgz
$ sudo mv fly /usr/local/bin/fly
$ rm -rf fly-6.7.6-darwin-amd64.tgz
</code></pre>

<p>Next, we need to setup our Concourse Target by Authenticating against our Concourse Endpoint, lets setup our target with the name <code>ci</code>, and make sure to replace the ip address with the ip of your concourse server:</p>

<pre><code class="bash">$ fly -t ci login -c http://10.20.30.40:8080
logging in to team 'main'

navigate to the following URL in your browser:

  http://10.20.30.40:8080/login?fly_port=42181

or enter token manually (input hidden):
target saved
</code></pre>

<p>Lets list our targets:</p>

<pre><code class="bash">$ fly targets
name  url                        team  expiry
ci    http://10.20.30.40:8080    main  Wed, 08 Nov 2021 15:32:59 UTC
</code></pre>

<p>Listing Registered Workers:</p>

<pre><code class="bash">$ fly -t ci workers
name              containers  platform  tags  team  state    version
10.20.30.40       0           linux     none  none  running  1.2
</code></pre>

<p>Listing Active Containers:</p>

<pre><code class="bash">$ fly -t ci containers
handle                                worker            pipeline     job            build #  build id  type   name                  attempt
</code></pre>

<h2>Hello World Pipeline:</h2>

<p>Let&rsquo;s create a basic pipeline, that will print out <code>Hello, World!</code>:</p>

<p>Our <code>hello-world.yml</code></p>

<pre><code class="yml">jobs:
- name: my-job
  plan:
  - task: say-hello
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: alpine
          tag: edge
      run:
        path: /bin/sh
        args:
        - -c
        - |
          echo "============="
          echo "Hello, World!"
          echo "============="
</code></pre>

<p>Applying the configuration to our pipeline:</p>

<pre><code class="bash">$ fly -t ci set-pipeline -p yeeehaa -c hello-world.yml
jobs:
  job my-job has been added:
    name: my-job
    plan:
    - task: say-hello
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: alpine
            tag: edge
        run:
          path: /bin/sh
          args:
          - -c
          - |
            echo "============="
            echo "Hello, World!"
            echo "============="

apply configuration? [yN]: y
pipeline created!
you can view your pipeline here: http://10.20.30.40:8080/teams/main/pipelines/yeeehaa

the pipeline is currently paused. to unpause, either:
  - run the unpause-pipeline command
  - click play next to the pipeline in the web ui
</code></pre>

<p>We can browse to the WebUI to unpause the pipeline, but since I like to do everything on cli as far as possible, I will unpause the pipeline via cli:</p>

<pre><code class="bash">$ fly -t ci unpause-pipeline -p yeeehaa
unpaused 'yeeehaa'
</code></pre>

<p>Now our Pipeline is unpaused, but since we did not specify any triggers, we need to manually trigger the pipeline to run, you can either via the WebUI, select your pipeline which in this case will be named <code>yeeehaa</code> and then select the job, which will be <code>my-job</code> then hit the <code>+</code> sign, which will trigger the pipeline.</p>

<p>I will be using the cli:</p>

<pre><code class="bash">$ fly -t ci trigger-job --job yeeehaa/my-job
started yeeehaa/my-job #1
</code></pre>

<p>Via the WebUI on <code>http://10.20.30.40:8080/teams/main/pipelines/yeeehaa/jobs/my-job/builds/1</code> you should see the <code>Hello, World!</code> output, or via the cli, we also have the option to see the output, so let&rsquo;s trigger it again, but this time passing the <code>--watch</code> flag:</p>

<pre><code class="bash">$ fly -t ci trigger-job --job yeeehaa/my-job --watch
started yeeehaa/my-job #2

initializing
running /bin/sh -c echo "============="
echo "Hello, World!"
echo "============="

=============
Hello, World!
=============
succeeded
</code></pre>

<p>Listing our Workers and Containers again:</p>

<pre><code class="bash">$ fly -t ci workers
name              containers  platform  tags  team  state    version
10.20.30.40       2           linux     none  none  running  1.2

$ fly -t ci containers
handle                                worker            pipeline     job         build #  build id  type   name           attempt
36982955-54fd-4c1b-57b8-216486c58db8  10.20.30.40       yeeehaa      my-job      2        729       task   say-hello      n/a
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Run Localstack as a Service Container for AWS Mock Services on Drone CI]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/04/run-localstack-as-a-service-container-for-aws-mock-services-on-drone-ci/"/>
    <updated>2020-02-04T23:43:30+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/04/run-localstack-as-a-service-container-for-aws-mock-services-on-drone-ci</id>
    <content type="html"><![CDATA[<p>In this tutorial we will setup a basic pipeline in drone to make use of service containers, we will provision localstack so that we can provision AWS mock services.</p>

<p>We will create a kinesis stream on localstack, when the service is up, we will create a stream, put 100 records in the stream, read them from the stream and delete the kinesis stream.</p>

<h2>Gitea and Drone Stack</h2>

<p>If you don’t have the stack setup, have a look at <a href="https://blog.ruanbekker.com/blog/2020/02/04/setup-gitea-and-drone-on-docker-2020-edition/">this post</a> where I go into detail on how to get that setup.</p>

<h2>Create the Drone Config</h2>

<p>In gitea, I have created a new git repository and created my drone config as <code>.drone.yml</code> with this pipeline config:</p>

<pre><code>---
kind: pipeline
type: docker
name: localstack

platform:
  os: linux
  arch: amd64

steps:
  - name: wait-for-localstack
    image: busybox
    commands:
      - sleep 10

  - name: list-kinesis-streams
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis list-streams

  - name: create-kinesis-streams
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis create-stream --stream-name mystream --shard-count 1

  - name: describe-kinesis-streams
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis describe-stream --stream-name mystream

  - name: put-record-into-kinesis
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - for record in $$(seq 1 100); do aws --endpoint-url=http://localstack:4568 kinesis put-record --stream-name mystream --partition-key 123 --data testdata_$$record ; done

  - name: get-record-from-kinesis
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - SHARD_ITERATOR=$$(aws --endpoint-url=http://localstack:4568 kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name mystream --query 'ShardIterator' --output text)
      - for each in $$(aws --endpoint-url=http://localstack:4568 kinesis get-records --shard-iterator $$SHARD_ITERATOR | jq -cr '.Records[].Data'); do echo $each | base64 -d ; echo "" ; done

  - name: delete-kinesis-stream
    image: ruanbekker/awscli
    environment:
      AWS_ACCESS_KEY_ID: 123
      AWS_SECRET_ACCESS_KEY: xyz
      AWS_DEFAULT_REGION: eu-west-1
    commands:
      - aws --endpoint-url=http://localstack:4568 kinesis delete-stream --stream-name mystream

services:
  - name: localstack
    image: localstack/localstack
    privileged: true
    environment:
      DOCKER_HOST: unix:///var/run/docker.sock
    volumes:
      - name: docker-socket
        path: /var/run/docker.sock
      - name: localstack-vol
        path: /tmp/localstack
    ports:
      - 8080

volumes:
- name: localstack-vol
  temp: {}
- name: docker-socket
  host:
    path: /var/run/docker.sock
</code></pre>

<p>To explain what we are doing, we are bringing up localstack as a service container, then using the aws cli tools we point to the localstack kinesis endpoint, creating a kinesis stream, put 100 records to the stream, then we read from the stream and delete thereafter.</p>

<h2>Trigger the Pipeline</h2>

<p>Then I head to drone activate my new git repository and select the repository as &ldquo;Trusted&rdquo;. I commited a dummy file to trigger the pipeline and it should look like this:</p>

<p><img width="893" alt="image" src="https://user-images.githubusercontent.com/567298/73788817-63a32180-47a6-11ea-96c7-6abba7af2b27.png"></p>

<p>List Streams:</p>

<p><img width="974" alt="image" src="https://user-images.githubusercontent.com/567298/73788860-73bb0100-47a6-11ea-9c80-f2b8bfc18d53.png"></p>

<p>Put Records:</p>

<p><img width="896" alt="image" src="https://user-images.githubusercontent.com/567298/73788895-87666780-47a6-11ea-8d90-2c454ec9174a.png"></p>

<p>Delete Stream:</p>

<p><img width="924" alt="image" src="https://user-images.githubusercontent.com/567298/73788988-aebd3480-47a6-11ea-85d9-9ed7424c648b.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Run Kubernetes (K3s) as a Service Container on Drone CI]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/04/run-kubernetes-k3s-as-a-service-container-on-drone-ci/"/>
    <updated>2020-02-04T22:37:06+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/04/run-kubernetes-k3s-as-a-service-container-on-drone-ci</id>
    <content type="html"><![CDATA[<p><a href="https://docs.drone.io/pipeline/docker/syntax/services/">Drone services</a> allow you to run a service container and will be available for the duration of your build, which is great if you want a ephemeral service to test your applications against.</p>

<p>Today we will experiment with services on <a href="https://github.com/drone/drone">drone</a>  and will deploy a <a href="https://github.com/rancher/k3s">k3s</a> (a kubernetes distribution built by rancher) cluster as a drone service and interact with our cluster using kubectl.</p>

<p>I will be using multiple pipelines, where we will first deploy our &ldquo;dev cluster&rdquo;, when it&rsquo;s up, we will use kubectl to interact with the cluster, once that is done, we will deploy our &ldquo;staging cluster&rdquo; and do the same.</p>

<p>This is very basic and we are not doing anything special, but this is a starting point and you can do pretty much whatever you want.</p>

<h2>What is Drone</h2>

<p>If you are not aware of Drone, Drone is a container-native continious deliver platform built on Go and you can check them out <a href="https://github.com/drone/drone">here: github.com/drone</a></p>

<h2>Setup Gitea and Drone</h2>

<p>If you don&rsquo;t have the stack setup, have a look at <a href="https://blog.ruanbekker.com/blog/2020/02/04/setup-gitea-and-drone-on-docker-2020-edition/">this post</a> where I go into detail on how to get that setup.</p>

<h2>Create your Git Repo</h2>

<p>Go ahead and create a git repo, you can name it anything, then it should look something like this:</p>

<p><img width="1171" alt="image" src="https://user-images.githubusercontent.com/567298/73783555-90ead200-479c-11ea-8386-12518fb21b22.png"></p>

<p>Create a drone configuration, <code>.drone.yml</code> my pipeline will look like this:</p>

<pre><code>---
kind: pipeline
type: docker
name: dev

platform:
  os: linux
  arch: amd64

steps:
  - name: wait-for-k3s
    image: ruanbekker/build-tools
    commands:
      - sleep 30

  - name: prepare-k3s-kubeconfig
    image: alpine
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    detach: false
    commands:
      - sed -i -e "s/127.0.0.1/k3s/g" /k3s-kubeconfig/kubeconfig.yaml

  - name: test-kubernetes
    image: ruanbekker/kubectl
    volumes:
      - name: k3s-kubeconfig
        path: /tmp
    environment:
      KUBECONFIG: /tmp/kubeconfig.yaml
    commands:
      - kubectl get nodes -o wide

services:
  - name: k3s
    image: rancher/k3s:v0.9.1
    privileged: true
    command:
      - server
    environment:
      K3S_KUBECONFIG_OUTPUT: /k3s-kubeconfig/kubeconfig.yaml
      K3S_KUBECONFIG_MODE: 777
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    ports:
      - 6443

volumes:
- name: k3s-kubeconfig
  temp: {}

---
kind: pipeline
type: docker
name: staging

platform:
  os: linux
  arch: amd64

steps:
  - name: wait-for-k3s
    image: ruanbekker/build-tools
    commands:
      - sleep 30

  - name: prepare-k3s-kubeconfig
    image: alpine
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    detach: false
    commands:
      - sed -i -e "s/127.0.0.1/k3s/g" /k3s-kubeconfig/kubeconfig.yaml

  - name: test-kubernetes
    image: ruanbekker/kubectl
    volumes:
      - name: k3s-kubeconfig
        path: /tmp
    environment:
      KUBECONFIG: /tmp/kubeconfig.yaml
    commands:
      - kubectl get nodes -o wide


services:
  - name: k3s
    image: rancher/k3s:v0.9.1
    privileged: true
    command:
      - server
    environment:
      K3S_KUBECONFIG_OUTPUT: /k3s-kubeconfig/kubeconfig.yaml
      K3S_KUBECONFIG_MODE: 777
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    ports:
      - 6443

volumes:
- name: k3s-kubeconfig
  temp: {}

depends_on:
- dev
</code></pre>

<p>In this pipeline you can see that the staging pipeline depends on dev, so dev pipeline will start by creating the k3s service container, once its up I am using a step just to sleep for 30 seconds to allow it to boot.</p>

<p>Then I have defined a volume that will be persistent during the build time, which we will use to dump our kubeconfig file and update the hostname of our kubernetes endpoint. Once that is done our last step will set that file to the environment and use kubectl to interact with kubernetes.</p>

<p>Once our dev pipeline has finished, our staging pipeline will start.</p>

<h2>Activate the Repo in Drone</h2>

<p>Head over to drone on port <code>80</code> and activate the newly created git repo (and make sure that you select &ldquo;Trusted&rdquo;) and you will see the activity feed being empty:</p>

<p><img width="1008" alt="image" src="https://user-images.githubusercontent.com/567298/73784085-80872700-479d-11ea-9005-4cac54ac000d.png"></p>

<p>Commit a dummy file to git and you should see your pipeline being triggered:</p>

<p><img width="1013" alt="image" src="https://user-images.githubusercontent.com/567298/73784286-dd82dd00-479d-11ea-93f4-6363da53c1c1.png"></p>

<p>Once your pipeline has finished and everything succeeded, you should see the output of your nodes in your kubernetes service container:</p>

<p><img width="1068" alt="image" src="https://user-images.githubusercontent.com/567298/73784435-220e7880-479e-11ea-8f9d-a9856632302d.png"></p>

<p>As I mentioned earlier, we are not doing anything special but service containers allows us to do some awesome things.</p>

<p>Thank you for reading. If you like my content, feel free to visit me at <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<p><a href="https://twitter.com/ruanbekker"><img src="https://user-images.githubusercontent.com/567298/71188576-e2410f80-2289-11ea-8667-08f0c14ab7b5.png" alt="" /></a></p>

<p><a href="https://ko-fi.com/A6423ZIQ"><img src="https://www.ko-fi.com/img/githubbutton_sm.svg" alt="ko-fi" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup Gitea and Drone on Docker 2020 Edition]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/04/setup-gitea-and-drone-on-docker-2020-edition/"/>
    <updated>2020-02-04T21:58:39+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/04/setup-gitea-and-drone-on-docker-2020-edition</id>
    <content type="html"><![CDATA[<p>This post will show how to setup gitea and drone on a docker host with docker-compose. The drone example in this tutorial will be very basic, but in future posts I will focus more on pipeline examples using drone.</p>

<p>As this post I will use to link back for those who needs to setup the stack first.</p>

<h2>Deploy Gitea and Drone</h2>

<p>Get the docker-compose.yml:</p>

<pre><code>$ wget -O docker-compose.yml https://gist.githubusercontent.com/ruanbekker/27d2cb2e3f4194ee5cfe2bcdc9c4bf52/raw/25590a23e87190a871d70fd57ab461ce303cd286/2020.02.04-gitea-drone_docker-compose.yml
</code></pre>

<p>Verify the environment variables and adjust the defaults if you want to change something, if you want your git clone ssh url to point to a dns name as well as the url for gitea, then change the following to your dns:</p>

<pre><code>  gitea:
    ...
    environment:
      - ROOT_URL=http://gi.myresolvable.dns:3000
      - SSH_DOMAIN=git.myresolvable.dns
</code></pre>

<p>then deploy:</p>

<pre><code>$ docker-compose up -d
</code></pre>

<h2>Access your Stack</h2>

<p>The default port for Gitea in this setup is port <code>3000</code>:</p>

<p><img width="1273" alt="image" src="https://user-images.githubusercontent.com/567298/73778916-9b08d280-4794-11ea-88a6-8aafcd6e2656.png"></p>

<p>Initial configuration will be pre-populated from our environment variables:</p>

<p><img width="859" alt="image" src="https://user-images.githubusercontent.com/567298/73778973-b378ed00-4794-11ea-8615-d8deeee07b32.png"></p>

<p>From the additional settings section, create your admin user (this user is referenced in our docker-compose as well)</p>

<p><img width="871" alt="image" src="https://user-images.githubusercontent.com/567298/73779102-df946e00-4794-11ea-9177-712904e9dbee.png"></p>

<p>Because I am using gitea as my hostname, you will be redirected to <code>http://gitea:3000/user/login</code>, if you don&rsquo;t have a host entry setup for that it will fail, but you can just replace your servers ip in the request url and it will take you to the login screen, and after logging on, you should see this screen:</p>

<p><img width="1269" alt="image" src="https://user-images.githubusercontent.com/567298/73779494-752ffd80-4795-11ea-9c34-ff9eee269b0c.png"></p>

<p>Access drone on port 80, you will be directed to the login screen:</p>

<p><img width="773" alt="image" src="https://user-images.githubusercontent.com/567298/73779560-9395f900-4795-11ea-8f90-e420aa4c383d.png"></p>

<p>Use the same credentials that you have used to sign up with gitea, and after logging on, you should see this:</p>

<p><img width="1280" alt="image" src="https://user-images.githubusercontent.com/567298/73779651-b2948b00-4795-11ea-9939-51531467b600.png"></p>

<p>If ever your login does not work, just delete the drone access token on gitea (gitea:3000/user/settings/applications)</p>

<h2>Create a Git Repository</h2>

<p>On gitea, create a new git repository:</p>

<p><img width="698" alt="image" src="https://user-images.githubusercontent.com/567298/73779800-fdae9e00-4795-11ea-9422-938a24c08eb3.png"></p>

<p>You should now see your git repository:</p>

<p><img width="1005" alt="image" src="https://user-images.githubusercontent.com/567298/73779843-10c16e00-4796-11ea-98c6-2f70519146f0.png"></p>

<p>Create a new file <code>.drone.yml</code> with the following content:</p>

<pre><code>kind: pipeline
name: hello-world
type: docker

steps:
  - name: say-hello
    image: busybox
    commands:
      - echo hello-world
</code></pre>

<p>It should look like this:</p>

<p><img width="1019" alt="image" src="https://user-images.githubusercontent.com/567298/73779989-4fefbf00-4796-11ea-8e65-8441d3440d19.png"></p>

<h2>Configure Drone</h2>

<p>Commit the file in your git repository and head over to drone (which should be available on port <code>80</code>) and select &ldquo;Sync&rdquo;, after a couple of seconds you should see the git repository:</p>

<p><img width="860" alt="image" src="https://user-images.githubusercontent.com/567298/73780087-7f063080-4796-11ea-92ce-3d216c4e4097.png"></p>

<p>Select &ldquo;Activate&rdquo; and &ldquo;Activate Repository&rdquo;, on the next screen select &ldquo;Trusted&rdquo;, verify that the configuration file name is the same as which we created, then select save:</p>

<p><img width="860" alt="image" src="https://user-images.githubusercontent.com/567298/73780208-b543b000-4796-11ea-98f1-0f072eeae0ef.png"></p>

<h2>Trigger the Build</h2>

<p>If you click on &ldquo;Activity Feed&rdquo; you should see a empty feed. Head back to git and commit a dummy file to trigger the build to start. I will create a file name <code>trigger</code> with the value as <code>1</code> for my dummy file.</p>

<p>After committing the file, you will see on drone that the build started:</p>

<p><img width="900" alt="image" src="https://user-images.githubusercontent.com/567298/73780444-297e5380-4797-11ea-94e6-58c01ae11143.png"></p>

<p>When we select the build, you can see we have a clone step and the step that we defined to echo &ldquo;hello-world&rdquo;:</p>

<p><img width="851" alt="image" src="https://user-images.githubusercontent.com/567298/73780516-46b32200-4797-11ea-8a07-0563dea90d83.png"></p>

<h2>Thank You</h2>

<p>This was a basic introduction for gitea and drone, but I will use this post in conjunction with more gitea examples in the future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Concourse CI to Deploy to Docker Swarm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/05/04/using-concourse-ci-to-deploy-to-docker-swarm/"/>
    <updated>2019-05-04T17:11:17-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/05/04/using-concourse-ci-to-deploy-to-docker-swarm</id>
    <content type="html"><![CDATA[<p><img src="https://i.snag.gy/gzkdu9.jpg?nocache=1511644783495" alt="" /></p>

<p>In this tutorial we will use Concourse to Deploy our application to Docker Swarm.</p>

<h2>The Flow</h2>

<ul>
<li>Our application code resides on Github</li>
<li>The pipeline triggers when a commit is pushed to the master branch</li>
<li>The pipeline will automatically deploy to the staging environment</li>
<li>The pipeline requires a manual trigger to deploy to prod</li>
<li>Note: Staging and Prod on the same swarm for demonstration</li>
</ul>


<p>The code for this tutorial is available on my <strong><a href="https://github.com/ruanbekker/concourse-swarm-app-demo">github repository</a></strong></p>

<h2>Application Structure</h2>

<p>The application structure for our code looks like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/57184912-1d412f00-6ec3-11e9-85e9-6517d83e96e8.png" alt="" /></p>

<h2>Pipeline Walktrough</h2>

<p>Our <code>ci/pipeline.yml</code></p>

<pre><code class="yaml">resources:
  - name: main-repo
    type: git
    source:
      uri: git@github.com:ruanbekker/concourse-swarm-app-demo.git
      branch: master
      private_key: ((github_private_key))

  - name: main-repo-staging
    type: git
    source:
      uri: git@github.com:ruanbekker/concourse-swarm-app-demo.git
      branch: master
      private_key: ((github_private_key))
      paths:
        - config/staging/*

  - name: main-repo-prod
    type: git
    source:
      uri: git@github.com:ruanbekker/concourse-swarm-app-demo.git
      branch: master
      private_key: ((github_private_key))
      paths:
        - config/prod/*

  - name: slack-alert
    type: slack-notification
    source:
      url: ((slack_notification_url))

  - name: version-staging
    type: semver
    source:
      driver: git
      uri: git@github.com:ruanbekker/concourse-swarm-app-demo.git
      private_key: ((github_private_key))
      file: version-staging
      branch: version-staging

  - name: version-prod
    type: semver
    source:
      driver: git
      uri: git@github.com:ruanbekker/concourse-swarm-app-demo.git
      private_key: ((github_private_key))
      file: version-prod
      branch: version-prod

resource_types:
  - name: slack-notification
    type: docker-image
    source:
      repository: cfcommunity/slack-notification-resource
      tag: v1.3.0

jobs:
  - name: bump-staging-version
    plan:
    - get: main-repo-staging
      trigger: true
    - get: version-staging
    - put: version-staging
      params:
        bump: major

  - name: bump-prod-version
    plan:
    - get: main-repo-prod
      trigger: true
    - get: version-prod
    - put: version-prod
      params:
        bump: major

  - name: deploy-staging
    plan:
    - get: main-repo-staging
    - get: main-repo
    - get: version-staging
      passed:
      - bump-staging-version
      trigger: true
    - task: deploy-staging
      params:
        DOCKER_SWARM_HOSTNAME: ((docker_swarm_staging_host))
        DOCKER_SWARM_KEY: ((docker_swarm_key))
        DOCKER_HUB_USER: ((docker_hub_user))
        DOCKER_HUB_PASSWORD: ((docker_hub_password))
        SERVICE_NAME: app-staging
        SWARM: staging
        ENVIRONMENT: staging
        AWS_ACCESS_KEY_ID: ((aws_access_key_id))
        AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        AWS_DEFAULT_REGION: ((aws_region))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: rbekker87/build-tools
            tag: latest
            username: ((docker_hub_user))
            password: ((docker_hub_password))
        inputs:
        - name: main-repo-staging
        - name: main-repo
        - name: version-staging
        run:
          path: /bin/sh
          args:
            - -c
            - |
              ./main-repo/ci/scripts/deploy.sh
      on_failure:
        put: slack-alert
        params:
          channel: '#system_events'
          username: 'concourse'
          icon_emoji: ':concourse:'
          silent: true
          text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) FAILED :rage: - TestApp Deploy to staging-swarm failed
            http://ci.example.local/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME
      on_success:
        put: slack-alert
        params:
          channel: '#system_events'
          username: 'concourse'
          icon_emoji: ':concourse:'
          silent: true
          text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) SUCCESS :aww_yeah: - TestApp Deploy to staging-swarm succeeded
            http://ci.example.local/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME

  - name: deploy-prod
    plan:
    - get: main-repo-prod
    - get: main-repo
    - get: version-prod
      passed:
      - bump-prod-version
    - task: deploy-prod
      params:
        DOCKER_SWARM_HOSTNAME: ((docker_swarm_prod_host))
        DOCKER_SWARM_KEY: ((docker_swarm_key))
        DOCKER_HUB_USER: ((docker_hub_user))
        DOCKER_HUB_PASSWORD: ((docker_hub_password))
        SERVICE_NAME: app-prod
        SWARM: prod
        ENVIRONMENT: production
        AWS_ACCESS_KEY_ID: ((aws_access_key_id))
        AWS_SECRET_ACCESS_KEY: ((aws_secret_access_key))
        AWS_DEFAULT_REGION: ((aws_region))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: rbekker87/build-tools
            tag: latest
            username: ((docker_hub_user))
            password: ((docker_hub_password))
        inputs:
        - name: main-repo-prod
        - name: main-repo
        - name: version-prod
        run:
          path: /bin/sh
          args:
            - -c
            - |
              ./main-repo/ci/scripts/deploy.sh
      on_failure:
        put: slack-alert
        params:
          channel: '#system_events'
          username: 'concourse'
          icon_emoji: ':concourse:'
          silent: true
          text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) FAILED :rage: - TestApp Deploy to prod-swarm failed
            http://ci.example.local/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME
      on_success:
        put: slack-alert
        params:
          channel: '#system_events'
          username: 'concourse'
          icon_emoji: ':concourse:'
          silent: true
          text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) SUCCESS :aww_yeah: - TestApp Deploy to prod-swarm succeeded
            http://ci.example.local/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME
</code></pre>

<p>Our <code>ci/credentials.yml</code> which will hold all our secret info, which will remain local:</p>

<pre><code>username: yourdockerusername
password: yourdockerpassword
docker_swarm_prod_host: 10.20.30.40
...
</code></pre>

<p>The first step of our deploy will invoke a shell script that will establish a ssh tunnel to the docker host, mounting the docker socket to a tcp local port, then exporting the docker host port to the tunneled port, <code>ci/scripts/deploy.sh</code>:</p>

<pre><code>#!/usr/bin/env sh

export DOCKER_HOST="localhost:2376"

echo "${DOCKER_SWARM_KEY}" | sed -e 's/\(KEY-----\)\s/\1\n/g; s/\s\(-----END\)/\n\1/g' | sed -e '2s/\s\+/\n/g' &gt; key.pem
chmod 600 key.pem

screen -S \
  sshtunnel -m -d sh -c \
  "ssh -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -i ./key.pem -NL localhost:2376:/var/run/docker.sock root@$DOCKER_SWARM_HOSTNAME"

sleep 5
docker login -u "${DOCKER_HUB_USER}" -p "${DOCKER_HUB_PASSWORD}"
docker stack deploy --prune -c ./main-repo/ci/docker/docker-compose.${ENVIRONMENT}.yml $SERVICE_NAME --with-registry-auth

if [ $? != "0" ]
  then
    echo "deploy failure for: $SERVICE_NAME"
    screen -S sshtunnel -X quit
    exit 1
  else
    set -x
    echo "deploy success for: $SERVICE_NAME"
    screen -S sshtunnel -X quit
fi
</code></pre>

<p>The deploy script references the docker-compose files, first our <code>ci/docker/docker-compose.staging.yml</code>:</p>

<pre><code>version: "3.4"

services:
  web:
    image: ruanbekker/web-center-name
    environment:
      - APP_ENVIRONMENT=Staging
    ports:
      - 81:5000
    networks:
      - web_net
    deploy:
      mode: replicated
      replicas: 2

networks:
  web_net: {}
</code></pre>

<p>Also, our docker-compose for production, <code>ci/docker/docker-compose.production.yml</code>:</p>

<pre><code>version: "3.4"

services:
  web:
    image: ruanbekker/web-center-name
    environment:
      - APP_ENVIRONMENT=Production
    ports:
      - 80:5000
    networks:
      - web_net
    deploy:
      mode: replicated
      replicas: 10

networks:
  web_net: {}
</code></pre>

<h2>Set the Pipeline in Concourse</h2>

<p>Create 2 branches in your github repository for versioning: <code>version-staging</code> and <code>version-prod</code>, then logon to concourse and save the target:</p>

<pre><code>$ fly -t ci login -n main -c http://&lt;concourse-ip&gt;
</code></pre>

<p>Set the pipeline, point the config, local variables definition and name the pipeline:</p>

<pre><code>$ fly -t ci sp -n main -c ci/pipeline.yml -p &lt;pipeline-name&gt; -l ci/&lt;variables&gt;.yml
</code></pre>

<p>You will find that the pipeline will look like below and that it will be in a paused state:</p>

<p><img src="https://user-images.githubusercontent.com/567298/54060759-96dfd800-4206-11e9-9236-e3b86783417c.png" alt="" /></p>

<p>Unpause the pipeline:</p>

<pre><code>$ fly -t ci up -p swarm-demo
</code></pre>

<p>The pipeline should kick-off automatically due to the trigger that is set to true:</p>

<p><img src="https://user-images.githubusercontent.com/567298/54060811-cbec2a80-4206-11e9-8de7-a0b308f20cef.png" alt="" /></p>

<p>Deployed automatically to staging, prod is a manual trigger:</p>

<p><img src="https://user-images.githubusercontent.com/567298/54060991-8e3bd180-4207-11e9-9726-2c01ca10d24a.png" alt="" /></p>

<h2>Testing our Application</h2>

<p>For demonstration purposes we have deployed staging on port 81 and production on port 80.</p>

<p>Testing Staging on <a href="http://">http://</a><swarm-ip>:81/</p>

<p><img src="https://user-images.githubusercontent.com/567298/57185377-73fe3700-6eca-11e9-91d3-953e754cbde9.png" alt="" /></p>

<p>Testing Production on <a href="http://">http://</a><swarm-ip>:80/</p>

<p><img src="https://user-images.githubusercontent.com/567298/57185383-8d06e800-6eca-11e9-8cff-c3a665f9f377.png" alt="" /></p>
]]></content>
  </entry>
  
</feed>
