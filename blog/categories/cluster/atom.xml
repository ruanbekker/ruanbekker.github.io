<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cluster | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/cluster/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2020-06-13T19:29:27+02:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setup a 5 Node Highly Available Elasticsearch Cluster]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/04/02/setup-a-5-node-highly-available-elasticsearch-cluster/"/>
    <updated>2019-04-02T11:05:19+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/04/02/setup-a-5-node-highly-available-elasticsearch-cluster</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53352581-b3892f80-392b-11e9-9532-5db5cbfc8f1c.jpg" alt="elasticsearch" /></p>

<p>This is post 1 of my big collection of <strong><a href="https://blog.ruanbekker.com/blog/categories/elasticsearch-tutorials">elasticsearch-tutorials</a></strong> which includes, setup, index, management, searching, etc. More details at the bottom.</p>

<p>In this tutorial we will setup a <strong>5 node highly available elasticsearch cluster</strong> that will consist of 3 Elasticsearch Master Nodes and 2 Elasticsearch Data Nodes.</p>

<blockquote><p>&ldquo;Three master nodes is the way to start, but only if you&rsquo;re building a full cluster, which at minimum is 3 master nodes plus at least 2 data nodes.&rdquo;
 - <a href="https://discuss.elastic.co/t/should-dedicated-master-nodes-and-data-nodes-be-considered-separately/75093/14">https://discuss.elastic.co/t/should-dedicated-master-nodes-and-data-nodes-be-considered-separately/75093/14</a></p></blockquote>

<p><a href="https://bekkerclothing.com/collections/developer?utm_source=blog.ruanbekker.com&utm_medium=blog&utm_campaign=leaderboard_ad" target="_blank"><img alt="bekker-clothing-developer-tshirts" src="https://user-images.githubusercontent.com/567298/70170981-7c278a80-16d6-11ea-9759-6621d02c1423.png"></a></p>

<h2>The Overview:</h2>

<p>In short the responsibilites of the node types:</p>

<p><strong>Master Nodes</strong>: Master nodes are responsible for Cluster related tasks, creating / deleting indexes, tracking of nodes, allocate shards to nodes, etc.</p>

<p><strong>Data Nodes</strong>: Data nodes are responsible for hosting the actual shards that has the indexed data also handles data related operations like CRUD, search, and aggregations.</p>

<p>For more concepts of Elasticsearch, have a look at their <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started-concepts.html">basic-concepts</a> documentation.</p>

<p>Our Inventory will consist of:</p>

<p><strong>Master Nodes:</strong></p>

<pre><code>Hostname: es-master-1, Private IP: 172.31.0.77
Hostname: es-master-2, Private IP: 172.31.0.45
Hostname: es-master-3, Private IP: 172.31.1.31
</code></pre>

<p><strong>Data Nodes:</strong></p>

<pre><code>Hostname: es-data-1, Private IP:172.31.2.30
Hostname: es-data-2, Private IP:172.31.0.83
</code></pre>

<p><strong>Reserved Volumes</strong> for Data Nodes:</p>

<pre><code>es-data-1: 10GB assigned to /dev/vdb
es-data-2: 10GB assigned to /dev/vdb
</code></pre>

<p><strong>Authentication:</strong></p>

<p>Note that I have configured the bind address for elasticsearch to <code>0.0.0.0</code> using <code>network.host: 0.0.0.0</code> for this demonstration, but this means that if your server has a public ip address with no firewall rules or no auth, that anyone will be able to interact with your cluster.</p>

<p>This address will also be reachable for all nodes to see each other.</p>

<p>It&rsquo;s advisable do protect your endpoint, either with <a href="https://blog.ruanbekker.com/blog/2017/08/31/secure-your-access-to-kibana-5-and-elasticsearch-5-with-nginx-for-aws/">basic auth using nginx</a> which can be found in the embedded link, or using firewall rules to protect communication from the outside (depending on your setup)</p>

<h2>Setup the Elasticsearch Master Nodes</h2>

<p>The setup below how to provision a elasticsearch master node. Repeat this on node: <code>es-master-1</code>, <code>es-master-2</code>, <code>es-master-3</code></p>

<p>Set your hosts file for name resolution (if you don&rsquo;t have private dns in place):</p>

<pre><code>$ cat &gt; /etc/hosts &lt;&lt; EOF
127.0.0.1 localhost
172.31.0.77 es-master-1
172.31.0.45 es-master-2
172.31.1.31 es-master-3
172.31.2.30 es-data-1
172.31.0.83 es-data-2
EOF
</code></pre>

<p>Get the elasticsearch repositories, install the java development kit dependency and install elasticsearch:</p>

<pre><code>$ apt update &amp;&amp; apt upgrade -y
$ apt install software-properties-common python-software-properties apt-transport-https -y
$ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
$ echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list
$ apt update
$ apt install default-jdk -y
$ apt install elasticsearch -y
</code></pre>

<p>The elasticsearch config, before we get to the full example config, I just want to show a snippet of how you could split up logs and data.</p>

<p>Note that you can seperate your logging between data/logs like this:</p>

<pre><code># example of log splitting:
...
path:
  logs: /var/log/elasticsearch
  data: /var/data/elasticsearch
...
</code></pre>

<p>Also, your data can be divided between paths:</p>

<pre><code># example of data paths:
...
path:
  data:
    - /mnt/elasticsearch_1
    - /mnt/elasticsearch_2
    - /mnt/elasticsearch_3
...
</code></pre>

<p>Bootstrap the elasticsearch config with a cluster name (all the nodes should have the same cluster name), set the nodes as master <code>node.master: true</code> disable the <code>node.data</code> and specify that the cluster should at least have a minimum of 2 master nodes before it stops. This is used to prevent split brain.</p>

<p>To avoid a split brain, this setting should be set to a quorum of master-eligible nodes:
<code>(master_eligible_nodes / 2) + 1</code></p>

<p>The full example config:</p>

<pre><code>$ cat &gt; /etc/elasticsearch/elasticsearch.yml &lt;&lt; EOF
cluster.name: es-cluster
node.name: \${HOSTNAME}
node.master: true
node.data: false
path.logs: /var/log/elasticsearch
bootstrap.memory_lock: true
network.host: 0.0.0.0
discovery.zen.minimum_master_nodes: 2
discovery.zen.ping.unicast.hosts: ["es-master-1", "es-master-2", "es-master-3"]
EOF
</code></pre>

<p>Important settings for your elasticsearch cluster is described on their <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/system-config.html">docs</a>:</p>

<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html">Disable swapping</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/file-descriptors.html">Increase file descriptors</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html">Ensure sufficient virtual memory</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/max-number-of-threads.html">Ensure sufficient threads</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/networkaddress-cache-ttl.html">JVM DNS cache settings</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/executable-jna-tmpdir.html">Temporary directory not mounted with noexec</a></li>
</ul>


<pre><code>$ cat &gt; /etc/default/elasticsearch &lt;&lt; EOF
ES_STARTUP_SLEEP_TIME=5
MAX_OPEN_FILES=65536
MAX_LOCKED_MEMORY=unlimited
EOF
</code></pre>

<p>Ensure that pages are not swapped out to disk by requesting the JVM to lock the heap in memory by setting <code>LimitMEMLOCK=infinity</code>. Set the maxiumim file descriptor number for this process: <code>LimitNOFILE</code> and increase the number of threads using <code>LimitNPROC</code>:</p>

<pre><code>$ vim /usr/lib/systemd/system/elasticsearch.service

[Service]
LimitMEMLOCK=infinity
LimitNOFILE=65535
LimitNPROC=4096
...
</code></pre>

<p>Increase the limit on the number of open files descriptors to user elasticsearch of 65536 or higher</p>

<pre><code>$ cat &gt; /etc/security/limits.conf &lt;&lt; EOF
elasticsearch soft memlock unlimited
elasticsearch hard memlock unlimited
EOF
</code></pre>

<p>Increase the value of the mmap counts as elasticsearch uses mmapfs directory to store its indices:</p>

<pre><code>$ sysctl -w vm.max_map_count=262144
</code></pre>

<p>For a permanent setting, update <code>vm.max_map_count</code> in <code>/etc/sysctl.conf</code> and run</p>

<pre><code>$ sysctl -p /etc/sysctl.conf 
</code></pre>

<p>Prepare the directories and set the ownership to elasticsearch:</p>

<pre><code>$ mkdir /usr/share/elasticsearch/data
$ chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data
</code></pre>

<p>Reload the systemd daemon, enable and start elasticsearch</p>

<pre><code>$ systemctl daemon-reload
$ systemctl enable elasticsearch
$ systemctl restart elasticsearch
</code></pre>

<p>Once all 3 elasticsearch masters has been started, verify that they are listening: <code>netstat -tulpn | grep 9200</code> then look at the cluster health:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cluster/health?pretty
{
  "cluster_name" : "es-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 3,
  "number_of_data_nodes" : 0,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
</code></pre>

<p>Have a look at the nodes, you will see that the node.role for now shows <code>mi</code>:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cat/nodes?v
ip          heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.163.68.8           11          80  18    0.28    0.14     0.09 mi        -      es-master-2
10.163.68.5           14          80  14    0.27    0.18     0.11 mi        *      es-master-1
10.163.68.4           15          79   6    0.62    0.47     0.18 mi        -      es-master-3
</code></pre>

<h2>Setup the Elasticsearch Data Nodes</h2>

<p>Now that we have our 3 elasticsearch master nodes running, its time to provision the 2 elasticsearch data nodes. This setup needs to be repeated on both <code>es-data-1</code> and <code>es-data-2</code>.</p>

<p>Configure the hosts file for name resolution:</p>

<pre><code>$ cat &gt; /etc/hosts &lt;&lt; EOF
127.0.0.1 localhost
172.31.0.77 es-master-1
172.31.0.45 es-master-2
172.31.1.31 es-master-3
172.31.2.30 es-data-1
172.31.0.83 es-data-2
EOF
</code></pre>

<p>Get the elasticsearch repositories, install the java development kit dependency and install elasticsearch:</p>

<pre><code>$ apt update &amp;&amp; apt upgrade -y
$ apt install software-properties-common python-software-properties apt-transport-https -y
$ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
$ echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list
$ apt update
$ apt install default-jdk -y
$ apt install elasticsearch -y
</code></pre>

<p>Since we attached an extra disk to our data nodes, verify that you can see the disk:</p>

<pre><code>$ lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
vda    253:0    0  25G  0 disk
└─vda1 253:1    0  25G  0 part /
vdb    253:16   0  10G  0 disk             &lt;----
</code></pre>

<p>Provision the block device with xfs or anything else that you prefer, create the directory where elasticsearch data will reside, change the ownership that elasticsearch has permission to write/read, set the device on startup and mount the disk:</p>

<pre><code>$ mkfs.xfs /dev/vdb
$ mkdir /data
$ mkdir /data/nodes
$ chown -R elasticsearch:elasticsearch /data
$ chown -R elasticsearch:elasticsearch /data/nodes
$ echo '/dev/vdb /data xfs defaults 0 0' &gt;&gt; /etc/fstab
$ mount -a
</code></pre>

<p>Verify that the disk is mounted:</p>

<pre><code>$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            994M     0  994M   0% /dev
tmpfs           201M  3.1M  197M   2% /run
/dev/vda1        25G  1.8G   23G   8% /
/dev/vdb         10G   33M   10G   1% /data
</code></pre>

<p>Bootstrap the elasticsearch config with a cluster name, set the <code>node.name</code> to an identifier, in this case I will use the servers hostname, set the <code>node.master</code> to false as this will be data nodes, also enable these nodes as data nodes: <code>node.data: true</code>, configure the <code>path.data: /data</code> to the path that we configured, etc:</p>

<pre><code>$ cat &gt; /etc/elasticsearch/elasticsearch.yml &lt;&lt; EOF
cluster.name: es-cluster
node.name: \${HOSTNAME}
node.master: false
node.data: true
path.data: /data
path.logs: /var/log/elasticsearch
bootstrap.memory_lock: true
network.host: 0.0.0.0
discovery.zen.minimum_master_nodes: 2
discovery.zen.ping.unicast.hosts: ["es-master-1", "es-master-2", "es-master-3"]
EOF
</code></pre>

<p>Set a couple of important settings for your elasticsearch cluster is described on their <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/system-config.html">docs</a>:</p>

<pre><code>$ cat &gt; /etc/default/elasticsearch &lt;&lt; EOF
ES_STARTUP_SLEEP_TIME=5
MAX_OPEN_FILES=65536
MAX_LOCKED_MEMORY=unlimited
EOF
</code></pre>

<p>Disable swapping, increase the file descriptors and increase the maximum number of threads:</p>

<pre><code>$ vim /usr/lib/systemd/system/elasticsearch.service
[Service]
LimitMEMLOCK=infinity
LimitNOFILE=65535
LimitNPROC=4096
</code></pre>

<p>Also update them via limits.conf:</p>

<pre><code>$ cat &gt; /etc/security/limits.conf &lt;&lt; EOF
elasticsearch soft memlock unlimited
elasticsearch hard memlock unlimited
EOF
</code></pre>

<p>Reload the systemd daemon, enable and start elasticsearch. Allow it to start and check if the ports are listening with <code>netstat -tulpn | grep 9200</code>, then:</p>

<pre><code>$ systemctl daemon-reload
$ systemctl enable elasticsearch
$ systemctl restart elasticsearch
</code></pre>

<p>Verify that everything works as expected, look at the cluster health and look at the status and number of nodes:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cluster/health?pretty
{
  "cluster_name" : "es-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 5,
  "number_of_data_nodes" : 2,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
</code></pre>

<p>Look at the nodes api and you will see that we now have the extra 2 nodes showing up on <code>node.role</code> as <code>di</code>:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cat/nodes?v
ip           heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.163.68.7             9          96   6    0.12    0.11     0.03 di        -      es-data-2
10.163.68.5            10          80   2    0.20    0.09     0.08 mi        *      es-master-1
10.163.68.11           12          96   9    0.12    0.09     0.03 di        -      es-data-1
10.163.68.4            10          79   0    0.00    0.12     0.11 mi        -      es-master-3
10.163.68.8            12          79   1    0.05    0.06     0.07 mi        -      es-master-2
</code></pre>

<h2>Interact with Elasticsearch</h2>

<p>Let&rsquo;s interact with elasticsearch, the overview:</p>

<pre><code>$ curl http://127.0.0.1:9200
{
  "name" : "es-data-1",
  "cluster_name" : "es-cluster",
  "cluster_uuid" : "5BLs4sxsSEK-4OxlGnmlmw",
  "version" : {
    "number" : "6.7.0",
    "build_flavor" : "default",
    "build_type" : "deb",
    "build_hash" : "8453f77",
    "build_date" : "2019-03-21T15:32:29.844721Z",
    "build_snapshot" : false,
    "lucene_version" : "7.7.0",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  },
  "tagline" : "You Know, for Search"
}
</code></pre>

<p>Let&rsquo;s look at the Health API:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cat/health?v
epoch      timestamp cluster    status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
1554154652 21:37:32  es-cluster green           5         2     10   5    0    0        0             0                  -                100.0%
</code></pre>

<p>Let&rsquo;s ingest some data into elasticsearch, we will create an index named <code>first-index</code> with some dummy data about people, username, name, surname, location and hobbies:</p>

<pre><code>$ curl -H 'Content-Type: application/json' -XPOST http://127.0.0.1:9200/first-index/docs/ -d '{"username": "mikes", "name": "mike", "surname": "steyn", "location": {"country": "south africa", "city": "cape town"}, "hobbies": ["sport", "coffee"]}'

$ curl -H 'Content-Type: application/json' -XPOST http://127.0.0.1:9200/first-index/docs/ -d '{"username": "clarissas", "name": "clarissa", "surname": "smith", "location": {"country": "ireland", "city": "dublin"}, "hobbies": ["shopping", "reading", "chess"]}'

$ curl -H 'Content-Type: application/json' -XPOST http://127.0.0.1:9200/first-index/docs/ -d '{"username": "franka", "name": "frank", "surname": "adams", "location": {"country": "new zealand", "city": "auckland"}, "hobbies": ["programming", "swimming", "rugby"]}'
</code></pre>

<p>Now that we ingested our data into elasticsearch, lets have a look at the Indices API, where the number of documents, size etc should reflect:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cat/indices?v
health status index       uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   first-index 1o6yM7tCSqagqoeihKM7_g   5   1          3            0     40.6kb         20.3kb
</code></pre>

<p>Now lets request a search, which will give you by default 10 returned documents:</p>

<pre><code>$ curl http://127.0.0.1:9200/first-index/_search?pretty
{
  "took" : 116,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 3,
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "first-index",
        "_type" : "docs",
        "_id" : "-NTO2mkB8pugP4aC2jtZ",
        "_score" : 1.0,
        "_source" : {
          "username" : "mikes",
          "name" : "mike",
          "surname" : "steyn",
          "location" : {
            "country" : "south africa",
            "city" : "cape town"
          },
          "hobbies" : [
            "sport",
            "coffee"
          ]
        }
      },
      {
        "_index" : "first-index",
        "_type" : "docs",
        "_id" : "-tTR2mkB8pugP4aCAzvG",
        "_score" : 1.0,
        "_source" : {
          "username" : "franka",
          "name" : "frank",
          "surname" : "adams",
          "location" : {
            "country" : "new zealand",
            "city" : "auckland"
          },
          "hobbies" : [
            "programming",
            "swimming",
            "rugby"
          ]
        }
      },
      {
        "_index" : "first-index",
        "_type" : "docs",
        "_id" : "-dTP2mkB8pugP4aC1ztI",
        "_score" : 1.0,
        "_source" : {
          "username" : "clarissas",
          "name" : "clarissa",
          "surname" : "smith",
          "location" : {
            "country" : "ireland",
            "city" : "dublin"
          },
          "hobbies" : [
            "shopping",
            "reading",
            "chess"
          ]
        }
      }
    ]
  }
}
</code></pre>

<p>Let&rsquo;s have a look at our shards using the Shards API, you will also see where each document is assigned to a specific shard, and also if its a primary or replica shard:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cat/shards?v
index       shard prirep state   docs store ip           node
first-index 4     p      STARTED    0  230b 10.163.68.7  es-data-2
first-index 4     r      STARTED    0  230b 10.163.68.11 es-data-1
first-index 2     p      STARTED    0  230b 10.163.68.7  es-data-2
first-index 2     r      STARTED    0  230b 10.163.68.11 es-data-1
first-index 3     r      STARTED    1 6.6kb 10.163.68.7  es-data-2
first-index 3     p      STARTED    1 6.6kb 10.163.68.11 es-data-1
first-index 1     r      STARTED    2  13kb 10.163.68.7  es-data-2
first-index 1     p      STARTED    2  13kb 10.163.68.11 es-data-1
first-index 0     p      STARTED    0  230b 10.163.68.7  es-data-2
first-index 0     r      STARTED    0  230b 10.163.68.11 es-data-1
</code></pre>

<p>Then we can also use the Allocation API to see the size of our indices, disk space per node:</p>

<pre><code>$ curl http://127.0.0.1:9200/_cat/allocation?v
shards disk.indices disk.used disk.avail disk.total disk.percent host         ip           node
     5       20.3kb    32.4mb      9.9gb      9.9gb            0 10.163.68.11 10.163.68.11 es-data-1
     5       20.3kb    32.4mb      9.9gb      9.9gb            0 10.163.68.7  10.163.68.7  es-data-2
</code></pre>

<p>Let&rsquo;s search for anyone with the surname <code>smith</code>:</p>

<pre><code>$ curl -s http://127.0.0.1:9200/first-index/_search?q=surname=smith | jq .
{
  "took": 22,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.2876821,
    "hits": [
      {
        "_index": "first-index",
        "_type": "docs",
        "_id": "-dTP2mkB8pugP4aC1ztI",
        "_score": 0.2876821,
        "_source": {
          "username": "clarissas",
          "name": "clarissa",
          "surname": "smith",
          "location": {
            "country": "ireland",
            "city": "dublin"
          },
          "hobbies": [
            "shopping",
            "reading",
            "chess"
          ]
        }
      }
    ]
  }
}
</code></pre>

<p>Let&rsquo;s search for anyone with <code>rugby</code> as one of their hobbies:</p>

<pre><code>$ curl -s http://127.0.0.1:9200/first-index/_search?q=hobbies=rugby | jq .
{
  "took": 23,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.64072424,
    "hits": [
      {
        "_index": "first-index",
        "_type": "docs",
        "_id": "-tTR2mkB8pugP4aCAzvG",
        "_score": 0.64072424,
        "_source": {
          "username": "franka",
          "name": "frank",
          "surname": "adams",
          "location": {
            "country": "new zealand",
            "city": "auckland"
          },
          "hobbies": [
            "programming",
            "swimming",
            "rugby"
          ]
        }
      }
    ]
  }
}
</code></pre>

<h2>More on Elasticsearch</h2>

<p>I am planning to write up <strong>elasticsearch</strong> articles on the following topics:</p>

<ul>
<li><a href="">Setting up a 5 Node HA Elasticsearch Cluster</a></li>
<li>Indexes / Replicas</li>
<li>Search Queries</li>
<li>Delete Queries</li>
<li>Elasticsearch Snapshots and Restores on S3</li>
<li>Mapping Templates</li>
<li>Resizing Index Shards</li>
<li>Dealing with Old Timeseries Data</li>
<li>Elasticsearch Percentiles</li>
<li>Managing Yellow and Red Status Clusters</li>
<li>Managing High JVM Memory Pressure</li>
<li>and more</li>
</ul>


<p>As I finish up the writing of these posts they will be published under the <a href="https://blog.ruanbekker.com/blog/categories/elasticsearch-tutorials">#elasticsearch-tutorials</a> category on my blog and for any other elasticsearch tutorials, you can find them under the <a href="https://blog.ruanbekker.com/blog/categories/elasticsearch">#elasticsearch</a> category.</p>

<p>Oke byyyyyye :D</p>

<h2>Resources</h2>

<ul>
<li><a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Elasticsearch Docs</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a 3 Node Docker Swarm Cluster on Ubuntu 16.04]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/01/10/setup-a-3-node-docker-swarm-cluster-on-ubuntu-16-dot-04/"/>
    <updated>2019-01-10T16:52:07+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/01/10/setup-a-3-node-docker-swarm-cluster-on-ubuntu-16-dot-04</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53351889-85572000-392a-11e9-9720-464e9318206e.jpg" alt="" /></p>

<p>Docker Swarm is a Clustering and Orchestration Framework for the Docker ecosystem. Have a look at their <a href="https://docs.docker.com/engine/swarm/">official documentation</a> for detailed information.</p>

<p>In this Tutorial we will Setup a 3 Node Docker Swarm Cluster and to Demonstrate How Easy it is to Deploy a Web Application with 2 Replicas from a Docker Image.</p>

<p><br></p>

<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>


<p><br></p>

<h2>Overview of What we will be Doing</h2>

<ul>
<li>Install Docker on 3 Servers with Ubuntu 16.04</li>
<li>Initialize the Swarm and Join the Worker Nodes</li>
<li>Create a Nginx Service with 2 Replicas</li>
<li>Do some Inspection: View some info on the Service</li>
</ul>


<h2>Prerequisites</h2>

<p>3 Fresh Deployed Ubuntu 16.04 Servers. ( 1GB Memory Servers will be good for development )</p>

<h2>What is Docker</h2>

<p>Docker is a Open Source Technology that allows you to create lightweight, isolated, reproducible application instances which is called Containers. Docker is built on top of the LXC technology, so it uses Linux Containers and as mentioned, it&rsquo;s lightweight compared to a traditional VM.</p>

<p>A Container is isolated and uses the Kernel of the Docker host, it also utilizes Kernel features such as cgroups and namespaces in order to make them isolated.</p>

<h2>Installing Docker Community Edition</h2>

<p>Remove any older versions of Docker that might be present and install the dependencies:</p>

<pre><code class="bash">$ sudo apt remove docker docker-engine -y
$ sudo apt install linux-image-extra-$(uname -r) linux-image-extra-virtual python-setuptools -y
$ sudo apt install apt-transport-https ca-certificates curl software-properties-common -y
</code></pre>

<p>Get the needed repository to setup Docker Community Edition:</p>

<pre><code class="bash">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo apt-key fingerprint 0EBFCD88
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
</code></pre>

<p>Update the repository index and Install Docker Community Edition:</p>

<pre><code class="bash">$ sudo apt update
$ sudo apt install docker-ce -y
$ sudo easy_install pip
$ sudo pip install docker-compose
</code></pre>

<p>Enable Docker on Startup and Start the Docker Engine:</p>

<pre><code class="bash">$ sudo systemctl enable docker
$ sudo systemctl restart docker
</code></pre>

<p>If you would like to execute your docker commands without sudo, add your user to the docker group:</p>

<pre><code class="bash">$ sudo usermod -aG docker $(whoami)
</code></pre>

<p>Test your Setup by Running a Hello World Container. You will see that if the image is not in the local docker image cache, it will pull the image from docker hub (or the respective docker registry), then once the image is saved locally, docker will then instantiate the container from that image:</p>

<pre><code class="bash">$ docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
78445dd45222: Pull complete
Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.
</code></pre>

<h2>DNS Configuration</h2>

<p>If you have a DNS Server you can configure the A Records for these hosts on DNS, but for simplicity, I will add the noted IP Addresses from the previous step into my <code>/etc/hosts</code> file so we can resolve names to IP&rsquo;s</p>

<p>Open up the the hosts file:</p>

<pre><code class="bash">$ sudo vim /etc/hosts
</code></pre>

<p>In my example, my IP Addresses:</p>

<pre><code>192.0.2.41  manager
192.0.2.42  worker-1
192.0.2.43  worker-2
</code></pre>

<p>Repeat the above steps on the other 2 Servers and make note of the IP Addresses of each node. You should be able to ping and reach the nodes that was configured. Make sure to allow all traffic between these nodes.</p>

<h2>Initialize the Swarm:</h2>

<p>Now we will initialize the swarm on the manager node and as we have more than one network interface, we will specify the &ndash;advertise-addr option:</p>

<pre><code class="bash">$ docker swarm init --advertise-addr 192.0.2.41
Swarm initialized: current node (siqyf3yricsvjkzvej00a9b8h) is now a manager.

    To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 \
    192.0.2.41:2377

    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
</code></pre>

<p>From the response above, we received the join token that allows the workers to register with the manager node. If its a scenario where you want to have more than one manager node, you can run <code>docker swarm join-token manager</code> to receive the join token for additional manager.</p>

<p>Let&rsquo;s add the two worker nodes to the manager:</p>

<pre><code class="bash">$ [worker-1] docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.0.2.41:2377
This node joined a swarm as a worker.
</code></pre>

<pre><code class="bash">$ [worker-2] docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.0.2.41:2377
This node joined a swarm as a worker.
</code></pre>

<p>To see the node status, so that we can determine if the nodes are active/available etc, from the manager node, list all the nodes in the swarm:</p>

<pre><code class="bash">[manager] $ docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
j14mte3v1jhtbm3pb2qrpgwp6    worker-1  Ready   Active 
siqyf3yricsvjkzvej00a9b8h *  master    Ready   Active        Leader
srl5yzme5hxnzxal2t1efmwje    worker-2  Ready   Active
</code></pre>

<h2>Reobtaining the Join Tokens</h2>

<p>If at any time, you lost your join token, it can be retrieved by running the following for the manager token:</p>

<pre><code class="bash">$ docker swarm join-token manager -q SWMTKN-1-67chzvi4epx28ii18gizcia8idfar5hokojz660igeavnrltf0-09ijujbnnh4v960b8xel58pmj
</code></pre>

<p>And the following to retrieve the worker token:</p>

<pre><code class="bash">$ docker swarm join-token worker -q SWMTKN-1-67chzvi4epx28ii18gizcia8idfar5hokojz660igeavnrltf0-acs21nn28v17uwhw0oqg5ibwx
</code></pre>

<p>Swarm Services in Docker uses a declarative model which means that you define the desired state of the service, and rely on Docker to maintain this state. More information on this can be found on their <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/">Documentation</a></p>

<p>At this moment, we will see that we have no services running in our swarm:</p>

<pre><code class="bash">[manager] $ docker service ls
ID  NAME  MODE  REPLICAS  IMAGE
</code></pre>

<h2>Deploying our First Service</h2>

<p>Now onto the creation of a standard nginx service with 2 replicas, which means that there will be 2 containers of nginx running in our swarm.</p>

<p>But first, we need to create a overlay network, which is a network driver that creates a distributed network among multiple Docker daemon hosts. Swarm takes care of the routing automatically, which is routed via the port mappings. So you can have that your container sits on worker-2, when you hit your manager node on the published port, it will route the request to the desired application that resides on the respective container.</p>

<p>To create a overlay network called mynet:</p>

<pre><code class="bash">[manager] $ docker network create --driver overlay mynet
</code></pre>

<p>Now onto creating the Service. If any of these containers fail, they will handled by the manager node and will be spawned again to have the desired number that we set on the replica option:</p>

<pre><code class="bash">[manager] $ docker service create --name my-web --publish 8080:80 --replicas 2 --network mynet nginx
</code></pre>

<p>Let&rsquo;s have a look at our nginx service:</p>

<pre><code class="bash">[manager] $ docker service ls
ID            NAME    MODE        REPLICAS  IMAGE
1okycpshfusq  my-web  replicated  2/2       nginx:latest
</code></pre>

<p>After we see that the replica count is 2/2 our service is ready.</p>

<p>To see on which nodes our containers are running that makes up our service:</p>

<pre><code class="bash">[manager] $ docker service ps my-web
ID            NAME      IMAGE         NODE      DESIRED STATE  CURRENT STATE           ERROR  PORTS
k0qqrh8s0c2d  my-web.1  nginx:latest  worker-1  Running        Running 30 seconds ago
nku9wer6tmll  my-web.2  nginx:latest  worker-2  Running        Running 30 seconds ago
</code></pre>

<p>From the above output, we can see that worker-1 and worker-2 are serving our containers for our service. We can also retrieve more information of our service by using the inspect option, which will give you a detailed response in json format of the service:</p>

<pre><code class="bash">[manager] $ docker service inspect my-web
</code></pre>

<p>We can get the Endpoint Port info by using inspect and using the &ndash;format parameter to filter the output:</p>

<pre><code class="bash">[manager] $ docker service inspect --format="" my-web  | python -m json.tool
</code></pre>

<p>From the output we will find the PublishedPort is the Port that we Expose, which will be the listener. Our TargetPort will be the port that is listening on the container:</p>

<pre><code class="json">[
    {
        "Protocol": "tcp",
        "PublishMode": "ingress",
        "PublishedPort": 8080,
        "TargetPort": 80
    }
]
</code></pre>

<p>Now that we went through the inspection of our service, its time to test our base nginx service.</p>

<h2>Testing Nginx in our Swarm</h2>

<p>Make a request against your docker node manager address on the port that was exposed, in this case 8080:</p>

<pre><code class="bash">$ curl -I http://docker-node-manager-ip:8080

HTTP/1.1 200 OK
Server: nginx/1.15.5
Date: Thu, 10 Jan 2019 14:48:40 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 02 Oct 2018 14:49:27 GMT
Connection: keep-alive
ETag: "5bb38577-264"
Accept-Ranges: bytes
</code></pre>

<p>Now we have successfull setup a 3 node docker swarm cluster and deployed a basic nginx service to our swarm. Please have a look at my other <a href="https://blog.ruanbekker.com/blog/categories/docker/">Docker Swarm Tutorials</a> for other content.</p>

<h2>Thank You</h2>

<p>Please feel free to show support by, <strong>sharing</strong> this post, making a <strong>donation</strong>, <strong>subscribing</strong> or <strong>reach out to me</strong> if you want me to demo and write up on any specific tech topic.</p>

<center>
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick" />
<input type="hidden" name="hosted_button_id" value="W7CBGYTCWGANQ" />
<input type="image" src="https://user-images.githubusercontent.com/567298/49853901-461c3700-fdf1-11e8-9d80-8a424a3173af.png" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
</form>
</center>




<p><p></p>

<p>Thanks for reading!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My PiStack Blog Proudly Hosted on My RaspberryPi Swarm Cluster]]></title>
    <link href="https://blog.ruanbekker.com/blog/2018/10/23/my-pistack-blog-proudly-hosted-on-my-raspberrypi-swarm-cluster/"/>
    <updated>2018-10-23T22:11:19+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2018/10/23/my-pistack-blog-proudly-hosted-on-my-raspberrypi-swarm-cluster</id>
    <content type="html"><![CDATA[<p>This is a repost of my <a href="http://blog.pistack.co.za/my-blog-proudly-hosted-on-my-raspberrypi-cluster/">first blogpost which is hosted on my Raspberry Pi Cluster (04 July 2017)</a>, that runs Docker Swarm and is served from my Home in South Africa, and can be accessed on <a href="http://blog.pistack.co.za">http://blog.pistack.co.za</a></p>

<h2>Just Look at It!</h2>

<ul>
<li>3x Raspberry Pi 3 Model B</li>
<li>Quad Core 1.2GHz Broadcom BCM2837 64bit CPU</li>
<li>1GB RAM</li>
<li>BCM43438 wireless LAN and Bluetooth Low Energy (BLE) on board</li>
<li>3x 32GB Sandisk SD Cards (Replicated GlusterFS Volume for <code>/gluster</code> partition)</li>
<li>Upgraded switched Micro USB power source up to 2.5A</li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/rpi-cluster.jpg" alt="" /></p>

<h2>My Setup:</h2>

<p>I have 3x <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberrypi 3&rsquo;s</a>, each with a <a href="https://www.sandisk.com/home/memory-cards/sd-cards/ultra-sd">32GB SanDisk SD Card</a>, formatted with <a href="https://www.raspberrypi.org/downloads/raspbian/">Raspbian Jessie Lite</a>, powered by a <a href="https://www.pishop.co.za/store/rpi-power/anid%C3%A9es-6-port-50w-high-power-usb-hub-25aport">6 Port USB Hub</a> and networked with a <a href="https://m.takealot.com/#product_1?id=35258721">Totolink 5 Port Gigabit Switch</a>, but note that: <em>the Rpi does not support Gigabit Networking</em></p>

<p>For persistent storage I have setup a Replicated GlusterFS Volume across the 3 nodes.</p>

<p>More details on how I did the setup, can be found from the <a href="https://blog.ruanbekker.com/blog/2018/10/23/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes/">Setting Up a Docker Swarm Cluster on RaspberryPi Nodes</a> blog post.</p>

<h2>Thanks!</h2>

<p>Thanks for the visit, I will blog about awesome Docker and RaspberryPi related stuff as my mind stumble along awesome ideas :)</p>

<p><p>
<script id="mNCC" language="javascript">
    medianet_width = &ldquo;728&rdquo;;
    medianet_height = &ldquo;90&rdquo;;
    medianet_crid = &ldquo;346651356&rdquo;;
    medianet_versionId = &ldquo;3111299&rdquo;;
  </script>
<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>
<p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a 3 Node MongoDB Replica Set on Ubuntu 16]]></title>
    <link href="https://blog.ruanbekker.com/blog/2017/09/03/setup-a-3-node-mongodb-replica-set-on-ubuntu-16/"/>
    <updated>2017-09-03T01:29:10+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2017/09/03/setup-a-3-node-mongodb-replica-set-on-ubuntu-16</id>
    <content type="html"><![CDATA[<p>Today we will setup a 3 Node Replica Set for MongoDB on Ubuntu 16. A Replica Set is a form of data replication, so that your data resides on more than one node for data durability. We will setup the 1st node as the primary node, the second as the secondary node and the 3rd node will act as an arbiter.</p>

<p>The arbiter node can almost be mentioned as a voter node, as it will be set in place to prevent split brain.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://eladnava.com/deploy-a-highly-available-mongodb-replica-set-on-aws/">https://eladnava.com/deploy-a-highly-available-mongodb-replica-set-on-aws/</a></li>
<li><a href="https://stackoverflow.com/questions/38524150/mongodb-replica-set-with-simple-password-authentication">https://stackoverflow.com/questions/38524150/mongodb-replica-set-with-simple-password-authentication</a> (auth)</li>
<li><a href="https://stackoverflow.com/questions/14789622/mongodb-keyfile-too-open-permissions">https://stackoverflow.com/questions/14789622/mongodb-keyfile-too-open-permissions</a></li>
</ul>


<h2>Installing MongoDB on our 3 Nodes:</h2>

<p>Our case, using Ubuntu 16.04, setting up our repository and installing mongodb from our repository:</p>

<pre><code class="bash">$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6
$ echo "deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list
$ apt update
$ apt install -y mongodb-org -y
</code></pre>

<p>Preparing our Directories:</p>

<pre><code class="bash">$ mkdir -p /srv/mongodb/rs0-0 /srv/mongodb/rs0-1 /srv/mongodb/rs0-2
$ mkdir -p /var/log/mongodb/rs0-0 /var/log/mongodb/rs0-1 /var/log/mongodb/rs0-2
</code></pre>

<p>Populating our MongoDB Configuration:</p>

<ul>
<li>MongoDB Prefers XFS File Systems when using WiredTiger.</li>
</ul>


<pre><code class="bash">$ cat &gt; /etc/mongod.conf &lt;&lt; EOF
storage:
  dbPath: /var/lib/mongodb
  journal:
    enabled: false

storage:
  mmapv1:
    smallFiles: true

systemLog:
  destination: file
  logAppend: true
  path: /var/log/mongodb/mongod.log

net:
  port: 27017
  bindIp: 0.0.0.0

replication:
  replSetName: rs0

security:
  authorization: enabled
EOF
</code></pre>

<p>Enable MongoDB On Startup and Start MongoDB:</p>

<pre><code class="bash">$ systemctl enable mongod
$ systemctl restart mongod
</code></pre>

<h2>Setup MongoDB Replica Sets:</h2>

<p>In our setup we will have 3 nodes: (mongodb-1, mongodb-2, mongodb3) From our Primary Node, connect to MongoDB and inititalize our replica set:</p>

<pre><code class="bash">$ mongo 
MongoDB shell version v3.4.7
connecting to: mongodb://127.0.0.1:27017
MongoDB server version: 3.4.7
&gt; rs.initiate()
{
        "info2" : "no configuration specified. Using a default configuration for the set",
        "me" : "mysql-1:27017",
        "ok" : 1
}
</code></pre>

<p>Next, add our 2 other MongoDB Nodes, remember <code>mongodb-3</code> is our arbiter node:</p>

<pre><code class="bash">rs0:SECONDARY&gt; rs.add("mongodb-2")
{ "ok" : 1 }
rs0:PRIMARY&gt; rs.add("mongodb-3", true)
{ "ok" : 1 }
</code></pre>

<p>Verify the Replica Set Status:</p>

<pre><code class="bash">rs0:PRIMARY&gt; rs.status()
</code></pre>

<pre><code class="json">{
        "set" : "rs0",
        "date" : ISODate("2017-08-27T13:17:42.469Z"),
        "myState" : 1,
        "term" : NumberLong(1),
        "heartbeatIntervalMillis" : NumberLong(2000),
        "optimes" : {
                "lastCommittedOpTime" : {
                        "ts" : Timestamp(0, 0),
                        "t" : NumberLong(-1)
                },
                "appliedOpTime" : {
                        "ts" : Timestamp(1503839853, 1),
                        "t" : NumberLong(1)
                },
                "durableOpTime" : {
                        "ts" : Timestamp(1503839722, 1),
                        "t" : NumberLong(-1)
                }
        },
        "members" : [
                {
                        "_id" : 0,
                        "name" : "mysql-1:27017",
                        "health" : 1,
                        "state" : 1,
                        "stateStr" : "PRIMARY",
                        "uptime" : 422,
                        "optime" : {
                                "ts" : Timestamp(1503839853, 1),
                                "t" : NumberLong(1)
                        },
                        "optimeDate" : ISODate("2017-08-27T13:17:33Z"),
                        "electionTime" : Timestamp(1503839723, 1),
                        "electionDate" : ISODate("2017-08-27T13:15:23Z"),
                        "configVersion" : 3,
                        "self" : true
                },
                {
                        "_id" : 1,
                        "name" : "mongodb-2:27017",
                        "health" : 1,
                        "state" : 2,
                        "stateStr" : "SECONDARY",
                        "uptime" : 28,
                        "optime" : {
                                "ts" : Timestamp(1503839853, 1),
                                "t" : NumberLong(1)
                        },
                        "optimeDurable" : {
                                "ts" : Timestamp(0, 0),
                                "t" : NumberLong(-1)
                        },
                        "optimeDate" : ISODate("2017-08-27T13:17:33Z"),
                        "optimeDurableDate" : ISODate("1970-01-01T00:00:00Z"),
                        "lastHeartbeat" : ISODate("2017-08-27T13:17:41.707Z"),
                        "lastHeartbeatRecv" : ISODate("2017-08-27T13:17:40.699Z"),
                        "pingMs" : NumberLong(4),
                        "syncingTo" : "mysql-1:27017",
                        "configVersion" : 3
                },
                {
                        "_id" : 2,
                        "name" : "mongodb-3:27017",
                        "health" : 1,
                        "state" : 7,
                        "stateStr" : "ARBITER",
                        "uptime" : 8,
                        "lastHeartbeat" : ISODate("2017-08-27T13:17:41.721Z"),
                        "lastHeartbeatRecv" : ISODate("2017-08-27T13:17:38.749Z"),
                        "pingMs" : NumberLong(2),
                        "configVersion" : 3
                }
        ],
        "ok" : 1
}
rs0:PRIMARY&gt; exit
bye
</code></pre>

<h2>Setup Auth:</h2>

<p>Setup Authentication on our MongoDB Database, we will create the user <code>adminuser</code> and setup the password to <code>secret</code>:</p>

<pre><code class="bash">rs0:PRIMARY&gt; use admin
switched to db admin

rs0:PRIMARY&gt; db.createUser({user: "adminuser", pwd: "secret", roles:[{role: "root", db: "admin"}]})
</code></pre>

<pre><code class="json">Successfully added user: {
        "user" : "adminuser",
        "roles" : [
                {
                        "role" : "root",
                        "db" : "admin"
                }
        ]
}
rs0:PRIMARY&gt; exit
</code></pre>

<p>Restart MongoDB:</p>

<pre><code class="bash">$ systemctl restart mongod
</code></pre>

<h2>Connect and Authenticate against MongoDB:</h2>

<p>Connect to your MongoDB Cluster with auth:</p>

<pre><code class="bash">$ mongo --host mongodb.example.com --port 27017 -u &lt;username&gt; -p --authenticationDatabase admin
</code></pre>
]]></content>
  </entry>
  
</feed>
