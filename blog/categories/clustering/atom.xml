<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Clustering | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/clustering/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-02-11T17:40:03-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rejoining or Bootstrapping MySQL Galera Cluster Nodes After Shutdown]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/10/rejoining-or-bootstrapping-mysql-galera-cluster-nodes-after-shutdown/"/>
    <updated>2017-12-10T18:03:44-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/10/rejoining-or-bootstrapping-mysql-galera-cluster-nodes-after-shutdown</id>
    <content type="html"><![CDATA[<p>I have a 3 Node MySQL Galera Cluster that faced a shutdown on all 3 nodes at the same time, luckily this is only a testing environment, but at that time it was down and did not want to start up.</p>

<h2>Issues Faced</h2>

<p>When trying to start MySQL the only error visible was:</p>

<pre><code class="bash">$ /etc/init.d/mysql restart
 * MySQL server PID file could not be found!
Starting MySQL
........ * The server quit without updating PID file (/var/run/mysqld/mysqld.pid).
 * Failed to restart server.
</code></pre>

<p>At that time I can see that the galera port is started, but not mysql:</p>

<pre><code class="bash">$ ps aux | grep mysql
root     23580  0.0  0.0   4508  1800 pts/0    S    00:37   0:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --pid-file=/var/run/mysqld/mysqld.pid
mysql    24144  0.7 22.2 1185116 455660 pts/0  Sl   00:38   0:00 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib/mysql/plugin --user=mysql --log-error=/var/log/mysql/error.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/run/mysqld/mysqld.sock --port=3306 --wsrep_start_position=long:string

$ netstat -tulpn
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 0.0.0.0:4567            0.0.0.0:*               LISTEN      25507/mysqld
</code></pre>

<h2>Why?</h2>

<p>More in detail is explained on a <a href="https://severalnines.com/blog/how-bootstrap-mysqlmariadb-galera-cluster">SeveralNines Blog Post</a>, but due to the fact that all the nodes left the cluster, one of the nodes needs to be started as a referencing point, before the other nodes can rejoin or bootstrapped to the cluster.</p>

<h2>Rejoining the Cluster</h2>

<p>Consult the blog for more information, but from my end, I had a look at the node with the highest seqno and then updated <code>safe_to_bootstrap</code> to <code>1</code>:</p>

<pre><code class="bash">$ cat /var/lib/mysql/grastate.dat
# GALERA saved state
version: 2.1
uuid:    e9f9cf6a-87a1-11e7-9fb4-52612b906897
seqno:   123512
safe_to_bootstrap: 1
</code></pre>

<p>Then made sure that no mysql processes are running, then did a bootstrap:</p>

<pre><code class="bash">$ /etc/init.d/mysql bootstrap
Bootstrapping the cluster
Starting MySQL
</code></pre>

<p>Then restarted mysql on the other nodes.</p>

<h2>Verifying</h2>

<p>To verify that all your nodes has checked in, I have 3 nodes:</p>

<pre><code class="sql">mysql&gt; SHOW STATUS LIKE 'wsrep_%';
+------------------------------+---------------------------------------------------+
| Variable_name                | Value                                             |
+------------------------------+---------------------------------------------------+
| wsrep_local_recv_queue_avg   | 0.000000                                          |
| wsrep_local_state_comment    | Synced                                            |
| wsrep_incoming_addresses     | 10.3.132.91:3306,10.4.1.201:3306,10.4.113.21:3306 |
| wsrep_evs_state              | OPERATIONAL                                       |
| wsrep_cluster_size           | 3                                                 |
| wsrep_cluster_status         | Primary                                           |
| wsrep_connected              | ON                                                |
+------------------------------+---------------------------------------------------+
</code></pre>

<p>or a shorter version:</p>

<pre><code class="sql">mysql&gt; SHOW GLOBAL STATUS LIKE 'wsrep_cluster_size';
+------------------------------+---------------------------------------------------+
| Variable_name                | Value                                             |
+------------------------------+---------------------------------------------------+
| wsrep_cluster_size           | 3                                                 |
+------------------------------+---------------------------------------------------+
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a 3 Node Galera MariaDB Cluster on Ubuntu 16]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/22/setup-a-3-node-galera-mariadb-cluster-on-ubuntu-16/"/>
    <updated>2017-11-22T18:17:14-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/22/setup-a-3-node-galera-mariadb-cluster-on-ubuntu-16</id>
    <content type="html"><![CDATA[<p><img src="https://i.snag.gy/lpT6Du.jpg" alt="" /></p>

<p>Today we will setup a 3-Node Galera MariaDB Cluster which is a Multi Master MySQL/MariaDB Cluster on Ubuntu 16.04</p>

<h2>Our Server Details:</h2>

<pre><code class="bash">172.31.11.174     mysql-1
172.31.13.206     mysql-2
172.31.6.93       mysql-3
</code></pre>

<h2>Update Repo Index and Upgrade:</h2>

<p>Update the repository indexes and install the needed packages:</p>

<pre><code class="bash">$ sudo apt update &amp;&amp; sudo apt upgrade -y
</code></pre>

<p>Install the needed repository and packages:</p>

<pre><code class="bash">$ apt install software-properties-common -y
$ apt-key adv --recv-keys --keyserver hkp://keyserver.ubuntu.com:80 0xF1656F24C74CD1D8
$ add-apt-repository 'deb [arch=amd64,i386,ppc64el] http://mirror.lstn.net/mariadb/repo/10.1/ubuntu xenial main'
$ apt update
$ apt install mariadb-server rsync -y
</code></pre>

<h2>Configuration:</h2>

<pre><code class="bash">cat &gt; /etc/mysql/conf.d/galera.cnf &lt;&lt; EOF
[mysqld]
binlog_format=ROW
default-storage-engine=innodb
innodb_autoinc_lock_mode=2
bind-address=0.0.0.0

# Galera Provider Configuration
wsrep_on=ON
wsrep_provider=/usr/lib/galera/libgalera_smm.so

# Galera Cluster Configuration
wsrep_cluster_name="my-galera-cluster"
wsrep_cluster_address="gcomm://172.31.11.174,172.31.13.206,172.31.6.93"
# Galera Synchronization Configuration
wsrep_sst_method=rsync

# Galera Node Configuration
wsrep_node_address="172.31.11.174"
wsrep_node_name="mysql-1"
EOF
</code></pre>

<p>Comment out bind-address, so that MariaDB process is reachable from other nodes, by default it wont be in the config, but just to make sure, if it is uncommented, comment the config:</p>

<pre><code class="bash /etc/mysql/my.cnf"># bind-address = 127.0.0.1
</code></pre>

<p>Stop the MariaDB Process:</p>

<pre><code class="bash">$ systemctl stop mariadb
</code></pre>

<p>Note: Repeat the above steps on all 3 nodes.</p>

<h2>Initialize the Cluster:</h2>

<p>On the First Node, Initialize the Galera Cluster:</p>

<pre><code class="bash">$ /usr/bin/galera_new_cluster
$ systemctl enable mariadb
</code></pre>

<p>Check how many nodes are active in the Cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 1     |
+--------------------+-------+
</code></pre>

<h2>Node-2: Start and Enable MariaDB</h2>

<pre><code class="bash">$ systemctl start mariadb
$ systemctl enable mariadb
</code></pre>

<p>Verify that the Node has checked in with the Cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 2     |
+--------------------+-------+
</code></pre>

<h2>Node-3: Start and Enable MariaDB</h2>

<pre><code class="bash">$ systemctl start mariadb
$ systemctl enable mariadb
</code></pre>

<p>Verify that the Node has checked in with the Cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 3     |
+--------------------+-------+
</code></pre>

<h2>Create a Database, Table and Record:</h2>

<p>Write some data to the table, then reboot the node, in this example on node-1, then logon to node-2 check the number of nodes that&rsquo;s active in the cluster, which should be 2, then at the same time, look if the data is replicated:</p>

<h2>Node-1: Writing the Data to Our Galera Cluster</h2>

<pre><code class="mysql">MariaDB [(none)]&gt; create database test;
MariaDB [(none)]&gt; use test;
MariaDB [test]&gt;   create database test;
MariaDB [test]&gt;   create table foo (name VARCHAR(20));
MariaDB [test]&gt;   insert into foo values('ruan');
MariaDB [test]&gt;   select * from foo;
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<p>Now that our data is in our database, reboot the node, logon to node-2 and check if the data is replicated:</p>

<pre><code class="mysql">$ mysql -u root -p
MariaDB [(none)]&gt; use test;
MariaDB [test]&gt;   select * from foo;
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<p>While the one node is rebooting, check how many nodes are checked into our cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 2     |
+--------------------+-------+
</code></pre>

<p>Our data is replicated, and after waiting for a couple of seconds, we retry our command to see if the rebooted node checked into the cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 3     |
+--------------------+-------+
</code></pre>

<p>We can confirm that the node that was rebooted, has checked in with the cluster again.</p>

<h2>Firewall Rules opened while testing:</h2>

<p>TCP: <code>3306, 4567, 4568, 4444</code>
UDP: <code>4567</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a Local MongoDB Development 3 Member Replica Set]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/08/27/setup-a-local-mongodb-development-3-member-replica-set/"/>
    <updated>2017-08-27T01:10:16-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/08/27/setup-a-local-mongodb-development-3-member-replica-set</id>
    <content type="html"><![CDATA[<p>Setup a Development Environment of a MongoDB Replica Set consisting of 3 mongod MongoDB Instances.</p>

<p>This is purely aimed for a testing or development environment, as one of the key points is that security is disabled, and that for this post, all 3 instances will be running on the same node.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/">https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/</a></li>
<li><a href="https://docs.mongodb.com/manual/tutorial/deploy-replica-set-for-testing/">https://docs.mongodb.com/manual/tutorial/deploy-replica-set-for-testing/</a></li>
</ul>


<h2>Installation:</h2>

<p>I am using Ubuntu 16.04, for other distributions, have a look at <a href="https://docs.mongodb.com/manual/administration/install-community/">MongoDBs Installation Page</a></p>

<pre><code class="bash MongoDB Installation">$ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6
$ echo "deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list
$ apt update
$ apt install -y mongodb-org -y
</code></pre>

<h2>Prepare Directories:</h2>

<p>Prepare the data directories, and as I am planning to use the <code>--fork</code> option, I need to specify the the <code>--logpath</code>, so therefore I will create the log directories as well:</p>

<pre><code class="bash Create the Directory Paths">$ mkdir -p /srv/mongodb/rs0-0 /srv/mongodb/rs0-1 /srv/mongodb/rs0-2
$ mkdir -p /var/log/mongodb/rs0-0 /var/log/mongodb/rs0-1 /var/log/mongodb/rs0-2
</code></pre>

<h2>Run 3 MongoDB Instances:</h2>

<p>Create 3 MongoDB Instances, each instance listening on it&rsquo;s unique port.</p>

<p>From MongoDB&rsquo;s Documentation:</p>

<blockquote><p>&ldquo;The &ndash;smallfiles and &ndash;oplogSize settings reduce the disk space that each mongod instance uses&rdquo;</p></blockquote>

<pre><code class="bash">$ mongod --port 27017 --dbpath /srv/mongodb/rs0-0 --replSet rs0 --smallfiles --oplogSize 128 --logpath /var/log/mongodb/rs0-0/server.log --fork
$ mongod --port 27018 --dbpath /srv/mongodb/rs0-1 --replSet rs0 --smallfiles --oplogSize 128 --logpath /var/log/mongodb/rs0-1/server.log --fork
$ mongod --port 27019 --dbpath /srv/mongodb/rs0-2 --replSet rs0 --smallfiles --oplogSize 128 --logpath /var/log/mongodb/rs0-2/server.log --fork
</code></pre>

<h2>Cofirm:</h2>

<p>Confirm that the processes are listening on the ports that we defined:</p>

<pre><code class="bash">$ netstat -tulpn
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 0.0.0.0:27017           0.0.0.0:*               LISTEN      1100/mongod
tcp        0      0 0.0.0.0:27018           0.0.0.0:*               LISTEN      1127/mongod
tcp        0      0 0.0.0.0:27019           0.0.0.0:*               LISTEN      1154/mongod
</code></pre>

<h2>Connect to the first MongoDB Instnace:</h2>

<p>Connect to our first MongoDB Instance, where we will setup the replica set:</p>

<pre><code class="bash">$ mongo --port 27017
\&gt;
</code></pre>

<p>Create the Replica Set Configuration Object:</p>

<pre><code class="bash">&gt; rsconf = {
             _id: "rs0",
             members: [
                        {
                         _id: 0,
                         host: "10.78.1.24:27017"
                        }
                      ]
           }
</code></pre>

<p>Initiate the replica set configuration:</p>

<pre><code class="bash">&gt; rs.initiate( rsconf )
{ "ok" : 1 }
</code></pre>

<p>Display the Replica Configuration with <code>rs.conf()</code>:</p>

<pre><code class="bash">rs0:SECONDARY&gt; rs.conf()
{
        "_id" : "rs0",
        "version" : 1,
        "protocolVersion" : NumberLong(1),
        "members" : [
                {
                        "_id" : 0,
                        "host" : "10.78.1.24:27017",
                        "arbiterOnly" : false,
                        "buildIndexes" : true,
                        "hidden" : false,
                        "priority" : 1,
                        "tags" : {

                        },
                        "slaveDelay" : NumberLong(0),
                        "votes" : 1
                }
        ],
        "settings" : {
                "chainingAllowed" : true,
                "heartbeatIntervalMillis" : 2000,
                "heartbeatTimeoutSecs" : 10,
                "electionTimeoutMillis" : 10000,
                "catchUpTimeoutMillis" : 60000,
                "getLastErrorModes" : {

                },
                "getLastErrorDefaults" : {
                        "w" : 1,
                        "wtimeout" : 0
                },
                "replicaSetId" : ObjectId("59a2339f5ff27709a1645d28")
        }
}
</code></pre>

<p>Add the other two mongodb instances to the replica set using <code>rs.add()</code>:</p>

<pre><code class="bash">rs0:PRIMARY&gt; rs.add("10.78.1.24:27018")
{ "ok" : 1 }

rs0:PRIMARY&gt; rs.add("10.78.1.24:27019")
{ "ok" : 1 }
</code></pre>

<p>View the status of our MongoDB Replica Set with <code>rs.status()</code>:</p>

<pre><code class="bash">rs0:PRIMARY&gt; rs.status()
</code></pre>

<pre><code class="json">{
        "set" : "rs0",
        "date" : ISODate("2017-08-27T02:52:08.106Z"),
        "myState" : 1,
        "term" : NumberLong(1),
        "heartbeatIntervalMillis" : NumberLong(2000),
        "optimes" : {
                "lastCommittedOpTime" : {
                        "ts" : Timestamp(1503802316, 1),
                        "t" : NumberLong(1)
                },
                "appliedOpTime" : {
                        "ts" : Timestamp(1503802316, 1),
                        "t" : NumberLong(1)
                },
                "durableOpTime" : {
                        "ts" : Timestamp(1503802316, 1),
                        "t" : NumberLong(1)
                }
        },
        "members" : [
                {
                        "_id" : 0,
                        "name" : "10.78.1.24:27017",
                        "health" : 1,
                        "state" : 1,
                        "stateStr" : "PRIMARY",
                        "uptime" : 890,
                        "optime" : {
                                "ts" : Timestamp(1503802316, 1),
                                "t" : NumberLong(1)
                        },
                        "optimeDate" : ISODate("2017-08-27T02:51:56Z"),
                        "infoMessage" : "could not find member to sync from",
                        "electionTime" : Timestamp(1503802272, 1),
                        "electionDate" : ISODate("2017-08-27T02:51:12Z"),
                        "configVersion" : 3,
                        "self" : true
                },
                {
                        "_id" : 1,
                        "name" : "10.78.1.24:27018",
                        "health" : 1,
                        "state" : 2,
                        "stateStr" : "SECONDARY",
                        "uptime" : 16,
                        "optime" : {
                                "ts" : Timestamp(1503802316, 1),
                                "t" : NumberLong(1)
                        },
                        "optimeDurable" : {
                                "ts" : Timestamp(1503802316, 1),
                                "t" : NumberLong(1)
                        },
                        "optimeDate" : ISODate("2017-08-27T02:51:56Z"),
                        "optimeDurableDate" : ISODate("2017-08-27T02:51:56Z"),
                        "lastHeartbeat" : ISODate("2017-08-27T02:52:06.638Z"),
                        "lastHeartbeatRecv" : ISODate("2017-08-27T02:52:07.638Z"),
                        "pingMs" : NumberLong(0),
                        "syncingTo" : "10.78.1.24:27017",
                        "configVersion" : 3
                },
                {
                        "_id" : 2,
                        "name" : "10.78.1.24:27019",
                        "health" : 1,
                        "state" : 2,
                        "stateStr" : "SECONDARY",
                        "uptime" : 11,
                        "optime" : {
                                "ts" : Timestamp(1503802316, 1),
                                "t" : NumberLong(1)
                        },
                        "optimeDurable" : {
                                "ts" : Timestamp(1503802316, 1),
                                "t" : NumberLong(1)
                        },
                        "optimeDate" : ISODate("2017-08-27T02:51:56Z"),
                        "optimeDurableDate" : ISODate("2017-08-27T02:51:56Z"),
                        "lastHeartbeat" : ISODate("2017-08-27T02:52:06.638Z"),
                        "lastHeartbeatRecv" : ISODate("2017-08-27T02:52:07.241Z"),
                        "pingMs" : NumberLong(0),
                        "configVersion" : 3
                }
        ],
        "ok" : 1
}
</code></pre>

<h2>Write some Data to MongoDB:</h2>

<p>Create a Database named <code>mydb</code>:</p>

<pre><code class="bash">rs0:PRIMARY&gt; use mydb
switched to db mydb
</code></pre>

<p>Create a Collection, named <code>mycol1</code>:</p>

<pre><code class="bash">rs0:PRIMARY&gt; db.createCollection("mycol1")
{ "ok" : 1 }

rs0:PRIMARY&gt; show collections
mycol1
</code></pre>

<p>Write 2 documents with:</p>

<ul>
<li>Name: James, Home Address: Country => South Africa, City => Cape Town</li>
<li>Name: Frank, Home Address: Country => Ireland, City => Dublin</li>
</ul>


<pre><code class="bash Write some Data">rs0:PRIMARY&gt; db.mycol1.insert({"name": "james", "home address": {"country": "south africa", "city": "cape town"}})
WriteResult({ "nInserted" : 1 })

rs0:PRIMARY&gt; db.mycol1.insert({"name": "frank", "home address": {"country": "ireland", "city": "dublin"}})
WriteResult({ "nInserted" : 1 })
</code></pre>

<p>Count all Documents in our Database:</p>

<pre><code class="bash Counting">rs0:PRIMARY&gt; db.mycol1.find().count()
2
</code></pre>

<p>Scan through all documents, and show the in <code>pretty print</code>:</p>

<pre><code class="bash Pretty Print">rs0:PRIMARY&gt; db.mycol1.find().pretty()
{
        "_id" : ObjectId("59a23d26c0c3824694f79ff6"),
        "name" : "james",
        "home address" : {
                "country" : "south africa",
                "city" : "cape town"
        }
}
{
        "_id" : ObjectId("59a23dbdc0c3824694f79ff7"),
        "name" : "frank",
        "home address" : {
                "country" : "ireland",
                "city" : "dublin"
        }
}
</code></pre>

<p>Find Information about <code>Frank</code>:</p>

<pre><code class="bash Franks Info">rs0:PRIMARY&gt; db.mycol1.find({"name": "frank"})
{ "_id" : ObjectId("59a23dbdc0c3824694f79ff7"), "name" : "frank", "home address" : { "country" : "ireland", "city" : "dublin" } }
</code></pre>

<p>Delete the Database, but confirm which database your are logged on, the delete using <code>dropDatabase()</code>:</p>

<pre><code class="bash Drop Database">rs0:PRIMARY&gt; db
mydb

rs0:PRIMARY&gt; db.dropDatabase()
{ "dropped" : "mydb", "ok" : 1 }

rs0:PRIMARY&gt; exit
bye
</code></pre>
]]></content>
  </entry>
  
</feed>
