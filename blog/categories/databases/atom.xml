<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Databases | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/databases/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2023-12-22T07:58:04-05:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Getting Started With FerretDB on Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/06/14/getting-started-with-ferretdb-on-docker/"/>
    <updated>2023-06-14T22:00:00-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/06/14/getting-started-with-ferretdb-on-docker</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/how-to-run-ferretdb-on-docker.png" alt="how-to-run-ferretdb-on-docker" /></p>

<p>In this post we will have a look at <strong>FerretDB</strong> which is a opensource proxy that translates MongoDB queries to SQL, where PostgreSQL being the database engine.</p>

<h2>More about FerretDB</h2>

<p>From <a href="https://www.ferretdb.io/">FerretDB</a> website, they describe FerretDB as:</p>

<blockquote><p>Initially built as open-source software, MongoDB was a game-changer for many developers, enabling them to build fast and robust applications. Its ease of use and extensive documentation made it a top choice for many developers looking for an open-source database. However, all this changed when they switched to an SSPL license, moving away from their open-source roots.</p>

<p>In light of this, FerretDB was founded to become the true open-source alternative to MongoDB, making it the go-to choice for most MongoDB users looking for an open-source alternative to MongoDB. With FerretDB, users can run the same MongoDB protocol queries without needing to learn a new language or command.</p></blockquote>

<h2>What can you expect from this tutorial</h2>

<p>We will be doing the following:</p>

<ul>
<li>deploying ferretdb and postgres on docker containers using docker compose</li>
<li>then use <code>mongosh</code> as a client to logon to ferretdb using the ferretdb endpoint</li>
<li>explore some example queries to insert and read data from ferretdb</li>
<li>use scripting to generate data into ferretedb</li>
<li>explore the embedded prometheus endpoint for metrics</li>
</ul>


<h2>Deploy FerretDB</h2>

<p>The following <code>docker-compose.yaml</code> defines a postgres container which will be used as the database engine for ferretdb, and then we define the ferretdb container, which connects to postgres via the environment variable <code>FERRETDB_POSTGRESQL_URL</code>.</p>

<pre><code class="yml">version: "3.9"

services:
  postgres:
    image: postgres:14.8-bullseye
    container_name: postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=ferret
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ferretdb
    volumes:
      - pgvol:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready", "-d", "db_prod"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    networks:
      - ferretdb
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  ferretdb:
    image: ghcr.io/ferretdb/ferretdb:1.1.0
    container_name: ferretdb
    restart: unless-stopped
    ports:
      - 27017:27017
      - 8080:8080
    environment:
      - FERRETDB_POSTGRESQL_URL=postgres://postgres:5432/ferretdb
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ferretdb
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

networks:
  ferretdb:
    name: ferretdb

volumes:
  pgvol: 
</code></pre>

<p>Once you have the content above saved in <code>docker-compose.yaml</code> you can run the following to run the containers in a detached mode:</p>

<pre><code class="bash">docker-compose up -d
</code></pre>

<h2>Connect to FerretDB</h2>

<p>Once the containers started, we can connect to our ferretdb server using mongosh, which is a shell utility to connect to the database). I will make use of a container to do this, where I will reference the network which we defined in our docker compose file, and set the endpoint that mongosh need to connect to:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb --entrypoint=mongosh mongo:6.0 "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN"
</code></pre>

<p>Once it successfully connects to ferretdb, we should see the following prompt:</p>

<pre><code class="bash">Current Mongosh Log ID: 64626c5c259916d1a68b7dad
Connecting to:      mongodb://&lt;credentials&gt;@ferretdb/ferretdb?authMechanism=PLAIN&amp;directConnection=true&amp;appName=mongosh+1.8.2
Using MongoDB:      6.0.42
Using Mongosh:      1.8.2

ferretdb&gt;
</code></pre>

<h2>Run example queries on FerretDB</h2>

<p>If you are familiar with MongoDB, you will find the following identical to MongoDB.</p>

<p>First we show the current databases:</p>

<pre><code class="bash">ferretdb&gt; show dbs;
public  0 B
</code></pre>

<p>The we create and use the database named <code>mydb</code>:</p>

<pre><code class="bash">ferretdb&gt; use mydb
switched to db mydb
</code></pre>

<p>To see which database are we currently connected to:</p>

<pre><code class="bash">mydb&gt; db
mydb
</code></pre>

<p>Now we can create a collection named <code>mycol1</code> and <code>mycol2</code>:</p>

<pre><code class="bash">mydb&gt; db.createCollection("mycol1")
{ ok: 1 }
mydb&gt; db.createCollection("mycol2")
{ ok: 1 }
</code></pre>

<p>We can view our collections by running the following:</p>

<pre><code class="bash">mydb&gt; show collections
mycol1
mycol2
</code></pre>

<p>To write one document into our collection named <code>col1</code> with the following data:</p>

<pre><code class="json">{
  "name": "ruan",
  "age": 32,
  "hobbies": [
    "golf",
    "programming",
    "music"
  ]
}
</code></pre>

<p>We can execute:</p>

<pre><code class="bash">mydb&gt; db.mycol1.insertOne({"name": "ruan", "age": 32, "hobbies": ["golf", "programming", "music"]})
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("64626cea259916d1a68b7dae") }
}
</code></pre>

<p>And we can insert another document:</p>

<pre><code class="bash">mydb&gt; db.mycol1.insertOne({"name": "michelle", "age": 28, "hobbies": ["art", "music", "reading"]})
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("64626cf1259916d1a68b7daf") }
}
</code></pre>

<p>We can then use <code>countDocuments()</code> to view the number of documents in our collection named <code>mycol1</code>:</p>

<pre><code class="bash">ferretdb&gt; db.mycol1.countDocuments()
2
</code></pre>

<p>If we want to find all our documents in our <code>mycol1</code> collection:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find()
[
  {
    _id: ObjectId("64626cea259916d1a68b7dae"),
    name: 'ruan',
    age: 32,
    hobbies: [ 'golf', 'programming', 'music' ]
  },
  {
    _id: ObjectId("64626cf1259916d1a68b7daf"),
    name: 'michelle',
    age: 28,
    hobbies: [ 'art', 'music', 'reading' ]
  }
]
</code></pre>

<p>If we want to only display specific fields in our response, such as name and age, we can project fields to return from our query:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({}, {"name": 1, "age": 1})
[
  { _id: ObjectId("64626cea259916d1a68b7dae"), name: 'ruan', age: 32 },
  {
    _id: ObjectId("64626cf1259916d1a68b7daf"),
    name: 'michelle',
    age: 28
  }
]
</code></pre>

<p>We can also suppress the <code>_id</code> field by setting the value to <code>0</code>:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({}, {"_id": 0, "name": 1, "age": 1})
[
  { name: 'ruan', age: 32 },
  { name: 'michelle', age: 28 }
]
</code></pre>

<p>Next we can return all the fields name and age from our collection where the age field is equals to 32:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({"age": 32}, {"_id": 0, "name": 1, "age": 1})
[ { name: 'ruan', age: 32 } ]
</code></pre>

<p>We can also find a specific document by its id as example, and return only the field value, like name:</p>

<pre><code class="bash">mydb&gt; db.mycol1.findOne({_id: ObjectId("64626cea259916d1a68b7dae")}).name
ruan
</code></pre>

<p>Next we will find all documents where the age is greater than 30:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({"age": {"$gt": 30}})
[
  {
    _id: ObjectId("64626cea259916d1a68b7dae"),
    name: 'ruan',
    age: 32,
    hobbies: [ 'golf', 'programming', 'music' ]
  }
]
</code></pre>

<p>Let&rsquo;s explore how to insert many documents at once using <code>insertMany()</code>, first create a new collection:</p>

<pre><code class="bash">ferretdb&gt; db.createCollection("mycol2")
{ ok: 1 }
</code></pre>

<p>We can then define the docs variable, and assign a array with 2 json documents:</p>

<pre><code class="bash">ferretdb&gt; var docs = [{name: "peter", age: 34, hobbies: ["ski", "programming", "music"]}, {name: "sam", age: 39, hobbies: ["running", "camping", "music"]}]
</code></pre>

<p>Now we can insert our documents to ferretdb using <code>insertMany()</code>:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.insertMany(docs)
{
  acknowledged: true,
  insertedIds: {
    '0': ObjectId("6464ceb1413cee26e9bf709f"),
    '1': ObjectId("6464ceb1413cee26e9bf70a0")
  }
}
</code></pre>

<p>We can count the documents inside our collection using:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.countDocuments()
2
</code></pre>

<p>And we can search for all the documents inside the collection:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.find()
[
  {
    _id: ObjectId("6464ceb1413cee26e9bf709f"),
    name: 'peter',
    age: 34,
    hobbies: [ 'ski', 'programming', 'music' ]
  },
  {
    _id: ObjectId("6464ceb1413cee26e9bf70a0"),
    name: 'sam',
    age: 39,
    hobbies: [ 'running', 'camping', 'music' ]
  }
]
</code></pre>

<p>And searching for any data using the name <code>peter</code>:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.find({name: "peter"})
[
  {
    _id: ObjectId("6464ceb1413cee26e9bf709f"),
    name: 'peter',
    age: 34,
    hobbies: [ 'ski', 'programming', 'music' ]
  }
]
</code></pre>

<h2>Scripting</h2>

<p>We will create a script so that we can generate data that we want to write into FerretDB.</p>

<p>Create the following script, <code>write.js</code>:</p>

<pre><code>var txs = []
for (var x = 0; x &lt; 1000 ; x++) {
 var transaction_types = ["credit card", "cash", "account"];
 var store_names = ["edgards", "cna", "makro", "picknpay", "checkers"];
 var random_transaction_type = Math.floor(Math.random() * (2 - 0 + 1)) + 0;
 var random_store_name = Math.floor(Math.random() * (4 - 0 + 1)) + 0;
 var random_age = Math.floor(Math.random() * (80 - 18) + 18)
 txs.push({
   transaction: 'tx_' + x,
   transaction_price: Math.round(Math.random()*1000),
   transaction_type: transaction_types[random_transaction_type],
   store_name: store_names[random_store_name],
   age: random_age
   });
}
console.log("drop and recreate the collection")
db.mycollection1.drop()
db.createCollection("mycollection1")
console.log("insert documents into collection")
db.mycollection1.insertMany(txs)
</code></pre>

<p>The script will loop a 1000 times and create documents that will include fields of <code>transaction_types</code>, <code>store_names</code>, <code>random_transaction_type</code>, <code>random_store_name</code> and <code>random_age</code>.</p>

<p>Use docker, mount the file inside the container, point the database endpoint to ferretdb and load the file that we want to execute:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb -v $PWD/write.js:/src/write.js --entrypoint=mongosh mongo:6.0 "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN" --eval 'load("/src/write.js")'
</code></pre>

<p>Now when we run a mongosh client:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb -v $PWD/write.js:/src/write.js --entrypoint=mongosh mongo:6.0 "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN"
</code></pre>

<p>And we query for the <code>store_name: picknpay</code> and only show the <code>transaction_type</code> and <code>transaction</code> fields:</p>

<pre><code class="bash">ferretdb&gt; db.mycollection1.find({"store_name": "picknpay"}, {_id: 0, transaction_type: 1, transaction: 1})
[
  { transaction_type: 'credit card', transaction: 'tx_3' },
  { transaction_type: 'cash', transaction: 'tx_9' },
  { transaction_type: 'account', transaction: 'tx_10' },
  { transaction_type: 'credit card', transaction: 'tx_15' },
  { transaction_type: 'credit card', transaction: 'tx_19' },
  { transaction_type: 'cash', transaction: 'tx_21' },
  { transaction_type: 'cash', transaction: 'tx_28' },
  { transaction_type: 'account', transaction: 'tx_31' },
  { transaction_type: 'cash', transaction: 'tx_37' },
  { transaction_type: 'cash', transaction: 'tx_39' },
  { transaction_type: 'account', transaction: 'tx_40' },
  { transaction_type: 'cash', transaction: 'tx_51' },
  { transaction_type: 'account', transaction: 'tx_52' },
  { transaction_type: 'cash', transaction: 'tx_58' },
  { transaction_type: 'credit card', transaction: 'tx_62' },
  { transaction_type: 'credit card', transaction: 'tx_65' },
  { transaction_type: 'account', transaction: 'tx_69' },
  { transaction_type: 'account', transaction: 'tx_71' },
  { transaction_type: 'cash', transaction: 'tx_72' },
  { transaction_type: 'account', transaction: 'tx_74' }
]
</code></pre>

<p>We can also use the <code>--eval</code> flag with the mongosh container to run ad-hoc queries such as counting documents for a collection:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb \
  -v $PWD/write.js:/src/write.js:ro \
  --entrypoint=mongosh mongo:6.0 \
  "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN" --eval 'db.mycollection1.countDocuments()'
</code></pre>

<h2>Prometheus Metrics</h2>

<p>FerretDB provides prometheus metrics out of the box, and outputs prometheus metrics on the <code>:8080/debug/metrics</code> endpoint:</p>

<pre><code class="bash">curl http://localhost:8080/debug/metrics
</code></pre>

<p>Which will output metrics more or less like the following:</p>

<pre><code>ferretdb_client_accepts_total{error="0"} 98
ferretdb_client_connected 0
ferretdb_client_requests_total{command="aggregate",opcode="OP_MSG"} 5
ferretdb_client_requests_total{command="atlasVersion",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="buildInfo",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="buildinfo",opcode="OP_MSG"} 2
ferretdb_client_requests_total{command="count",opcode="OP_MSG"} 5
ferretdb_client_requests_total{command="create",opcode="OP_MSG"} 7
ferretdb_client_requests_total{command="drop",opcode="OP_MSG"} 3
ferretdb_client_requests_total{command="dropDatabase",opcode="OP_MSG"} 4
ferretdb_client_requests_total{command="find",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="getCmdLineOpts",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="getFreeMonitoringStatus",opcode="OP_MSG"} 20
ferretdb_client_requests_total{command="getLog",opcode="OP_MSG"} 20
ferretdb_client_requests_total{command="getParameter",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="hello",opcode="OP_MSG"} 20
ferretdb_client_requests_total{command="insert",opcode="OP_MSG"} 15
ferretdb_client_requests_total{command="ismaster",opcode="OP_MSG"} 238
ferretdb_client_requests_total{command="listCollections",opcode="OP_MSG"} 49
ferretdb_client_requests_total{command="listDatabases",opcode="OP_MSG"} 12
ferretdb_client_requests_total{command="ping",opcode="OP_MSG"} 40
ferretdb_client_requests_total{command="saslStart",opcode="OP_MSG"} 70
ferretdb_client_requests_total{command="setFreeMonitoring",opcode="OP_MSG"} 1
ferretdb_client_requests_total{command="unknown",opcode="OP_QUERY"} 96
ferretdb_client_responses_total{argument="unknown",command="aggregate",opcode="OP_MSG",result="ok"} 5
ferretdb_client_responses_total{argument="unknown",command="atlasVersion",opcode="OP_MSG",result="CommandNotFound"} 27
ferretdb_client_responses_total{argument="unknown",command="buildInfo",opcode="OP_MSG",result="ok"} 27
ferretdb_client_responses_total{argument="unknown",command="buildinfo",opcode="OP_MSG",result="ok"} 2
ferretdb_client_responses_total{argument="unknown",command="count",opcode="OP_MSG",result="ok"} 5
ferretdb_client_responses_total{argument="unknown",command="create",opcode="OP_MSG",result="ok"} 7
ferretdb_client_responses_total{argument="unknown",command="drop",opcode="OP_MSG",result="NamespaceNotFound"} 2
ferretdb_client_responses_total{argument="unknown",command="drop",opcode="OP_MSG",result="ok"} 1
ferretdb_client_responses_total{argument="unknown",command="dropDatabase",opcode="OP_MSG",result="ok"} 4
ferretdb_client_responses_total{argument="unknown",command="find",opcode="OP_MSG",result="ok"} 27
ferretdb_client_responses_total{argument="unknown",command="getCmdLineOpts",opcode="OP_MSG",result="ok"} 27
ferretdb_client_responses_total{argument="unknown",command="getFreeMonitoringStatus",opcode="OP_MSG",result="ok"} 20
ferretdb_client_responses_total{argument="unknown",command="getLog",opcode="OP_MSG",result="ok"} 20
ferretdb_client_responses_total{argument="unknown",command="getParameter",opcode="OP_MSG",result="Unset"} 27
ferretdb_client_responses_total{argument="unknown",command="hello",opcode="OP_MSG",result="ok"} 20
ferretdb_client_responses_total{argument="unknown",command="insert",opcode="OP_MSG",result="ok"} 15
ferretdb_client_responses_total{argument="unknown",command="ismaster",opcode="OP_MSG",result="ok"} 238
ferretdb_client_responses_total{argument="unknown",command="listCollections",opcode="OP_MSG",result="ok"} 49
ferretdb_client_responses_total{argument="unknown",command="listDatabases",opcode="OP_MSG",result="ok"} 12
ferretdb_client_responses_total{argument="unknown",command="ping",opcode="OP_MSG",result="ok"} 40
ferretdb_client_responses_total{argument="unknown",command="saslStart",opcode="OP_MSG",result="ok"} 70
ferretdb_client_responses_total{argument="unknown",command="setFreeMonitoring",opcode="OP_MSG",result="ok"} 1
ferretdb_client_responses_total{argument="unknown",command="unknown",opcode="OP_REPLY",result="ok"} 93
ferretdb_client_responses_total{argument="unknown",command="unknown",opcode="OP_REPLY",result="unhandled"} 3
ferretdb_up{branch="unknown",commit="3344cbb98bb744dd044bcf2d51fe9ab65db22f0b",debug="false",dirty="true",package="docker",telemetry="disabled",update_available="false",uuid="08174d33-05fd-45ed-adb9-d2e343e0af83",version="v1.1.0"} 1
process_cpu_seconds_total 16.98
process_max_fds 1.048576e+06
process_open_fds 13
process_resident_memory_bytes 2.5714688e+07
process_start_time_seconds 1.68425346762e+09
process_virtual_memory_bytes 7.52529408e+08
process_virtual_memory_max_bytes 1.8446744073709552e+19
promhttp_metric_handler_errors_total{cause="encoding"} 0
promhttp_metric_handler_errors_total{cause="gathering"} 0
promhttp_metric_handler_requests_in_flight 1
promhttp_metric_handler_requests_total{code="200"} 2
promhttp_metric_handler_requests_total{code="500"} 0
promhttp_metric_handler_requests_total{code="503"} 0
</code></pre>

<h2>Resources</h2>

<p>Please see the follwoing resources for FerretDB:</p>

<ul>
<li><a href="https://docs.ferretdb.io/">https://docs.ferretdb.io/</a></li>
<li><a href="https://github.com/ferretdb/FerretDB/pkgs/container/ferretdb">https://github.com/ferretdb/FerretDB/pkgs/container/ferretdb</a></li>
<li><a href="https://docs.ferretdb.io/quickstart-guide/docker/">https://docs.ferretdb.io/quickstart-guide/docker/</a></li>
<li><a href="https://github.com/ruanbekker/cheatsheets/tree/master/mongodb/shell">https://github.com/ruanbekker/cheatsheets/tree/master/mongodb/shell</a></li>
</ul>


<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improve MySQL Write Performance Using Batch Writes]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/06/13/improve-mysql-write-performance-using-batch-writes/"/>
    <updated>2020-06-13T19:31:32+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/06/13/improve-mysql-write-performance-using-batch-writes</id>
    <content type="html"><![CDATA[<p><img src="https://img.sysadmins.co.za/wngib2.png" alt="mysql-python-performance" /></p>

<p>I am no DBA, but I got curious when I noticed sluggish write performance on a mysql database, and I remembered somewhere that you should always use batch writes over sequential writes. So I decided to test it out, using a python script and a mysql server.</p>

<h2>What will we be doing</h2>

<p>I wrote a python script that writes 100,000 records to a database and keeps time of how long the writes took, 2 examples which I will compare:</p>

<ul>
<li>One script writing each record to the database</li>
<li>One script writing all the records as batch</li>
</ul>


<h2>Sequential Writes</h2>

<p>It took 48 seconds to write 100,000 records into a database using sequential writes:</p>

<pre><code class="python">...
for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    cur.execute(
        """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
        (userid, name, job, age, credit_card_num, status)
    )
...
</code></pre>

<p>Running that shows us this:</p>

<pre><code>$ python3 mysql_seq_writes.py
start
writing customers to database
finish
inserted 100000 records in 48s
</code></pre>

<h2>Batch Writes</h2>

<p>It took 3 seconds to write to write 100,000 records using batch writes:</p>

<pre><code class="python">...
for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    bunch_users.append((userid, name, job, age, credit_card_num, status))

cur.executemany(
    """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
    bunch_users
)
...
</code></pre>

<p>Running that shows us this:</p>

<pre><code>$ python3 mysql_batch_writes.py
start
writing customers to database
finish
inserted 100000 records in 3s
</code></pre>

<h2>Looking at the Scripts</h2>

<p>The script used for sequential writes:</p>

<pre><code class="python">import datetime
import random
import MySQLdb
from datetime import datetime as dt

host="172.18.0.1"
user="root"
password="password"
dbname="shopdb"
records=100000

db = MySQLdb.connect(host, user, password, dbname)

names = ['ruan', 'donovan', 'james', 'warren', 'angie', 'nicole', 'jenny', 'penny', 'amber']
job = ['doctor', 'scientist', 'teacher', 'police officer', 'waiter', 'banker', 'it']

cur = db.cursor()
cur.execute("DROP TABLE IF EXISTS customers")
cur.execute("CREATE TABLE customers(userid VARCHAR(50), name VARCHAR(50), surname VARCHAR(50), job VARCHAR(50), age INT(2), credit_card_num VARCHAR(50), status VARCHAR(10))")

bunch_users = []
userids = []

print("start")

def gen_id():
    return str(random.randint(0,9999)).zfill(4)

def gen_user(username):
    ccnum = '{0}-{1}-{2}-{3}'.format(gen_id(), gen_id(), gen_id(), gen_id())
    userid = username + '_' + ccnum.split('-')[0] + ccnum.split('-')[2]
    return {"uid": userid, "ccnum": ccnum}

for name in range(records):
    userids.append(gen_user(random.choice(names)))

print("writing customers to database")

timestart = int(dt.now().strftime("%s"))

for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    #bunch_users.append((userid, name, job, age, credit_card_num, status))

    cur.execute(
        """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
        (userid, name, job, age, credit_card_num, status)
    )

db.commit()
db.close()
timefinish = int(dt.now().strftime("%s"))
print("finish")
print("inserted {} records in {}s".format(records, timefinish-timestart))
</code></pre>

<p>The script used for the batch writes:</p>

<pre><code class="python">import datetime
import random
import MySQLdb
from datetime import datetime as dt

host="172.18.0.1"
user="root"
password="password"
dbname="shopdb"
records=100000

db = MySQLdb.connect(host, user, password, dbname)

names = ['ruan', 'donovan', 'james', 'warren', 'angie', 'nicole', 'jenny', 'penny', 'amber']
job = ['doctor', 'scientist', 'teacher', 'police officer', 'waiter', 'banker', 'it']

cur = db.cursor()
cur.execute("DROP TABLE IF EXISTS customers")
cur.execute("CREATE TABLE customers(userid VARCHAR(50), name VARCHAR(50), surname VARCHAR(50), job VARCHAR(50), age INT(2), credit_card_num VARCHAR(50), status VARCHAR(10))")

bunch_users = []
userids = []

print("start")

def gen_id():
    return str(random.randint(0,9999)).zfill(4)

def gen_user(username):
    ccnum = '{0}-{1}-{2}-{3}'.format(gen_id(), gen_id(), gen_id(), gen_id())
    userid = username + '_' + ccnum.split('-')[0] + ccnum.split('-')[2]
    return {"uid": userid, "ccnum": ccnum}

for name in range(records):
    userids.append(gen_user(random.choice(names)))

for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    bunch_users.append((userid, name, job, age, credit_card_num, status))

timestart = int(dt.now().strftime("%s"))

print("writing customers to database")
cur.executemany(
    """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
    bunch_users
)

db.commit()
db.close()
timefinish = int(dt.now().strftime("%s"))
print("finish")
print("inserted {} records in {}s".format(records, timefinish-timestart))
</code></pre>

<h2>Thanks</h2>

<p>Thanks for reading, so this was kind of interesting to see to never do sequential writes but write them in bulk when you have large amount of writes.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running a HA MySQL Galera Cluster on Docker Swarm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/05/10/running-a-ha-mysql-galera-cluster-on-docker-swarm/"/>
    <updated>2019-05-10T07:02:39-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/05/10/running-a-ha-mysql-galera-cluster-on-docker-swarm</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/57523982-c904d780-7326-11e9-981a-7a9cb9552c2f.png" alt="image" /></p>

<p>In this post we will setup a highly available mysql galera cluster on docker swarm.</p>

<h2>About</h2>

<p>The service is based of <a href="https://github.com/toughIQ/docker-mariadb-cluster">docker-mariadb-cluster</a> repository and it&rsquo;s designed not to have any persistent data attached to the service, but rely on the &ldquo;nodes&rdquo; to replicate the data.</p>

<p>Note, that however this proof of concept works, I always recommend to use a remote mysql database outside your cluster, such as RDS etc.</p>

<p>Since we don&rsquo;t persist any data on the mysql cluster, I have associated a dbclient service that will run continious backups, which we will persist the path where the backups reside to disk.</p>

<h2>Deploy the MySQL Cluster</h2>

<p>The <a href="https://raw.githubusercontent.com/ruanbekker/dockerfiles/master/mysql-cluster/docker-compose.yml">docker-compose.yml</a> that we will use looks like this:</p>

<pre><code class="yaml">version: '3.5'
services:
  dbclient:
    image: alpine
    environment:
      - BACKUP_ENABLED=1
      - BACKUP_INTERVAL=3600
      - BACKUP_PATH=/data
      - BACKUP_FILENAME=db_backup
    networks:
      - dbnet
    entrypoint: |
      sh -c 'sh -s &lt;&lt; EOF
      apk add --no-cache mysql-client
      while true
        do
          if [ $$BACKUP_ENABLED == 1 ]
            then
              sleep $$BACKUP_INTERVAL
              mkdir -p $$BACKUP_PATH/$$(date +%F)
              echo "$$(date +%FT%H.%m) - Making Backup to : $$BACKUP_PATH/$$(date +%F)/$$BACKUP_FILENAME-$$(date +%FT%H.%m).sql.gz"
              mysqldump -u root -ppassword -h dblb --all-databases | gzip &gt; $$BACKUP_PATH/$$(date +%F)/$$BACKUP_FILENAME-$$(date +%FT%H.%m).sql.gz
              find $$BACKUP_PATH -mtime 7 -delete
          fi
        done
      EOF'
    volumes:
      - vol_dbclient:/data
    deploy:
      mode: replicated
      replicas: 1

  dbcluster:
    image: toughiq/mariadb-cluster
    networks:
      - dbnet
    environment:
      - DB_SERVICE_NAME=dbcluster
      - MYSQL_ROOT_PASSWORD=password
      - MYSQL_DATABASE=mydb
      - MYSQL_USER=mydbuser
      - MYSQL_PASSWORD=mydbpass
    deploy:
      mode: replicated
      replicas: 1

  dblb:
    image: toughiq/maxscale
    networks:
      - dbnet
    ports:
      - 3306:3306
    environment:
      - DB_SERVICE_NAME=dbcluster
      - ENABLE_ROOT_USER=1
    deploy:
      mode: replicated
      replicas: 1

volumes:
  vol_dbclient:
    driver: local

networks:
  dbnet:
    name: dbnet
    driver: overlay
</code></pre>

<p>The dbclient is configured to be in the same network as the cluster so it can reach the mysql service. The default behavior is that it will make a backup every hour (3600 seconds) to the <code>/data/{date}/</code> path.</p>

<p>Deploy the stack:</p>

<pre><code>$ docker stack deploy -c docker-compose.yml galera
Creating network dbnet
Creating service galera_dbcluster
Creating service galera_dblb
Creating service galera_dbclient
</code></pre>

<p>Have a look to see if all the services is running:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
jm7p70qre72u        galera_dbclient     replicated          1/1                 alpine:latest
p8kcr5y7szte        galera_dbcluster    replicated          1/1                 toughiq/mariadb-cluster:latest
1hu3oxhujgfm        galera_dblb         replicated          1/1                 toughiq/maxscale:latest          :3306-&gt;3306/tcp
</code></pre>

<h2>The Backup Client</h2>

<p>As mentioned the backup client backs up to the <code>/data/</code> path:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) find /data/
/data/
/data/2019-05-10
/data/2019-05-10/db_backup-2019-05-10T10.05.sql.gz
</code></pre>

<p>Let&rsquo;s go ahead and populate some data into our mysql database:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb
MySQL [(none)]&gt; create table mydb.foo (name varchar(10));
MySQL [(none)]&gt; insert into mydb.foo values('ruan');
MySQL [(none)]&gt; exit
</code></pre>

<h2>Scale the Cluster</h2>

<p>At the moment we only have 1 replica for our mysql cluster, let&rsquo;s go ahead and scale the cluster to 3 replicas:</p>

<pre><code>$ docker service scale galera_dbcluster=3
galera_dbcluster scaled to 3
overall progress: 3 out of 3 tasks
1/3: running   [==================================================&gt;]
2/3: running   [==================================================&gt;]
3/3: running   [==================================================&gt;]
verify: Service converged
</code></pre>

<p>Verify that the service has been scaled:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
jm7p70qre72u        galera_dbclient     replicated          1/1                 alpine:latest
p8kcr5y7szte        galera_dbcluster    replicated          3/3                 toughiq/mariadb-cluster:latest
1hu3oxhujgfm        galera_dblb         replicated          1/1                 toughiq/maxscale:latest          :3306-&gt;3306/tcp
</code></pre>

<p>Test, by reading from the database:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<h2>Simulate a Node Failure:</h2>

<p>Simulate a node failure by killing one of the mysql containers:</p>

<pre><code>$ docker kill 9e336032ab52
</code></pre>

<p>Verify that one container is missing from our service:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
p8kcr5y7szte        galera_dbcluster    replicated          2/3                 toughiq/mariadb-cluster:latest
</code></pre>

<p>While the container is provisioning, as we have 2 out of 3 running containers, read the data 3 times so test that the round robin queries dont hit the affected container (the dblb wont route traffic to the affected container):</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+

$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+

$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<p>Verify that the 3rd container has checked in:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
p8kcr5y7szte        galera_dbcluster    replicated          3/3                 toughiq/mariadb-cluster:latest
</code></pre>

<h2>How to Restore?</h2>

<p>I&rsquo;m deleting the database to simulate the scenario where we need to restore:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) sh
&gt; mysql -uroot -ppassword -h dblb -e'drop database mydb;'
</code></pre>

<p>Ensure the db is not present:</p>

<pre><code>&gt; mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
ERROR 1146 (42S02) at line 1: Table 'mydb.foo' doesn't exist
</code></pre>

<p>Find the archive and extract:</p>

<pre><code>&gt; find /data/
/data/
/data/2019-05-10
/data/2019-05-10/db_backup-2019-05-10T10.05.sql.gz

&gt; gunzip /data/2019-05-10/db_backup-2019-05-10T10.05.sql.gz
</code></pre>

<p>Restore the backed up database to MySQL:</p>

<pre><code>&gt; mysql -uroot -ppassword -h dblb &lt; /data/2019-05-10/db_backup-2019-05-10T10.05.sql
</code></pre>

<p>Test that we can read our data:</p>

<pre><code>&gt; mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB Examples With Golang]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/04/17/mongodb-examples-with-golang/"/>
    <updated>2019-04-17T08:51:35-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/04/17/mongodb-examples-with-golang</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/55478904-236e9200-561d-11e9-9382-f31b25a9ae03.png" alt="" /></p>

<p>While looking into working with mongodb using golang, I found it quite frustrating getting it up and running and decided to make a quick post about it.</p>

<p><a href="https://github.com/ruanbekker/cheatsheets" target="_blank"><img alt="ruanbekker-cheatsheets" src="https://user-images.githubusercontent.com/567298/169162832-ef3019de-bc49-4d6c-b2a6-8ac17c457d24.png"></a></p>

<h2>What are we doing?</h2>

<p>Examples using the golang driver for mongodb to connect, read, update and delete documents from mongodb.</p>

<h2>Environment:</h2>

<p>Provision a mongodb server in docker:</p>

<pre><code>$ docker network create container-net
$ docker run -itd --name mongodb --network container-net -p 27017:27017 ruanbekker/mongodb
</code></pre>

<p>Drop into a golang environment using docker:</p>

<pre><code>$ docker run -it golang:alpine sh
</code></pre>

<p>Get the dependencies:</p>

<pre><code>$ apk add --no-cache git
</code></pre>

<p>Change to your project path:</p>

<pre><code>$ mkdir $GOPATH/src/myapp
$ cd $GOPATH/src/myapp
</code></pre>

<p>Download the golang mongodb driver:</p>

<pre><code>$ go get go.mongodb.org/mongo-driver
</code></pre>

<h2>Connecting to MongoDB in Golang</h2>

<p>First example will be to connect to your mongodb instance:</p>

<pre><code class="go">package main

import (
    "context"
    "fmt"
    "log"
    "go.mongodb.org/mongo-driver/mongo"
    "go.mongodb.org/mongo-driver/bson"
    "go.mongodb.org/mongo-driver/mongo/options"
)

type Person struct {
    Name string
    Age  int
    City string
}

func main() {
    clientOptions := options.Client().ApplyURI("mongodb://mongodb:27017")
    client, err := mongo.Connect(context.TODO(), clientOptions)

    if err != nil {
        log.Fatal(err)
    }

    err = client.Ping(context.TODO(), nil)

    if err != nil {
        log.Fatal(err)
    }

    fmt.Println("Connected to MongoDB!")

}
</code></pre>

<p>Running our app:</p>

<pre><code class="bash">$ go run main.go
Connected to MongoDB!
</code></pre>

<h2>Writing to MongoDB with Golang</h2>

<p>Let&rsquo;s insert a single document to MongoDB:</p>

<pre><code class="go">func main() {
    ..
    collection := client.Database("mydb").Collection("persons")

    ruan := Person{"Ruan", 34, "Cape Town"}

    insertResult, err := collection.InsertOne(context.TODO(), ruan)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Println("Inserted a Single Document: ", insertResult.InsertedID)
}
</code></pre>

<p>Running it will produce:</p>

<pre><code class="bash">$ go run main.go
Connected to MongoDB!
Inserted a single document:  ObjectID("5cb717dcf597b4411252341f")
</code></pre>

<p>Writing more than one document:</p>

<pre><code>func main() {
    ..
    collection := client.Database("mydb").Collection("persons")

    ruan := Person{"Ruan", 34, "Cape Town"}
    james := Person{"James", 32, "Nairobi"}
    frankie := Person{"Frankie", 31, "Nairobi"}

    trainers := []interface{}{james, frankie}

    insertManyResult, err := collection.InsertMany(context.TODO(), trainers)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Println("Inserted multiple documents: ", insertManyResult.InsertedIDs)
}
</code></pre>

<p>This will output in:</p>

<pre><code class="bash">$ go run main.go
Inserted Multiple Documents:  [ObjectID("5cb717dcf597b44112523420") ObjectID("5cb717dcf597b44112523421")]
</code></pre>

<h2>Updating Documents in MongoDB using Golang</h2>

<p>Updating Frankie&rsquo;s age:</p>

<pre><code>func main() {
    ..
    filter := bson.Dname
    update := bson.D{
        {"$inc", bson.D{
            {"age", 1},
        }},
    }

    updateResult, err := collection.UpdateOne(context.TODO(), filter, update)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("Matched %v documents and updated %v documents.\n", updateResult.MatchedCount, updateResult.ModifiedCount)
}
</code></pre>

<p>Running that will update Frankie&rsquo;s age:</p>

<pre><code class="bash">$ go run main.go
Matched 1 documents and updated 1 documents.
</code></pre>

<h2>Reading Data from MongoDB</h2>

<p>Reading the data:</p>

<pre><code class="go">funct main() {
    ..
    filter := bson.Dname
    var result Trainer

    err = collection.FindOne(context.TODO(), filter).Decode(&amp;result)
    if err != nil {
        log.Fatal(err)
    }

    fmt.Printf("Found a single document: %+v\n", result)

    findOptions := options.Find()
    findOptions.SetLimit(2)

}
</code></pre>



<pre><code class="bash">$ go run main.go
Found a single document: {Name:Frankie Age:32 City:Nairobi}
</code></pre>

<p>Finding multiple documents and returning the cursor</p>

<pre><code class="go">func main() {
    ..
    var results []*Trainer
    cur, err := collection.Find(context.TODO(), bson.D, findOptions)
    if err != nil {
        log.Fatal(err)
    }

    for cur.Next(context.TODO()) {
        var elem Trainer
        err := cur.Decode(&amp;elem)
        if err != nil {
            log.Fatal(err)
        }

        results = append(results, &amp;elem)
    }

    if err := cur.Err(); err != nil {
        log.Fatal(err)
    }

    cur.Close(context.TODO())
    fmt.Printf("Found multiple documents (array of pointers): %+v\n", results)
}
</code></pre>

<p>Running the example:</p>

<pre><code>$ go run main.go
Found multiple documents (array of pointers): [0xc0001215c0 0xc0001215f0]
</code></pre>

<h2>Deleting Data from MongoDB:</h2>

<p>Deleting our data and closing the connection:</p>

<pre><code class="go">func main(){
    ..
    deleteResult, err := collection.DeleteMany(context.TODO(), bson.D)
    if err != nil {
        log.Fatal(err)
    }

    fmt.Printf("Deleted %v documents in the trainers collection\n", deleteResult.DeletedCount)

    err = client.Disconnect(context.TODO())

    if err != nil {
        log.Fatal(err)
    } else {
        fmt.Println("Connection to MongoDB closed.")
    }
}
</code></pre>

<p>Running the example:</p>

<pre><code class="bash">$ go run main.go
Deleted 3 documents in the trainers collection
Connection to MongoDB closed.
</code></pre>

<p>The code for this example can be found at <a href="https://github.com/ruanbekker/code-examples/blob/master/mongodb/golang/examples.go">github.com/ruanbekker/code-examples/mongodb/golang/examples.go</a></p>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.mongodb.com/blog/post/mongodb-go-driver-tutorial">https://www.mongodb.com/blog/post/mongodb-go-driver-tutorial</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Inner Joins Examples With SQLite]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/04/06/sql-inner-joins-examples-with-sqlite/"/>
    <updated>2019-04-06T15:47:38-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/04/06/sql-inner-joins-examples-with-sqlite</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/55704774-53cb7d00-59dd-11e9-9f43-65ec3aa857b5.png" alt="sqlite" /></p>

<h2>Overview</h2>

<p>In this tutorial we will get started with sqlite and use inner joins to query data from multiple tables to answer specific use case needs.</p>

<h2>Connecting to your Sqlite Database</h2>

<p>Connecting to your database uses the argument to the target database. You can use additional flags to set the properties that you want to enable:</p>

<pre><code class="sql">$ sqlite3 -header -column mydatabase.db
</code></pre>

<p>or you can specify the additional options to your config:</p>

<pre><code class="bash">cat &gt; ~/.sqliterc &lt;&lt; EOF
.mode column
.headers on
EOF
</code></pre>

<p>Then connecting to your database:</p>

<pre><code class="bash">$ sqlite3 mydatabase.db
-- Loading resources from /Users/ruan/.sqliterc
SQLite version 3.16.0 2016-11-04 19:09:39
Enter ".help" for usage hints.
sqlite&gt;
</code></pre>

<h2>Create the Tables</h2>

<p>Create the <code>users</code> table:</p>

<pre><code class="sql">sqlite&gt; create table users (
   ...&gt; id INT(20), name VARCHAR(20), surname VARCHAR(20), city VARCHAR(20),
   ...&gt; age INT(2), credit_card_num VARCHAR(20), job_position VARCHAR(20)
   ...&gt; );
</code></pre>

<p>Create the <code>transactions</code> table:</p>

<pre><code class="sql">sqlite&gt; create table transactions (
   ...&gt; credit_card_num VARCHAR(20), transaction_id INT(20), shop_name VARCHAR(20),
   ...&gt; product_name VARCHAR(20), spent_total DECIMAL(6,2), purchase_option VARCHAR(20)
   ...&gt; );
</code></pre>

<p>You can view the tables using <code>.tables</code>:</p>

<pre><code class="sql">sqlite&gt; .tables
transactions  users 
</code></pre>

<p>And view the schema of the tables using <code>.schema &lt;table-name&gt;</code></p>

<pre><code class="sql">sqlite&gt; .schema users
CREATE TABLE users (
id INT(20), name VARCHAR(20), surname VARCHAR(20), city VARCHAR(20),
age INT(2), credit_card_num VARCHAR(20), job_position VARCHAR(20)
);
</code></pre>

<h2>Write to Sqlite Database</h2>

<p>Now we will populate data to our tables. Insert a record to our users table:</p>

<pre><code class="sql">sqlite&gt; insert into users values(1, 'ruan', 'bekker', 'cape town', 31, '2345-8970-6712-4352', 'devops');
</code></pre>

<p>Insert a record to our transactions table:</p>

<pre><code class="sql">sqlite&gt; insert into transactions values('2345-8970-6712-4352', 981623, 'spaza01', 'burger', 101.02, 'credit_card');
</code></pre>

<h2>Read from the Sqlite Database</h2>

<p>Read the data from the users table:</p>

<pre><code class="sql">sqlite&gt; select * from users;
id          name        surname     city        age         credit_card_num      job_position
----------  ----------  ----------  ----------  ----------  -------------------  ------------
1           ruan        bekker      cape town   31          2345-8970-6712-4352  devops      
</code></pre>

<p>Read the data from the transactions table:</p>

<pre><code class="sql">sqlite&gt; select * from transactions;
credit_card_num      transaction_id  shop_name   product_name  spent_total  purchase_option
-------------------  --------------  ----------  ------------  -----------  ---------------
2345-8970-6712-4352  981623          spaza01     burger        101.02       credit_card    
</code></pre>

<h2>Inner Joins with Sqlite</h2>

<p>This is where stuff gets interesting.</p>

<p>Let&rsquo;s say you want to join data from 2 tables, in this example we have a table with our userdata and a table with transaction data.</p>

<p>Say we want to see the user&rsquo;s name, transaction id, the product they purchased and the total amount spent, we will make use of inner joins.</p>

<p>Example looks like this:</p>

<pre><code class="sql">sqlite&gt; select a.name, b.transaction_id, b.product_name, b.spent_total
   ...&gt; from users
   ...&gt; as a inner join transactions
   ...&gt; as b on a.credit_card_num = b.credit_card_num
   ...&gt; where a.credit_card_num = '2345-8970-6712-4352';
name        transaction_id  product_name  spent_total
----------  --------------  ------------  -----------
ruan        981623          burger         101.02  
</code></pre>

<p>Let&rsquo;s say you dont know the credit_card number but you would like to do a lookup the credit card number via the user&rsquo;s id, then pass the value to the where statement:</p>

<pre><code class="sql">sqlite&gt; select a.name, b.transaction_id, b.product_name, b.spent_total
   ...&gt; from users
   ...&gt; as a inner join transactions
   ...&gt; as b on a.credit_card_num = b.credit_card_num
   ...&gt; where a.credit_card_num = (select credit_card_num from users where id = 1);
name        transaction_id  product_name  spent_total
----------  --------------  ------------  -----------
ruan        981623          burger         101.02   
</code></pre>

<p>Let&rsquo;s create another table called <code>products</code>:</p>

<pre><code class="sql">sqlite&gt; create table products (
   ...&gt; product_id INTEGER(18), product_name VARCHAR(20), 
   ...&gt; product_category VARCHAR(20), product_price DECIMAL(6,2)
   ...&gt; );
</code></pre>

<p>Write a record with product data to the table:</p>

<pre><code class="sql">sqlite&gt; insert into products values(0231, 'burger', 'fast foods', 101.02);
</code></pre>

<p>Now, lets say the question will be that we need to display the users name, credit card number, product name as well as the product category and products price, by only giving you the credit card number</p>

<pre><code class="sql">sqlite&gt; select a.name, b.credit_card_num, c.product_name, c.product_category, c.product_price
   ...&gt; from users
   ...&gt; as a inner join transactions
   ...&gt; as b on a.credit_card_num = b.credit_card_num inner join products
   ...&gt; as c on b.product_name = c.product_name
   ...&gt; where a.credit_card_num = '2345-8970-6712-4352' and c.product_name = 'burger';
name        credit_card_num      product_name  product_category   product_price
----------  -------------------  ------------  -----------------  -------------
ruan        2345-8970-6712-4352  burger        fast foods         101.02   
</code></pre>
]]></content>
  </entry>
  
</feed>
