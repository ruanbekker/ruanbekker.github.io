<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Devops | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/devops/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2024-03-08T19:39:26-05:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Use Cert-Manager DNS Challenge With Cloudflare on Kubernetes With Helm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/12/22/how-to-use-cert-manager-dns-challenge-with-cloudflare-on-kubernetes-with-helm/"/>
    <updated>2023-12-22T08:04:02-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/12/22/how-to-use-cert-manager-dns-challenge-with-cloudflare-on-kubernetes-with-helm</id>
    <content type="html"><![CDATA[<p>In this tutorial, we will be issuing <a href="https://letsencrypt.org/docs/challenge-types/">Let&rsquo;s Encrypt</a> certificates using <a href="https://cert-manager.io/docs/">cert-manager</a> on <a href="https://kubernetes.io/">Kubernetes</a> and we will be using the <a href="https://letsencrypt.org/docs/challenge-types/#dns-01-challenge">DNS Challenge</a> with <a href="https://www.cloudflare.com/en-gb/">Cloudflare</a>.</p>

<p>The reason I am using DNS Challenge instead of HTTP Challenge is because the Kubernetes environment is local on my laptop and there isn&rsquo;t a direct HTTP route into my environment from the internet and I would like to not expose the endpoints to the public internet.</p>

<h2>Summary of what we will be doing</h2>

<p>We would like to have Let&rsquo;s Encrypt Certificates on our web application that will be issued by Cert-Manager using the DNS Challenge from CloudFlare.</p>

<p>Our ingress controller will be ingress-nginx and our endpoints will be private, as they will resolve to private IP addresses, hence the reason why we are using DNS validation instead of HTTP.</p>

<h2>Pre-Requisites</h2>

<p>To follow along in this tutorial you will need the following</p>

<ul>
<li><p><a href="https://blog.ruanbekker.com/blog/2022/09/20/kind-for-local-kubernetes-clusters/">https://blog.ruanbekker.com/blog/2022/09/20/kind-for-local-kubernetes-clusters/</a></p></li>
<li><p><a href="https://helm.sh/docs/intro/install/">Helm</a></p></li>
<li><p><a href="https://kubernetes.io/docs/tasks/tools/">Kubectl</a></p></li>
<li><p><a href="https://www.cloudflare.com/en-gb/">Cloudflare</a> Account</p></li>
<li><p>Patience (just kidding, I will try my best to make it easy)</p></li>
</ul>


<h2>Install a Kubernetes Cluster</h2>

<p>If you already have a Kubernetes Cluster, you can skip this step.</p>

<p>Define the <code>kind-config.yaml</code></p>

<pre><code class="yaml">kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  image: kindest/node:v1.26.6@sha256:6e2d8b28a5b601defe327b98bd1c2d1930b49e5d8c512e1895099e4504007adb
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
    listenAddress: "0.0.0.0"
  - containerPort: 443
    hostPort: 443
    protocol: TCP
</code></pre>

<p>Then create the cluster with <code>kind</code>:</p>

<pre><code class="bash">kind create cluster --name example --config kind-config.yaml
</code></pre>

<h2>Nginx Ingress Controller</h2>

<p>First we need to install a ingress controller and I am opting in to use ingress-nginx, so first we need to add the helm repository to our local repositories:</p>

<pre><code class="bash">helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
</code></pre>

<p>Then we need to update our repositories:</p>

<pre><code class="bash">helm repo update
</code></pre>

<p>Then we can install the helm release:</p>

<pre><code class="bash">helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace \
  --set controller.kind=DaemonSet \
  --set controller.hostPort.enabled=true \
  --set controller.ingressClass=nginx
</code></pre>

<p>You can view all the default values from their GitHub repository where the chart is hosted:</p>

<ul>
<li><a href="https://github.com/kubernetes/ingress-nginx/blob/main/charts/ingress-nginx/values.yaml"><strong>https://github.com/kubernetes/ingress-nginx/blob/main/charts/ingress-nginx/values.yaml</strong></a></li>
</ul>


<p>Once the release has been deployed, you should see the ingress-nginx pod running under the <code>ingress-nginx</code> namespace:</p>

<pre><code class="bash">kubectl get pods -n ingress-nginx
</code></pre>

<h2>Cert-Manager</h2>

<p>The next step is to install cert-manager using helm, first add the repository:</p>

<pre><code class="bash">helm repo add jetstack https://charts.jetstack.io
</code></pre>

<p>Update the repositories:</p>

<pre><code class="bash">helm repo update
</code></pre>

<p>Then install the cert-manager release:</p>

<pre><code class="bash">helm upgrade --install cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --version v1.13.1 \
  --set installCRDs=true
</code></pre>

<h2>Cloudflare API Token</h2>

<p>We need to grant Cert-Manager access to make DNS changes on our Cloudflare account for DNS validation on our behalf, and in order to do that, we need to create a Cloudflare API Token.</p>

<p>As per the <a href="https://cert-manager.io/docs/configuration/acme/dns01/cloudflare/#api-tokens">cert-manager documentation</a>, from your profile select <a href="https://dash.cloudflare.com/profile/api-tokens">API Tokens</a>, create an API Token and select <code>Edit Zone DNS</code> template.</p>

<p>Then select the following:</p>

<ul>
<li><p>Permissions:</p>

<ul>
<li><p>Zone: DNS -&gt; Edit</p></li>
<li><p>Zone: Zone -&gt; Read</p></li>
</ul>
</li>
<li><p>Zone Resources:</p>

<ul>
<li>Include -&gt; All Zones</li>
</ul>
</li>
</ul>


<p><img src="https://gitlab.com/bekker-space/workshops/ingress-nginx/uploads/c19d741352f767a1bfb97ef4fd716364/image.png%20align=" title="left" alt="" /></p>

<p>Then create the token and save the value somewhere safe, as we will be using it in the next step.</p>

<h2>Cert-Manager ClusterIssuer</h2>

<p>First, we need to create a Kubernetes secret with the API Token that we created in the previous step.</p>

<pre><code class="bash">kubectl create secret generic cloudflare-api-key-secret \
  --from-literal=api-key=[YOUR_CLOUDFLARE_API_KEY]
</code></pre>

<p>Then create the <code>clusterissuer.yaml</code></p>

<pre><code class="yaml">apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-dns01-issuer
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: you@example.com  # your email address for updates
    privateKeySecretRef:
      name: letsencrypt-dns01-private-key
    solvers:
    - dns01:
        cloudflare:
          email: you@example.com # your cloudflare account email address
          apiTokenSecretRef:
            name: cloudflare-api-key-secret
            key: api-key
</code></pre>

<p>Then create the cluster issuer:</p>

<pre><code class="bash">kubectl apply -f clusterissuer.yaml
</code></pre>

<h2>Request a Certificate</h2>

<p>Now that we have our <code>ClusterIssuer</code> created, we can request a certificate. In my scenario, I have a domain <code>example.com</code> which is hosted on CloudFlare and I would like to create a wildcard certificate on the sub-domain <code>*.workshop.example.com</code></p>

<p>Certificates are scoped on a namespace level, and ClusterIssuer&rsquo;s are cluster-wide, therefore I am prefixing my certificate with the namespace (just my personal preference).</p>

<pre><code class="yaml">apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: default-workshop-certificate
  namespace: default
spec:
  secretName: default-workshop-example-tls
  issuerRef:
    name: letsencrypt-dns01-issuer
    kind: ClusterIssuer
  commonName: workshop.example.com
  dnsNames:
  - workshop.example.com
  - '*.workshop.example.com'
</code></pre>

<p>Before we create the certificate on CloudFlare, I have created private DNS to the names mentioned in the manifest above like the following:</p>

<pre><code class="bash">- workshop.example.com -&gt; A Record -&gt; 10.5.24.254
- *.workshop.example.com -&gt; CNAME -&gt; workshop.example.com
</code></pre>

<p>In the DNS configuration mentioned above, to explain why I am creating 2 entries:</p>

<ul>
<li><p><code>10.2.24.254</code> - This is my LoadBalancer IP Address</p></li>
<li><p>I have a static DNS entry to the name <code>workshop.example.com</code> so if my LoadBalancer IP Address ever change, I can just change this address</p></li>
<li><p>I am creating a wildcard DNS entry for <code>*.workshop.example.com</code> and I am creating a CNAME record for it to resolve to <code>workshop.example.com</code> so it will essentially respond to the LoadBalancer IP.</p></li>
<li><p>So lets say I create <code>test1.workshop.example.com</code> and <code>test2.workshop.example.com</code> then it will resolve to the LoadBalancer IP in <code>workshop.example.com</code> and as mentioned before, if the LoadBalancer IP ever changes, I only have to update the A Record of <code>workshop.example.com</code></p></li>
</ul>


<p>Then after DNS was created, I went ahead and created the certificate:</p>

<pre><code class="bash">kubectl apply -f certificate.yaml
</code></pre>

<p>You can view the progress by viewing the certificate status by running:</p>

<pre><code class="bash">kubectl get certificate -n default
</code></pre>

<h2>Specify the Certificate in your Ingress</h2>

<p>Let&rsquo;s deploy a <code>nginx</code> web server deployment and I have concatenated the following in one manifest called <code>deployment.yaml</code>:</p>

<ul>
<li><p><code>Deployment</code></p></li>
<li><p><code>Service</code></p></li>
<li><p><code>Ingress</code></p></li>
</ul>


<pre><code class="yaml">---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-web
  namespace: default
  labels:
    app: nginx-web
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-web
  template:
    metadata:
      labels:
        app: nginx-web
    spec:
      containers:
      - name: nginx
        image: nginx:1.19
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-web-service
  namespace: default
  labels:
    app: nginx-web
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: nginx-web
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx-web-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: "nginx"
spec:
  rules:
  - host: nginx.workshop.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx-web-service
            port:
              number: 80
  tls:
  - hosts:
    - nginx.workshop.example.com
    secretName: default-workshop-example-tls
</code></pre>

<p>A few important things to notice on the ingress resource:</p>

<ul>
<li><p><code>host</code> the host needs to match the certificate</p></li>
<li><p><code>secretName</code> the secret needs to match the secret defined in the certificate</p></li>
</ul>


<p>Then create the deployment:</p>

<pre><code class="bash">kubectl apply -f deployment.yaml
</code></pre>

<h2>Ensure DNS Challenges are successful</h2>

<p>Ensure that cert-manager can set DNS-01 challenge records correctly, if you encounter issues, you can inspect the cert-manager pod logs.</p>

<p>To view the pods for cert-manager:</p>

<pre><code class="bash">kubectl get pods -n cert-manager
</code></pre>

<p>Then view the logs using:</p>

<pre><code class="bash">kubectl logs -f pod &lt;pod-id&gt; -n cert-manager
</code></pre>

<h2>Test</h2>

<p>You can open up a browser and access the ingress on your browser, in my case it would be <code>https://nginx.workshop.example.com</code> and verify that you have a certificate issued from Lets Encrypt.</p>

<h2>Thank You</h2>

<p>Thanks for reading, if you enjoy my content please feel free to follow me on <a href="https://twitter.com/ruanbekker"><strong>Twitter -</strong></a> @<a href="@ruanbekker">@ruanbekker</a> or visit me on my <a href="https://ruan.dev/"><strong>website -</strong></a> <a href="http://ruan.dev"><strong>ruan.dev</strong></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Deploy Ingress-Nginx Controller on Kubernetes With Helm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/12/22/how-to-deploy-ingress-nginx-controller-on-kubernetes-with-helm/"/>
    <updated>2023-12-22T07:56:22-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/12/22/how-to-deploy-ingress-nginx-controller-on-kubernetes-with-helm</id>
    <content type="html"><![CDATA[<p>In this tutorial we will deploy the <a href="https://github.com/kubernetes/ingress-nginx">ingress-nginx</a> controller on kubernetes.</p>

<h2>Pre-Requisites</h2>

<p>I will be using kind to run a kubernetes cluster locally, if you want to follow along, have a look at my previous post on how to install <a href="https://kubernetes.io/docs/tasks/tools/">kubectl</a> and kind and the basic usage of kind:</p>

<ul>
<li><a href="https://blog.ruanbekker.com/blog/2022/09/20/kind-for-local-kubernetes-clusters/">https://blog.ruanbekker.com/blog/2022/09/20/kind-for-local-kubernetes-clusters/</a></li>
</ul>


<p>You will also need <a href="https://helm.sh/docs/intro/install/">helm</a> to deploy the ingress-nginx release from their helm charts, you can see their documentation on how to install it:</p>

<ul>
<li><a href="https://helm.sh/docs/intro/install/">https://helm.sh/docs/intro/install/</a></li>
</ul>


<h2>Create the Kubernetes Cluster</h2>

<p>First we will define the kind configuration which will expose port 80 locally in a file name <code>kind-config.yaml</code></p>

<pre><code class="yaml">kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  image: kindest/node:v1.25.11@sha256:227fa11ce74ea76a0474eeefb84cb75d8dad1b08638371ecf0e86259b35be0c8
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
    listenAddress: "0.0.0.0"
  - containerPort: 443
    hostPort: 443
    protocol: TCP
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
</code></pre>

<p>Then go ahead and create the kubernetes cluster:</p>

<pre><code class="bash">kind create cluster --name workshop --config kind-config.yaml
</code></pre>

<h2>Install ingress-nginx using Helm</h2>

<p>Install the ingress-nginx helm chart, by first adding the repository:</p>

<pre><code class="bash">helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
</code></pre>

<p>Then update your local repositories:</p>

<pre><code class="bash">helm repo update
</code></pre>

<p>Then install the helm release, and set a couple of overrides.</p>

<p>The reason we use NodePort is because our kubernetes cluster runs on docker containers, and from our kind config we have exposed port 80 locally, we are using the NodePort service so that we can make an HTTP request to port 80 to traverse to the port of the service:</p>

<pre><code class="bash">helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx --create-namespace \
  --set controller.kind=DaemonSet \
  --set controller.hostPort.enabled=true \
  --set controller.ingressClass=nginx
</code></pre>

<p>You can view all the default values from their GitHub repository where the chart is hosted:</p>

<ul>
<li><a href="https://github.com/kubernetes/ingress-nginx/blob/main/charts/ingress-nginx/values.yaml">https://github.com/kubernetes/ingress-nginx/blob/main/charts/ingress-nginx/values.yaml</a></li>
</ul>


<p>Once the release has been deployed, you should see the ingress-nginx pod running under the <code>ingress-nginx</code> namespace:</p>

<pre><code class="bash">kubectl get pods -n ingress-nginx
</code></pre>

<h2>Deploy a Web Application</h2>

<p>We will create 3 files:</p>

<ul>
<li><p><code>example/deployment.yaml</code></p></li>
<li><p><code>example/service.yaml</code></p></li>
<li><p><code>example/ingress.yaml</code></p></li>
</ul>


<p>Create the example directory:</p>

<pre><code class="bash">mkdir example
</code></pre>

<p>Our <code>example/deployment.yaml</code></p>

<pre><code class="yaml">---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: webapp
  name: webapp
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webapp
  template:
    metadata:
      labels:
        app: webapp
    spec:
      containers:
      - image: ruanbekker/web-center-name-v2
        name: webapp
        ports:
        - name: http
          containerPort: 5000
        env:
        - name: APP_TITLE
          value: "Runs on Kind"
        resources:
          requests:
            memory: "64Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "1000m"
</code></pre>

<p>Our <code>example/service.yaml</code></p>

<pre><code class="yaml">---
apiVersion: v1
kind: Service
metadata:
  name: webapp
  namespace: default
spec:
  type: ClusterIP
  selector:
    app: webapp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 5000
</code></pre>

<p>Our <code>example/ingress.yaml</code></p>

<pre><code class="yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: webapp
  namespace: default
spec:
  ingressClassName: nginx
  rules:
    - host: example.127.0.0.1.nip.io
      http:
        paths:
          - pathType: Prefix
            backend:
              service:
                name: webapp
                port:
                  number: 80
            path: /
</code></pre>

<p>In summary, we are creating a deployment with a pod that listens on port 5000, and then we are creating a service with port 80 that will forward its connections to the container port of 5000.</p>

<p>Then we define our ingress that will match our hostname and forward its connections to our service on port 80, and also notice that we are defining our ingress class name, which we have set in our helm values.</p>

<p>Deploy this example with kubectl:</p>

<pre><code class="bash">kubectly apply -f example/
</code></pre>

<p>Now you can access the web application at <a href="http://example.127.0.0.1.nip.io">http://example.127.0.0.1.nip.io</a></p>

<h2>Teardown</h2>

<p>You can delete the resources that we&rsquo;ve created using:</p>

<pre><code class="bash">kubectl delete -f example/
</code></pre>

<p>Delete the cluster using:</p>

<pre><code class="bash">kind delete cluster --name workshop
</code></pre>

<h2>Thank You</h2>

<p>Thanks for reading, if you enjoy my content please feel free to follow me on <a href="https://twitter.com/ruanbekker"><strong>Twitter - @ruanbekker</strong></a> or visit me on my <a href="https://ruan.dev/"><strong>website -</strong></a> <a href="http://ruan.dev"><strong>ruan.dev</strong></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating a Python Lambda Function With Terraform on AWS]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/08/03/creating-a-python-lambda-function-with-terraform-on-aws/"/>
    <updated>2023-08-03T11:29:35-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/08/03/creating-a-python-lambda-function-with-terraform-on-aws</id>
    <content type="html"><![CDATA[<p>In this tutorial I will explain how to deploy a AWS Lambda Function with Terraform using the Python runtime. It will include the permissions it needs to write its logs to AWS CloudWatch as well as to get information from the AWS API&rsquo;s as a boilerplate for you to expand on it.</p>

<p>We will also use CloudWatch Events to trigger this lambda function every two hours.</p>

<h2>Pre-Requisites</h2>

<p>First you will need to have <a href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli">Terraform</a> installed as well as authentication for Terraform to interact with your AWS account, I have written a post about it and you can follow that on &ldquo;<a href="https://blog.ruanbekker.com/blog/2023/07/15/how-to-use-the-aws-terraform-provider/">How to use the AWS Terraform Provider</a>&rdquo;.</p>

<h2>Project Structure</h2>

<p>The following code will be available on my <a href="https://github.com/ruanbekker/terraformfiles/tree/master/modules/aws-lambda-function">github repository</a>, but if you would like to follow along we will create everything step by step.</p>

<p>First create the project directory:</p>

<pre><code class="bash">mkdir -p ~/workspace/aws-lambda-terraform
</code></pre>

<p>Then change into the directory:</p>

<pre><code class="bash">cd ~/workspace/aws-lambda-terraform
</code></pre>

<p>First we want to create our modules directory:</p>

<pre><code class="bash">mkdir -p modules/lambda-function
</code></pre>

<p>Then our environment directory:</p>

<pre><code class="bash">mkdir -p environment/test
</code></pre>

<p>We will also create the directory for our function code:</p>

<pre><code class="bash">mkdir -p modules/lambda-function/functions
</code></pre>

<p>And we can create the file for our python function:</p>

<pre><code class="bash">touch modules/lambda-function/functions/demo.py
</code></pre>

<p>Now we will create our files inside our modules directory:</p>

<pre><code class="bash">touch modules/lambda-function/{main,versions,outputs,variables}.tf
</code></pre>

<p>Then create the files inside our environments directory:</p>

<pre><code class="bash">touch environment/test/{main,provider,output}.tf
</code></pre>

<p>Then in summary our project structure should look more or less like this:</p>

<pre><code class="bash">tree .
.
├── environment
│   └── test
│       ├── main.tf
│       ├── output.tf
│       └── provider.tf
└── modules
    └── lambda-function
        ├── functions
        │   └── demo.py
        ├── main.tf
        ├── outputs.tf
        ├── variables.tf
        └── versions.tf

5 directories, 8 files
</code></pre>

<h2>Terraform Code</h2>

<p>We will first start populating the modules bit, and start with <code>modules/lambda-function/main.tf</code>:</p>

<pre><code>data "aws_iam_policy_document" "lambda" {
  statement {
    actions = ["sts:AssumeRole"]

    principals {
      type        = "Service"
      identifiers = ["lambda.amazonaws.com"]
    }
  }
}

data "aws_iam_policy_document" "lambda_execution" {
  count = var.logs_enabled ? 1 : 0

  statement {
    sid     = "GetCallerIdentity"
    effect  = "Allow"

    actions = [
      "sts:GetCallerIdentity"
    ]

    resources = ["*"]

  }

  statement {
    sid     = "DescribeFunctionsInRegion"
    effect  = "Allow"

    actions = [
      "lambda:GetFunction"
    ]

    resources = ["*"]

    condition {
      test     = "StringEquals"
      variable = "aws:RequestedRegion"
      values = [var.aws_region]
    }
  }

}

resource "aws_iam_role_policy" "lambda_execution_policy" {
  count  = var.logs_enabled ? 1 : 0
  name   = "${var.project_name}-lambda-function-execution-policy"
  role   = aws_iam_role.lambda_role[count.index].id
  policy = data.aws_iam_policy_document.lambda_execution[count.index].json
}

data "archive_file" "lambda_zip" {
  type        = "zip"
  source_file = "${path.module}/functions/demo.py"
  output_path = "${path.module}/lambda-archives/package.zip"
}

resource "aws_iam_role" "lambda_role" {
  count              = var.logs_enabled ? 1 : 0
  name               = "${var.project_name}-lambda-function-role"
  assume_role_policy = data.aws_iam_policy_document.lambda.json
}

resource "aws_lambda_function" "lambda" {
  count            = var.logs_enabled ? 1 : 0
  filename         = data.archive_file.lambda_zip.output_path
  function_name    = "${var.project_name}-lambda-function"
  role             = aws_iam_role.lambda_role[count.index].arn
  handler          = "demo.lambda_handler"
  source_code_hash = filebase64sha256(data.archive_file.lambda_zip.output_path)
  runtime          = "python3.8"
  timeout          = 30

  environment {
    variables = {
      PROJECT_NAME  = var.project_name
      FUNCTION_NAME = "${var.project_name}-lambda-function"
    }
  }

  depends_on = [
    data.archive_file.lambda_zip
  ]

}

resource "aws_cloudwatch_event_rule" "every_two_hours" {
  count               = var.logs_enabled ? 1 : 0
  name                = "${var.project_name}-every-two-hours"
  description         = "Fires every 2 hours"
  schedule_expression = "rate(2 hours)"
}

resource "aws_lambda_permission" "allow_cloudwatch" {
  count         = var.logs_enabled ? 1 : 0
  statement_id  = "AllowExecutionFromCloudWatch"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.lambda[count.index].function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.every_two_hours[count.index].arn
}

resource "aws_cloudwatch_event_target" "cloudwatch_event" {
  count     = var.logs_enabled ? 1 : 0
  rule      = aws_cloudwatch_event_rule.every_two_hours[count.index].name
  target_id = "${var.project_name}-snapshot-retention-target"
  arn       = aws_lambda_function.lambda[count.index].arn
}

// CloudWatch Logs
resource "aws_cloudwatch_log_group" "cloudwatch_log_group" {
  count     = var.logs_enabled ? 1 : 0
  name      = "/aws/lambda/${aws_lambda_function.lambda[count.index].function_name}"
  retention_in_days = 5
}

resource "aws_iam_role_policy_attachment" "lambda_exec_policy" {
  count      = var.logs_enabled ? 1 : 0
  role       = aws_iam_role.lambda_role[count.index].name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}
</code></pre>

<p>The next one will be the <code>modules/lambda-function/variables.tf</code>:</p>

<pre><code>variable "aws_region" {
  default = "eu-west-1"
  type    = string
}

variable "project_name" {
  default = "example"
  type    = string
}

variable "logs_enabled" {
  default = false
  type    = bool
}
</code></pre>

<p>Then define the modules output in <code>modules/lambda-function/outputs.tf</code>:</p>

<pre><code>output "arn_string" {
  value = aws_lambda_function.lambda[*].arn
}
</code></pre>

<p>Then we define our python function code in <code>modules/lambda-function/functions/demo.py</code>:</p>

<pre><code class="python">import os
import json
import logging
import boto3

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    client = boto3.client('lambda')
    logger.info(event)

    response = client.get_function(
        FunctionName=os.environ['FUNCTION_NAME']
    )

    logger.info(response)

    return {
        'statusCode' : 200,
        'body': response
    }
</code></pre>

<p>For our environment we want to specify the source as our module in <code>environment/test/main.tf</code>:</p>

<pre><code>module "myfunction" {
  source       = "../../modules/lambda-function"
  project_name = "test"
  logs_enabled = true
}
</code></pre>

<p>Our outputs in <code>environment/test/output.tf</code>:</p>

<pre><code>output "arn_string" {
  value = module.myfunction.arn_string
}
</code></pre>

<p>And since we are using AWS, we need to define our providers and the profile that we will use to authenticate against AWS, in my case, im using the default profile in <code>environment/test/provider.tf</code>:</p>

<pre><code>terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "4.23.0"
    }
  }
}

provider "aws" {
  region                   = "eu-west-1"
  profile                  = "default"
  shared_credentials_files = ["~/.aws/credentials"]
}
</code></pre>

<h2>Terraform Plan</h2>

<p>Now that we have defined our terraform code we can run:</p>

<pre><code class="bash">terraform plan
</code></pre>

<p>And it should return something more or less like the following:</p>

<pre><code class="bash">Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # module.myfunction.aws_cloudwatch_event_rule.every_two_hours[0] will be created
  + resource "aws_cloudwatch_event_rule" "every_two_hours" {
      + arn                 = (known after apply)
      + description         = "Fires every 2 hours"
      + event_bus_name      = "default"
      + id                  = (known after apply)
      + is_enabled          = true
      + name                = "test-every-two-hours"
      + name_prefix         = (known after apply)
      + schedule_expression = "rate(2 hours)"
      + tags_all            = (known after apply)
    }

  # module.myfunction.aws_cloudwatch_event_target.cloudwatch_event[0] will be created
  + resource "aws_cloudwatch_event_target" "cloudwatch_event" {
      + arn            = (known after apply)
      + event_bus_name = "default"
      + id             = (known after apply)
      + rule           = "test-every-two-hours"
      + target_id      = "test-snapshot-retention-target"
    }

  # module.myfunction.aws_cloudwatch_log_group.cloudwatch_log_group[0] will be created
  + resource "aws_cloudwatch_log_group" "cloudwatch_log_group" {
      + arn               = (known after apply)
      + id                = (known after apply)
      + name              = "/aws/lambda/test-lambda-function"
      + retention_in_days = 5
      + tags_all          = (known after apply)
    }

  # module.myfunction.aws_iam_role.lambda_role[0] will be created
  + resource "aws_iam_role" "lambda_role" {
      + arn                   = (known after apply)
      + assume_role_policy    = jsonencode(
            {
              + Statement = [
                  + {
                      + Action   = "sts:GetCallerIdentity"
                      + Effect   = "Allow"
                      + Resource = "*"
                      + Sid      = "GetCallerIdentity"
                    },
                  + {
                      + Action    = "lambda:GetFunction"
                      + Condition = {
                          + StringEquals = {
                              + "aws:RequestedRegion" = "eu-west-1"
                            }
                        }
                      + Effect    = "Allow"
                      + Resource  = "*"
                      + Sid       = "DescribeFunctionsInRegion"
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + create_date           = (known after apply)
      + force_detach_policies = false
      + id                    = (known after apply)
      + managed_policy_arns   = (known after apply)
      + max_session_duration  = 3600
      + name                  = "test-lambda-function-role"
      + name_prefix           = (known after apply)
      + path                  = "/"
      + tags_all              = (known after apply)
      + unique_id             = (known after apply)
    }

  # module.myfunction.aws_iam_role_policy.lambda_execution_policy[0] will be created
  + resource "aws_iam_role_policy" "lambda_execution_policy" {
      + id     = (known after apply)
      + name   = "test-lambda-function-execution-policy"
      + policy = jsonencode(
            {
              + Statement = [
                  + {
                      + Action   = "sts:GetCallerIdentity"
                      + Effect   = "Allow"
                      + Resource = "*"
                      + Sid      = "GetCallerIdentity"
                    },
                  + {
                      + Action    = "lambda:GetFunction"
                      + Condition = {
                          + StringEquals = {
                              + "aws:RequestedRegion" = "eu-west-1"
                            }
                        }
                      + Effect    = "Allow"
                      + Resource  = "*"
                      + Sid       = "DescribeFunctionsInRegion"
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + role   = (known after apply)
    }

  # module.myfunction.aws_iam_role_policy_attachment.lambda_exec_policy[0] will be created
  + resource "aws_iam_role_policy_attachment" "lambda_exec_policy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      + role       = "test-lambda-function-role"
    }

  # module.myfunction.aws_lambda_function.lambda[0] will be created
  + resource "aws_lambda_function" "lambda" {
      + architectures                  = (known after apply)
      + arn                            = (known after apply)
      + filename                       = "../../modules/lambda-function/lambda-archives/package.zip"
      + function_name                  = "test-lambda-function"
      + handler                        = "demo.lambda_handler"
      + id                             = (known after apply)
      + invoke_arn                     = (known after apply)
      + last_modified                  = (known after apply)
      + memory_size                    = 128
      + package_type                   = "Zip"
      + publish                        = false
      + qualified_arn                  = (known after apply)
      + reserved_concurrent_executions = -1
      + role                           = (known after apply)
      + runtime                        = "python3.8"
      + signing_job_arn                = (known after apply)
      + signing_profile_version_arn    = (known after apply)
      + source_code_hash               = "MI7FD/KHgxRFh7cmPjzxg+w494pmyRGgQIr9Ls8Yups="
      + source_code_size               = (known after apply)
      + tags_all                       = (known after apply)
      + timeout                        = 30
      + version                        = (known after apply)

      + environment {
          + variables = {
              + "FUNCTION_NAME" = "test-lambda-function"
              + "PROJECT_NAME"  = "test"
            }
        }
    }

  # module.myfunction.aws_lambda_permission.allow_cloudwatch[0] will be created
  + resource "aws_lambda_permission" "allow_cloudwatch" {
      + action              = "lambda:InvokeFunction"
      + function_name       = "test-lambda-function"
      + id                  = (known after apply)
      + principal           = "events.amazonaws.com"
      + source_arn          = (known after apply)
      + statement_id        = "AllowExecutionFromCloudWatch"
      + statement_id_prefix = (known after apply)
    }

Plan: 8 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + arn_string = [
      + (known after apply),
    ]
</code></pre>

<h2>Create Resources</h2>

<p>If you are happy with the plan you can go ahead and run:</p>

<pre><code>terraform apply
</code></pre>

<p>Which will create the resources in AWS. Upon creation we should see something like this:</p>

<pre><code>Apply complete! Resources: 0 added, 1 changed, 0 destroyed.

Outputs:

arn_string = [
  "arn:aws:lambda:eu-west-1:000000000000:function:test-lambda-function",
]
</code></pre>

<p>Since we have our aws cli configured with a profile we can also test our lambda function:</p>

<pre><code class="bash">$ aws --profile default lambda invoke --function-name test-lambda-function --cli-binary-format raw-in-base64-out --payload '{"name": "ruan"}' out.log
{
    "StatusCode": 200,
    "ExecutedVersion": "$LATEST"
}
</code></pre>

<p>And the response from the invocation can be seen in the file we defined:</p>

<pre><code class="bash">$ cat out.log
{"statusCode": 200, "body": {"ResponseMetadata": {"RequestId": "5171x", "HTTPStatusCode": 200, "HTTPHeaders": {"date": "Thu, 21 Dec 2023 06:34:13 GMT", "content-type": "application/json", "content-length": "3517", "connection": "keep-alive", "x-amzn-requestid": "5171x"}, "RetryAttempts": 0}, "Configuration": {"FunctionName": "test-lambda-function", "FunctionArn": "arn:aws:lambda:eu-west-1:000000000000:function:test-lambda-function", "Runtime": "python3.8", "Role": "arn:aws:iam::000000000000:role/test-lambda-function-role", "Handler": "demo.lambda_handler", "CodeSize": 401, "Description": "", "Timeout": 30, "MemorySize": 128, "LastModified": "2023-12-21T06:26:46.000+0000", "CodeSha256": "x", "Version": "$LATEST", "Environment": {"Variables": {"FUNCTION_NAME": "test-lambda-function", "PROJECT_NAME": "test"}}, "TracingConfig": {"Mode": "PassThrough"}, "RevisionId": "7faex", "State": "Active", "LastUpdateStatus": "Successful", "PackageType": "Zip", "Architectures": ["x86_64"], "EphemeralStorage": {"Size": 512}, "SnapStart": {"ApplyOn": "None", "OptimizationStatus": "Off"}, "RuntimeVersionConfig": {"RuntimeVersionArn": "arn:aws:lambda:eu-west-1::runtime:x"}}, "Code": {"RepositoryType": "S3", "Location": "https://awslambda-eu-west-1-tasks.s3.eu-west-1.amazonaws.com/snapshots/x/test-lambda-function-x?queryparameters"}}}
</code></pre>

<h2>Updating Lambda Function Code</h2>

<p>If we want to redeploy our function with updated code, we can change the content of <code>functions/demo.py</code> and then run:</p>

<pre><code>terraform apply
</code></pre>

<p>Since our terraform code defined that if the source has of the function code changes, it will trigger a redeploy, and from the computed plan we can see that it will redeploy our function code:</p>

<pre><code class="bash">Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  ~ update in-place

Terraform will perform the following actions:

  # module.myfunction.aws_lambda_function.lambda[0] will be updated in-place
  ~ resource "aws_lambda_function" "lambda" {
        id                             = "test-lambda-function"
      ~ last_modified                  = "2023-12-21T06:26:46.000+0000" -&gt; (known after apply)
      ~ source_code_hash               = "8TLrm4GmTrfAxwfElmIjws1Vf9UDZ6k2w1+VEONJaCQ=" -&gt; "RIQ62KCcjlcHh5lLCOlrkB7GioBpLY1Y5vN4UZGyN+c="
        tags                           = {}
        # (18 unchanged attributes hidden)

        # (3 unchanged blocks hidden)
    }

Plan: 0 to add, 1 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value:
</code></pre>

<p>After entering &ldquo;yes&rdquo; we will update our function code</p>

<h2>Discover AWS Console</h2>

<p>If we logon to the AWS Console and head to Lambda we can inspect our function code:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker/assets/567298/2326b074-fa5b-443c-8715-59451293ccb2" alt="image" /></p>

<p>If we manually want to trigger the function, select &ldquo;Test&rdquo;, then enter the &ldquo;Event name&rdquo; with something like &ldquo;testing&rdquo; then click &ldquo;Test&rdquo;:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker/assets/567298/76bcde33-185f-47ed-a70c-4d967df80e92" alt="image" /></p>

<p>If we follow the CloudWatch log link we can view the logs in CloudWatch:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker/assets/567298/f5483602-3144-48ce-98bf-d50f625cdd92" alt="image" /></p>

<h2>Destroy Infrastructure</h2>

<p>If you followed along and would like to destroy the created infrastructure:</p>

<pre><code class="bash">terraform destroy
</code></pre>

<h2>Resources</h2>

<p>Terraform Examples</p>

<ul>
<li><a href="https://github.com/ruanbekker/terraformfiles/tree/master/modules/aws-lambda-function">https://github.com/ruanbekker/terraformfiles/tree/master/modules/aws-lambda-function</a></li>
</ul>


<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Use the MySQL Terraform Provider]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/07/15/how-to-use-the-mysql-terraform-provider/"/>
    <updated>2023-07-15T20:55:23-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/07/15/how-to-use-the-mysql-terraform-provider</id>
    <content type="html"><![CDATA[<p>In this tutorial we will provision a MySQL Server with Docker and then use Terraform to provision MySQL Users, Database Schemas and MySQL Grants with the MySQL Terraform Provider.</p>

<h2>About</h2>

<p>Terraform is super powerful and can do a lot of things. And it shines when it provisions Infrastructure. So in a scenario where we use Terraform to provision RDS MySQL Database Instances, we might still want to provision extra MySQL Users, or Database Schemas and the respective MySQL Grants.</p>

<p>Usually you will logon to the database and create them manually with sql syntax. But in this tutorial we want to make use of Docker to provision our MySQL Server and we would like to make use of Terraform to provision the MySQL Database Schemas, Grants and Users.</p>

<p>Instead of using AWS RDS, I will be provisioning a MySQL Server on Docker so that we can keep the costs free, for those who are following along.</p>

<p>We will also go through the steps on how to rotate the database password that we will be provisioning for our user.</p>

<h2>MySQL Server</h2>

<p>First we will provision a MySQL Server on Docker Containers, I have a <code>docker-compose.yaml</code> which is available in my <a href="https://github.com/ruanbekker/quick-starts/blob/main/docker/mysql/docker-compose.yaml">quick-starts</a> github repository:</p>

<pre><code class="yaml">version: "3.8"

services:
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - 3306:3306
    environment:
      - MYSQL_DATABASE=sample
      - MYSQL_ROOT_PASSWORD=rootpassword
</code></pre>

<p>Once you have saved that in your current working directory, you can start the container with docker compose:</p>

<pre><code class="bash">docker-compose up -d
</code></pre>

<p>You can test the mysql container by logging onto the mysql server with the correct auth:</p>

<pre><code class="bash">docker exec -it mysql mysql -u root -prootpassword -e 'show databases;'
</code></pre>

<p>This should be more or less the output:</p>

<pre><code class="sql">+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sample             |
| sys                |
+--------------------+
</code></pre>

<h2>Terraform</h2>

<p>If you don&rsquo;t have Terraform installed, you can install it from their <a href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli">documentation</a>.</p>

<p>If you want the source code of this example, its available in my <a href="https://github.com/ruanbekker/quick-starts/tree/main/terraform/mysql/petoju-provider">terraform-mysql/petoju-provider</a> repository. Which you can clone and jump into the <code>terraform/mysql/petoju-provider</code> directory.</p>

<p>First we will define the <code>providers.tf</code>:</p>

<pre><code class="bash">terraform {
  required_providers {
    mysql = {
      source = "petoju/mysql"
      version = "3.0.37"
    }
  }
}

provider "mysql" {
  alias    = "local"
  endpoint = "127.0.0.1:3306"
  username = "root"
  password = "rootpassword"
}
</code></pre>

<p>Then the <code>main.tf</code>:</p>

<pre><code class="bash">resource "random_password" "user_password" {
  length           = 24
  special          = true
  min_special      = 2
  override_special = "!#$%^&amp;*()-_=+[]{}&lt;&gt;:?"
  keepers = {
    password_version = var.password_version
  }
}

resource "mysql_database" "user_db" {
  provider = mysql.local
  name = var.database_name
}

resource "mysql_user" "user_id" {
  provider = mysql.local
  user = var.database_username
  plaintext_password = random_password.user_password.result
  host = "%"
  tls_option = "NONE"
}

resource "mysql_grant" "user_id" {
  provider = mysql.local
  user = var.database_username
  host = "%"
  database = var.database_name
  privileges = ["SELECT", "UPDATE"]
  depends_on = [
    mysql_user.user_id
  ]
}
</code></pre>

<p>Then the <code>variables.tf</code>:</p>

<pre><code class="bash">variable "database_name" {
  description = "The name of the database that you want created."
  type        = string
  default     = null
}

variable "database_username" {
  description = "The name of the database username that you want created."
  type        = string
  default     = null
}

variable "password_version" {
  description = "The password rotates when this value gets updated."
  type        = number
  default     = 0
}
</code></pre>

<p>Then our <code>outputs.tf</code>:</p>

<pre><code class="bash">output "user" {
  value = mysql_user.user_id.user
}

output "password" {
  sensitive = true
  value = random_password.user_password.result
}
</code></pre>

<p>Our <code>terraform.tfvars</code> that defines the values of our variables:</p>

<pre><code class="bash">database_name     = "foobar"
database_username = "ruanb"
password_version  = 0
</code></pre>

<p>Now we are ready to run our terraform code, which will ultimately create a database, user and grants. Outputs the encrypted string of your password which was encrypted with your <code>keybase_username</code>.</p>

<p>Initialise Terraform:</p>

<pre><code class="bash">terraform init
</code></pre>

<p>Run the plan to see what terraform wants to provision:</p>

<pre><code class="bash">terraform plan
</code></pre>

<p>And we can see the following resources will be created:</p>

<pre><code class="bash">Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # mysql_database.user_db will be created
  + resource "mysql_database" "user_db" {
      + default_character_set = "utf8mb4"
      + default_collation     = "utf8mb4_general_ci"
      + id                    = (known after apply)
      + name                  = "foobar"
    }

  # mysql_grant.user_id will be created
  + resource "mysql_grant" "user_id" {
      + database   = "foobar"
      + grant      = false
      + host       = "%"
      + id         = (known after apply)
      + privileges = [
          + "SELECT",
          + "UPDATE",
        ]
      + table      = "*"
      + tls_option = "NONE"
      + user       = "ruanb"
    }

  # mysql_user.user_id will be created
  + resource "mysql_user" "user_id" {
      + host               = "%"
      + id                 = (known after apply)
      + plaintext_password = (sensitive value)
      + tls_option         = "NONE"
      + user               = "ruanb"
    }

  # random_password.user_password will be created
  + resource "random_password" "user_password" {
      + bcrypt_hash      = (sensitive value)
      + id               = (known after apply)
      + keepers          = {
          + "password_version" = "0"
        }
      + length           = 24
      + lower            = true
      + min_lower        = 0
      + min_numeric      = 0
      + min_special      = 2
      + min_upper        = 0
      + number           = true
      + numeric          = true
      + override_special = "!#$%^&amp;*()-_=+[]{}&lt;&gt;:?"
      + result           = (sensitive value)
      + special          = true
      + upper            = true
    }

Plan: 4 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + password = (sensitive value)
  + user     = "ruanb"
</code></pre>

<p>Run the apply which will create the database, the user, sets the password and applies the grants:</p>

<pre><code class="bash">terraform apply
</code></pre>

<p>Then our returned output should show something like this:</p>

<pre><code class="bash">Apply complete! Resources: 4 added, 0 changed, 0 destroyed.

Outputs:

password = &lt;sensitive&gt;
user = "ruanb"
</code></pre>

<p>As our password is set as sensitive, we can access the value with <code>terraform output -raw password</code>, let&rsquo;s assign the password to a variable:</p>

<pre><code class="bash">DBPASS=$(terraform output -raw password)
</code></pre>

<p>Then we can exec into the mysql container and logon to the mysql server with our new credentials:</p>

<pre><code class="bash">docker exec -it mysql mysql -u ruanb -p$DBPASS
</code></pre>

<p>And we can see we are logged onto the mysql server:</p>

<pre><code class="bash">Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 14
Server version: 8.0.33 MySQL Community Server - GPL

mysql&gt;
</code></pre>

<p>If we run <code>show databases;</code> we should see the following:</p>

<pre><code class="sql">mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| foobar             |
| information_schema |
| performance_schema |
+--------------------+
3 rows in set (0.03 sec)
</code></pre>

<p>If we want to rotate the mysql password for the user, we can update the <code>password_version</code> variable either in our <code>terraform.tfvars</code> or via the cli. Let&rsquo;s pass the variable in the cli and do a <code>terraform plan</code> to verify the changes:</p>

<pre><code class="bash">terraform plan -var password_version=1
</code></pre>

<p>And due to our value for the random resource keepers parameter being updated, it will trigger the value of our password to be changed, and that will let terraform update our mysql user&rsquo;s password:</p>

<pre><code class="bash">Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  ~ update in-place
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # mysql_user.user_id will be updated in-place
  ~ resource "mysql_user" "user_id" {
        id                 = "ruanb@%"
      ~ plaintext_password = (sensitive value)
        # (5 unchanged attributes hidden)
    }

  # random_password.user_password must be replaced
-/+ resource "random_password" "user_password" {
      ~ bcrypt_hash      = (sensitive value)
      ~ id               = "none" -&gt; (known after apply)
      ~ keepers          = { # forces replacement
          ~ "password_version" = "0" -&gt; "1"
        }
      ~ result           = (sensitive value)
        # (11 unchanged attributes hidden)
    }

Plan: 1 to add, 1 to change, 1 to destroy.
</code></pre>

<p>Let&rsquo;s go ahead by updating our password:</p>

<pre><code class="bash">terraform apply -var password_version=1 -auto-approve
</code></pre>

<p>To validate that the password has changed, we can try to logon to mysql by using the password variable that was created initially:</p>

<pre><code class="bash">docker exec -it mysql mysql -u ruanb -p$DBPASS
</code></pre>

<p>And as you can see authentication failed:</p>

<pre><code class="bash">mysql: [Warning] Using a password on the command line interface can be insecure.
ERROR 1045 (28000): Access denied for user 'ruanb'@'localhost' (using password: YES)
</code></pre>

<p>Set the new password to the variable again:</p>

<pre><code class="bash">DBPASS=$(terraform output -raw password)
</code></pre>

<p>Then try to logon again:</p>

<pre><code class="bash">docker exec -it mysql mysql -u ruanb -p$DBPASS
</code></pre>

<p>And we can see we are logged on again:</p>

<pre><code class="bash">Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 22
Server version: 8.0.33 MySQL Community Server - GPL

mysql&gt;
</code></pre>

<h2>Resources</h2>

<p>The terraform mysql provider:
- <a href="https://registry.terraform.io/providers/petoju/mysql/latest/docs">https://registry.terraform.io/providers/petoju/mysql/latest/docs</a></p>

<p>The quick-starts repository:
- <a href="https://github.com/ruanbekker/quick-starts">https://github.com/ruanbekker/quick-starts</a></p>

<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Use the AWS Terraform Provider]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/07/15/how-to-use-the-aws-terraform-provider/"/>
    <updated>2023-07-15T20:01:13-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/07/15/how-to-use-the-aws-terraform-provider</id>
    <content type="html"><![CDATA[<p>In this post we will be using the AWS Terraform provider, from how to install Terraform, create a AWS IAM User, configure the AWS Provider and deploy a EC2 instance using Terraform.</p>

<h2>AWS IAM User</h2>

<p>In order to authenticate against AWS’s APIs, we need to create a AWS IAM User and create Access Keys for Terraform to use to authenticate.</p>

<p>From <a href="https://aws.amazon.com/">https://aws.amazon.com/</a> logon to your account, then search for IAM:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/c53d15d3-1af2-4e15-aafb-229cc4274bf5" alt="aws-iam-search-result" /></p>

<p>Select IAM, then select “Users” on the left hand side and select “Create User”, then provide the username for your AWS IAM User:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/35f74a94-98d3-44c4-9651-a504780e5a6e" alt="aws-iam-user-creation-wizard" /></p>

<p>Now we need to assign permissions to our new AWS IAM User. For this scenario I will be assigning a IAM Policy directly to the user and I will be selecting the “AdministratorAccess” policy. Keep in mind that this allows admin access to your whole AWS account:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/779f2dac-0da9-4751-8e89-2ff33c088ae8" alt="permissions-for-your-aws-iam-user" /></p>

<p>Once you select the policy, select “Next” and select “Create User”. Once the user has been created, select “Users” on the left hand side, search for your user that we created, in my case “medium-terraform”.</p>

<p>Select the user and click on “Security credentials”. If you scroll down to the “Access keys” section, you will notice we don’t have any access keys for this user:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/45b5eb1f-999f-4e81-b439-9e8cd90f83a3" alt="aws-iam-access-keys" /></p>

<p>In order to allow Terraform access to our AWS Account, we need to create access keys that Terraform will use, and because we assigned full admin access to the user, Terraform will be able to manage resources in our AWS Account.</p>

<p>Click “Create access key”, then select the “CLI” option and select the confirmation at the bottom:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/22b13879-6256-4de8-ab5f-aecece3be432" alt="aws-iam-access-keys-wizard" /></p>

<p>Select “Next” and then select “Create access key”. I am providing a screenshot of the Access Key and Secret Access Key that has been provided, but by the time this post has been published, the key will be deleted.</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/a7a4124f-dc9c-4700-b0ed-d21d7df4fa6c" alt="retrieve-aws-iam-access-keys" /></p>

<p>Store your Access Key and Secret Access Key in a secure place and treat this like your passwords. If someone gets access to these keys they can manage your whole AWS Account.</p>

<p>I will be using the <a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html">AWS CLI</a> to configure my Access Key and Secret Access Key, as I will configure Terraform later to read my Access Keys from the Credential Provider config.</p>

<p>First we need to configure the AWS CLI by passing the profile name, which I have chosen <code>medium</code> for this demonstration:</p>

<pre><code class="bash">aws --profile medium configure
</code></pre>

<p>We will be asked to provide the access key, secret access key, aws region and the default output:</p>

<pre><code class="bash">AWS Access Key ID [None]: AKIATPRT2G4SGXLAC3HJ
AWS Secret Access Key [None]: KODnR[............]nYTYbd
Default region name [None]: eu-west-1
Default output format [None]: json
</code></pre>

<p>To verify if everything works as expected we can use the following command to verify:</p>

<pre><code class="bash">aws --profile medium sts get-caller-identity
</code></pre>

<p>The response should look something similar to the following:</p>

<pre><code class="json">{
    "UserId": "AIDATPRT2G4SOAO5Y7S5Z",
    "Account": "000000000000",
    "Arn": "arn:aws:iam::000000000000:user/medium-terraform"
}
</code></pre>

<h2>Terraform</h2>

<p>Now that we have our AWS IAM User configured, we can install Terraform, if you don’t have Terraform installed yet, you can follow their <a href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli">Installation Documentation</a>.</p>

<p>Once you have Terraform installed, we can setup our workspace where we will ultimately deploy a EC2 instance, but before we get there we need to create our project directory and change to that directory:</p>

<pre><code class="bash">mkdir ~/terraform-demo
cd ~/terraform-demo
</code></pre>

<p>Then we will create 4 files with <code>.tf</code> extensions:</p>

<pre><code class="bash">touch main.tf
touch outputs.tf
touch providers.tf
touch variables.tf
</code></pre>

<p>We will define our Terraform definitions on how we want our desired infrastructure to look like. We will get to the content in the files soon.</p>

<p>I personally love Terraform’s documentation as they are rich in examples and really easy to use.</p>

<p>Head over to the <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs">Terraform AWS Provider</a> documentation and you scroll a bit down, you can see the <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs#authentication-and-configuration">Authentication and Configuration</a> section where they outline the order in how Terraform will look for credentials and we will be making use of the shared credentials file as that is where our access key and secret access key is stored.</p>

<p>If you look at the top right corner of the Terraform AWS Provider documentation, they show you how to use the AWS Provider:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/03a55c32-bb1c-4f48-a441-c09918c824db" alt="terraform-aws-provider-docs" /></p>

<p>We can copy that code snippet and paste it into our <code>providers.tf</code> file and configure the aws provider section with the <code>medium</code> profile that we’ve created earlier.</p>

<p>This will tell Terraform where to look for credentials in order to authenticate with AWS.</p>

<p>Open <code>providers.tf</code> with your editor of choice:</p>

<pre><code class="bash">terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "5.8.0"
    }
  }
}

provider "aws" {
  shared_credentials_files = ["~/.aws/credentials"]
  profile                  = "medium"
  region                   = "eu-west-1"
}
</code></pre>

<p>Then we can open <code>main.tf</code> and populate the following to define the EC2 instance that we want to provision:</p>

<pre><code class="bash">data "aws_ami" "latest_ubuntu" {
  most_recent = true
  owners = ["099720109477"]

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-*-server-*"]
  }

  filter {
    name   = "architecture"
    values = ["x86_64"]
  }
}

resource "aws_instance" "ec2" {
  ami           = data.aws_ami.latest_ubuntu.id
  instance_type = var.instance_type
  tags = {
    Name = "${var.instance_name}-ec2-instance"
  }
}
</code></pre>

<p>In the above example we are filtering for the latest Ubuntu 22.04 64bit AMI then we are defining a EC2 instance and specifying the AMI ID that we filtered from our data source.</p>

<p>Note that we haven’t specified a SSH Keypair, as we are just focusing on how to provision a EC2 instance.</p>

<p>As you can see we are also referencing variables, which we need to define in <code>variables.tf</code> :</p>

<pre><code class="bash">variable "instance_name" {
  description = "Instance Name for EC2."
  type        = string
  default     = "test"
}

variable "instance_type" {
  description = "Instance Type for EC2."
  type        = string
  default     = "t2.micro"
}
</code></pre>

<p>And then lastly we need to define our <code>outputs.tf</code> which will be used to output the instance id and ip address:</p>

<pre><code class="bash">output "instance_id" {
  value = aws_instance.ec2.id
}

output "ip" {
  value = aws_instance.ec2.public_ip
}
</code></pre>

<h2>Deploy our EC2 with Terraform</h2>

<p>Now that our infrastructure has been defined as code, we can first initialise terraform which will initialise the backend and download all the providers that has been defined:</p>

<pre><code class="bash">terraform init
</code></pre>

<p>Once that has done we can run a “plan” which will show us what Terraform will deploy:</p>

<pre><code class="bash">terraform plan
</code></pre>

<p>Now terraform will show us the difference in what we have defined, and what is actually in AWS, as we know its a new account with zero infrastructure, the diff should show us that it needs to create a EC2 instance.</p>

<p>The response from the <code>terraform plan</code> shows us the following:</p>

<pre><code class="bash">Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_instance.ec2 will be created
  + resource "aws_instance" "ec2" {
      + ami                                  = "ami-0f56955469757e5aa"
      + arn                                  = (known after apply)
      + id                                   = (known after apply)
      + instance_type                        = "t2.micro"
      + key_name                             = (known after apply)
      + private_ip                           = (known after apply)
      + public_ip                            = (known after apply)
      + security_groups                      = (known after apply)
      + subnet_id                            = (known after apply)
      + tags                                 = {
          + "Name" = "test-ec2-instance"
        }
      + tags_all                             = {
          + "Name" = "test-ec2-instance"
        }
      + vpc_security_group_ids               = (known after apply)
    }

Plan: 1 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + instance_id = (known after apply)
  + ip          = (known after apply)
</code></pre>

<p>As you can see terraform has looked up the AMI ID using the data source, and we can see that terraform will provision 1 resource which is a EC2 instance. Once we hare happy with the plan, we can run a apply which will show us the same but this time prompt us if we want to proceed:</p>

<pre><code class="bash">Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

aws_instance.ec2: Creating...
aws_instance.ec2: Still creating... [10s elapsed]
aws_instance.ec2: Still creating... [20s elapsed]
aws_instance.ec2: Still creating... [30s elapsed]
aws_instance.ec2: Creation complete after 35s [id=i-005c08b899229fff0]

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

Outputs:

instance_id = "i-005c08b899229fff0"
ip = "34.253.196.167"
</code></pre>

<p>And now we can see our EC2 instance was provisioned and our outputs returned the instance id as well as the public ip address.</p>

<p>We can also confirm this by looking at the AWS EC2 Console:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/82b4d742-1c45-4d21-8766-10a5c0d074a1" alt="aws-ec2-instances-in-console" /></p>

<p>Note that Terraform Configuration is idempotent, so when we run a terraform apply again, terraform will check what we have defined as what we want our desired infrastructure to be like, and what we actually have in our AWS Account, and since we haven’t made any changes there should be no changes.</p>

<p>We can run a terraform apply to validate that:</p>

<pre><code class="bash">terraform apply
</code></pre>

<p>And we can see the response shows:</p>

<pre><code class="bash">data.aws_vpc.selected: Reading...
data.aws_ami.latest_ubuntu: Reading...
data.aws_ami.latest_ubuntu: Read complete after 1s [id=ami-0f56955469757e5aa]
data.aws_vpc.selected: Read complete after 1s [id=vpc-063d7ac3124053dfa]
data.aws_subnet.selected: Reading...
data.aws_subnet.selected: Read complete after 1s [id=subnet-0b7acd7593611c1bb]
aws_instance.ec2: Refreshing state... [id=i-005c08b899229fff0]

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.
</code></pre>

<h2>Cleanup</h2>

<p>Destroy the infrastructure that we provisioned:</p>

<pre><code class="bash">terraform destroy
</code></pre>

<p>It will show us what terraform will destroy, then upon confirming we should see the following output:</p>

<pre><code class="bash">Plan: 0 to add, 0 to change, 1 to destroy.

Changes to Outputs:
  - instance_id = "i-005c08b899229fff0" -&gt; null
  - ip          = "34.253.196.167" -&gt; null

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

aws_instance.ec2: Destroying... [id=i-005c08b899229fff0]
aws_instance.ec2: Still destroying... [id=i-005c08b899229fff0, 10s elapsed]
aws_instance.ec2: Still destroying... [id=i-005c08b899229fff0, 20s elapsed]
aws_instance.ec2: Still destroying... [id=i-005c08b899229fff0, 30s elapsed]
aws_instance.ec2: Destruction complete after 31s

Destroy complete! Resources: 1 destroyed.
</code></pre>

<p>If you followed along and you also want to clean up the AWS IAM user, head over to the AWS IAM Console and delete the “medium-terraform” IAM User.</p>

<h2>Thank You</h2>

<p>I hope you enjoyed this post, I will be posting more terraform related content.</p>

<p>Should you want to reach out to me, you can follow me on Twitter at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> or check out my website at <a href="https://ruan.dev">https://ruan.dev</a></p>
]]></content>
  </entry>
  
</feed>
