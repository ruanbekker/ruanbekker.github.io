<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Devops | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/devops/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2023-01-17T10:24:03-05:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Getting Started With Wiremock]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/01/14/getting-started-with-wiremock/"/>
    <updated>2023-01-14T17:03:12-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/01/14/getting-started-with-wiremock</id>
    <content type="html"><![CDATA[<p>In this tutorial we will use docker to run an instance of wiremock to setup a mock api for us to test our api&rsquo;s.</p>

<h2>Wiremock</h2>

<p><a href="https://wiremock.org/">Wiremock</a> is a tool for building mock API&rsquo;s which enables us to build stable development environments.</p>

<h2>Docker and Wiremock</h2>

<p>Run a wiremock instance with docker:</p>

<pre><code class="bash">docker run -it --rm -p 8080:8080 --name wiremock wiremock/wiremock:2.34.0
</code></pre>

<p>Then our wiremock instance will be exposed on port 8080 locally, which we can use to make a request against to create a api mapping:</p>

<pre><code class="bash">curl -XPOST -H "Content-Type: application/json" \
  http://localhost:8080/__admin/mappings
  -d '{"request": {"url": "/testapi","method": "GET"}, "response": {"status": 200, "body": "{\"result\": \"ok\"
}", "headers": {"Content-Type": "application/json"}}}'
</code></pre>

<p>The response should be something like this:</p>

<pre><code class="json">{
    "id" : "223a2c0a-8b43-42dc-8ba6-fe973da1e420",
    "request" : {
      "url" : "/testapi",
      "method" : "GET"
    },
    "response" : {
      "status" : 200,
      "body" : "{\"result\": \"ok\"}",
      "headers" : {
        "Content-Type" : "application/json"
      }
    },
    "uuid" : "223a2c0a-8b43-42dc-8ba6-fe973da1e420"
}
</code></pre>

<h2>Test Wiremock</h2>

<p>If we make a GET request against our API:</p>

<pre><code class="bash">curl http://localhost:8080/testapi
</code></pre>

<p>Our response should be:</p>

<pre><code class="json">{
  "result": "ok"
}
</code></pre>

<h2>Export Wiremock Mappings</h2>

<p>We can export our mappings to a local file named <code>stubs.json</code> with:</p>

<pre><code class="bash">curl -s http://localhost:8080/__admin/mappings --output stubs.json
</code></pre>

<h2>Import Wiremock Mappings</h2>

<p>We can import our mappings from our <code>stubs.json</code> file with:</p>

<pre><code class="bash">curl -XPOST -v --data-binary @stubs.json http://localhost:8080/__admin/mappings/import
</code></pre>

<h2>Resources</h2>

<ul>
<li><a href="https://wiremock.org/docs/docker/">https://wiremock.org/docs/docker/</a></li>
<li><a href="https://github.com/WireMock-Net/WireMock.Net/wiki/Admin-API-Reference">https://github.com/WireMock-Net/WireMock.Net/wiki/Admin-API-Reference</a></li>
</ul>


<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible Playbook for Your Macbook Homebrew Packages]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/08/28/ansible-playbook-for-your-macbook-homebrew-packages/"/>
    <updated>2022-08-28T19:14:54-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/08/28/ansible-playbook-for-your-macbook-homebrew-packages</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ansible-macbook.png" alt="ansible-macbook-homebrew" /></p>

<p>In this tutorial I will demonstrate how to use Ansible for Homebrew Configuration Management. The aim for using Ansible to manage your homebrew packages helps you to have a consistent list of packages on your macbook.</p>

<p>For me personally, when I get a new laptop it&rsquo;s always a mission to get the same packages installed as what I had before, and ansible solves that for us to have all our packages defined in configuration management.</p>

<h2>Install Ansible</h2>

<p>Install ansible with python and pip:</p>

<pre><code class="bash">python3 -m pip install ansible==4.9.0
</code></pre>

<h2>Ansible Configuration</h2>

<p>Create the <code>ansible.cfg</code> configuration file:</p>

<pre><code>[defaults]
inventory = inventory.ini
deprecation_warnings = False
</code></pre>

<p>Our <code>inventory.ini</code> will define the information about our target host, which will be localhost as we are using ansible to run against our local target which is our macbook:</p>

<pre><code>[localhost]
my.laptop  ansible_connection=local

[localhost:vars]
ansible_python_interpreter = /usr/bin/python3
</code></pre>

<h2>Ansible Playbook</h2>

<p>Our playbook <code>homebrew.yaml</code> will define the tasks to add the homebrew taps, cask packages and homebrew packages. You can change the packages as you desire, but these are the ones that I use:</p>

<pre><code class="yaml">- hosts: localhost
  name: Macbook Playbook
  gather_facts: False
  vars:
    TFENV_ARCH: amd64
  tasks:
    - name: Ensures taps are present via homebrew
      community.general.homebrew_tap:
        name: ""
        state: present
      with_items:
        - hashicorp/tap

    - name: Ensures packages are present via homebrew cask
      community.general.homebrew_cask:
        name: ""
        state: present
        install_options: 'appdir=/Applications'
      with_items:
        - visual-studio-code
        - multipass
        - spotify

    - name: Ensures packages are present via homebrew
      community.general.homebrew:
        name: ""
        path: "/Applications"
        state: present
      with_items:
        - openssl
        - readline
        - sqlite3
        - xz
        - zlib
        - jq
        - yq
        - wget
        - go
        - kubernetes-cli
        - fzf
        - sshuttle
        - hugo
        - helm
        - kind
        - awscli
        - gnupg
        - kubectx
        - helm
        - stern
        - terraform
        - tfenv
        - pyenv 
        - jsonnet
      ignore_errors: yes
      tags:
        - packages
</code></pre>

<h2>Deploy Playbook</h2>

<p>Now you can run the playbook using:</p>

<pre><code class="bash">ansible-playbook homebrew.yaml
</code></pre>

<h2>Source Code</h2>

<p>The code can be found in my github repository:
- <a href="https://github.com/ruanbekker/ansible-macbook-setup">https://github.com/ruanbekker/ansible-macbook-setup</a></p>

<h2>Thanks</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Remote Builds With Docker Contexts]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/07/14/remote-builds-with-docker-contexts/"/>
    <updated>2022-07-14T01:57:34-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/07/14/remote-builds-with-docker-contexts</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ruanbekker-docker-contexts.png" alt="using-docker-contexts" /></p>

<p>Often you want to save some battery life when you are doing docker builds and leverage a remote host to do the intensive work and we can utilise docker context over ssh to do just that.</p>

<h2>About</h2>

<p>In this tutorial I will show you how to use a remote docker engine to do docker builds, so you still run the docker client locally, but the context of your build will be sent to a remote docker engine via ssh.</p>

<p>We will setup password-less ssh, configure our ssh config, create the remote docker context, then use the remote docker context.</p>

<p><img src="https://user-images.githubusercontent.com/567298/178909518-26f580e9-2b96-41b3-bacd-a5ea5f848ebf.png" alt="image" /></p>

<h2>Password-less SSH</h2>

<p>I will be copying my public key to the remote host:</p>

<pre><code class="bash">$ ssh-copy-id ruan@192.168.2.18
</code></pre>

<p>Setup my ssh config:</p>

<pre><code class="bash">$ cat ~/.ssh/config
Host home-server
    Hostname 192.168.2.18
    User ruan
    IdentityFile ~/.ssh/id_rsa
    StrictHostKeyChecking no
    UserKnownHostsFile /dev/null
</code></pre>

<p>Test:</p>

<pre><code>$ ssh home-server whoami
ruan
</code></pre>

<h2>Docker Context</h2>

<p>On the target host (192.168.2.18) we can verify that docker is installed:</p>

<pre><code class="bash">$ docker version
Client: Docker Engine - Community
 Version:           20.10.12
 API version:       1.41
 Go version:        go1.16.12
 Git commit:        e91ed57
 Built:             Mon Dec 13 11:45:37 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.12
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.16.12
  Git commit:       459d0df
  Built:            Mon Dec 13 11:43:46 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.12
  GitCommit:        7b11cfaabd73bb80907dd23182b9347b4245eb5d
 runc:
  Version:          1.0.2
  GitCommit:        v1.0.2-0-g52b36a2
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
</code></pre>

<p>On the client (my laptop in this example), we will create a docker context called &ldquo;home-server&rdquo; and point it to our target host:</p>

<pre><code class="bash">$ docker context create home-server --docker "host=ssh://home-server"
home-server
Successfully created context "home-server"
</code></pre>

<p>Now we can list our contexts:</p>

<pre><code class="bash">docker context ls
NAME                TYPE                DESCRIPTION                               DOCKER ENDPOINT               KUBERNETES ENDPOINT                                  ORCHESTRATOR
default *           moby                Current DOCKER_HOST based configuration   unix:///var/run/docker.sock   https://k3d-master.127.0.0.1.nip.io:6445 (default)   swarm
home-server         moby                                                          ssh://home-server
</code></pre>

<h2>Using Contexts</h2>

<p>We can verify if this works by listing our cached docker images locally and on our remote host:</p>

<pre><code class="bash">$ docker --context=default images | wc -l
 16
</code></pre>

<p>And listing the remote images by specifying the context:</p>

<pre><code class="bash">$ docker --context=home-server images | wc -l
 70
</code></pre>

<p>We can set the default context to our target host:</p>

<pre><code>$ docker context use home-server
home-server
</code></pre>

<h2>Running Containers over Contexts</h2>

<p>So running containers with remote contexts essentially becomes running containers on remote hosts. In the past, I had to setup a ssh tunnel, point the docker host env var to that endpoint, then run containers on the remote host.</p>

<p>Thats something of the past, we can just point our docker context to our remote host and run the container. If you haven&rsquo;t set the default context, you can specify the context, so running a docker container on a remote host with your docker client locally:</p>

<pre><code class="bash">$ docker --context=home-server run -it -p 8002:8080 ruanbekker/hostname
2022/07/14 05:44:04 Server listening on port 8080
</code></pre>

<p>Now from our client (laptop), we can test our container on our remote host:</p>

<pre><code class="bash">$ curl http://192.168.2.18:8002
Hostname: 8605d292e2b4
</code></pre>

<p>The same way can be used to do remote docker builds, you have your Dockerfile locally, but when you build, you point the context to the remote host, and your context (dockerfile and files referenced in your dockerfile) will be sent to the remote host. This way you can save a lot of battery life as the computation is done on the remote docker engine.</p>

<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Prometheus Relabel Config Examples]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/05/30/prometheus-relabel-config-examples/"/>
    <updated>2022-05-30T03:01:01-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/05/30/prometheus-relabel-config-examples</id>
    <content type="html"><![CDATA[<p>This is a quick demonstration on how to use prometheus relabel configs, when you have scenarios for when example, you want to use a part of your hostname and assign it to a prometheus label.</p>

<h2>Prometheus Relabling</h2>

<p>Using a standard prometheus config to scrape two targets:
- <code>ip-192-168-64-29.multipass:9100</code>
- <code>ip-192-168-64-30.multipass:9100</code></p>

<pre><code>global:
  scrape_interval:     15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'local'

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 15s
    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'multipass-nodes'
    static_configs:
    - targets: ['ip-192-168-64-29.multipass:9100']
      labels:
        test: 1
    - targets: ['ip-192-168-64-30.multipass:9100']
      labels:
        test: 1
</code></pre>

<p>The Result:</p>

<p><img width="924" alt="image" src="https://user-images.githubusercontent.com/567298/170823370-f2c6b3a3-68a8-4f5a-ad43-2f1b832c95e0.png"></p>

<p>When we want to relabel one of the source the prometheus <a href="https://grafana.com/blog/2022/03/21/how-relabeling-in-prometheus-works/#internal-labels">internal labels</a>, <code>__address__</code> which will be the given target including the port, then we apply regex: <code>(.*)</code> to catch everything from the source label, and since there is only one group we use the <code>replacement</code> as <code>${1}-randomtext</code> and use that value to apply it as the value of the given <code>target_label</code> which in this case is for <code>randomlabel</code>, which will be in this case:</p>

<pre><code>global:
  scrape_interval:     15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'local'

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 15s
    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'multipass-nodes'
    static_configs:
    - targets: ['ip-192-168-64-29.multipass:9100']
      labels:
        test: 3
    - targets: ['ip-192-168-64-30.multipass:9100']
      labels:
        test: 3
    relabel_configs:
    - source_labels: [__address__]
      regex: '(.+)'
      replacement: '${1}-randomtext'
      target_label: randomlabel
</code></pre>

<p>The Result:</p>

<p><img width="1107" alt="image" src="https://user-images.githubusercontent.com/567298/170824588-44a79c3d-5131-4311-bcca-f5137d6acdad.png"></p>

<p>In this case we want to relabel the <code>__address__</code> and apply the value to the <code>instance</code> label, but we want to exclude the <code>:9100</code> from the <code>__address__</code> label:</p>

<pre><code># Config: https://github.com/prometheus/prometheus/blob/release-2.36/config/testdata/conf.good.yml
global:
  scrape_interval:     15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'local'

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 15s
    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'multipass-nodes'
    static_configs:
    - targets: ['ip-192-168-64-29.multipass:9100']
      labels:
        test: 4
    - targets: ['ip-192-168-64-30.multipass:9100']
      labels:
        test: 4
    relabel_configs:
    - source_labels: [__address__]
      separator: ':'
      regex: '(.*):(.*)'
      replacement: '${1}'
      target_label: instance
</code></pre>

<p>The Result:</p>

<p><img width="950" alt="image" src="https://user-images.githubusercontent.com/567298/170824806-45f0f243-5fe7-4635-9e9a-335616a322da.png"></p>

<h2>AWS EC2 SD Configs</h2>

<p>On AWS EC2 you can make use of the <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config">ec2_sd_config</a> where you can make use of EC2 Tags, to set the values of your tags to prometheus label values.</p>

<p>In this scenario, on my EC2 instances I have 3 tags:
- Key: PrometheusScrape, Value: Enabled
- Key: Name, Value: pdn-server-1
- Key: Environment, Value: dev</p>

<p>In our config, we only apply a node-exporter scrape config to instances which are tagged <code>PrometheusScrape=Enabled</code>, then we use the <code>Name</code> tag, and assign it&rsquo;s value to the <code>instance</code> tag, and the similarly we assign the <code>Environment</code> tag value to the <code>environment</code> promtheus label value.</p>

<p>Because this prometheus instance resides in the same VPC, I am using the <code>__meta_ec2_private_ip</code> which is the private ip address of the EC2 instance to assign it to the address where it needs to scrape the node exporter metrics endpoint:</p>

<pre><code class="yaml">scrape_configs:
  - job_name: node-exporter
    scrape_interval: 15s
    ec2_sd_configs:
    - region: eu-west-1
      port: 9100
      filters:
        - name: tag:PrometheusScrape
          values:
            - Enabled
    relabel_configs:
    - source_labels: [__meta_ec2_private_ip]
      replacement: '${1}:9100'
      target_label: __address__
    - source_labels: [__meta_ec2_tag_Name]
      target_label: instance
    - source_labels: [__meta_ec2_tag_Environment]
      target_label: environment
</code></pre>

<p>You will need a EC2 Ready Only instance role (or access keys on the configuration) in order for prometheus to read the EC2 tags on your account.</p>

<p>See their <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config">documentation</a> for more info.</p>

<h2>Stack</h2>

<p>The docker-compose used:</p>

<pre><code class="yaml">version: '3.8'

services:
  prometheus:
    image: prom/prometheus
    container_name: 'prometheus'
    user: root
    restart: unless-stopped
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention=14d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.external-url=http://prometheus.127.0.0.1.nip.io'
    ports:
      - 9090:9090
    networks:
      - public
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

networks:
  public:
    name: public

volumes:
  prometheus-data: {}
</code></pre>

<h2>References</h2>

<p>Usful docs:</p>

<ul>
<li><a href="https://grafana.com/blog/2022/03/21/how-relabeling-in-prometheus-works/#internal-labels">https://grafana.com/blog/2022/03/21/how-relabeling-in-prometheus-works/#internal-labels</a></li>
<li><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config">https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config</a></li>
<li><a href="https://regexr.com/">https://regexr.com/</a></li>
</ul>


<h2>Thank You</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong>, read my <strong><a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create a AWS Lambda Layer With Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/05/27/create-a-aws-lambda-layer-with-docker/"/>
    <updated>2022-05-27T06:19:05-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/05/27/create-a-aws-lambda-layer-with-docker</id>
    <content type="html"><![CDATA[<p>In this tutorial we will be creating a AWS Lambda Python <a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html">Layer</a> that will include the Python Requests package and we will compile the package with Docker and the LambCI image.</p>

<h2>Getting Started</h2>

<p>First we will create the directory where we will store the intermediate data:</p>

<pre><code class="bash">$ mkdir lambda-layers
$ cd lambda-layers
</code></pre>

<p>Then we will create the directory structure, as you can see I will be using the python 3.8 runtime:</p>

<pre><code class="bash">$ mkdir -p requests/python/lib/python3.8
$ cd requests
</code></pre>

<p>Write the dependencies to the requirements file:</p>

<pre><code class="bash">$ echo "requests" &gt; requirements.txt
</code></pre>

<p>Install dependencies locally using docker, where we will be using the <code>lambci/lambda:build-python3.8</code> iamge and we are mounting our current working directory to <code>/var/task</code> inside the container, and then we will be running the command <code>pip install -r requirements.txt -t python/lib/python3.7/site-packages/; exit</code> inside the container, which will essentially dump the content to our working directory:</p>

<pre><code class="bash">$ docker run -v $PWD:/var/task \
   lambci/lambda:build-python3.8 \
   sh -c "pip install -r requirements.txt -t python/lib/python3.8/site-packages/; exit"
</code></pre>

<p>Zip up the deployment package that we will push to AWS Lambda Layers:</p>

<pre><code class="bash">$ zip -r package.zip python &gt; /dev/null
</code></pre>

<p>Publish the layer using the aws cli tools, by specifying the deployment package, the compatible runtime and a identifier:</p>

<pre><code class="bash">$ aws --profile dev lambda \
   publish-layer-version --layer-name python-requests \
   --description "Python Requests using 3.8 Runtime" \
   --zip-file fileb://package.zip \
   --compatible-runtime "python3.8"
</code></pre>

<p>Then when you want to reference the layer on the functio that you want to create, you can do it like this:</p>

<pre><code class="bash">$ aws lambda create-function --function-name test-requests \
   --runtime python3.8 \
   --handler lambda_function.lambda_handler \
   --role "" --layers "arn:aws:lambda:eu-west-1:xxxxxxxxxxxx:layer:test-requests" \
   --code "S3Bucket=string,S3Key=string"
</code></pre>

<h2>Thank You</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong>, read my <strong><a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>

<p>Credit to <a href="https://oznetnerd.com/2020/11/11/lambda-packaging-the-right-way/">oznetnerd.com</a>.</p>
]]></content>
  </entry>
  
</feed>
