<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker-compose | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/docker-compose/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2022-02-08T05:19:35-05:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reduce Docker Log Size on Disk]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/12/23/reduce-docker-log-size-on-disk/"/>
    <updated>2020-12-23T04:11:35-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/12/23/reduce-docker-log-size-on-disk</id>
    <content type="html"><![CDATA[<p>In cases where you are using the defaults for logging and your application logs a lot you can consume a lot of disk space and you can run out of disk space quite quickly.</p>

<p>If it&rsquo;s a case where you already ran out of disk space, we can investigate the disk space consumed by docker logs:</p>

<pre><code>$ cd /var/lib/docker/containers
$ du -sh *
6.0G    14052251a0f13f46f65bc73d10c01408130ee8ae71529600ba5bd6bee76af4ee
1.2G    e6b40b1d30c5cf05e8cb201ca9abf6bd283d7cf7ceaa3be2a0422be7cd750a33
</code></pre>

<p>Referenced from <a href="https://blog.birkhoff.me/devops-truncate-docker-container-logs-periodically-to-free-up-server-disk-space/">https://blog.birkhoff.me/devops-truncate-docker-container-logs-periodically-to-free-up-server-disk-space/</a> you can truncate those files:</p>

<pre><code>$ sh -c 'truncate -s 0 /var/lib/docker/containers/*/*-json.log'
</code></pre>

<p>Check the size again:</p>

<pre><code>$ du -sh *
40K 14052251a0f13f46f65bc73d10c01408130ee8ae71529600ba5bd6bee76af4ee
36K e6b40b1d30c5cf05e8cb201ca9abf6bd283d7cf7ceaa3be2a0422be7cd750a33
</code></pre>

<p>To overcome this issue you can use this in logging options in your compose:</p>

<pre><code>...
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
...
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running a 3 Node Elasticsearch Cluster With Docker Compose on Your Laptop for Testing]]></title>
    <link href="https://blog.ruanbekker.com/blog/2018/04/29/running-a-3-node-elasticsearch-cluster-with-docker-compose-on-your-laptop-for-testing/"/>
    <updated>2018-04-29T13:43:35-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2018/04/29/running-a-3-node-elasticsearch-cluster-with-docker-compose-on-your-laptop-for-testing</id>
    <content type="html"><![CDATA[<p>Having a Elasticsearch cluster on your laptop with Docker for testing is great. And in this post I will show you how quick and easy it is, to have a 3 node elasticsearch cluster running on docker for testing.</p>

<p><a href="https://bekkerclothing.com/collections/developer?utm_source=blog.ruanbekker.com&utm_medium=blog&utm_campaign=leaderboard_ad" target="_blank"><img alt="bekker-clothing-developer-tshirts" src="https://user-images.githubusercontent.com/567298/70170981-7c278a80-16d6-11ea-9759-6621d02c1423.png"></a></p>

<h2>Pre-Requisites</h2>

<p>We need to set the <code>vm.max_map_count</code> kernel parameter:</p>

<pre><code class="bash">$ sudo sysctl -w vm.max_map_count=262144
</code></pre>

<p>To set this permanently, add it to <code>/etc/sysctl.conf</code> and reload with <code>sudo sysctl -p</code></p>

<h2>Docker Compose:</h2>

<p>The docker compose file that we will reference:</p>

<script src="https://gist.github.com/ruanbekker/410538a0e38c3df5c3ba76e7171f2eda.js"></script>


<p>The data of our elasticsearch container volumes will reside under /var/lib/docker, if you want them to persist in another location, you can use the <code>driver_opts</code> setting for the local volume driver.</p>

<h2>Deploy</h2>

<p>Deploy your elasticsearch cluster with docker compose:</p>

<pre><code>$ docker-compose up
</code></pre>

<p>This will run in the foreground, and you should see console output.</p>

<h2>Testing Elasticsearch</h2>

<p>Let&rsquo;s run a couple of queries, first up, check the cluster health api:</p>

<pre><code class="bash">$ curl http://127.0.0.1:9200/_cluster/health?pretty
{
  "cluster_name" : "docker-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 3,
  "number_of_data_nodes" : 3,
  "active_primary_shards" : 1,
  "active_shards" : 2,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
</code></pre>

<p>Create a index with replication count of 2:</p>

<pre><code class="bash">$ curl -H "Content-Type: application/json" -XPUT http://127.0.0.1:9200/test -d '{"number_of_replicas": 2}'
</code></pre>

<p>Ingest a document to elasticsearch:</p>

<pre><code class="bash">$ curl -H "Content-Type: application/json" -XPUT http://127.0.0.1:9200/test/docs/1 -d '{"name": "ruan"}'
{"_index":"test","_type":"docs","_id":"1","_version":1,"result":"created","_shards":{"total":3,"successful":3,"failed":0},"_seq_no":0,"_primary_term":1}
</code></pre>

<p>View the indices:</p>

<pre><code class="bash">$ curl http://127.0.0.1:9200/_cat/indices?v
health status index                       uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   test                        w4p2Q3fTR4uMSYBfpNVPqw   5   2          1            0      3.3kb          1.1kb
green  open   .monitoring-es-6-2018.04.29 W69lql-rSbORVfHZrj4vug   1   1       1601           38        4mb            2mb
</code></pre>

<h2>Kibana</h2>

<p>Kibana is also included in the stack and is accessible via <a href="http://localhost:5601/">http://localhost:5601/</a> and you it should look more or less like:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/kibana-local-home.png" alt="" /></p>

<h2>Elasticsearch Head UI</h2>

<p>I always prefer working directly with the RESTFul API, but if you would like to use a UI to interact with Elasticsearch, you can access it via <a href="http://localhost:9100/">http://localhost:9100/</a> and should look like this:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/elasticsearch-head-ui.png" alt="" /></p>

<h2>Deleting the Cluster:</h2>

<p>As its running in the foreground, you can just hit ctrl + c and as we persisted data in our compose, when you spin up the cluster again, the data will still be there.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html</a></li>
</ul>


<p>Update (2019.06) - I am preparing a full elasticsearch course available on <a href="https://github.com/ruanbekker/elasticsearch-demo">https://github.com/ruanbekker/elasticsearch-demo</a> and a <a href="https://gist.github.com/ruanbekker/e8a09604b14f37e8d2f743a87b930f93">Elasticsearch Cheetsheat</a>, feel free to check it out.</p>

<center>
        <script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script>
</center>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use Docker Secrets With MySQL on Docker Swarm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2017/11/23/use-docker-secrets-with-mysql-on-docker-swarm/"/>
    <updated>2017-11-23T16:55:15-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2017/11/23/use-docker-secrets-with-mysql-on-docker-swarm</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53351889-85572000-392a-11e9-9720-464e9318206e.jpg" alt="" /></p>

<p>Today we will use Docker Secrets, more specifically store our MySQL Passwords in Secrets, which will be passed to our containers, so that we don&rsquo;t use clear text passwords in our Compose files.</p>

<script id="mNCC" language="javascript">
    medianet_width = "728";
    medianet_height = "90";
    medianet_crid = "218284798";
    medianet_versionId = "3111299"; 
  </script>


<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>


<h2>What is Docker Secrets:</h2>

<p>In Docker, Docker Secrets are encrypted during transit and at rest in a Docker Swarm Cluster. The great thing about Docker Secrets is that you can manage these secrets from a central place, and the fact that it encrypts the data and transfers the data securely to the containers that needs the secrets. So you authorize which containers needs access to these secrets.</p>

<p>So instead of setting the MySQL Root Passwords in clear text, you will create the secrets, then in your docker-compose file, you will reference the secret name.</p>

<h2>Deploy MySQL with Docker Secrets</h2>

<p>We will deploy a Stack that contains MySQL and Adminer (WebUI for MySQL).</p>

<p>We will make the MySQL Service Persistent by setting a constraint to only run on the Manager node, as we will create the volume path on the host, and then map the host to the container so that the container can have persistent data. We will also create secrets for our MySQL Service so that we dont expose any plaintext passwords in our compose file.</p>

<p>Our Docker Compose file:</p>

<pre><code class="yaml docker-compose.yml">version: '3.3'

services:
  db:
    image: mysql
    secrets:
      - db_root_password
      - db_dba_password
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
      resources:
        reservations:
          memory: 128M
        limits:
          memory: 256M
    ports:
      - 3306:3306
    environment:
      MYSQL_USER: dba
      MYSQL_DATABASE: mydb
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
      MYSQL_PASSWORD_FILE: /run/secrets/db_dba_password
    networks:
      - appnet
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - type: bind
        source: /opt/docker/volumes/mysql
        target: /var/lib/mysql

  adminer:
    image: adminer
    ports:
      - 8080:8080
    networks:
      - appnet

secrets:
  db_root_password:
    external: true
  db_dba_password:
    external: true

networks:
  appnet:
    external: true
</code></pre>

<h2>Dependencies:</h2>

<p>As we specified our secrets and networks as external resources, it needs to exist before we deploy our stack. We also need to create the directory for our mysql data, as the data will be mapped from our host to our container.</p>

<p>Create the Overlay Network:</p>

<pre><code class="bash">$ docker network create --driver overlay appnet
</code></pre>

<p>Create the Secrets:</p>

<pre><code class="bash">$ openssl rand -base64 12 | docker secret create db_root_password -
$ openssl rand -base64 12 | docker secret create db_dba_password -
</code></pre>

<p>List the Secrets:</p>

<pre><code class="bash">$ docker secret ls
ID                          NAME                CREATED             UPDATED
jzhrwyxkiqt8v81ow0xjktqnw   db_root_password    12 seconds ago      12 seconds ago
plr6rbrqkqy7oplrd21pja3ol   db_dba_password     4 seconds ago       4 seconds ago
</code></pre>

<p>Inspect the secret, so that we can see that theres not value exposed:</p>

<pre><code class="bash">$ docker secret inspect db_root_password
[
    {
        "ID": "jzhrwyxkiqt8v81ow0xjktqnw",
        "Version": {
            "Index": 982811
        },
        "CreatedAt": "2017-11-23T14:33:17.005968748Z",
        "UpdatedAt": "2017-11-23T14:33:17.005968748Z",
        "Spec": {
            "Name": "db_root_password",
            "Labels": {}
        }
    }
]
</code></pre>

<p>Create the Directory for MySQL:</p>

<pre><code class="bash">$ mkdir -p /opt/docker/volumes/mysql
</code></pre>

<h2>Deployment Time!</h2>

<p>Deploy the stack:</p>

<pre><code>$ docker stack deploy -c docker-compose.yml apps
Creating service apps_adminer
Creating service apps_db
</code></pre>

<p>As you can see the data of our MySQL container resides on our host, which makes the data persistent for the container:</p>

<pre><code class="bash">$ ls /opt/docker/volumes/mysql/
auto.cnf  ca-key.pem  ca.pem  client-cert.pem  client-key.pem  ib_buffer_pool  ibdata1  ib_logfile0  ib_logfile1  ibtmp1  mydb  mysql  performance_schema  private_key.pem  public_key.pem  server-cert.pem  server-key.pem  sys
</code></pre>

<h2>Connect to MySQL</h2>

<p>The value of our secrets will reside under <code>/run/secrets/</code> in our container, as we have mapped it to our mysql container, lets have a look at them:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) ls /run/secrets/
db_dba_password  db_root_password
</code></pre>

<p>View the actual value of the <code>db_root_password</code>:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) cat /run/secrets/db_root_password
mRpcY1eY2+wimf10
</code></pre>

<p>Connecting to MySQL:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 8
Server version: 5.7.20 MySQL Community Server (GPL)

Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydb               |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)
</code></pre>

<p>As we have deployed adminer, you can access the Adminer WebUI on the Host&rsquo;s IP and the Defined Port.</p>

<h2>Testing Data Persistance:</h2>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.

mysql&gt; create database ruan;
Query OK, 1 row affected (0.00 sec)

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydb               |
| mysql              |
| performance_schema |
| ruan               |
| sys                |
+--------------------+
6 rows in set (0.00 sec)

mysql&gt; exit;
Bye
</code></pre>

<p>Verify the hostname of our container, before we kill the container:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) hostname
bdedb54bbc2b
</code></pre>

<p>Kill the container:</p>

<pre><code>$ docker kill $(docker ps -f name=apps_db -q)
bdedb54bbc2b
</code></pre>

<p>Verify the status of the MySQL Service, as we can see the service count is 0, so the container was succesfully killed.</p>

<pre><code class="bash">$ docker service ls -f name=apps_db
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
nzf96q05fktm        apps_db             replicated          0/1                 mysql:latest        *:3306-&gt;3306/tcp
</code></pre>

<p>After waiting for a couple of seconds, we can see the service is in service again, then check the hostname so that we can confirm that its a new container:</p>

<pre><code>$ docker service ls -f name=apps_db
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
nzf96q05fktm        apps_db             replicated          1/1                 mysql:latest        *:3306-&gt;3306/tcp

$ docker exec -it $(docker ps -f name=apps_db -q) hostname
95c15c89f891
</code></pre>

<p>Logong to MySQL again and verify if our perviously created database is still there:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydb               |
| mysql              |
| performance_schema |
| ruan               |
| sys                |
+--------------------+
6 rows in set (0.01 sec)
</code></pre>

<p>By design docker is stateless, but as we mapped the host&rsquo;s path to the container our data is persistent. As we have set a constraint so that the container must only spin up on this node, the container will always have access to the data path.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Local Dev Environment With Docker MySQL and Adminer WebUI With Docker Compose]]></title>
    <link href="https://blog.ruanbekker.com/blog/2017/11/13/local-dev-environment-with-docker-mysql-and-adminer-webui-with-docker-compose/"/>
    <updated>2017-11-13T16:15:34-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2017/11/13/local-dev-environment-with-docker-mysql-and-adminer-webui-with-docker-compose</id>
    <content type="html"><![CDATA[<p>Let&rsquo;s setup a local development environment with Docker, MySQL and Adminer WebUI using Docker Compose</p>

<h2>Docker Compose File:</h2>

<p>Let&rsquo;s look at our docker-compose file:</p>

<pre><code class="yml">version: '3.2'

services:
  mysql-client:
    image: alpine:edge
    volumes:
      - type: bind
        source: ./workspace
        target: /root/workspace
    networks:
      - docknet
    command: ping 127.0.0.1

  db:
    image: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: example
    networks:
      - docknet
    volumes:
      - type: volume
        source: dbdata
        target: /var/lib/mysql

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080
    networks:
      - docknet

networks:
    docknet:
        external: true

volumes:
  dbdata:
    external: true
</code></pre>

<p>Environment Variables for the MySQL Docker image is:</p>

<pre><code>- MYSQL_ROOT_PASSWORD
- MYSQL_DATABASE
- MYSQL_USER, MYSQL_PASSWORD
- MYSQL_ALLOW_EMPTY_PASSWORD
- MYSQL_RANDOM_ROOT_PASSWORD
- MYSQL_ONETIME_PASSWORD
</code></pre>

<p>More info can be viewed on this resource: <a href="https://hub.docker.com/_/mysql/">hub.docker.com/_/mysql/</a></p>

<h2>Pre-Requirements:</h2>

<p>Let&rsquo;s create our pre-requirement:</p>

<ol>
<li>Networks:</li>
</ol>


<pre><code class="bash">$ docker network create docknet
</code></pre>

<ol>
<li>Volumes:</li>
</ol>


<p>Our Volume for MySQL so that we have persistent data:</p>

<pre><code class="bash">$ docker volume create dbdata
</code></pre>

<p>Our <code>workspace</code> directory that will be persistent in our <code>debug-client</code> alpine container:</p>

<pre><code class="bash">$ mkdir -p workspace/python
</code></pre>

<h2>Launching our Services:</h2>

<p>Let&rsquo;s launch our services:</p>

<pre><code class="bash ">$ docker-compose -f mysql-compose.yml up -d
Creating mysql_db_1 ...
Creating mysql_adminer_1
Creating mysql_debug-client_1
</code></pre>

<p>Listing our Containers:</p>

<pre><code class="bash">$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                      NAMES
e05804ab6d64        alpine:edge         "ping 127.0.0.1"         21 seconds ago      Up 4 seconds                                   mysql_debug-client_1
c052ceeb6d3b        mysql               "docker-entrypoint..."   21 seconds ago      Up 5 seconds        3306/tcp                   mysql_db_1
2b0446daab4c        adminer             "entrypoint.sh doc..."   26 seconds ago      Up 5 seconds        0.0.0.0:8080-&gt;8080/tcp     mysql_adminer_1
</code></pre>

<h2>Using the Debug Container:</h2>

<p>I will use the debug container as the client to connect to the internal services, for example, the mysql-client:</p>

<pre><code class="bash">$ apk update
$ apk add mysql-client
$ mysql -h db -u root -ppassword
MySQL [(none)]&gt;
</code></pre>

<p>Also, you will find the persistent data directory for our workspace:</p>

<pre><code class="bash">$ ls /root/workspace/
python
</code></pre>

<h2>Accessing the MySQL WebUI: Adminer</h2>

<p>Access the service via the exposed endpoint:</p>

<pre><code class="bash">+ http://localhost:8080/
</code></pre>

<p>The login view:</p>

<p><img src="https://i.snag.gy/m8dUxe.jpg" alt="" /></p>

<p>Creating the Table:</p>

<p><img src="https://i.snag.gy/tPVbg6.jpg" alt="" /></p>

<h2>Deleting the Environment:</h2>

<p>The External Resources will not be deleted:</p>

<pre><code class="bash">$ docker-compose -f mysql-compose.yml down
Removing mysql_debug-client_1 ... done
Removing mysql_db_1           ... done
Removing mysql_adminer_1      ... done
Network docknet is external, skipping
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/_/mysql/">https://hub.docker.com/_/mysql/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating a Nodejs Hostname App With Docker Stacks on Swarm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2017/09/24/creating-a-nodejs-hostname-app-with-docker-stacks-on-swarm/"/>
    <updated>2017-09-24T17:52:51-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2017/09/24/creating-a-nodejs-hostname-app-with-docker-stacks-on-swarm</id>
    <content type="html"><![CDATA[<p>Create a Nodejs Application that responds GET requests with its Hostname.</p>

<p>Our nodejs application will sit beind a HAProxy Load Balancer, we are mounting the <code>docker.sock</code> from the host to the container, so as we scale our web application, our load balancer is aware of the changes, and scales as we scale our web application.</p>

<h2>Creating the Application:</h2>

<p>Our nodejs application:</p>

<pre><code class="javascript app.js">var http = require('http');
var os = require('os');
http.createServer(function (req, res) {
    res.writeHead(200, {'Content-Type': 'text/html'});
    res.end(`My Hostname: ${os.hostname()}\n`);
}).listen(8080);
</code></pre>

<p>Our Dockerfile:</p>

<pre><code class="docker Dockerfile">FROM node:alpine
ADD app.js /app.js
CMD ["node", "/app.js"]
</code></pre>

<p>Build and Push to your registry, or you could use my image on Dockerhub: <a href="https://hub.docker.com/r/rbekker87/node-containername/">hub.docker.com/r/rbekker87/node-containername</a></p>

<pre><code class="bash Build and Push">$ docker login
$ docker build -t &lt;username&gt;/&lt;repo&gt;:&lt;tag&gt; .
$ docker push  &lt;username&gt;/&lt;repo&gt;:&lt;tag&gt;
</code></pre>

<h2>Creating the Compose file</h2>

<p>Create the compose file that will define our services:</p>

<pre><code class="bash docker-compose.yml">version: '3'

services:
  node-app:
    image: rbekker87/node-containername
    networks:
      - nodenet
    environment:
      - SERVICE_PORTS=8080
    deploy:
      replicas: 20
      update_config:
        parallelism: 5
        delay: 10s
      restart_policy:
        condition: on-failure
        max_attempts: 3
        window: 120s

  loadbalancer:
    image: dockercloud/haproxy:latest
    depends_on:
      - node-app
    environment:
      - BALANCE=leastconn
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 80:80
    networks:
      - nodenet
    deploy:
      placement:
        constraints: [node.role == manager]

networks:
  nodenet:
    driver: overlay
</code></pre>

<h2>Create the Stack:</h2>

<p>Deploy the Stack by specifying the compose file and name of our stack:</p>

<pre><code class="bash Deploy our Stack">$ docker stack deploy -c docker-compose.yml node
</code></pre>

<p>List the Services in the Stack:</p>

<pre><code class="bash List Services in our Stack">$ docker stack ls
NAME                SERVICES
node                2
</code></pre>

<p>List the Tasks in the Stack:</p>

<pre><code class="bash Tasks in our Stack">$ docker stack ps node
ID                  NAME                  IMAGE                                 NODE     DESIRED STATE       CURRENT STATE            ERROR               PORTS
l5ryfaedzzaq        node_loadbalancer.1   dockercloud/haproxy:latest            dsm-01   Running             Running 40 minutes ago
c8nrrcvek79h        node_node-app.5       rbekker87/node-containername:latest   dsm-01   Running             Running 40 minutes ago
dqii18b2q5nn        node_node-app.10      rbekker87/node-containername:latest   dsm-01   Running             Running 40 minutes ago
vkpw2rugy0ah        node_node-app.11      rbekker87/node-containername:latest   dsm-01   Running             Running 40 minutes ago
mm88nvnvy5lg        node_node-app.12      rbekker87/node-containername:latest   dsm-01   Running             Running 40 minutes ago
oyx8rfqc1xl2        node_node-app.16      rbekker87/node-containername:latest   dsm-01   Running             Running 41 minutes ago
</code></pre>

<h2>Test out our Application</h2>

<p>Test out the Service:</p>

<pre><code class="bash GET Requests">$ curl -XGET http://127.0.0.1/
My Hostname: a6e34246e73b

$ curl -XGET http://127.0.0.1/
My Hostname: 5de71278be38

$ curl -XGET http://127.0.0.1/
My Hostname: e0b7316fdd51
</code></pre>

<h2>Scaling Out:</h2>

<p>Scale our Application out to 30 replica&rsquo;s</p>

<pre><code class="bash Scaling Up">$ docker service scale node-app=30
</code></pre>

<p>Scale our Application down to 10 replica&rsquo;s</p>

<pre><code class="bash Scaling Down">$ docker service scale node-app=10
</code></pre>

<h2>Cleanup</h2>

<p>Remove the Stack:</p>

<pre><code class="bash Delete the Stack">$ docker stack rm node
Removing service node_loadbalancer
Removing service node_node-app
Removing network node_nodenet
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://github.com/ruanbekker/docker-node-containername">https://github.com/ruanbekker/docker-node-containername</a></li>
<li><a href="https://hub.docker.com/r/rbekker87/node-containername/">https://hub.docker.com/r/rbekker87/node-containername/</a></li>
<li><a href="https://medium.com/@nirgn/load-balancing-applications-with-haproxy-and-docker-d719b7c5b231">Resource 1</a> + <a href="http://anokun7.github.io/microservices-demo/">Resource 2</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
