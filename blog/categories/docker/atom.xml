<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2023-07-16T08:48:02-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Use the MySQL Terraform Provider]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/07/15/how-to-use-the-mysql-terraform-provider/"/>
    <updated>2023-07-15T20:55:23-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/07/15/how-to-use-the-mysql-terraform-provider</id>
    <content type="html"><![CDATA[<p>In this tutorial we will provision a MySQL Server with Docker and then use Terraform to provision MySQL Users, Database Schemas and MySQL Grants with the MySQL Terraform Provider.</p>

<h2>About</h2>

<p>Terraform is super powerful and can do a lot of things. And it shines when it provisions Infrastructure. So in a scenario where we use Terraform to provision RDS MySQL Database Instances, we might still want to provision extra MySQL Users, or Database Schemas and the respective MySQL Grants.</p>

<p>Usually you will logon to the database and create them manually with sql syntax. But in this tutorial we want to make use of Docker to provision our MySQL Server and we would like to make use of Terraform to provision the MySQL Database Schemas, Grants and Users.</p>

<p>Instead of using AWS RDS, I will be provisioning a MySQL Server on Docker so that we can keep the costs free, for those who are following along.</p>

<p>We will also go through the steps on how to rotate the database password that we will be provisioning for our user.</p>

<h2>MySQL Server</h2>

<p>First we will provision a MySQL Server on Docker Containers, I have a <code>docker-compose.yaml</code> which is available in my <a href="https://github.com/ruanbekker/quick-starts/blob/main/docker/mysql/docker-compose.yaml">quick-starts</a> github repository:</p>

<pre><code class="yaml">version: "3.8"

services:
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - 3306:3306
    environment:
      - MYSQL_DATABASE=sample
      - MYSQL_ROOT_PASSWORD=rootpassword
</code></pre>

<p>Once you have saved that in your current working directory, you can start the container with docker compose:</p>

<pre><code class="bash">docker-compose up -d
</code></pre>

<p>You can test the mysql container by logging onto the mysql server with the correct auth:</p>

<pre><code class="bash">docker exec -it mysql mysql -u root -prootpassword -e 'show databases;'
</code></pre>

<p>This should be more or less the output:</p>

<pre><code class="sql">+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sample             |
| sys                |
+--------------------+
</code></pre>

<h2>Terraform</h2>

<p>If you don&rsquo;t have Terraform installed, you can install it from their <a href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli">documentation</a>.</p>

<p>If you want the source code of this example, its available in my <a href="https://github.com/ruanbekker/quick-starts/tree/main/terraform/mysql/petoju-provider">terraform-mysql/petoju-provider</a> repository. Which you can clone and jump into the <code>terraform/mysql/petoju-provider</code> directory.</p>

<p>First we will define the <code>providers.tf</code>:</p>

<pre><code class="bash">terraform {
  required_providers {
    mysql = {
      source = "petoju/mysql"
      version = "3.0.37"
    }
  }
}

provider "mysql" {
  alias    = "local"
  endpoint = "127.0.0.1:3306"
  username = "root"
  password = "rootpassword"
}
</code></pre>

<p>Then the <code>main.tf</code>:</p>

<pre><code class="bash">resource "random_password" "user_password" {
  length           = 24
  special          = true
  min_special      = 2
  override_special = "!#$%^&amp;*()-_=+[]{}&lt;&gt;:?"
  keepers = {
    password_version = var.password_version
  }
}

resource "mysql_database" "user_db" {
  provider = mysql.local
  name = var.database_name
}

resource "mysql_user" "user_id" {
  provider = mysql.local
  user = var.database_username
  plaintext_password = random_password.user_password.result
  host = "%"
  tls_option = "NONE"
}

resource "mysql_grant" "user_id" {
  provider = mysql.local
  user = var.database_username
  host = "%"
  database = var.database_name
  privileges = ["SELECT", "UPDATE"]
  depends_on = [
    mysql_user.user_id
  ]
}
</code></pre>

<p>Then the <code>variables.tf</code>:</p>

<pre><code class="bash">variable "database_name" {
  description = "The name of the database that you want created."
  type        = string
  default     = null
}

variable "database_username" {
  description = "The name of the database username that you want created."
  type        = string
  default     = null
}

variable "password_version" {
  description = "The password rotates when this value gets updated."
  type        = number
  default     = 0
}
</code></pre>

<p>Then our <code>outputs.tf</code>:</p>

<pre><code class="bash">output "user" {
  value = mysql_user.user_id.user
}

output "password" {
  sensitive = true
  value = random_password.user_password.result
}
</code></pre>

<p>Our <code>terraform.tfvars</code> that defines the values of our variables:</p>

<pre><code class="bash">database_name     = "foobar"
database_username = "ruanb"
password_version  = 0
</code></pre>

<p>Now we are ready to run our terraform code, which will ultimately create a database, user and grants. Outputs the encrypted string of your password which was encrypted with your <code>keybase_username</code>.</p>

<p>Initialise Terraform:</p>

<pre><code class="bash">terraform init
</code></pre>

<p>Run the plan to see what terraform wants to provision:</p>

<pre><code class="bash">terraform plan
</code></pre>

<p>And we can see the following resources will be created:</p>

<pre><code class="bash">Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # mysql_database.user_db will be created
  + resource "mysql_database" "user_db" {
      + default_character_set = "utf8mb4"
      + default_collation     = "utf8mb4_general_ci"
      + id                    = (known after apply)
      + name                  = "foobar"
    }

  # mysql_grant.user_id will be created
  + resource "mysql_grant" "user_id" {
      + database   = "foobar"
      + grant      = false
      + host       = "%"
      + id         = (known after apply)
      + privileges = [
          + "SELECT",
          + "UPDATE",
        ]
      + table      = "*"
      + tls_option = "NONE"
      + user       = "ruanb"
    }

  # mysql_user.user_id will be created
  + resource "mysql_user" "user_id" {
      + host               = "%"
      + id                 = (known after apply)
      + plaintext_password = (sensitive value)
      + tls_option         = "NONE"
      + user               = "ruanb"
    }

  # random_password.user_password will be created
  + resource "random_password" "user_password" {
      + bcrypt_hash      = (sensitive value)
      + id               = (known after apply)
      + keepers          = {
          + "password_version" = "0"
        }
      + length           = 24
      + lower            = true
      + min_lower        = 0
      + min_numeric      = 0
      + min_special      = 2
      + min_upper        = 0
      + number           = true
      + numeric          = true
      + override_special = "!#$%^&amp;*()-_=+[]{}&lt;&gt;:?"
      + result           = (sensitive value)
      + special          = true
      + upper            = true
    }

Plan: 4 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + password = (sensitive value)
  + user     = "ruanb"
</code></pre>

<p>Run the apply which will create the database, the user, sets the password and applies the grants:</p>

<pre><code class="bash">terraform apply
</code></pre>

<p>Then our returned output should show something like this:</p>

<pre><code class="bash">Apply complete! Resources: 4 added, 0 changed, 0 destroyed.

Outputs:

password = &lt;sensitive&gt;
user = "ruanb"
</code></pre>

<p>As our password is set as sensitive, we can access the value with <code>terraform output -raw password</code>, let&rsquo;s assign the password to a variable:</p>

<pre><code class="bash">DBPASS=$(terraform output -raw password)
</code></pre>

<p>Then we can exec into the mysql container and logon to the mysql server with our new credentials:</p>

<pre><code class="bash">docker exec -it mysql mysql -u ruanb -p$DBPASS
</code></pre>

<p>And we can see we are logged onto the mysql server:</p>

<pre><code class="bash">Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 14
Server version: 8.0.33 MySQL Community Server - GPL

mysql&gt;
</code></pre>

<p>If we run <code>show databases;</code> we should see the following:</p>

<pre><code class="sql">mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| foobar             |
| information_schema |
| performance_schema |
+--------------------+
3 rows in set (0.03 sec)
</code></pre>

<p>If we want to rotate the mysql password for the user, we can update the <code>password_version</code> variable either in our <code>terraform.tfvars</code> or via the cli. Let&rsquo;s pass the variable in the cli and do a <code>terraform plan</code> to verify the changes:</p>

<pre><code class="bash">terraform plan -var password_version=1
</code></pre>

<p>And due to our value for the random resource keepers parameter being updated, it will trigger the value of our password to be changed, and that will let terraform update our mysql user&rsquo;s password:</p>

<pre><code class="bash">Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  ~ update in-place
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # mysql_user.user_id will be updated in-place
  ~ resource "mysql_user" "user_id" {
        id                 = "ruanb@%"
      ~ plaintext_password = (sensitive value)
        # (5 unchanged attributes hidden)
    }

  # random_password.user_password must be replaced
-/+ resource "random_password" "user_password" {
      ~ bcrypt_hash      = (sensitive value)
      ~ id               = "none" -&gt; (known after apply)
      ~ keepers          = { # forces replacement
          ~ "password_version" = "0" -&gt; "1"
        }
      ~ result           = (sensitive value)
        # (11 unchanged attributes hidden)
    }

Plan: 1 to add, 1 to change, 1 to destroy.
</code></pre>

<p>Let&rsquo;s go ahead by updating our password:</p>

<pre><code class="bash">terraform apply -var password_version=1 -auto-approve
</code></pre>

<p>To validate that the password has changed, we can try to logon to mysql by using the password variable that was created initially:</p>

<pre><code class="bash">docker exec -it mysql mysql -u ruanb -p$DBPASS
</code></pre>

<p>And as you can see authentication failed:</p>

<pre><code class="bash">mysql: [Warning] Using a password on the command line interface can be insecure.
ERROR 1045 (28000): Access denied for user 'ruanb'@'localhost' (using password: YES)
</code></pre>

<p>Set the new password to the variable again:</p>

<pre><code class="bash">DBPASS=$(terraform output -raw password)
</code></pre>

<p>Then try to logon again:</p>

<pre><code class="bash">docker exec -it mysql mysql -u ruanb -p$DBPASS
</code></pre>

<p>And we can see we are logged on again:</p>

<pre><code class="bash">Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 22
Server version: 8.0.33 MySQL Community Server - GPL

mysql&gt;
</code></pre>

<h2>Resources</h2>

<p>The terraform mysql provider:
- <a href="https://registry.terraform.io/providers/petoju/mysql/latest/docs">https://registry.terraform.io/providers/petoju/mysql/latest/docs</a></p>

<p>The quick-starts repository:
- <a href="https://github.com/ruanbekker/quick-starts">https://github.com/ruanbekker/quick-starts</a></p>

<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With FerretDB on Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/06/14/getting-started-with-ferretdb-on-docker/"/>
    <updated>2023-06-14T22:00:00-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/06/14/getting-started-with-ferretdb-on-docker</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/how-to-run-ferretdb-on-docker.png" alt="how-to-run-ferretdb-on-docker" /></p>

<p>In this post we will have a look at <strong>FerretDB</strong> which is a opensource proxy that translates MongoDB queries to SQL, where PostgreSQL being the database engine.</p>

<h2>More about FerretDB</h2>

<p>From <a href="https://www.ferretdb.io/">FerretDB</a> website, they describe FerretDB as:</p>

<blockquote><p>Initially built as open-source software, MongoDB was a game-changer for many developers, enabling them to build fast and robust applications. Its ease of use and extensive documentation made it a top choice for many developers looking for an open-source database. However, all this changed when they switched to an SSPL license, moving away from their open-source roots.</p>

<p>In light of this, FerretDB was founded to become the true open-source alternative to MongoDB, making it the go-to choice for most MongoDB users looking for an open-source alternative to MongoDB. With FerretDB, users can run the same MongoDB protocol queries without needing to learn a new language or command.</p></blockquote>

<h2>What can you expect from this tutorial</h2>

<p>We will be doing the following:</p>

<ul>
<li>deploying ferretdb and postgres on docker containers using docker compose</li>
<li>then use <code>mongosh</code> as a client to logon to ferretdb using the ferretdb endpoint</li>
<li>explore some example queries to insert and read data from ferretdb</li>
<li>use scripting to generate data into ferretedb</li>
<li>explore the embedded prometheus endpoint for metrics</li>
</ul>


<h2>Deploy FerretDB</h2>

<p>The following <code>docker-compose.yaml</code> defines a postgres container which will be used as the database engine for ferretdb, and then we define the ferretdb container, which connects to postgres via the environment variable <code>FERRETDB_POSTGRESQL_URL</code>.</p>

<pre><code class="yml">version: "3.9"

services:
  postgres:
    image: postgres:14.8-bullseye
    container_name: postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=ferret
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=ferretdb
    volumes:
      - pgvol:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready", "-d", "db_prod"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    networks:
      - ferretdb
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  ferretdb:
    image: ghcr.io/ferretdb/ferretdb:1.1.0
    container_name: ferretdb
    restart: unless-stopped
    ports:
      - 27017:27017
      - 8080:8080
    environment:
      - FERRETDB_POSTGRESQL_URL=postgres://postgres:5432/ferretdb
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ferretdb
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

networks:
  ferretdb:
    name: ferretdb

volumes:
  pgvol: 
</code></pre>

<p>Once you have the content above saved in <code>docker-compose.yaml</code> you can run the following to run the containers in a detached mode:</p>

<pre><code class="bash">docker-compose up -d
</code></pre>

<h2>Connect to FerretDB</h2>

<p>Once the containers started, we can connect to our ferretdb server using mongosh, which is a shell utility to connect to the database). I will make use of a container to do this, where I will reference the network which we defined in our docker compose file, and set the endpoint that mongosh need to connect to:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb --entrypoint=mongosh mongo:6.0 "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN"
</code></pre>

<p>Once it successfully connects to ferretdb, we should see the following prompt:</p>

<pre><code class="bash">Current Mongosh Log ID: 64626c5c259916d1a68b7dad
Connecting to:      mongodb://&lt;credentials&gt;@ferretdb/ferretdb?authMechanism=PLAIN&amp;directConnection=true&amp;appName=mongosh+1.8.2
Using MongoDB:      6.0.42
Using Mongosh:      1.8.2

ferretdb&gt;
</code></pre>

<h2>Run example queries on FerretDB</h2>

<p>If you are familiar with MongoDB, you will find the following identical to MongoDB.</p>

<p>First we show the current databases:</p>

<pre><code class="bash">ferretdb&gt; show dbs;
public  0 B
</code></pre>

<p>The we create and use the database named <code>mydb</code>:</p>

<pre><code class="bash">ferretdb&gt; use mydb
switched to db mydb
</code></pre>

<p>To see which database are we currently connected to:</p>

<pre><code class="bash">mydb&gt; db
mydb
</code></pre>

<p>Now we can create a collection named <code>mycol1</code> and <code>mycol2</code>:</p>

<pre><code class="bash">mydb&gt; db.createCollection("mycol1")
{ ok: 1 }
mydb&gt; db.createCollection("mycol2")
{ ok: 1 }
</code></pre>

<p>We can view our collections by running the following:</p>

<pre><code class="bash">mydb&gt; show collections
mycol1
mycol2
</code></pre>

<p>To write one document into our collection named <code>col1</code> with the following data:</p>

<pre><code class="json">{
  "name": "ruan",
  "age": 32,
  "hobbies": [
    "golf",
    "programming",
    "music"
  ]
}
</code></pre>

<p>We can execute:</p>

<pre><code class="bash">mydb&gt; db.mycol1.insertOne({"name": "ruan", "age": 32, "hobbies": ["golf", "programming", "music"]})
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("64626cea259916d1a68b7dae") }
}
</code></pre>

<p>And we can insert another document:</p>

<pre><code class="bash">mydb&gt; db.mycol1.insertOne({"name": "michelle", "age": 28, "hobbies": ["art", "music", "reading"]})
{
  acknowledged: true,
  insertedIds: { '0': ObjectId("64626cf1259916d1a68b7daf") }
}
</code></pre>

<p>We can then use <code>countDocuments()</code> to view the number of documents in our collection named <code>mycol1</code>:</p>

<pre><code class="bash">ferretdb&gt; db.mycol1.countDocuments()
2
</code></pre>

<p>If we want to find all our documents in our <code>mycol1</code> collection:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find()
[
  {
    _id: ObjectId("64626cea259916d1a68b7dae"),
    name: 'ruan',
    age: 32,
    hobbies: [ 'golf', 'programming', 'music' ]
  },
  {
    _id: ObjectId("64626cf1259916d1a68b7daf"),
    name: 'michelle',
    age: 28,
    hobbies: [ 'art', 'music', 'reading' ]
  }
]
</code></pre>

<p>If we want to only display specific fields in our response, such as name and age, we can project fields to return from our query:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({}, {"name": 1, "age": 1})
[
  { _id: ObjectId("64626cea259916d1a68b7dae"), name: 'ruan', age: 32 },
  {
    _id: ObjectId("64626cf1259916d1a68b7daf"),
    name: 'michelle',
    age: 28
  }
]
</code></pre>

<p>We can also suppress the <code>_id</code> field by setting the value to <code>0</code>:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({}, {"_id": 0, "name": 1, "age": 1})
[
  { name: 'ruan', age: 32 },
  { name: 'michelle', age: 28 }
]
</code></pre>

<p>Next we can return all the fields name and age from our collection where the age field is equals to 32:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({"age": 32}, {"_id": 0, "name": 1, "age": 1})
[ { name: 'ruan', age: 32 } ]
</code></pre>

<p>We can also find a specific document by its id as example, and return only the field value, like name:</p>

<pre><code class="bash">mydb&gt; db.mycol1.findOne({_id: ObjectId("64626cea259916d1a68b7dae")}).name
ruan
</code></pre>

<p>Next we will find all documents where the age is greater than 30:</p>

<pre><code class="bash">mydb&gt; db.mycol1.find({"age": {"$gt": 30}})
[
  {
    _id: ObjectId("64626cea259916d1a68b7dae"),
    name: 'ruan',
    age: 32,
    hobbies: [ 'golf', 'programming', 'music' ]
  }
]
</code></pre>

<p>Let&rsquo;s explore how to insert many documents at once using <code>insertMany()</code>, first create a new collection:</p>

<pre><code class="bash">ferretdb&gt; db.createCollection("mycol2")
{ ok: 1 }
</code></pre>

<p>We can then define the docs variable, and assign a array with 2 json documents:</p>

<pre><code class="bash">ferretdb&gt; var docs = [{name: "peter", age: 34, hobbies: ["ski", "programming", "music"]}, {name: "sam", age: 39, hobbies: ["running", "camping", "music"]}]
</code></pre>

<p>Now we can insert our documents to ferretdb using <code>insertMany()</code>:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.insertMany(docs)
{
  acknowledged: true,
  insertedIds: {
    '0': ObjectId("6464ceb1413cee26e9bf709f"),
    '1': ObjectId("6464ceb1413cee26e9bf70a0")
  }
}
</code></pre>

<p>We can count the documents inside our collection using:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.countDocuments()
2
</code></pre>

<p>And we can search for all the documents inside the collection:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.find()
[
  {
    _id: ObjectId("6464ceb1413cee26e9bf709f"),
    name: 'peter',
    age: 34,
    hobbies: [ 'ski', 'programming', 'music' ]
  },
  {
    _id: ObjectId("6464ceb1413cee26e9bf70a0"),
    name: 'sam',
    age: 39,
    hobbies: [ 'running', 'camping', 'music' ]
  }
]
</code></pre>

<p>And searching for any data using the name <code>peter</code>:</p>

<pre><code class="bash">ferretdb&gt; db.mycol2.find({name: "peter"})
[
  {
    _id: ObjectId("6464ceb1413cee26e9bf709f"),
    name: 'peter',
    age: 34,
    hobbies: [ 'ski', 'programming', 'music' ]
  }
]
</code></pre>

<h2>Scripting</h2>

<p>We will create a script so that we can generate data that we want to write into FerretDB.</p>

<p>Create the following script, <code>write.js</code>:</p>

<pre><code>var txs = []
for (var x = 0; x &lt; 1000 ; x++) {
 var transaction_types = ["credit card", "cash", "account"];
 var store_names = ["edgards", "cna", "makro", "picknpay", "checkers"];
 var random_transaction_type = Math.floor(Math.random() * (2 - 0 + 1)) + 0;
 var random_store_name = Math.floor(Math.random() * (4 - 0 + 1)) + 0;
 var random_age = Math.floor(Math.random() * (80 - 18) + 18)
 txs.push({
   transaction: 'tx_' + x,
   transaction_price: Math.round(Math.random()*1000),
   transaction_type: transaction_types[random_transaction_type],
   store_name: store_names[random_store_name],
   age: random_age
   });
}
console.log("drop and recreate the collection")
db.mycollection1.drop()
db.createCollection("mycollection1")
console.log("insert documents into collection")
db.mycollection1.insertMany(txs)
</code></pre>

<p>The script will loop a 1000 times and create documents that will include fields of <code>transaction_types</code>, <code>store_names</code>, <code>random_transaction_type</code>, <code>random_store_name</code> and <code>random_age</code>.</p>

<p>Use docker, mount the file inside the container, point the database endpoint to ferretdb and load the file that we want to execute:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb -v $PWD/write.js:/src/write.js --entrypoint=mongosh mongo:6.0 "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN" --eval 'load("/src/write.js")'
</code></pre>

<p>Now when we run a mongosh client:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb -v $PWD/write.js:/src/write.js --entrypoint=mongosh mongo:6.0 "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN"
</code></pre>

<p>And we query for the <code>store_name: picknpay</code> and only show the <code>transaction_type</code> and <code>transaction</code> fields:</p>

<pre><code class="bash">ferretdb&gt; db.mycollection1.find({"store_name": "picknpay"}, {_id: 0, transaction_type: 1, transaction: 1})
[
  { transaction_type: 'credit card', transaction: 'tx_3' },
  { transaction_type: 'cash', transaction: 'tx_9' },
  { transaction_type: 'account', transaction: 'tx_10' },
  { transaction_type: 'credit card', transaction: 'tx_15' },
  { transaction_type: 'credit card', transaction: 'tx_19' },
  { transaction_type: 'cash', transaction: 'tx_21' },
  { transaction_type: 'cash', transaction: 'tx_28' },
  { transaction_type: 'account', transaction: 'tx_31' },
  { transaction_type: 'cash', transaction: 'tx_37' },
  { transaction_type: 'cash', transaction: 'tx_39' },
  { transaction_type: 'account', transaction: 'tx_40' },
  { transaction_type: 'cash', transaction: 'tx_51' },
  { transaction_type: 'account', transaction: 'tx_52' },
  { transaction_type: 'cash', transaction: 'tx_58' },
  { transaction_type: 'credit card', transaction: 'tx_62' },
  { transaction_type: 'credit card', transaction: 'tx_65' },
  { transaction_type: 'account', transaction: 'tx_69' },
  { transaction_type: 'account', transaction: 'tx_71' },
  { transaction_type: 'cash', transaction: 'tx_72' },
  { transaction_type: 'account', transaction: 'tx_74' }
]
</code></pre>

<p>We can also use the <code>--eval</code> flag with the mongosh container to run ad-hoc queries such as counting documents for a collection:</p>

<pre><code class="bash">docker run --rm -it --network=ferretdb \
  -v $PWD/write.js:/src/write.js:ro \
  --entrypoint=mongosh mongo:6.0 \
  "mongodb://ferret:password@ferretdb/ferretdb?authMechanism=PLAIN" --eval 'db.mycollection1.countDocuments()'
</code></pre>

<h2>Prometheus Metrics</h2>

<p>FerretDB provides prometheus metrics out of the box, and outputs prometheus metrics on the <code>:8080/debug/metrics</code> endpoint:</p>

<pre><code class="bash">curl http://localhost:8080/debug/metrics
</code></pre>

<p>Which will output metrics more or less like the following:</p>

<pre><code>ferretdb_client_accepts_total{error="0"} 98
ferretdb_client_connected 0
ferretdb_client_requests_total{command="aggregate",opcode="OP_MSG"} 5
ferretdb_client_requests_total{command="atlasVersion",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="buildInfo",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="buildinfo",opcode="OP_MSG"} 2
ferretdb_client_requests_total{command="count",opcode="OP_MSG"} 5
ferretdb_client_requests_total{command="create",opcode="OP_MSG"} 7
ferretdb_client_requests_total{command="drop",opcode="OP_MSG"} 3
ferretdb_client_requests_total{command="dropDatabase",opcode="OP_MSG"} 4
ferretdb_client_requests_total{command="find",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="getCmdLineOpts",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="getFreeMonitoringStatus",opcode="OP_MSG"} 20
ferretdb_client_requests_total{command="getLog",opcode="OP_MSG"} 20
ferretdb_client_requests_total{command="getParameter",opcode="OP_MSG"} 27
ferretdb_client_requests_total{command="hello",opcode="OP_MSG"} 20
ferretdb_client_requests_total{command="insert",opcode="OP_MSG"} 15
ferretdb_client_requests_total{command="ismaster",opcode="OP_MSG"} 238
ferretdb_client_requests_total{command="listCollections",opcode="OP_MSG"} 49
ferretdb_client_requests_total{command="listDatabases",opcode="OP_MSG"} 12
ferretdb_client_requests_total{command="ping",opcode="OP_MSG"} 40
ferretdb_client_requests_total{command="saslStart",opcode="OP_MSG"} 70
ferretdb_client_requests_total{command="setFreeMonitoring",opcode="OP_MSG"} 1
ferretdb_client_requests_total{command="unknown",opcode="OP_QUERY"} 96
ferretdb_client_responses_total{argument="unknown",command="aggregate",opcode="OP_MSG",result="ok"} 5
ferretdb_client_responses_total{argument="unknown",command="atlasVersion",opcode="OP_MSG",result="CommandNotFound"} 27
ferretdb_client_responses_total{argument="unknown",command="buildInfo",opcode="OP_MSG",result="ok"} 27
ferretdb_client_responses_total{argument="unknown",command="buildinfo",opcode="OP_MSG",result="ok"} 2
ferretdb_client_responses_total{argument="unknown",command="count",opcode="OP_MSG",result="ok"} 5
ferretdb_client_responses_total{argument="unknown",command="create",opcode="OP_MSG",result="ok"} 7
ferretdb_client_responses_total{argument="unknown",command="drop",opcode="OP_MSG",result="NamespaceNotFound"} 2
ferretdb_client_responses_total{argument="unknown",command="drop",opcode="OP_MSG",result="ok"} 1
ferretdb_client_responses_total{argument="unknown",command="dropDatabase",opcode="OP_MSG",result="ok"} 4
ferretdb_client_responses_total{argument="unknown",command="find",opcode="OP_MSG",result="ok"} 27
ferretdb_client_responses_total{argument="unknown",command="getCmdLineOpts",opcode="OP_MSG",result="ok"} 27
ferretdb_client_responses_total{argument="unknown",command="getFreeMonitoringStatus",opcode="OP_MSG",result="ok"} 20
ferretdb_client_responses_total{argument="unknown",command="getLog",opcode="OP_MSG",result="ok"} 20
ferretdb_client_responses_total{argument="unknown",command="getParameter",opcode="OP_MSG",result="Unset"} 27
ferretdb_client_responses_total{argument="unknown",command="hello",opcode="OP_MSG",result="ok"} 20
ferretdb_client_responses_total{argument="unknown",command="insert",opcode="OP_MSG",result="ok"} 15
ferretdb_client_responses_total{argument="unknown",command="ismaster",opcode="OP_MSG",result="ok"} 238
ferretdb_client_responses_total{argument="unknown",command="listCollections",opcode="OP_MSG",result="ok"} 49
ferretdb_client_responses_total{argument="unknown",command="listDatabases",opcode="OP_MSG",result="ok"} 12
ferretdb_client_responses_total{argument="unknown",command="ping",opcode="OP_MSG",result="ok"} 40
ferretdb_client_responses_total{argument="unknown",command="saslStart",opcode="OP_MSG",result="ok"} 70
ferretdb_client_responses_total{argument="unknown",command="setFreeMonitoring",opcode="OP_MSG",result="ok"} 1
ferretdb_client_responses_total{argument="unknown",command="unknown",opcode="OP_REPLY",result="ok"} 93
ferretdb_client_responses_total{argument="unknown",command="unknown",opcode="OP_REPLY",result="unhandled"} 3
ferretdb_up{branch="unknown",commit="3344cbb98bb744dd044bcf2d51fe9ab65db22f0b",debug="false",dirty="true",package="docker",telemetry="disabled",update_available="false",uuid="08174d33-05fd-45ed-adb9-d2e343e0af83",version="v1.1.0"} 1
process_cpu_seconds_total 16.98
process_max_fds 1.048576e+06
process_open_fds 13
process_resident_memory_bytes 2.5714688e+07
process_start_time_seconds 1.68425346762e+09
process_virtual_memory_bytes 7.52529408e+08
process_virtual_memory_max_bytes 1.8446744073709552e+19
promhttp_metric_handler_errors_total{cause="encoding"} 0
promhttp_metric_handler_errors_total{cause="gathering"} 0
promhttp_metric_handler_requests_in_flight 1
promhttp_metric_handler_requests_total{code="200"} 2
promhttp_metric_handler_requests_total{code="500"} 0
promhttp_metric_handler_requests_total{code="503"} 0
</code></pre>

<h2>Resources</h2>

<p>Please see the follwoing resources for FerretDB:</p>

<ul>
<li><a href="https://docs.ferretdb.io/">https://docs.ferretdb.io/</a></li>
<li><a href="https://github.com/ferretdb/FerretDB/pkgs/container/ferretdb">https://github.com/ferretdb/FerretDB/pkgs/container/ferretdb</a></li>
<li><a href="https://docs.ferretdb.io/quickstart-guide/docker/">https://docs.ferretdb.io/quickstart-guide/docker/</a></li>
<li><a href="https://github.com/ruanbekker/cheatsheets/tree/master/mongodb/shell">https://github.com/ruanbekker/cheatsheets/tree/master/mongodb/shell</a></li>
</ul>


<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running a Multi-Broker Kafka Cluster on Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/05/17/running-a-multi-broker-kafka-cluster-on-docker/"/>
    <updated>2023-05-17T10:50:57-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/05/17/running-a-multi-broker-kafka-cluster-on-docker</id>
    <content type="html"><![CDATA[<p>In this post we will run a <a href="https://kafka.apache.org/">Kakfa</a> cluster with 3 kafka brokers on docker compose and using a producer to send messages to our topics and a consumer that will receive the messages from the topics, which we will develop in python and explore the <a href="https://github.com/provectus/kafka-ui">kafka-ui</a>.</p>

<h2>What is Kafka?</h2>

<p>Kafka is a distributed event store and stream processing platform. Kafka is used to build real-time streaming data pipelines and real-time streaming applications.</p>

<p>This is a fantastic resource if you want to understand the components better in detail:
- <a href="https://www.upsolver.com/blog/apache-kafka-architecture-what-you-need-to-know">apache-kafka-architecture-what-you-need-to-know</a></p>

<p>But on a high level, the components of a typical Kafka setup:</p>

<ol>
<li>Zookeeper: Kafka relies on Zookeeper to do leadership election of Kafka Brokers and Topic Partitions.</li>
<li>Broker: Kafka server that receives messages from producers, assigns them to offsets and commit the messages to disk storage. A offset is used for data consistency in a event of failure, so that consumers know from where to consume from their last message.</li>
<li>Topic: A topic can be thought of categories to organize messages. Producers writes messages to topics, consumers reads from those topics.</li>
<li>Partitions: A topic is split into multiple partitions. This improves scalability through parallelism (not just one broker). Kafka also does replication</li>
</ol>


<p>For great in detail information about kafka and its components, I encourage you to visit the <a href="https://www.upsolver.com/blog/apache-kafka-architecture-what-you-need-to-know">mentioned post</a> from above.</p>

<h2>Launch Kafka</h2>

<p>This is the <code>docker-compose.yaml</code> that we will be using to run a kafka cluster with 3 broker containers, 1 zookeeper container, 1 producer, 1 consumer and a kafka-ui.</p>

<p>All the source code is available on my <a href="https://github.com/ruanbekker/quick-starts/tree/main/docker/kafka">quick-starts github repository</a> .</p>

<pre><code class="yaml">version: "3.9"

services:
  zookeeper:
    platform: linux/amd64
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION:-7.4.0}
    container_name: zookeeper
    restart: unless-stopped
    ports:
      - '32181:32181'
      - '2888:2888'
      - '3888:3888'
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
    healthcheck:
      test: echo stat | nc localhost 32181
      interval: 10s
      timeout: 10s
      retries: 3
    networks:
      - kafka
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

  kafka-ui: 
    container_name: kafka-ui 
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    depends_on:
      - broker-1
      - broker-2
      - broker-3
    environment:
      KAFKA_CLUSTERS_0_NAME: broker-1
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker-1:29091
      KAFKA_CLUSTERS_0_METRICS_PORT: 19101
      KAFKA_CLUSTERS_1_NAME: broker-2
      KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS: broker-2:29092
      KAFKA_CLUSTERS_1_METRICS_PORT: 19102
      KAFKA_CLUSTERS_2_NAME: broker-3
      KAFKA_CLUSTERS_2_BOOTSTRAPSERVERS: broker-3:29093
      KAFKA_CLUSTERS_2_METRICS_PORT: 19103
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - kafka
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

  broker-1:
    platform: linux/amd64
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.4.0}
    container_name: broker-1
    restart: unless-stopped
    ports:
      - '9091:9091'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-1:29091,EXTERNAL://localhost:9091
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_JMX_PORT: 19101
      KAFKA_JMX_HOSTNAME: localhost
    healthcheck:
      test: nc -vz localhost 9091
      interval: 10s
      timeout: 10s
      retries: 3
    networks:
      - kafka
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

  broker-2:
    platform: linux/amd64
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.4.0}
    container_name: broker-2
    restart: unless-stopped
    ports:
      - '9092:9092'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-2:29092,EXTERNAL://localhost:9092
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_JMX_PORT: 19102
      KAFKA_JMX_HOSTNAME: localhost
    healthcheck:
      test: nc -vz localhost 9092
      interval: 10s
      timeout: 10s
      retries: 3
    networks:
      - kafka
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

  broker-3:
    platform: linux/amd64
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-7.4.0}
    container_name: broker-3
    restart: unless-stopped
    ports:
      - '9093:9093'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker-3:29093,EXTERNAL://localhost:9093
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_JMX_PORT: 19103
      KAFKA_JMX_HOSTNAME: localhost
    healthcheck:
      test: nc -vz localhost 9093
      interval: 10s
      timeout: 10s
      retries: 3
    networks:
      - kafka
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

  producer:
    platform: linux/amd64
    container_name: producer
    image: ruanbekker/kafka-producer-consumer:2023-05-17
    # source: https://github.com/ruanbekker/quick-starts/tree/main/docker/kafka/python-client
    restart: always
    environment:
      - ACTION=producer
      - BOOTSTRAP_SERVERS=broker-1:29091,broker-2:29092,broker-3:29093
      - TOPIC=my-topic
      - PYTHONUNBUFFERED=1 # https://github.com/docker/compose/issues/4837#issuecomment-302765592
    networks:
      - kafka
    depends_on:
      - zookeeper
      - broker-1
      - broker-2
      - broker-3
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

  consumer:
    platform: linux/amd64
    container_name: consumer
    image: ruanbekker/kafka-producer-consumer:2023-05-17
    # source: https://github.com/ruanbekker/quick-starts/tree/main/docker/kafka/python-client
    restart: always
    environment:
      - ACTION=consumer
      - BOOTSTRAP_SERVERS=broker-1:29091,broker-2:29092,broker-3:29093
      - TOPIC=my-topic
      - CONSUMER_GROUP=cg-group-id
      - PYTHONUNBUFFERED=1 # https://github.com/docker/compose/issues/4837#issuecomment-302765592
    networks:
      - kafka
    depends_on:
      - zookeeper
      - broker-1
      - broker-2
      - broker-3
      - producer
    logging:
      driver: "json-file"
      options:
        max-size: "1m"

networks:
  kafka:
    name: kafka
</code></pre>

<p><strong>Note</strong>: This docker-compose yaml can be found in my <a href="https://github.com/ruanbekker/quick-starts/tree/main/docker/kafka">kafka quick-starts</a> repository.</p>

<p>In our compose file we defined our core stack:</p>

<ul>
<li>1 Zookeeper Container</li>
<li>3 Kafka Broker Containers</li>
<li>1 Kafka UI</li>
</ul>


<p>Then we have our clients:</p>

<ul>
<li>1 Producer that will send messages to our topics (source code: <a href="https://github.com/ruanbekker/quick-starts/blob/main/docker/kafka/python-client/produce.py">https://github.com/ruanbekker/quick-starts/blob/main/docker/kafka/python-client/produce.py</a> )</li>
<li>1 Consumer that will read the messages from our topics (source code: <a href="https://github.com/ruanbekker/quick-starts/blob/main/docker/kafka/python-client/consume.py">https://github.com/ruanbekker/quick-starts/blob/main/docker/kafka/python-client/consume.py</a> )</li>
</ul>


<p>We can boot the stack with:</p>

<pre><code class="bash">docker-compose up -d
</code></pre>

<p>You can verify that the brokers are passing their health checks with:</p>

<pre><code class="bash">docker-compose ps

NAME                IMAGE                                           COMMAND                  SERVICE             CREATED             STATUS                   PORTS
broker-1            confluentinc/cp-kafka:7.4.0                     "/etc/confluent/dock…"   broker-1            5 minutes ago       Up 4 minutes (healthy)   0.0.0.0:9091-&gt;9091/tcp, :::9091-&gt;9091/tcp, 9092/tcp
broker-2            confluentinc/cp-kafka:7.4.0                     "/etc/confluent/dock…"   broker-2            5 minutes ago       Up 4 minutes (healthy)   0.0.0.0:9092-&gt;9092/tcp, :::9092-&gt;9092/tcp
broker-3            confluentinc/cp-kafka:7.4.0                     "/etc/confluent/dock…"   broker-3            5 minutes ago       Up 4 minutes (healthy)   9092/tcp, 0.0.0.0:9093-&gt;9093/tcp, :::9093-&gt;9093/tcp
consumer            ruanbekker/kafka-producer-consumer:2023-05-17   "sh /src/run.sh $ACT…"   consumer            5 minutes ago       Up 4 minutes
kafka-ui            provectuslabs/kafka-ui:latest                   "/bin/sh -c 'java --…"   kafka-ui            5 minutes ago       Up 4 minutes             0.0.0.0:8080-&gt;8080/tcp, :::8080-&gt;8080/tcp
producer            ruanbekker/kafka-producer-consumer:2023-05-17   "sh /src/run.sh $ACT…"   producer            5 minutes ago       Up 4 minutes
zookeeper           confluentinc/cp-zookeeper:7.4.0                 "/etc/confluent/dock…"   zookeeper           5 minutes ago       Up 5 minutes (healthy)   0.0.0.0:2888-&gt;2888/tcp, :::2888-&gt;2888/tcp, 0.0.0.0:3888-&gt;3888/tcp, :::3888-&gt;3888/tcp, 2181/tcp, 0.0.0.0:32181-&gt;32181/tcp, :::32181-&gt;32181/tcp
</code></pre>

<h2>Producers and Consumers</h2>

<p>The producer generates random data and sends it to a topic, where the consumer will listen on the same topic and read messages from that topic.</p>

<p>To view the output of what the <code>producer</code> is doing, you can tail the logs:</p>

<pre><code class="bash">docker logs -f producer

setting up producer, checking if brokers are available
brokers not available yet
brokers are available and ready to produce messages
message sent to kafka with squence id of 1
message sent to kafka with squence id of 2
message sent to kafka with squence id of 3
</code></pre>

<p>And to view the output of what the <code>consumer</code> is doing, you can tail the logs:</p>

<pre><code class="bash">docker logs -f consumer

starting consumer, checks if brokers are availabe
brokers not availbe yet
brokers are available and ready to consume messages
{'sequence_id': 10, 'user_id': '20520', 'transaction_id': '4026fd10-2aca-4d2e-8bd2-8ef0201af2dd', 'product_id': '17974', 'address': '71741 Lopez Throughway | South John | BT', 'signup_at': '2023-05-11 06:54:52', 'platform_id': 'Tablet', 'message': 'transaction made by userid 119740995334901'}
{'sequence_id': 11, 'user_id': '78172', 'transaction_id': '4089cee1-0a58-4d9b-9489-97b6bc4b768f', 'product_id': '21477', 'address': '735 Jasmine Village Apt. 009 | South Deniseland | BN', 'signup_at': '2023-05-17 09:54:10', 'platform_id': 'Tablet', 'message': 'transaction made by userid 159204336307945'}
</code></pre>

<h2>Kafka UI</h2>

<p>The Kafka UI will be available on <a href="http://localhost:8080">http://localhost:8080</a></p>

<p>Where we can view lots of information, but in the below screenshot we can see our topics:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/5da40db5-a56a-4c7b-8f8c-929568e9eb81" alt="image" /></p>

<p>And when we look at the <code>my-topic</code>, we can see a overview dashboard of our topic information:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/f9feb32f-5828-41a5-91f5-9d614feb8e7c" alt="image" /></p>

<p>We can also look at the messages in our topic, and also search for messages:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/48f58970-d665-4bd5-8e76-5a770e885993" alt="image" /></p>

<p>And we can also look at the current consumers:</p>

<p><img src="https://github.com/ruanbekker/ruanbekker.github.io/assets/567298/68a25d64-9899-4073-ae02-76becc4c149a" alt="image" /></p>

<h2>Resources</h2>

<p>My Quick-Starts Github Repository:</p>

<ul>
<li><a href="https://github.com/ruanbekker/quick-starts">https://github.com/ruanbekker/quick-starts</a></li>
</ul>


<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Wiremock]]></title>
    <link href="https://blog.ruanbekker.com/blog/2023/01/14/getting-started-with-wiremock/"/>
    <updated>2023-01-14T17:03:12-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2023/01/14/getting-started-with-wiremock</id>
    <content type="html"><![CDATA[<p>In this tutorial we will use docker to run an instance of wiremock to setup a mock api for us to test our api&rsquo;s.</p>

<h2>Wiremock</h2>

<p><a href="https://wiremock.org/">Wiremock</a> is a tool for building mock API&rsquo;s which enables us to build stable development environments.</p>

<h2>Docker and Wiremock</h2>

<p>Run a wiremock instance with docker:</p>

<pre><code class="bash">docker run -it --rm -p 8080:8080 --name wiremock wiremock/wiremock:2.34.0
</code></pre>

<p>Then our wiremock instance will be exposed on port 8080 locally, which we can use to make a request against to create a api mapping:</p>

<pre><code class="bash">curl -XPOST -H "Content-Type: application/json" \
  http://localhost:8080/__admin/mappings
  -d '{"request": {"url": "/testapi","method": "GET"}, "response": {"status": 200, "body": "{\"result\": \"ok\"
}", "headers": {"Content-Type": "application/json"}}}'
</code></pre>

<p>The response should be something like this:</p>

<pre><code class="json">{
    "id" : "223a2c0a-8b43-42dc-8ba6-fe973da1e420",
    "request" : {
      "url" : "/testapi",
      "method" : "GET"
    },
    "response" : {
      "status" : 200,
      "body" : "{\"result\": \"ok\"}",
      "headers" : {
        "Content-Type" : "application/json"
      }
    },
    "uuid" : "223a2c0a-8b43-42dc-8ba6-fe973da1e420"
}
</code></pre>

<h2>Test Wiremock</h2>

<p>If we make a GET request against our API:</p>

<pre><code class="bash">curl http://localhost:8080/testapi
</code></pre>

<p>Our response should be:</p>

<pre><code class="json">{
  "result": "ok"
}
</code></pre>

<h2>Export Wiremock Mappings</h2>

<p>We can export our mappings to a local file named <code>stubs.json</code> with:</p>

<pre><code class="bash">curl -s http://localhost:8080/__admin/mappings --output stubs.json
</code></pre>

<h2>Import Wiremock Mappings</h2>

<p>We can import our mappings from our <code>stubs.json</code> file with:</p>

<pre><code class="bash">curl -XPOST -v --data-binary @stubs.json http://localhost:8080/__admin/mappings/import
</code></pre>

<h2>Resources</h2>

<ul>
<li><a href="https://wiremock.org/docs/docker/">https://wiremock.org/docs/docker/</a></li>
<li><a href="https://github.com/WireMock-Net/WireMock.Net/wiki/Admin-API-Reference">https://github.com/WireMock-Net/WireMock.Net/wiki/Admin-API-Reference</a></li>
</ul>


<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logging With Docker Promtail and Grafana Loki]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/11/18/logging-with-docker-promtail-and-grafana-loki/"/>
    <updated>2022-11-18T00:42:49-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/11/18/logging-with-docker-promtail-and-grafana-loki</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/202631247-4ee94f01-b34a-471f-b428-6aba80b31e8c.png" alt="grafana-loki-promtail" /></p>

<p>In this post we will use Grafana Promtail to collect all our logs and ship it to Grafana Loki.</p>

<h2>About</h2>

<p>We will be using Docker Compose and mount the docker socket to Grafana Promtail so that it is aware of all the docker events and configure it that only containers with docker labels <code>logging=promtail</code> needs to be enabled for logging, which will then scrape those logs and send it to Grafana Loki where we will visualize it in Grafana.</p>

<h2>Promtail</h2>

<p>In our promtail configuration <code>config/promtail.yaml</code>:</p>

<pre><code class="yaml"># https://grafana.com/docs/loki/latest/clients/promtail/configuration/
# https://docs.docker.com/engine/api/v1.41/#operation/ContainerList
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: flog_scrape 
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ["logging=promtail"] 
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      - source_labels: ['__meta_docker_container_log_stream']
        target_label: 'logstream'
      - source_labels: ['__meta_docker_container_label_logging_jobname']
        target_label: 'job'
</code></pre>

<p>You can see we are using the <code>docker_sd_configs</code> provider and filter only docker containers with the docker labels <code>logging=promtail</code> and once we have those logs we relabel our labels to have the container name and we also use docker labels like <code>log_stream</code> and <code>logging_jobname</code> to add labels to our logs.</p>

<h2>Grafana Config</h2>

<p>We would like to auto configure our datasources for Grafana and in <code>config/grafana-datasources.yml</code> we have:</p>

<pre><code class="yaml">apiVersion: 1

datasources:
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    version: 1
    editable: false
    isDefault: true
</code></pre>

<h2>Docker Compose</h2>

<p>Then lastly we have our <code>docker-compose.yml</code> that wire up all our containers:</p>

<pre><code class="yaml">version: '3.8'

services:
  nginx-app:
    container_name: nginx-app
    image: nginx
    labels:
      logging: "promtail"
      logging_jobname: "containerlogs"
    ports:
      - 8080:80
    networks:
      - app

  grafana:
    image: grafana/grafana:latest
    ports:
      - 3000:3000
    volumes:
      - ./config/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yaml
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    networks:
      - app

  loki:
    image: grafana/loki:latest
    ports:
      - 3100:3100
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - app

  promtail:
    image:  grafana/promtail:latest
    container_name: promtail
    volumes:
      - ./config/promtail.yaml:/etc/promtail/docker-config.yaml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/docker-config.yaml
    depends_on:
      - loki
    networks:
      - app

networks:
  app:
    name: app
</code></pre>

<p>As you can see with our nginx container we define our labels:</p>

<pre><code class="yaml">  nginx-app:
    container_name: nginx-app
    image: nginx
    labels:
      logging: "promtail"
      logging_jobname: "containerlogs"
</code></pre>

<p>Which uses <code>logging: "promtail"</code> to let promtail know this log container&rsquo;s log to be scraped and <code>logging_jobname: "containerlogs"</code> which will assign containerlogs to the job label.</p>

<h2>Start the stack</h2>

<p>If you are following along all this configuration is available in my github repository <a href="https://github.com/ruanbekker/docker-promtail-loki">https://github.com/ruanbekker/docker-promtail-loki</a> .</p>

<p>Once you have everything in place you can start it with:</p>

<pre><code class="bash">docker-compose up -d
</code></pre>

<p>Access nginx on <a href="http://localhost:8080">http://localhost:8080</a></p>

<p><img width="1113" alt="image" src="https://user-images.githubusercontent.com/567298/202505252-3cbc2d03-d1d2-48e6-bea7-5db54233b9a2.png"></p>

<p>Then navigate to grafana on <a href="http://localhost:3000">http://localhost:3000</a> and select explore on the left and select the container:</p>

<p><img width="560" alt="image" src="https://user-images.githubusercontent.com/567298/202504989-e05a08a2-eb2f-41a1-85f4-9a11a8affd7c.png"></p>

<p>And you will see the logs:</p>

<p><img width="1425" alt="image" src="https://user-images.githubusercontent.com/567298/202505099-c47b76cc-3090-4eb9-8459-db659d0aac18.png"></p>

<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>

<ul>
<li>Linktree: <a href="https://go.ruan.dev/links">https://go.ruan.dev/links</a></li>
<li>Patreon: <a href="https://go.ruan.dev/patreon">https://go.ruan.dev/patreon</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
