<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2020-06-13T19:29:27+02:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Increase Performance With Your Ghost Blog on Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/06/08/build-a-ghost-blog-with-nginx-cache-on-docker/"/>
    <updated>2020-06-08T23:28:07+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/06/08/build-a-ghost-blog-with-nginx-cache-on-docker</id>
    <content type="html"><![CDATA[<p><img src="https://img.sysadmins.co.za/wngib2.png" alt="nginx-blog-ghost-caching" /></p>

<p>Nginx Caching + Ghost == Great Performance.</p>

<p>In this post we will build a nginx reverse proxy with caching enabled for our static content such as images, which will be our frontend and therefore we will have port 80 exposed, and run our ghost blog as our backend, which we will proxy traffic through from our nginx container.</p>

<h2>But why would you want caching?</h2>

<p>Returning data from memory is a lot faster than returning data from disk, and in this case where a request is being made against nginx, then it proxy passes the request to ghost, gets the data that you requested and returns the data to the client.</p>

<p>So for items that rarely changes like images, we can benefit from caching, so the images can be returned from the nginx service, where the first request will be made to ghost and then it will be loaded into nginx cache, so then the next time when you request the same image it will be returned from cache instead of making that same request to ghost again.</p>

<h2>Caching Info</h2>

<p>For this demonstration once we define the size of our chache which will be 500MB and we specify that if an object has not been accessed for 24 hours, we can expire the object from the cache.</p>

<h2>Nginx</h2>

<p>We will build our nginx container by adding our custom nginx config to our dockerfile.</p>

<p>Our <code>Dockerfile</code> will look like the following:</p>

<pre><code>ROM nginx:stable
ADD nginx.conf /etc/nginx/nginx.conf
</code></pre>

<p>Our <code>nginx.conf</code> configuration file:</p>

<pre><code>events {
  worker_connections  1024;
}

http {
  default_type       text/html;
  access_log         /dev/stdout;
  sendfile           on;
  keepalive_timeout  65;

  #proxy_cache_path /tmp/ghostcache levels=1:2 keys_zone=ghostcache:500m max_size=2g inactive=30d;
  proxy_cache_path /tmp/ghostcache levels=1:2 keys_zone=ghostcache:60m max_size=500m inactive=24h;
  proxy_cache_key "$scheme$request_method$host$request_uri";
  proxy_cache_methods GET HEAD;

  server {
    listen 80;

    location / {
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $http_host;
        proxy_pass http://ghost:2368;
    }

    location ~* \.(?:css|js|ico)$ {
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $http_host;
        proxy_pass http://ghost:2368;
        access_log off;
    }

    location ^~ /content/images/ {
        proxy_cache ghostcache;
        proxy_cache_valid 60m;
        proxy_cache_valid 404 1m;
        proxy_ignore_headers Set-Cookie;
        proxy_hide_header Set-Cookie;
        proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;
        proxy_ignore_headers Cache-Control;
        add_header X-Cache-Status $upstream_cache_status;

        proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_pass http://ghost:2368;
        access_log off;
    }
  }
}
</code></pre>

<p>Then our <code>docker-compose.yml</code> where we will add our nginx and ghost container to run together:</p>

<pre><code>version: '3.4'

services:
  ghost:
    image: ghost:3.15.1
    container_name: 'ghost'
    environment:
      - NODE_ENV=production
      - url=http://localhost:80
    networks:
      - ghost
    volumes:
      - ghost_content:/var/lib/ghost/content/data

  proxy:
    build: .
    container_name: 'proxy'
    depends_on:
      - ghost
    ports:
      - 80:80
    networks:
      - ghost

networks:
  ghost: {}

volumes:
  ghost_content: {}
</code></pre>

<p>To boot our stack:</p>

<pre><code>$ docker-compose up
</code></pre>

<h2>Test Caching</h2>

<p>Once your containers are in a running state, open your browsers devloper tools and look at the networking tab, then access your ghost blog on <code>http://localhost:80/</code>, the first time a image is opened you should see the cache shows <code>MISS</code> when you refresh again you should see a <code>HIT</code>, which means that the object is being returned from your cache.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting the Correct Service Name in Datadog Logging for Docker Swarm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/12/11/setting-the-correct-service-name-in-datadog-logging-for-docker-swarm/"/>
    <updated>2019-12-11T23:35:53+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/12/11/setting-the-correct-service-name-in-datadog-logging-for-docker-swarm</id>
    <content type="html"><![CDATA[<p>For some reason, when logging to datadog from your applications running on docker swarm, the service names in datadog appears to have the names on the docker image. The application talks to the datadog agent which runs in global mode on swarm.</p>

<p>Setting <code>DATADOG_SERVICE_NAME</code> or <code>DD_SERVICE_NAME</code> as environment variables on the swarm service has zero affect, as they keep showing the service name as the docker image name, as example:</p>

<p><img width="1268" alt="08496333-01C4-4492-807E-FAC40826AFDE" src="https://user-images.githubusercontent.com/567298/70661591-49007080-1c6d-11ea-8230-0dbe086bd168.png"></p>

<p>If we inspect the tags, we can see that the docker image shows as the source and maps through as the docker service name. As you can see the swarm service name is what we want to be the service name (not alpine):</p>

<p><img width="1269" alt="783C6D52-62B2-4F2B-A6D4-28150CC58005" src="https://user-images.githubusercontent.com/567298/70661651-65041200-1c6d-11ea-858b-90034099c319.png"></p>

<p>One way how to fix this is to setup a pipeline processor, head over to Logs -> Configuration:</p>

<p><img width="267" alt="93CEE277-55A6-4DE1-8AE6-A02C64B0ACAD" src="https://user-images.githubusercontent.com/567298/70661767-adbbcb00-1c6d-11ea-8274-ad5da6ddfdd7.png"></p>

<p>Select &ldquo;Pipelines&rdquo; and add a new pipeline, select the filter <code>source:alpine</code> to limit down the results to the alpine image, and name your processor:</p>

<p><img width="763" alt="0BF3D6A6-9646-442D-A494-8DF489C5217F" src="https://user-images.githubusercontent.com/567298/70661837-cdeb8a00-1c6d-11ea-8fb4-2c272fda596f.png"></p>

<p>Next add a new processor and set the type to remapper, select the tag group as &ldquo;swarm_service&rdquo; and set the attribute to service and name the processor:</p>

<p><img width="762" alt="C02092F4-0EEC-4AF9-9E2A-F7A126560CD8" src="https://user-images.githubusercontent.com/567298/70662081-3a668900-1c6e-11ea-9ea9-9f80dfc669f3.png"></p>

<p>Add a new processor:</p>

<p><img width="1151" alt="5C2F7FB9-8948-4588-A283-86E94BC07513" src="https://user-images.githubusercontent.com/567298/70661901-e6f43b00-1c6d-11ea-9dbc-8c4c3a24b51b.png"></p>

<p>Select a service remapper, set the attribute to service and name the processor:</p>

<p><img width="761" alt="852904AE-9395-4B4B-B1F4-54427D88C970" src="https://user-images.githubusercontent.com/567298/70661986-0ab78100-1c6e-11ea-9edc-5fd748d73d0c.png"></p>

<p>Now when you go back to logs, you will find that the service name is being set to the correct service name in datadog:</p>

<p><img width="1159" alt="0F11DDC4-E99C-4A2F-B6AB-7409B4E7546C" src="https://user-images.githubusercontent.com/567298/70662290-95987b80-1c6e-11ea-8d8c-bec4d44cde60.png"></p>

<p>When you inspect one of the logs, you will see that the attribute is being set to the log:</p>

<p><img width="633" alt="4B098970-6345-40B9-9F90-411D8FE6A9E6" src="https://user-images.githubusercontent.com/567298/70662330-a9dc7880-1c6e-11ea-8b48-51900161cf01.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Deploy a Webapp on a AWS EKS Kubernetes Cluster]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster/"/>
    <updated>2019-11-17T00:21:19+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/11/17/how-to-deploy-a-webapp-on-a-aws-eks-kubernetes-cluster</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/68999897-f59a3d00-08cf-11ea-83c7-8624e6048106.png" alt="kubernetes-eks-deploy-webapp" /></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <a href="https://github.com/ruanbekker"><img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /></a></p>

<p><a href="https://twitter.com/ruanbekker?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @ruanbekker</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>In our previous post, <a href="https://blog.ruanbekker.com/blog/2019/11/16/how-to-setup-a-aws-eks-kubernetes-cluster/">Part 1 - Setup a EKS Cluster</a> we went through the steps on how to Setup a EKS Cluster.</p>

<h2>What are we doing today</h2>

<p>In this post, we will deploy a sample web application to EKS and access our application using a ELB that EKS provides us.</p>

<h2>Deployment Manifests</h2>

<p>We will have two manifests that we will deploy to Kubernetes, a deployment manifest that will hold the information about our application and a service manifest that will hold the information about the service load balancer.</p>

<p>The deployment manifest, you will notice that we are specifying that we want 3 containers, we are using labels so that our service and deployment can find each other and we are using a basic http web application that will listen on port 8000 inside the container:</p>

<pre><code class="bash">$ cat deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-hostname-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: ruanbekker/hostname
          ports:
          - name: http
            containerPort: 8000
</code></pre>

<p>The service manifest, you will notice that we are specifying <code>type: LoadBalancer</code> in our service manifest, this will tell EKS to provision a ELB for your application so that we can access our application from the internet.</p>

<p>You will see that the selector is specifying <code>my-app</code> which we also provided in our deployment.yml so that our service know where to find our backend application. We are also stating that the service is listening on port 80, and will forward its traffic to our deployment on port 8000:</p>

<pre><code class="bash">$ cat service.yml
apiVersion: v1
kind: Service
metadata:
  name: my-hostname-app-service
  labels:
    app: my-app
spec:
  ports:
  - port: 80
    targetPort: 8000
  selector:
    app: my-app
  type: LoadBalancer
</code></pre>

<h2>Deployment Time</h2>

<p>Deploy our application:</p>

<pre><code class="bash">$ kubectl apply -f deployment.yml
deployment.apps/my-hostname-app created
</code></pre>

<p>Deploy our service:</p>

<pre><code class="bash">$ kubectl apply -f service.yml
service/my-hostname-app-service created
</code></pre>

<p>Now when we look at our deployment, we should see that 3 replicas of our application is running:</p>

<pre><code class="bash">$ kubectl get deployments
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
my-hostname-app   3/3     3            3           4m38s
</code></pre>

<p>To see the pods of that deployment, look at the pods:</p>

<pre><code class="bash">$ kubectl get pods
NAME                               READY   STATUS    RESTARTS   AGE
my-hostname-app-5dcd48dfc5-2j8zm   1/1     Running   0          24s
my-hostname-app-5dcd48dfc5-58vkc   1/1     Running   0          24s
my-hostname-app-5dcd48dfc5-cmjwj   1/1     Running   0          24s
</code></pre>

<p>As we have more than one service in our EKS cluster, we can specify the labels that we have applied on our manifests to filter what we want to see (<code>app: my-app</code>):</p>

<pre><code class="bash">$ kubectl get service --selector app=my-app
NAME                      TYPE           CLUSTER-IP       EXTERNAL-IP                                                              PORT(S)        AGE
my-hostname-app-service   LoadBalancer   10.100.114.166   a460661ce089b11ea97cd06dd7513db6-669054126.eu-west-1.elb.amazonaws.com   80:30648/TCP   2m29s
</code></pre>

<p>As we can see EKS provisioned a ELB for us, and we can access the application by making a HTTP request:</p>

<pre><code class="bash">$ curl -i http://a460661ce089b11ea97cd06dd7513db6-669054126.eu-west-1.elb.amazonaws.com
HTTP/1.1 200 OK
Date: Sat, 16 Nov 2019 18:05:27 GMT
Content-Length: 43
Content-Type: text/plain; charset=utf-8

Hostname: my-hostname-app-5dcd48dfc5-2j8zm
</code></pre>

<h2>Scaling our Deployment</h2>

<p>Let&rsquo;s scale our deployment to 5 replicas:</p>

<pre><code class="bash">$ kubectl scale deployment/my-hostname-app --replicas 5
deployment.extensions/my-hostname-app scaled
</code></pre>

<p>After all the pods has been deployed, you should be able to see the 5 out of 5 pods that we provisioned, should be running:</p>

<pre><code class="bash">$ kubectl get deployments
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
my-hostname-app   5/5     5            5           5m7s
</code></pre>

<p>We can then also see the pods that our deployment is referencing:</p>

<pre><code class="bash">$ kubectl get pods
NAME                               READY   STATUS    RESTARTS   AGE
my-hostname-app-5dcd48dfc5-2j8zm   1/1     Running   0          6m8s
my-hostname-app-5dcd48dfc5-58vkc   1/1     Running   0          6m8s
my-hostname-app-5dcd48dfc5-cmjwj   1/1     Running   0          6m8s
my-hostname-app-5dcd48dfc5-m4xcq   1/1     Running   0          67s
my-hostname-app-5dcd48dfc5-zf6xl   1/1     Running   0          68s
</code></pre>

<h2>Further Reading on Kubernetes</h2>

<p>This is one amazing resource that covers a lot of kubernetes topics and will help you throughout your EKS journey:</p>

<ul>
<li><a href="https://eksworkshop.com/introduction/">EKSWorkshop</a></li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/worker.html">Worker Nodes Documentation</a></li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/eks-guestbook.html">Guestbook Kubernetes Sample Application</a></li>
</ul>


<h2>Thank You</h2>

<p>Let me know what you think. If you liked my content, feel free to checkout my content on <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<center><script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script></center>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing AWS Lambda Functions Locally on Docker With LambCi]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/11/14/testing-aws-lambda-functions-locally-on-docker-with-lambci/"/>
    <updated>2019-11-14T23:57:10+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/11/14/testing-aws-lambda-functions-locally-on-docker-with-lambci</id>
    <content type="html"><![CDATA[<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <a href="https://github.com/ruanbekker"><img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /></a></p>

<p><a href="https://twitter.com/ruanbekker?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @ruanbekker</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>I discovered a Docker image called <strong>LambCi</strong> that allows you to test lambda functions locally on docker and wanted to share with you how it works.</p>

<h2>Python Lambda Function</h2>

<p>We will create a basic lambda function to demonstrate how it works.</p>

<pre><code>$ mkdir task
$ cat &gt; task/lambda_function.py &lt;&lt; EOF
import json

def lambda_handler(event, context):
    if event:

        try:
            event['name']
            name = event['name']
            output_string = 'My name is {}'.format(name.capitalize())

        except KeyError:
            output_string = 'A name was not defined in the event payload'

    return output_string
EOF
</code></pre>

<p>Now that we&rsquo;ve created the function, run the docker container with the parameters of the functions handler method and the event parameters:</p>

<pre><code>$ docker run --rm -v "$PWD/task":/var/task lambci/lambda:python3.7 lambda_function.lambda_handler '{"name": "ruan"}'
START RequestId: 70025895-1233-1362-8006-c2784b5d80b6 Version: $LATEST
END RequestId: 70025895-1233-1362-8006-c2784b5d80b6
REPORT RequestId: 70025895-1233-1362-8006-c2784b5d80b6  Duration: 7.51 ms   Billed Duration: 100 ms Memory Size: 1536 MB    Max Memory Used: 23 MB
"My name is Ruan"
</code></pre>

<p>And another call:</p>

<pre><code>$ docker run --rm -v "$PWD/task":/var/task lambci/lambda:python3.7 lambda_function.lambda_handler '{"nam": "ruan"}'
START RequestId: f7ab2e97-05db-1184-a009-11b92638534f Version: $LATEST
END RequestId: f7ab2e97-05db-1184-a009-11b92638534f
REPORT RequestId: f7ab2e97-05db-1184-a009-11b92638534f  Duration: 5.32 ms   Billed Duration: 100 ms Memory Size: 1536 MB    Max Memory Used: 23 MB
"A name was not defined in the event payload"
</code></pre>

<p>Checkout the dockerhub page for more info:
- <a href="https://hub.docker.com/r/lambci/lambda/">https://hub.docker.com/r/lambci/lambda/</a></p>

<h2>Thank You</h2>

<p>Let me know what you think. If you liked my content, feel free to checkout my content on <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<center><script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script></center>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running vs Code in Your Browser With Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/09/14/running-vs-code-in-your-browser-with-docker/"/>
    <updated>2019-09-14T12:56:05+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/09/14/running-vs-code-in-your-browser-with-docker</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/64907374-cc9fd500-d6f1-11e9-87f0-3cae18f02c8d.png" alt="vscode" /></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <a href="https://github.com/bekkerstacks/traefik"><img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /></a></p>

<p><a href="https://twitter.com/ruanbekker?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @ruanbekker</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>

<p>Today we will setup a Visual Studio Code instance running on Docker, so that you can access VSCode via the web browser.</p>

<h2>VSCode in Docker</h2>

<p>The work directory will be under <code>code</code> and the application will store its data under <code>data</code>. Lets go ahead and create them:</p>

<pre><code>mkdir demo/{code,data}
cd demo
</code></pre>

<p>Run the vscode container:</p>

<pre><code>$ docker run --rm --name vscode \
  -it -p 8443:8443 -p 8888:8888 \
  -v $(pwd)/data:/data -v $(pwd)/code:/code \
ruanbekker/vscode:python-3.7
</code></pre>

<p>The password that you require on login will be prompted in the output:</p>

<pre><code>INFO  code-server v1.1156-vsc1.33.1
INFO  Additional documentation: http://github.com/cdr/code-server
INFO  Initializing {"data-dir":"/data","extensions-dir":"/data/extensions","working-dir":"/code","log-dir":"/root/.cache/code-server/logs/20190914105631217"}
INFO  Starting shared process [1/5]...
INFO  Starting webserver... {"host":"0.0.0.0","port":8443}
INFO
INFO  Password: 4b050c4fa0ef109d53c10d9f
INFO
INFO  Started (click the link below to open):
INFO  https://localhost:8443/
INFO  Connected to shared process
</code></pre>

<p>Access vscode on <code>https://localhost:8443/</code> and after you accepted the self-signed certificate warning, you will be presented with the login page:</p>

<p><img width="775" alt="image" src="https://user-images.githubusercontent.com/567298/64907196-89dcfd80-d6ef-11e9-82ac-09196c926f82.png"></p>

<p>After you have logged a example of creating a python file will look like this:</p>

<p><img width="898" alt="image" src="https://user-images.githubusercontent.com/567298/64907240-02dc5500-d6f0-11e9-8443-cc1778b0de86.png"></p>

<p>The source code for this docker image can be found at <a href="https://github.com/ruanbekker/dockerfiles/tree/master/vscode">https://github.com/ruanbekker/dockerfiles/tree/master/vscode</a> .</p>

<h2>Different versions</h2>

<p>Currently I have only <a href="https://hub.docker.com/r/ruanbekker/vscode/tags">python available on docker hub</a> with the requests and flask packages available. But you can fork the repository and add the upstream or packages of your choice.</p>
]]></content>
  </entry>
  
</feed>
