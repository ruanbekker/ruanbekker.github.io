<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-02-11T17:42:22-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Hive for Small Datasets on My Mac Using Docker]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/01/23/using-hive-for-small-datasets-on-my-mac-using-docker/"/>
    <updated>2018-01-23T10:06:16-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/01/23/using-hive-for-small-datasets-on-my-mac-using-docker</id>
    <content type="html"><![CDATA[<p>I wanted to process a small subset of data, and not wanting to spin up a cluster, so I used <code>nagasuga/docker-hive</code> docker image to run Hive on my Mac.</p>

<h2>Running Hive</h2>

<pre><code class="bash">$ docker run -it -v /home/me/resource-data.csv:/resource-data.csv nagasuga/docker-hive /bin/bash -c 'cd /usr/local/hive &amp;&amp; ./bin/hive'
hive&gt;
</code></pre>

<p>Once I was entered into my hive shell, I created a table for my CSV data:</p>

<h2>Creating the Table</h2>

<pre><code class="sql">hive&gt; create table resources (ResourceType STRING, Owner STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;

hive&gt; hive&gt; show tables;
OK
resources

hive&gt; describe resources;
OK
resourcetype            string
owner                   string
</code></pre>

<h2>Loading the Data</h2>

<p>My csv data is located at <code>/resource-data.csv</code> on the container, which I will load into my table:</p>

<pre><code class="sql">hive&gt; load data local inpath '/resource-data.csv' into table resources;
Loading data to table default.resources
</code></pre>

<h2>Query the Data</h2>

<p>Just two simple queries for demonstration:</p>

<pre><code class="sql">hive&gt; select * from resources limit 3;
OK
EC2  Engineering
EC2  Finance
EC2  Product

hive&gt; hive&gt; select count(resourcetype) as num, owner from resources group by owner order by num desc limit 3;
K
50   Engineering
20   Product
10   Finance
</code></pre>

<h2>Resource:</h2>

<p>Thanks to <a href="https://github.com/nagasuga/docker-hive">https://github.com/nagasuga/docker-hive</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create a Chatbot With Chatterbot on Python]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/13/create-a-chatbot-with-chatterbot-on-python/"/>
    <updated>2017-12-13T08:53:50-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/13/create-a-chatbot-with-chatterbot-on-python</id>
    <content type="html"><![CDATA[<p><img src="https://chatterbot.readthedocs.io/en/stable/_images/banner.png" alt="" /></p>

<p>So I&rsquo;ve been wanting to take a stab at chatbots for some time, and recently discovered <a href="https://github.com/gunthercox/ChatterBot">Chatterbot</a>, so in this tutorial I will go through some examples on setting up a very basic chatbot.</p>

<h2>Getting the Dependencies:</h2>

<p>I will be using Alpine on <a href="docker.com">Docker</a> to run all the the examples, I am using Alpine so that we have a basic container with nothing special pre-installed.</p>

<p>Chatterbot is written in Python, so let&rsquo;s install Python and Chatterbot:</p>

<pre><code class="bash">$ docker run -it --name chatbot alpine:edge sh
$ apk update &amp;&amp; apk add python py2-pip
$ pip install pip --upgrade --user
$ pip install chatterbot
</code></pre>

<h2>Setup the Basic Chatbot:</h2>

<p>Now that our dependencies is installed, enter the Python interpreter where we will instantiate our Chatbot, and get a response from our Chatbot. By default the library will create a sqlite database to build up statements that is passed to and from the bot.</p>

<p>At this point, the bot is still pretty useless:</p>

<pre><code class="bash">$ python
&gt;&gt;&gt; from chatterbot import ChatBot
&gt;&gt;&gt; chatbot = ChatBot('Ben')
&gt;&gt;&gt; chatbot.get_response('What is your name?')
&lt;Statement text:What is your name?&gt;
&gt;&gt;&gt; chatbot.get_response('My name is Ruan, what is your name?')
&lt;Statement text:What is your name?&gt;
</code></pre>

<h2>Training your Bot:</h2>

<p>To enable your bot to have some knowledge, we can train the bot with training data. The training data is populated in a list, which will represent the conversation.</p>

<p>Exit the python interpreter and delete the sqlite database:</p>

<pre><code class="bash">$ rm -rf db.sqlite3
</code></pre>

<p>Now our Bot wont have any history of what we said. Start the interpreter again and add some data to train our bot. In this example, we want our Chatbot to respond when we ask it, what his name is:</p>

<pre><code class="bash">&gt;&gt;&gt; from chatterbot import ChatBot
&gt;&gt;&gt; from chatterbot.trainers import ListTrainer
&gt;&gt;&gt; chatbot = ChatBot('Ben')
&gt;&gt;&gt; chatbot.set_trainer(ListTrainer)
&gt;&gt;&gt; chatbot.train(['What is your name?', 'My name is Ben'])
List Trainer: [####################] 100%
</code></pre>

<p>Now that we have trained our bot, let&rsquo;s try to chat to our bot:</p>

<pre><code class="bash">&gt;&gt;&gt; chatbot.get_response('What is your name?')
&lt;Statement text:My name is Ben&gt;
&gt;&gt;&gt; chatbot.get_response('Who is Ben?')
&lt;Statement text:My name is Ben&gt;
</code></pre>

<p>We can also enable our bot to respond on multiple statements:</p>

<pre><code class="bash">&gt;&gt;&gt; chatbot.train(['Do you know someone with the name of Sarah?', 'Yes, my sisters name is Sarah', 'Is your sisters name, Sarah?', 'Faw shizzle!'])
List Trainer: [####################] 100%

&gt;&gt;&gt; chatbot.get_response('do you know someone with the name of Sarah?')
&lt;Statement text:Yes, my sisters name is Sarah&gt;
&gt;&gt;&gt; chatbot.get_response('is your sisters name Sarah?')
&lt;Statement text:Faw shizzle!&gt;
</code></pre>

<p>With that said, we can define our list of statements in our code:</p>

<pre><code class="python">&gt;&gt;&gt; conversations = [
...     'Are you an athlete?', 'No, are you mad? I am a bot',
...     'Do you like big bang theory?', 'Bazinga!',
...     'What is my name?', 'Ruan',
...     'What color is the sky?', 'Blue, stop asking me stupid questions'
... ]

&gt;&gt;&gt; chatbot.train(conversations)
List Trainer: [####################] 100%
&gt;&gt;&gt; chatbot.get_response('What color is the sky?')
&lt;Statement text:Blue, stop asking me stupid questions&gt;
</code></pre>

<p>So we can see it works as expected, but let&rsquo;s state one of the answers from our statements, to see what happens:</p>

<pre><code class="bash">&gt;&gt;&gt; chatbot.get_response('Bazinga')
&lt;Statement text:What is my name?&gt;
&gt;&gt;&gt; chatbot.get_response('Your name is Ben')
&lt;Statement text:Yes, my name is Ben&gt;
</code></pre>

<p>So we can see it uses natural language processing to learn from the data that we provide our bot. Just to check another question:</p>

<pre><code class="bash">&gt;&gt;&gt; chatbot.get_response('Do you like big bang theory?')
&lt;Statement text:Bazinga!&gt;
</code></pre>

<p>If we have quite a large subset of learning data, we can add all the data in a file, seperated by new lines then we can use python to read the data from disk, and split up the data in the expected format.</p>

<p>The training file will reside in our working directory, let&rsquo;s name it <code>training-data.txt</code> and the content will look like this:</p>

<pre><code class="bash">What is Bitcoin?
Bitcoin is a Crypto Currency
Where is this blog hosted?
Github
</code></pre>

<p>A visual example of how we will process this data will look like this:</p>

<pre><code class="bash">&gt;&gt;&gt; data = open('training-data.txt').read()
&gt;&gt;&gt; data.strip().split('\n')
['What is Bitcoin?', 'Bitcoin is a Crypto Currency', 'Where is this blog hosted?', 'Github']
</code></pre>

<p>And in action, it will look like this:</p>

<pre><code class="bash">&gt;&gt;&gt; data = open('training-data.txt').read()
&gt;&gt;&gt; conversations = data.strip().split('\n')
&gt;&gt;&gt; chatbot.train(conversations)
List Trainer: [####################] 100%

&gt;&gt;&gt; chatbot.get_response('Where is this blog hosted?')
&lt;Statement text:Github&gt;
</code></pre>

<p>There is also pre-populated data that you can use to train your bot, on the <a href="https://chatterbot.readthedocs.io/en/stable/training.html#training-with-corpus-data">documentation</a> is a couple of examples, but for demonstration, we will use the CorpusTrainer:</p>

<pre><code class="bash">&gt;&gt;&gt; from chatterbot.trainers import ChatterBotCorpusTrainer
&gt;&gt;&gt; chatterbot.set_trainer(ChatterBotCorpusTrainer)
&gt;&gt;&gt; chatbot.train("chatterbot.corpus.english")
ai.yml Training: [####################] 100%
botprofile.yml Training: [####################] 100%
computers.yml Training: [####################] 100%
conversations.yml Training: [####################] 100%
emotion.yml Training: [####################] 100%
food.yml Training: [####################] 100%
gossip.yml Training: [####################] 100%
greetings.yml Training: [####################] 100%
history.yml Training: [####################] 100%
humor.yml Training: [####################] 100%
literature.yml Training: [####################] 100%
money.yml Training: [####################] 100%
movies.yml Training: [####################] 100%
politics.yml Training: [####################] 100%
psychology.yml Training: [####################] 100%
science.yml Training: [####################] 100%
sports.yml Training: [####################] 100%
trivia.yml Training: [####################] 100%

&gt;&gt;&gt; chatbot.get_response('Do you like peace?')
&lt;Statement text:not especially. i am not into violence.&gt;
&gt;&gt;&gt; chatbot.get_response('Are you emotional?')
&lt;Statement text:Sort of.&gt;
&gt;&gt;&gt; chatbot.get_response('What language do you speak?')
&lt;Statement text:Python.&gt;
&gt;&gt;&gt; chatbot.get_response('What is your name?')
&lt;Statement text:My name is Ben&gt;
&gt;&gt;&gt; chatbot.get_response('Who is the President of America?')
&lt;Statement text:Richard Nixon&gt; #data seems outdated :D
&gt;&gt;&gt; chatbot.get_response('I like cheese')
&lt;Statement text:What kind of movies do you like?&gt;
</code></pre>

<h2>Using an External Database like MongoDB</h2>

<p>Instead of using sqlite on the same host, we can use a NoSQL Database like MongoDB that resides outside our application.</p>

<p>For the sake of this tutorial, I will use Docker to spin up a MongoDB Container:</p>

<pre><code class="bash">$ docker run -d --name mongodb -p 27017:27017 -p 28017:28017 -e AUTH=no -e OPLOG_SIZE=50 tutum/mongodb
</code></pre>

<p>Below is my code of a terminal application that uses Chatterbot, MongoDB as a Storage Adapter, and we are using a while loop, so that we can chat with our bot, and in our except statement, we can stop our application by using our keyboard to exit:</p>

<pre><code class="python">from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer

chatbot = ChatBot(
    "Chatbot Backed by MongoDB",
    storage_adapter="chatterbot.storage.MongoDatabaseAdapter",
    database="chatterbot_db",
    database_uri="mongodb://172.17.0.3:27017/",
    logic_adapters=[
        'chatterbot.logic.BestMatch'
    ],
    trainer='chatterbot.trainers.ChatterBotCorpusTrainer',
    filters=[
        'chatterbot.filters.RepetitiveResponseFilter'
    ],
    input_adapter='chatterbot.input.TerminalAdapter',
    output_adapter='chatterbot.output.TerminalAdapter'
)

chatbot.set_trainer(ChatterBotCorpusTrainer)
chatbot.train("chatterbot.corpus.english")

print('Chatbot Started:')

while True:
    try:
        print(" -&gt; You:")
        botInput = chatbot.get_response(None)
    except (KeyboardInterrupt, EOFError, SystemExit):
        break
</code></pre>

<p>Running the example:</p>

<pre><code class="bash">$ python bot.py
 -&gt; You:
How are you?
I am doing well.
 -&gt; You:
Tell me a joke
A 3-legged dog walks into an old west saloon, slides up to the bar and announces "I'm looking for the man who shot my paw."
</code></pre>

<p>And from mongodb, we can see some data:</p>

<pre><code class="bash">$ mongo
&gt; show dbs
admin          0.078GB
chatterbot_db  0.078GB
local          0.078GB

&gt; use chatterbot_db
switched to db chatterbot_db

&gt; show collections;
conversations
statements
system.indexes

&gt; db.conversations.find().count()
4
&gt; db.statements.find().count()
1240
&gt; db.system.indexes.find().count()
3
</code></pre>

<p>That was a basic tutorial on Chatterbot, next I will be looking into mining data from Twitter&rsquo;s API and see how clever our bot can become.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://chatterbot.readthedocs.io/en/stable/quickstart.html#quick-start-guide">Chatterbot Documentation</a></li>
<li><a href="https://github.com/gunthercox/ChatterBot/tree/master/examples">Chatterbot Examples</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use Docker Secrets With MySQL on Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/23/use-docker-secrets-with-mysql-on-docker-swarm/"/>
    <updated>2017-11-23T16:55:15-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/23/use-docker-secrets-with-mysql-on-docker-swarm</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/docker-logo.png" alt="" /></p>

<p>Today we will use Docker Secrets, more specifically store our MySQL Passwords in Secrets, which will be passed to our containers, so that we don&rsquo;t use clear text passwords in our Compose files.</p>

<h2>What is Docker Secrets:</h2>

<p>In Docker, Docker Secrets are encrypted during transit and at rest in a Docker Swarm Cluster. The great thing about Docker Secrets is that you can manage these secrets from a central place, and the fact that it encrypts the data and transfers the data securely to the containers that needs the secrets. So you authorize which containers needs access to these secrets.</p>

<p>So instead of setting the MySQL Root Passwords in clear text, you will create the secrets, then in your docker-compose file, you will reference the secret name.</p>

<h2>Deploy MySQL with Docker Secrets</h2>

<p>We will deploy a Stack that contains MySQL and Adminer (WebUI for MySQL).</p>

<p>We will make the MySQL Service Persistent by setting a constraint to only run on the Manager node, as we will create the volume path on the host, and then map the host to the container so that the container can have persistent data. We will also create secrets for our MySQL Service so that we dont expose any plaintext passwords in our compose file.</p>

<p>Our Docker Compose file:</p>

<pre><code class="yaml docker-compose.yml">version: '3.3'

services:
  db:
    image: mysql
    secrets:
      - db_root_password
      - db_dba_password
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
      resources:
        reservations:
          memory: 128M
        limits:
          memory: 256M
    ports:
      - 3306:3306
    environment:
      MYSQL_USER: dba
      MYSQL_DATABASE: mydb
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
      MYSQL_PASSWORD_FILE: /run/secrets/db_dba_password
    networks:
      - appnet
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - type: bind
        source: /opt/docker/volumes/mysql
        target: /var/lib/mysql

  adminer:
    image: adminer
    ports:
      - 8080:8080
    networks:
      - appnet

secrets:
  db_root_password:
    external: true
  db_dba_password:
    external: true

networks:
  appnet:
    external: true
</code></pre>

<h2>Dependencies:</h2>

<p>As we specified our secrets and networks as external resources, it needs to exist before we deploy our stack. We also need to create the directory for our mysql data, as the data will be mapped from our host to our container.</p>

<p>Create the Overlay Network:</p>

<pre><code class="bash">$ docker network create --driver overlay appnet
</code></pre>

<p>Create the Secrets:</p>

<pre><code class="bash">$ openssl rand -base64 12 | docker secret create db_root_password -
$ openssl rand -base64 12 | docker secret create db_dba_password -
</code></pre>

<p>List the Secrets:</p>

<pre><code class="bash">$ docker secret ls
ID                          NAME                CREATED             UPDATED
jzhrwyxkiqt8v81ow0xjktqnw   db_root_password    12 seconds ago      12 seconds ago
plr6rbrqkqy7oplrd21pja3ol   db_dba_password     4 seconds ago       4 seconds ago
</code></pre>

<p>Inspect the secret, so that we can see that theres not value exposed:</p>

<pre><code class="bash">$ docker secret inspect db_root_password
[
    {
        "ID": "jzhrwyxkiqt8v81ow0xjktqnw",
        "Version": {
            "Index": 982811
        },
        "CreatedAt": "2017-11-23T14:33:17.005968748Z",
        "UpdatedAt": "2017-11-23T14:33:17.005968748Z",
        "Spec": {
            "Name": "db_root_password",
            "Labels": {}
        }
    }
]
</code></pre>

<p>Create the Directory for MySQL:</p>

<pre><code class="bash">$ mkdir -p /opt/docker/volumes/mysql
</code></pre>

<h2>Deployment Time!</h2>

<p>Deploy the stack:</p>

<pre><code>$ docker stack deploy -c docker-compose.yml apps
Creating service apps_adminer
Creating service apps_db
</code></pre>

<p>As you can see the data of our MySQL container resides on our host, which makes the data persistent for the container:</p>

<pre><code class="bash">$ ls /opt/docker/volumes/mysql/
auto.cnf  ca-key.pem  ca.pem  client-cert.pem  client-key.pem  ib_buffer_pool  ibdata1  ib_logfile0  ib_logfile1  ibtmp1  mydb  mysql  performance_schema  private_key.pem  public_key.pem  server-cert.pem  server-key.pem  sys
</code></pre>

<h2>Connect to MySQL</h2>

<p>The value of our secrets will reside under <code>/run/secrets/</code> in our container, as we have mapped it to our mysql container, lets have a look at them:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) ls /run/secrets/
db_dba_password  db_root_password
</code></pre>

<p>View the actual value of the <code>db_root_password</code>:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) cat /run/secrets/db_root_password
mRpcY1eY2+wimf10
</code></pre>

<p>Connecting to MySQL:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 8
Server version: 5.7.20 MySQL Community Server (GPL)

Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydb               |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)
</code></pre>

<p>As we have deployed adminer, you can access the Adminer WebUI on the Host&rsquo;s IP and the Defined Port.</p>

<h2>Testing Data Persistance:</h2>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.

mysql&gt; create database ruan;
Query OK, 1 row affected (0.00 sec)

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydb               |
| mysql              |
| performance_schema |
| ruan               |
| sys                |
+--------------------+
6 rows in set (0.00 sec)

mysql&gt; exit;
Bye
</code></pre>

<p>Verify the hostname of our container, before we kill the container:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) hostname
bdedb54bbc2b
</code></pre>

<p>Kill the container:</p>

<pre><code>$ docker kill $(docker ps -f name=apps_db -q)
bdedb54bbc2b
</code></pre>

<p>Verify the status of the MySQL Service, as we can see the service count is 0, so the container was succesfully killed.</p>

<pre><code class="bash">$ docker service ls -f name=apps_db
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
nzf96q05fktm        apps_db             replicated          0/1                 mysql:latest        *:3306-&gt;3306/tcp
</code></pre>

<p>After waiting for a couple of seconds, we can see the service is in service again, then check the hostname so that we can confirm that its a new container:</p>

<pre><code>$ docker service ls -f name=apps_db
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
nzf96q05fktm        apps_db             replicated          1/1                 mysql:latest        *:3306-&gt;3306/tcp

$ docker exec -it $(docker ps -f name=apps_db -q) hostname
95c15c89f891
</code></pre>

<p>Logong to MySQL again and verify if our perviously created database is still there:</p>

<pre><code class="bash">$ docker exec -it $(docker ps -f name=apps_db -q) mysql -u root -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.

mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mydb               |
| mysql              |
| performance_schema |
| ruan               |
| sys                |
+--------------------+
6 rows in set (0.01 sec)
</code></pre>

<p>By design docker is stateless, but as we mapped the host&rsquo;s path to the container our data is persistent. As we have set a constraint so that the container must only spin up on this node, the container will always have access to the data path.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Local Dev Environment With Docker MySQL and Adminer WebUI With Docker Compose]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/13/local-dev-environment-with-docker-mysql-and-adminer-webui-with-docker-compose/"/>
    <updated>2017-11-13T16:15:34-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/13/local-dev-environment-with-docker-mysql-and-adminer-webui-with-docker-compose</id>
    <content type="html"><![CDATA[<p>Let&rsquo;s setup a local development environment with Docker, MySQL and Adminer WebUI using Docker Compose</p>

<h2>Docker Compose File:</h2>

<p>Let&rsquo;s look at our docker-compose file:</p>

<pre><code class="yml">version: '3.2'

services:
  mysql-client:
    image: alpine:edge
    volumes:
      - type: bind
        source: ./workspace
        target: /root/workspace
    networks:
      - docknet
    command: ping 127.0.0.1

  db:
    image: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: example
    networks:
      - docknet
    volumes:
      - type: volume
        source: dbdata
        target: /var/lib/mysql

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080
    networks:
      - docknet

networks:
    docknet:
        external: true

volumes:
  dbdata:
    external: true
</code></pre>

<h2>Pre-Requirements:</h2>

<p>Let&rsquo;s create our pre-requirement:</p>

<ol>
<li>Networks:</li>
</ol>


<pre><code class="bash">$ docker network create docknet
</code></pre>

<ol>
<li>Volumes:</li>
</ol>


<p>Our Volume for MySQL so that we have persistent data:</p>

<pre><code class="bash">$ docker volume create dbdata
</code></pre>

<p>Our <code>workspace</code> directory that will be persistent in our <code>debug-client</code> alpine container:</p>

<pre><code class="bash">$ mkdir -p workspace/python
</code></pre>

<h2>Launching our Services:</h2>

<p>Let&rsquo;s launch our services:</p>

<pre><code class="bash ">$ docker-compose -f mysql-compose.yml up -d
Creating mysql_db_1 ...
Creating mysql_adminer_1
Creating mysql_debug-client_1
</code></pre>

<p>Listing our Containers:</p>

<pre><code class="bash">$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                      NAMES
e05804ab6d64        alpine:edge         "ping 127.0.0.1"         21 seconds ago      Up 4 seconds                                   mysql_debug-client_1
c052ceeb6d3b        mysql               "docker-entrypoint..."   21 seconds ago      Up 5 seconds        3306/tcp                   mysql_db_1
2b0446daab4c        adminer             "entrypoint.sh doc..."   26 seconds ago      Up 5 seconds        0.0.0.0:8080-&gt;8080/tcp     mysql_adminer_1
</code></pre>

<h2>Using the Debug Container:</h2>

<p>I will use the debug container as the client to connect to the internal services, for example, the mysql-client:</p>

<pre><code class="bash">$ apk update
$ apk add mysql-client
$ mysql -h db -u root -ppassword
MySQL [(none)]&gt;
</code></pre>

<p>Also, you will find the persistent data directory for our workspace:</p>

<pre><code class="bash">$ ls /root/workspace/
python
</code></pre>

<h2>Accessing the MySQL WebUI: Adminer</h2>

<p>Access the service via the exposed endpoint:</p>

<pre><code class="bash">+ http://localhost:8080/
</code></pre>

<p>The login view:</p>

<p><img src="https://i.snag.gy/m8dUxe.jpg" alt="" /></p>

<p>Creating the Table:</p>

<p><img src="https://i.snag.gy/tPVbg6.jpg" alt="" /></p>

<h2>Deleting the Environment:</h2>

<p>The External Resources will not be deleted:</p>

<pre><code class="bash">$ docker-compose -f mysql-compose.yml down
Removing mysql_debug-client_1 ... done
Removing mysql_db_1           ... done
Removing mysql_adminer_1      ... done
Network docknet is external, skipping
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Java Web Applications on Tomcat With Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/10/24/running-java-web-applications-on-tomcat-with-docker-swarm/"/>
    <updated>2017-10-24T09:37:38-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/10/24/running-java-web-applications-on-tomcat-with-docker-swarm</id>
    <content type="html"><![CDATA[<p>From <a href="https://sysadmins.co.za/running-java-web-applications-on-docker-with-payara-micro/?referral=blog.ruanbekker.com?category=java">this post</a> we used Payara Micro to Setup a Web Application, and a full example was provided on how to create a <code>war</code> file that will be used for the deployment.</p>

<p>Today we will be using Tomcat to deploy the same application. The official repository can be found on <a href="https://hub.docker.com/_/tomcat/">hub.docker.com/_/tomcat</a> .</p>

<h2>Our Dockerfile for our Own Tomcat Image:</h2>

<p>The <code>Dockerfile</code> is modified a bit (CATALINA_OPTS) to be able to pass <code>JVM</code> environment variables, but if you would like to use the standard image you can skip this and just use the image from their repository.</p>

<pre><code class="bash">FROM openjdk:8-jre-alpine

ENV CATALINA_HOME /usr/local/tomcat
ENV PATH $CATALINA_HOME/bin:$PATH
RUN mkdir -p "$CATALINA_HOME"
WORKDIR $CATALINA_HOME
ENV CATALINA_OPTS -Xmx768m -Xms512m -XX:PermSize=256m -XX:MaxPermSize=512m -XX:ReservedCodeCacheSize=64m -XX:+UseG1GC -XX:+CMSClassUnloadingEnabled -XX:+PrintHeapAtGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
# let "Tomcat Native" live somewhere isolated
ENV TOMCAT_NATIVE_LIBDIR $CATALINA_HOME/native-jni-lib
ENV LD_LIBRARY_PATH ${LD_LIBRARY_PATH:+$LD_LIBRARY_PATH:}$TOMCAT_NATIVE_LIBDIR

RUN apk add --no-cache gnupg

# see https://www.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/KEYS
# see also "update.sh" (https://github.com/docker-library/tomcat/blob/master/update.sh)
ENV GPG_KEYS 05AB33110949707C93A279E3D3EFE6B686867BA6 07E48665A34DCAFAE522E5E6266191C37C037D42 47309207D818FFD8DCD3F83F1931D684307A10A5 541FBE7D8F78B25E055DDEE13C370389288584E7 61B832AC2F1C5A90F0F9B00A1C506407564C17A3 713DA88BE50911535FE716F5208B0AB1D63011C7 79F7026C690BAA50B92CD8B66A3AD3F4F22C4FED 9BA44C2621385CB966EBA586F72C284D731FABEE A27677289986DB50844682F8ACB77FC2E86E29AC A9C5DF4D22E99998D9875A5110C01C5A2F6059E7 DCFD35E0BF8CA7344752DE8B6FB21E8933C60243 F3A04C595DB5B6A5F1ECA43E3B7BBB100D811BBE F7DA48BB64BCB84ECBA7EE6935CD23C10D498E23
RUN set -ex; \
    for key in $GPG_KEYS; do \
        gpg --keyserver ha.pool.sks-keyservers.net --recv-keys "$key"; \
    done

ENV TOMCAT_MAJOR 8
ENV TOMCAT_VERSION 8.5.23
ENV TOMCAT_SHA1 1ba27c1bb86ab9c8404e98068800f90bd662523c

ENV TOMCAT_TGZ_URLS \
# https://issues.apache.org/jira/browse/INFRA-8753?focusedCommentId=14735394#comment-14735394
    https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz \
# if the version is outdated, we might have to pull from the dist/archive :/
    https://www-us.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz \
    https://www.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz \
    https://archive.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz

ENV TOMCAT_ASC_URLS \
    https://www.apache.org/dyn/closer.cgi?action=download&amp;filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz.asc \
# not all the mirrors actually carry the .asc files :'(
    https://www-us.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz.asc \
    https://www.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz.asc \
    https://archive.apache.org/dist/tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz.asc

RUN set -eux; \
    \
    apk add --no-cache --virtual .fetch-deps \
        ca-certificates \
        openssl \
    ; \
    \
    success=; \
    for url in $TOMCAT_TGZ_URLS; do \
        if wget -O tomcat.tar.gz "$url"; then \
            success=1; \
            break; \
        fi; \
    done; \
    [ -n "$success" ]; \
    \
    echo "$TOMCAT_SHA1 *tomcat.tar.gz" | sha1sum -c -; \
    \
    success=; \
    for url in $TOMCAT_ASC_URLS; do \
        if wget -O tomcat.tar.gz.asc "$url"; then \
            success=1; \
            break; \
        fi; \
    done; \
    [ -n "$success" ]; \
    \
    gpg --batch --verify tomcat.tar.gz.asc tomcat.tar.gz; \
    tar -xvf tomcat.tar.gz --strip-components=1; \
    rm bin/*.bat; \
    rm tomcat.tar.gz*; \
    \
    nativeBuildDir="$(mktemp -d)"; \
    tar -xvf bin/tomcat-native.tar.gz -C "$nativeBuildDir" --strip-components=1; \
    apk add --no-cache --virtual .native-build-deps \
        apr-dev \
        coreutils \
        dpkg-dev dpkg \
        gcc \
        libc-dev \
        make \
        "openjdk${JAVA_VERSION%%[-~bu]*}"="$JAVA_ALPINE_VERSION" \
        openssl-dev \
    ; \
    ( \
        export CATALINA_HOME="$PWD"; \
        cd "$nativeBuildDir/native"; \
        gnuArch="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)"; \
        ./configure \
            --build="$gnuArch" \
            --libdir="$TOMCAT_NATIVE_LIBDIR" \
            --prefix="$CATALINA_HOME" \
            --with-apr="$(which apr-1-config)" \
            --with-java-home="$(docker-java-home)" \
            --with-ssl=yes; \
        make -j "$(nproc)"; \
        make install; \
    ); \
    runDeps="$( \
        scanelf --needed --nobanner --format '%n#p' --recursive "$TOMCAT_NATIVE_LIBDIR" \
            | tr ',' '\n' \
            | sort -u \
            | awk 'system("[ -e /usr/local/lib/" $1 " ]") == 0 { next } { print "so:" $1 }' \
    )"; \
    apk add --virtual .tomcat-native-rundeps $runDeps; \
    apk del .fetch-deps .native-build-deps; \
    rm -rf "$nativeBuildDir"; \
    rm bin/tomcat-native.tar.gz; \
    \
# sh removes env vars it doesn't support (ones with periods)
# https://github.com/docker-library/tomcat/issues/77
    apk add --no-cache bash; \
    find ./bin/ -name '*.sh' -exec sed -ri 's|^#!/bin/sh$|#!/usr/bin/env bash|' '{}' +

# verify Tomcat Native is working properly
RUN set -e \
    &amp;&amp; nativeLines="$(catalina.sh configtest 2&gt;&amp;1)" \
    &amp;&amp; nativeLines="$(echo "$nativeLines" | grep 'Apache Tomcat Native')" \
    &amp;&amp; nativeLines="$(echo "$nativeLines" | sort -u)" \
    &amp;&amp; if ! echo "$nativeLines" | grep 'INFO: Loaded APR based Apache Tomcat Native library' &gt;&amp;2; then \
        echo &gt;&amp;2 "$nativeLines"; \
        exit 1; \
    fi

EXPOSE 8080
CMD ["catalina.sh", "run"]
</code></pre>

<h2>Building our Image and Pusing to our Registry:</h2>

<pre><code class="bash">$ docker build -t registry.gitlab.com/&lt;user&gt;/&lt;repo&gt;/&lt;image&gt;:&lt;tag&gt;
$ docker push registry.gitlab.com/&lt;user&gt;/&lt;repo&gt;/&lt;image&gt;:&lt;tag&gt;
</code></pre>

<h2>Dockerfile for our Application:</h2>

<p>Now that we have built our image for Tomcat, we can write our <code>Dockerfile</code> for our application, note that the <code>hello.war</code> file also needs to be in the same working directory, unless written otherwise:</p>

<pre><code class="docker">FROM registry.gitlab.com/&lt;user&gt;/&lt;repo&gt;/&lt;image&gt;:&lt;tag&gt;
COPY hello.war /usr/local/tomcat/webapps/hello.war
</code></pre>

<h2>Setup the Compose file for our Stack:</h2>

<p>We will use docker stack to deploy our application, note that I have <a href="https://sysadmins.co.za/traefik-a-modern-http-reverse-proxy-and-load-balancer-for-microservices-such-as-docker/">Traefik</a> that acts as my reverse proxy.</p>

<p>Below, our <code>app.yml</code> compose file:</p>

<pre><code class="yml">version: '3'

services:
  hello:
    image: registry.gitlab.com/&lt;user&gt;/&lt;repo&gt;/&lt;image&gt;:&lt;tag&gt;
    networks:
      - appnet
    deploy:
      labels:
        - "traefik.port=8080"
        - "traefik.docker.network=appnet"
        - "traefik.frontend.rule=Host:apps.mydomain.com; PathPrefix: /hello/"
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - 'node.role==worker'

networks:
  appnet:
    external: true
</code></pre>

<h2>Deploy our Application:</h2>

<p>From our compose file we defined that our network is external, so if you are using the same name, and you have not yet setup the overlay network:</p>

<pre><code class="bash">$ docker network create --driver overlay appnet
</code></pre>

<p>Now deploy the stack:</p>

<pre><code class="bash">$ docker stack deploy --compose-file app.yml apps
</code></pre>

<h2>Testing our Application:</h2>

<pre><code class="bash">$ curl http://apps.mydomain.com/hello/

&lt;!DOCTYPE html&gt;
&lt;html&gt;
            Hello World!
   Test Page with Docker + Payara Micro&lt;/h3&gt;

   Serving From ContainerId: d24f8cd982fc
&lt;/html&gt;
</code></pre>
]]></content>
  </entry>
  
</feed>
