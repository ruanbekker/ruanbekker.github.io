<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-08-20T04:22:55-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Tutorial on DynamoDB Using Bash and the AWS CLI Tools to Interact With a Music Dataset]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/14/tutorial-on-dynamodb-using-bash-and-the-aws-cli-tools-to-interact-with-a-music-dataset/"/>
    <updated>2018-08-14T16:33:22-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/14/tutorial-on-dynamodb-using-bash-and-the-aws-cli-tools-to-interact-with-a-music-dataset</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/aws-logo.png" alt="" /></p>

<p>In this tutorial we will be using Amazons DynamoDB (DynamoDB Local) to host a sample dataset consisting of music data that I retrieved from the iTunes API, which we will be using the aws cli tools to interact with the data.</p>

<p>We will be doing the following:</p>

<ul>
<li>Use Docker to provision a Local DynamoDB Server</li>
<li>Create a DynamoDB Table with a Hash and Range Key</li>
<li>List the Table</li>
<li>Create a Item in DynamoDB</li>
<li>Read a Item from DynamoDB</li>
<li>Read a Item from DynamoDB by specifying the details you would like to read</li>
<li>Batch Write multiple items to DynamoDB</li>
<li>Scan all your Items from DynamoDB</li>
<li>Query by Artist</li>
<li>Query by Artist and Song</li>
<li>Query all the Songs from an Artist starting with a specific letter</li>
<li>Indexes</li>
<li>Delete the Table</li>
</ul>


<p>If you are just getting started with DynamoDB, I recommend having a look at <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html">Amazons DynamoDB Documentation</a> Page first.</p>

<h2>The Music Dataset:</h2>

<p>I used the <a href="https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/">iTunes API</a> to get the music metadata, but I also have a post on <a href="http://blog.ruanbekker.com/blog/2018/05/08/use-python-requests-to-interact-with-the-itunes-api-to-search-for-music-info/">how to query the iTunes API</a> to get data from them to use.</p>

<p>a Quick way in Python to get the top 10 songs from Guns and Roses, will look like this:</p>

<pre><code class="python">&gt;&gt;&gt; a = 'https://itunes.apple.com/search?term=guns+and+roses&amp;limit=10'
&gt;&gt;&gt; b = requests.get(a).json()
&gt;&gt;&gt; print(json.dumps(b, indent=2))
</code></pre>

<h2>Create the DynamoDB Local Server on Docker:</h2>

<p>If you have a AWS Account you can provision your table from there, but if you want to test it locally, you can provision a local DynamoDB Server using Docker:</p>

<pre><code>$ docker run -it -p 8000:8000 --name dynamodb-local rbekker87/dynamodb-local
</code></pre>

<h2>Install the AWS CLI Tools:</h2>

<pre><code class="bash">$ pip install awscli
$ aws configure
# you can enter random data if you are using dynamodb-local
</code></pre>

<h2>Create the DynamoDB Table:</h2>

<p>Create a DynamoDB Table named <code>MusicCollection</code> with a <code>Artist (HASH)</code> and <code>SongTitle (RANGE)</code> key attributes:</p>

<pre><code class="bash">$ aws dynamodb create-table --table-name MusicCollection \
  --attribute-definitions AttributeName=Artist,AttributeType=S AttributeName=SongTitle,AttributeType=S \
  --key-schema AttributeName=Artist,KeyType=HASH AttributeName=SongTitle,KeyType=RANGE \
  --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
  --endpoint-url http://localhost:8000

Response:
{
    "TableDescription": {
        "TableArn": "arn:aws:dynamodb:ddblocal:000000000000:table/MusicCollection",
        "AttributeDefinitions": [
            {
                "AttributeName": "Artist",
                "AttributeType": "S"
            },
            {
                "AttributeName": "SongTitle",
                "AttributeType": "S"
            }
        ],
        "ProvisionedThroughput": {
            "NumberOfDecreasesToday": 0,
            "WriteCapacityUnits": 5,
            "LastIncreaseDateTime": 0.0,
            "ReadCapacityUnits": 5,
            "LastDecreaseDateTime": 0.0
        },
        "TableSizeBytes": 0,
        "TableName": "MusicCollection",
        "TableStatus": "ACTIVE",
        "KeySchema": [
            {
                "KeyType": "HASH",
                "AttributeName": "Artist"
            },
            {
                "KeyType": "RANGE",
                "AttributeName": "SongTitle"
            }
        ],
        "ItemCount": 0,
        "CreationDateTime": 1525339294.186
    }
}
</code></pre>

<h2>Listing the Tables:</h2>

<p>List the DynamoDB Table that you created:</p>

<pre><code class="bash">$ aws dynamodb list-tables --endpoint-url http://localhost:8000

{
    "TableNames": [
        "MusicCollection"
    ]
}
</code></pre>

<h2>Create a Item in DynamoDB:</h2>

<p>Add a song from the band <code>Bring me the Horizon</code> called <code>Sleepwalking</code> from the album <code>Sempiternal</code> to the table by using the <code>PutItem</code> call:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 put-item --table-name MusicCollection \
  --item '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}, "AlbumTitle": {"S": "Sempiternal"}}'
</code></pre>

<h2>Read a Item from DynamoDB</h2>

<p>Get the Song Details from the Table by using the <code>GetItem</code> call:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 get-item --table-name MusicCollection \
  --key  '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}}'

{
    "Item": {
        "Artist": {
            "S": "Bring me the Horizon"
        },
        "SongTitle": {
            "S": "Sleepwalking"
        },
        "AlbumTitle": {
            "S": "Sempiternal"
        }
    }
}
</code></pre>

<p>To only get specific attributes we can use <code>--aatributes-to-get</code>:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 get-item --table-name MusicCollection \
  --attributes-to-get '["AlbumTitle", "SongTitle"]' \
  --key  '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}}'

{
    "Item": {
        "SongTitle": {
            "S": "Sleepwalking"
        },
        "AlbumTitle": {
            "S": "Sempiternal"
        }
    }
}
</code></pre>

<p>However, AWS Recommends to use the <code>--projection-expression</code> parameter:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 get-item --table-name MusicCollection \
  --projection-expression "AlbumTitle, SongTitle" \
  --key  '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}}'

{
    "Item": {
        "SongTitle": {
            "S": "Sleepwalking"
        },
        "AlbumTitle": {
            "S": "Sempiternal"
        }
    }
}
</code></pre>

<ul>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.AttributesToGet.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.AttributesToGet.html</a></li>
</ul>


<h2>Batch Write</h2>

<p>Now lets use the <a href="https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/">iTunes API</a> to get a collection of some songs, which I will dump into a <a href="https://github.com/ruanbekker/dynamodb-local-docker/blob/master/demo/batch-write-songs.json">json file on github</a>. So now that we have a json file with a collection of songs from multiple artists, we can go ahead and write it into our table using the <code>BatchWriteItem</code> call:</p>

<pre><code class="bash">$ wget https://raw.githubusercontent.com/ruanbekker/dynamodb-local-docker/master/demo/batch-write-songs.json
$ aws dynamodb batch-write-item --request-items file://music-table/batch-write-songs.json --endpoint-url http://localhost:8000
</code></pre>

<h2>Scan the Table:</h2>

<p>This can be a very expensive call, as a <code>Scan</code> will return all the items from your table, and depending on the size of your table, you could be throttled, but since we are using dynamodb local and only having 16 items in our table, we can do a scan to return all the items in our table:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 scan --table-name MusicCollection
{
    "Count": 16,
</code></pre>

<h2>Query</h2>

<p>Let&rsquo;s start using the <code>Query</code> call to get all the songs from the Artist: AC/DC</p>

<ul>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.QueryFilter.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.QueryFilter.html</a></li>
</ul>


<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --key-condition-expression "Artist = :a" \
  --expression-attribute-values  '{":a":{"S":"AC/DC"}}'

{
    "Count": 3,
    "Items": [
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "Back In Black"
            },
            "AlbumTitle": {
                "S": "Back In Black"
            }
        },
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "Thunderstruck"
            },
            "AlbumTitle": {
                "S": "The Razors Edge"
            }
        },
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "You Shook Me All Night Long"
            },
            "AlbumTitle": {
                "S": "Back in Black"
            }
        }
    ],
    "ScannedCount": 3,
    "ConsumedCapacity": null
}
</code></pre>

<p>Query to get the details of a specific Song from a specific Artist:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --key-condition-expression "Artist = :a and SongTitle = :t" \
  --expression-attribute-values  '{ ":a": {"S": "AC/DC"}, ":t": {"S": "You Shook Me All Night Long"}}'

{
    "Count": 1,
    "Items": [
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "You Shook Me All Night Long"
            },
            "AlbumTitle": {
                "S": "Back in Black"
            }
        }
    ],
    "ScannedCount": 1,
    "ConsumedCapacity": null
}
</code></pre>

<p>Query to get all the songs from the Beatles that starts with the letter &lsquo;H&rsquo;:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --key-condition-expression "Artist = :a and begins_with(SongTitle, :t)" \
  --expression-attribute-values  '{":a":{"S":"The Beatles"}, ":t": {"S": "h"}}'

{
    "Count": 2,
    "Items": [
        {
            "Artist": {
                "S": "The Beatles"
            },
            "SongTitle": {
                "S": "Happy Day"
            },
            "AlbumTitle": {
                "S": "The Beatles 1967-1970 (The Blue Album)"
            }
        },
        {
            "Artist": {
                "S": "The Beatles"
            },
            "SongTitle": {
                "S": "Help!"
            },
            "AlbumTitle": {
                "S": "The Beatles Box Set"
            }
        }
    ],
    "ScannedCount": 2,
    "ConsumedCapacity": null
}
</code></pre>

<p>So our table consists of Artist (HASH) and SongTitle (RANGE), so we can only query based on those attributes. You will find when you try to query on a attribute that is not part of the KeySchema, a exception will be received:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES --table-name MusicCollection --key-condition-expression "Artist = :a and AlbumTitle = :t" --expression-attribute-values  '{":a":{"S":"AC/DC"}, ":t": {"S": "Back in Black"}}'

An error occurred (ValidationException) when calling the Query operation: Query condition missed key schema element
</code></pre>

<p>So how do we query on a attribute that is not part of the KeySchema? Let&rsquo;s say you want to query all the songs from a Artist and a specific Album.</p>

<h2>Global Secondary Indexes:</h2>

<p>Add Global Secondary Index, with the Attributes: Artist and AlbumTitle.</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 update-table --table-name MusicCollection \
  --attribute-definitions AttributeName=Artist,AttributeType=S AttributeName=SongTitle,AttributeType=S AttributeName=AlbumTitle,AttributeType=S \
  --global-secondary-index-updates "Create={"IndexName"="album-index", "KeySchema"=[ {"AttributeName"="Artist", "KeyType"="HASH"}, {"AttributeName"="AlbumTitle", "KeyType"="RANGE" }], "Projection"={"ProjectionType"="INCLUDE", "NonKeyAttributes"="AlbumTitle"}, "ProvisionedThroughput"= {"ReadCapacityUnits"=1, "WriteCapacityUnits"=1} }"

{
    "TableDescription": {
        "TableArn": "arn:aws:dynamodb:ddblocal:000000000000:table/MusicCollection",
        "AttributeDefinitions": [
            {
                "AttributeName": "Artist",
                "AttributeType": "S"
            },
            {
                "AttributeName": "SongTitle",
                "AttributeType": "S"
            },
            {
                "AttributeName": "AlbumTitle",
                "AttributeType": "S"
            }
        ],
        "GlobalSecondaryIndexes": [
            {
                "IndexName": "album-index",
                "Projection": {
                    "ProjectionType": "INCLUDE",
                    "NonKeyAttributes": [
                        "AlbumTitle"
                    ]
                },
                "ProvisionedThroughput": {
                    "WriteCapacityUnits": 1,
                    "ReadCapacityUnits": 1
                },
                "IndexStatus": "CREATING",
                "Backfilling": false,
                "KeySchema": [
                    {
                        "KeyType": "HASH",
                        "AttributeName": "Artist"
                    },
                    {
                        "KeyType": "RANGE",
                        "AttributeName": "AlbumTitle"
                    }
                ],
                "IndexArn": "arn:aws:dynamodb:ddblocal:000000000000:table/MusicCollection/index/album-index"
            }
        ],
        "ProvisionedThroughput": {
            "NumberOfDecreasesToday": 0,
            "WriteCapacityUnits": 5,
            "LastIncreaseDateTime": 0.0,
            "ReadCapacityUnits": 5,
            "LastDecreaseDateTime": 0.0
        },
        "TableSizeBytes": 984,
        "TableName": "MusicCollection",
        "TableStatus": "ACTIVE",
        "KeySchema": [
            {
                "KeyType": "HASH",
                "AttributeName": "Artist"
            },
            {
                "KeyType": "RANGE",
                "AttributeName": "SongTitle"
            }
        ],
        "ItemCount": 15,
        "CreationDateTime": 1525339294.186
    }
}
</code></pre>

<p>Now when we use the same query, but we specify our index, we will get the data:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query \
  --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --index-name album-index \
  --key-condition-expression "Artist = :a and AlbumTitle = :t" \
  --expression-attribute-values  '{":a":{"S":"AC/DC"}, ":t": {"S": "Back in Black"}}'

{
    "Count": 1,
    "Items": [
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "You Shook Me All Night Long"
            },
            "AlbumTitle": {
                "S": "Back in Black"
            }
        }
    ],
    "ScannedCount": 1,
    "ConsumedCapacity": null
}
</code></pre>

<h2>Delete the Table:</h2>

<p>Delete the Table that we created:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 delete-table --table-name MusicCollection
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.Query.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.Query.html</a></li>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Indexes.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Indexes.html</a></li>
<li><a href="https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/">https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build a REST API War File for Payara With Java Springboot and Maven Part 1]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/09/build-a-rest-api-war-file-for-payara-with-java-springboot-and-maven-part-1/"/>
    <updated>2018-08-09T20:43:34-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/09/build-a-rest-api-war-file-for-payara-with-java-springboot-and-maven-part-1</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/payara-logo.png" alt="" /></p>

<p>This is a command line approach to create a java web app for payara that takes war files, which we will be using in conjunction with springboot and apache maven.</p>

<h2>Setup Java and Apache Maven:</h2>

<p>Setup Java 1.8:</p>

<pre><code class="bash">$ apt update
$ apt install wget openssl vim software-properties-common -y
$ add-apt-repository ppa:webupd8team/java -y
$ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C2518248EEA14886
$ apt update &amp;&amp; apt install oracle-java8-installer -y
</code></pre>

<p>Setup Apache Maven:</p>

<pre><code class="bash">$ cd /opt
$ curl -SL  http://www-eu.apache.org/dist/maven/maven-3/3.5.4/binaries/apache-maven-3.5.4-bin.tar.gz | tar -xz
$ mv apache-maven-3.5.4 maven
$ echo 'M2_HOME=/opt/maven' &gt; /etc/profile.d/mavenenv.sh
$ echo 'export PATH=${M2_HOME}/bin:${PATH}' &gt;&gt; /etc/profile.d/mavenenv.sh
$ chmod +x /etc/profile.d/mavenenv.sh
$ source /etc/profile.d/mavenenv.sh
</code></pre>

<p>Ensure Java and Maven is installed:</p>

<pre><code class="bash">$ java -version
java version "1.8.0_181"

$ mvn -version
Apache Maven 3.5.4
</code></pre>

<h2>Prepare the directories:</h2>

<p>Prepare the directories where we will be working with our application&rsquo;s source code:</p>

<pre><code class="bash">$ mkdir -p /root/app
$ cd /root/app
$ mkdir -p src/main/webapp/WEB-INF
$ mkdir -p src/main/java/fish/payara/spring/boot/{controller,domain}
</code></pre>

<h2>The source code:</h2>

<p>The <code>pom.xml</code> file:</p>

<pre><code class="bash">$ vim pom.xml
</code></pre>

<pre><code class="xml">&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;fish.payara.appserver&lt;/groupId&gt;
    &lt;artifactId&gt;payara-micro-with-spring-boot-rest&lt;/artifactId&gt;
    &lt;version&gt;1.0&lt;/version&gt;
    &lt;packaging&gt;war&lt;/packaging&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;compilerArguments&gt;
                        &lt;source&gt;1.8&lt;/source&gt;
                        &lt;target&gt;1.8&lt;/target&gt;
                    &lt;/compilerArguments&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
                &lt;version&gt;1.2.6.RELEASE&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
            &lt;exclusions&gt;
                &lt;exclusion&gt;
                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                    &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;
                &lt;/exclusion&gt;
            &lt;/exclusions&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
        &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.batch&lt;/groupId&gt;
        &lt;artifactId&gt;spring-batch-test&lt;/artifactId&gt;
        &lt;scope&gt;import&lt;/scope&gt;
    &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.crsh&lt;/groupId&gt;
            &lt;artifactId&gt;crsh.plugins&lt;/artifactId&gt;
            &lt;version&gt;1.2.11&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;
            &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;
            &lt;version&gt;3.1.0&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>

<p>The <code>web.xml</code>:</p>

<pre><code class="bash">$ vim src/main/webapp/WEB-INF/web.xml
</code></pre>

<pre><code class="xml">&lt;web-app
    xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaeehttp://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd"
    version="3.1"&gt;

&lt;/web-app&gt;
</code></pre>

<p>The <code>Application.java</code>:</p>

<pre><code class="bash">$ vim src/main/java/fish/payara/spring/boot/Application.java
</code></pre>

<pre><code class="java">package fish.payara.spring.boot;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.builder.SpringApplicationBuilder;
import org.springframework.boot.context.web.SpringBootServletInitializer;

@SpringBootApplication
public class Application extends SpringBootServletInitializer {

    @Override
    protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {
        return application.sources(Application.class);
    }

    public static void main(String[] args) throws Exception {
        SpringApplication.run(Application.class, args);
    }
}
</code></pre>

<p>The <code>Person.java</code>:</p>

<pre><code class="bash">$ vim src/main/java/fish/payara/spring/boot/domain/Person.java
</code></pre>

<pre><code class="java">package fish.payara.spring.boot.domain;

public class Person {

    private int id;
    private String name;
    private String lastName;
    private String email;

    public Person() {
    }

    public Person(int id, String name, String lastName, String email) {
        this.id = id;
        this.name = name;
        this.lastName = lastName;
        this.email = email;
    }

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public String getLastName() {
        return lastName;
    }

    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    public String getEmail() {
        return email;
    }

    public void setEmail(String email) {
        this.email = email;
    }
}
</code></pre>

<p>The <code>PersonRestController.java</code>:</p>

<pre><code class="bash">$ src/main/java/fish/payara/spring/boot/controller/PersonRestController.java
</code></pre>

<pre><code class="java">package fish.payara.spring.boot.controller;

import fish.payara.spring.boot.domain.Person;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import javax.annotation.PostConstruct;
import java.util.Collection;
import java.util.HashMap;
import java.util.Map;

@RestController
@RequestMapping("/person")
public class PersonRestController {

    Map&lt;Integer, Person&gt; personMap = new HashMap&lt;&gt;();

    @PostConstruct
    public void init() {
        personMap.put(1, new Person(1, "Ruan", "Bekker", "ruan@gmail.com"));
        personMap.put(2, new Person(2, "Steve", "James", "steve@gmail.com"));
        personMap.put(3, new Person(3, "Frank", "Phillips", "frank@gmail.com"));
    }

    @RequestMapping("/all")
    public Collection&lt;Person&gt; getAll() {
        return personMap.values();
    }
}
</code></pre>

<h2>Build with Maven:</h2>

<p>Build the war file with maven:</p>

<pre><code class="bash">$ mvn clean package

[INFO] Packaging webapp
[INFO] Assembling webapp [payara-micro-with-spring-boot-rest] in [/root/app/target/payara-micro-with-spring-boot-rest-1.0]
[INFO] Processing war project
[INFO] Copying webapp resources [/root/app/src/main/webapp]
[INFO] Webapp assembled in [113 msecs]
[INFO] Building war: /root/app/target/payara-micro-with-spring-boot-rest-1.0.war
[INFO] WEB-INF/web.xml already added, skipping
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 18.662 s
[INFO] Finished at: 2018-08-04T10:46:50Z
[INFO] ------------------------------------------------------------------------
</code></pre>

<p>You will find your war file under:</p>

<pre><code class="bash">$ ls target/
classes  maven-archiver  maven-status  payara-micro-with-spring-boot-rest-1.0  payara-micro-with-spring-boot-rest-1.0.war
</code></pre>

<p>You can change the name in the <code>pom.xml</code>, but since we already built it, lets rename the file to something shorter:</p>

<pre><code class="bash">$ mv /root/app/target/payara-micro-with-spring-boot-rest-1.0.war /root/app/target/webapp.war
</code></pre>

<h2>Deploy your Application with Payara Micro:</h2>

<p>Deploy your application with docker:</p>

<pre><code class="bash">$ docker run -it -p 8080:8080 -v /root/app/target:/opt/payara/deployments payara/micro --deploy /opt/payara/deployments/webapp.war


  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v1.2.6.RELEASE)

{
    "Instance Configuration": {
        "Host": "4e90ecf6a1a7",
        "Http Port(s)": "8080",
        "Https Port(s)": "",
        "Instance Name": "Cloudy-Chub",
        "Instance Group": "MicroShoal",
        "Hazelcast Member UUID": "a1af817d-473b-4fa7-9ee9-7d53291a35a2",
        "Deployed": [
            {
                "Name": "webapp",
                "Type": "war",
                "Context Root": "/webapp"
            }
        ]
    }
}
2018-08-04 11:26:39.655  INFO 1 --- [           main] PayaraMicro                              :
Payara Micro URLs:
http://4e90ecf6a1a7:8080/webapp
</code></pre>

<h2>Testing</h2>

<p>Let&rsquo;s hit our app&rsquo;s health endpoint to test:</p>

<pre><code class="bash">$ curl -s http://localhost:8080/webapp/health | jq .
{
  "status": "UP"
}
</code></pre>

<p>Now to interact with our API:</p>

<pre><code class="bash">$ curl -s http://localhost:8080/webapp/person/all | jq .
[
  {
    "id": 1,
    "name": "Ruan",
    "lastName": "Bekker",
    "email": "ruan@gmail.com"
  },
  {
    "id": 2,
    "name": "Steve",
    "lastName": "James",
    "email": "steve@gmail.com"
  },
  {
    "id": 3,
    "name": "Frank",
    "lastName": "Phillips",
    "email": "frank@gmail.com"
  }
]
</code></pre>

<p>Payara also provides a <code>/metrics</code> endpoint:</p>

<pre><code class="bash">$ curl -s http://localhost:8080/webapp/metrics | jq .
{
  "mem": 219648,
  "mem.free": 67104,
  "processors": 4,
  "instance.uptime": 369749,
  "uptime": 390417,
  "systemload.average": 0.14697265625,
  "heap.committed": 219648,
  "heap.init": 32768,
  "heap.used": 152543,
  "heap": 455168,
  "threads.peak": 98,
  "threads.daemon": 37,
  "threads": 72,
  "classes": 16951,
  "classes.loaded": 16951,
  "classes.unloaded": 0,
  "gc.ps_scavenge.count": 42,
  "gc.ps_scavenge.time": 515,
  "gc.ps_marksweep.count": 4,
  "gc.ps_marksweep.time": 634,
  "counter.status.200.health": 1,
  "counter.status.200.mappings": 2,
  "counter.status.200.person.all": 2,
  "counter.status.404.error": 5,
  "gauge.response.error": 6,
  "gauge.response.health": 120,
  "gauge.response.mappings": 3,
  "gauge.response.person.all": 9
}
</code></pre>

<p>And to get a mapping of all the endpoints:</p>

<pre><code class="bash">$ curl -s http://localhost:8080/webapp/mappings | jq .
</code></pre>

<p>If you decided to deploy as a jar, you can use the payara-micro jar to deploy the war file:</p>

<pre><code class="bash">$ java -jar payara-micro-5.182.jar --deploy target/webapp.war
</code></pre>

<p>For more info on this, have a look at their <a href="https://blog.payara.fish/creating-rest-web-services-with-spring-boot-hosted-on-payara-micro">website</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploy Docker Swarm Using Ansible]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/06/14/deploy-docker-swarm-using-ansible/"/>
    <updated>2018-06-14T06:05:46-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/06/14/deploy-docker-swarm-using-ansible</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/docker-logo.png" alt="" /></p>

<p>In this setup we will use Ansible to Deploy Docker Swarm.</p>

<p>With this setup, I have a client node, which will be my jump box, as it will be used to ssh with the docker user to my swarm nodes with passwordless ssh access.</p>

<p>The repository for the source code can be found on my <a href="https://github.com/ruanbekker/ansible-docker-swarm">Github Repository</a></p>

<h2>Pre-Check</h2>

<p>Hosts file:</p>

<pre><code>$ cat /etc/hosts
10.0.8.2 client
192.168.1.10 swarm-manager
192.168.1.11 swarm-worker-1
192.168.1.12 swarm-worker-2
</code></pre>

<p>SSH Config:</p>

<pre><code>$ cat ~/.ssh/config 
Host client
  Hostname client
  User root
  IdentityFile /tmp/key.pem
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null

Host swarm-manager
  Hostname swarm-manager
  User root
  IdentityFile /tmp/key.pem
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null

Host swarm-worker-1
  Hostname swarm-worker-1
  User root
  IdentityFile /tmp/key.pem
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null

Host swarm-worker-2
  Hostname swarm-worker-2
  User root
  IdentityFile /tmp/key.pem
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null
</code></pre>

<p>Install Ansible:</p>

<pre><code>$ apt install python-setuptools -y
$ easy_install pip
$ pip install ansible
</code></pre>

<p>Ensure passwordless ssh is working:</p>

<pre><code>$ ansible -i inventory.ini -u root -m ping all
client | SUCCESS =&gt; {
    "changed": false, 
    "ping": "pong"
}
swarm-manager | SUCCESS =&gt; {
    "changed": false, 
    "ping": "pong"
}
swarm-worker-2 | SUCCESS =&gt; {
    "changed": false, 
    "ping": "pong"
}
swarm-worker-1 | SUCCESS =&gt; {
    "changed": false, 
    "ping": "pong"
}
</code></pre>

<h2>Deploy Docker Swarm</h2>

<pre><code>$ ansible-playbook -i inventory.ini -u root deploy-swarm.yml 
PLAY RECAP 

client                     : ok=11   changed=3    unreachable=0    failed=0   
swarm-manager              : ok=18   changed=4    unreachable=0    failed=0   
swarm-worker-1             : ok=15   changed=1    unreachable=0    failed=0   
swarm-worker-2             : ok=15   changed=1    unreachable=0    failed=0   
</code></pre>

<p>SSH to the Swarm Manager and List the Nodes:</p>

<pre><code>$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
0ead0jshzkpyrw7livudrzq9o *   swarm-manager       Ready               Active              Leader              18.03.1-ce
iwyp6t3wcjdww0r797kwwkvvy     swarm-worker-1      Ready               Active                                  18.03.1-ce
ytcc86ixi0kuuw5mq5xxqamt1     swarm-worker-2      Ready               Active                                  18.03.1-ce
</code></pre>

<h2>Test Application on Swarm</h2>

<p>Create a Nginx Demo Service:</p>

<pre><code>$ docker network create --driver overlay appnet
$ docker service create --name nginx --publish 80:80 --network appnet --replicas 6 nginx
$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
k3vwvhmiqbfk        nginx               replicated          6/6                 nginx:latest        *:80-&gt;80/tcp

$ docker service ps nginx
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
tspsypgis3qe        nginx.1             nginx:latest        swarm-manager       Running             Running 34 seconds ago                       
g2f0ytwb2jjg        nginx.2             nginx:latest        swarm-worker-1      Running             Running 34 seconds ago                       
clcmew8bcvom        nginx.3             nginx:latest        swarm-manager       Running             Running 34 seconds ago                       
q293r8zwu692        nginx.4             nginx:latest        swarm-worker-2      Running             Running 34 seconds ago                       
sv7bqa5e08zw        nginx.5             nginx:latest        swarm-worker-1      Running             Running 34 seconds ago                       
r7qg9nk0a9o2        nginx.6             nginx:latest        swarm-worker-2      Running             Running 34 seconds ago   
</code></pre>

<p>Test the Application:</p>

<pre><code>$ curl -i http://192.168.1.10
HTTP/1.1 200 OK
Server: nginx/1.15.0
Date: Thu, 14 Jun 2018 10:01:34 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 05 Jun 2018 12:00:18 GMT
Connection: keep-alive
ETag: "5b167b52-264"
Accept-Ranges: bytes
</code></pre>

<p>Delete the Service:</p>

<pre><code>
$ docker service rm nginx
nginx
</code></pre>

<h2>Delete the Swarm:</h2>

<pre><code>$ ansible-playbook -i inventory.ini -u root delete-swarm.yml 

PLAY RECAP 
swarm-manager              : ok=2    changed=1    unreachable=0    failed=0   
swarm-worker-1             : ok=2    changed=1    unreachable=0    failed=0   
swarm-worker-2             : ok=2    changed=1    unreachable=0    failed=0   
</code></pre>

<p>Ensure the Nodes is removed from the Swarm, SSH to your Swarm Manager:</p>

<pre><code>$ docker node ls
Error response from daemon: This node is not a swarm manager. Use "docker swarm init" or "docker swarm join" to connect this node to swarm and try again.
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clearing Up Disk Space on Docker Swarm by Removing Unused Data With Prune]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/06/01/clearing-up-disk-space-on-docker-swarm-by-removing-unused-data-with-prune/"/>
    <updated>2018-06-01T02:19:21-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/06/01/clearing-up-disk-space-on-docker-swarm-by-removing-unused-data-with-prune</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/docker-logo.png" alt="" /></p>

<p>After some time, your system can run out of disk space when running a lot of containers / volumes etc. You will find that at times, you will have a lot of unused containers, stopped containers, unused images, unused networks that is just sitting there, which consumes data on your nodes.</p>

<p>One way to clean them is by using <code>docker system prune</code>.</p>

<h2>Check Docker Disk Space</h2>

<p>The command below will show the amount of disk space consumed, and how much is reclaimable:</p>

<pre><code class="bash">$ docker system df
TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE
Images              229                 125                 23.94GB             14.65GB (61%)
Containers          322                 16                  8.229GB             8.222GB (99%)
Local Volumes       77                  41                  698MB               19.13MB (2%)
Build Cache                                                 0B                  0B
</code></pre>

<h2>Removing Unsued Data:</h2>

<p>By using Prune, we can remove the unused resources that is consuming data:</p>

<pre><code class="bash">$ docker system prune

WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all dangling images
        - all build cache
Are you sure you want to continue? [y/N] y

Deleted Containers:
a3d7db158e065d0c86160fd5d688875f8b7435848ea91db57ed007
47890dcfea4a105f43e790dd8ad3c6d7c4ad7e738186c034d7a46b

Deleted Networks:
traefik-net
app_appnet

Deleted Images:
deleted: sha256:5b9909c10e93afec
deleted: sha256:d81eesdfihweo3rk

Total reclaimed space: 14.18GB
</code></pre>

<p>For related <a href="https://goo.gl/L2NYxU">Docker</a> posts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Wildcard SSL Certificate With Letsencrypt on Docker Swarm Using Traefik]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/05/28/wildcard-ssl-certificate-with-letsencrypt-on-docker-swarm-using-traefik/"/>
    <updated>2018-05-28T17:36:17-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/05/28/wildcard-ssl-certificate-with-letsencrypt-on-docker-swarm-using-traefik</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/traefik.png" alt="" /></p>

<p>With Letsencrypt supporting Wildcard certificates is really awesome. Now, we can setup traefik to listen on 443, acting as a reverse proxy and is doing HTTPS Termination to our Applications thats running in our Swarm.</p>

<h2>Architectural Design:</h2>

<p>At the moment we have 3 Manager Nodes, and 5 Worker Nodes:</p>

<ul>
<li>Using a Dummy Domain example.com which is set to the 3 Public IP&rsquo;s of our Manager Nodes</li>
<li>DNS is set for: <code>example.com</code> A Record to: <code>52.10.1.10</code>, <code>52.10.1.11</code>, <code>52.10.1.12</code></li>
<li>DNS is set for: <code>*.example.com</code> CNAME to <code>example.com</code></li>
<li>Any application that is spawned into our Swarm, will be labeled with a <code>traefik.frontend.rule</code> which will be routed to the service and redirected from HTTP to HTTPS</li>
</ul>


<h2>Create the Overlay Network:</h2>

<p>Create the overlay network that will be used for our stack:</p>

<pre><code class="bash">$ docker network create --driver overlay appnet
</code></pre>

<h2>Create the Compose Files for our Stacks:</h2>

<p>Create the Traefik Service Compose file, we will deploy it in Global Mode, constraint to our Manager Nodes, so that every manager node has a copy of traefik running.</p>

<pre><code class="bash">$ cat &gt; traefik-compose.yml &lt;&lt; EOF

version: "3.4"
services:
  proxy:
    image: traefik:latest
    command:
      - "--api"
      - "--entrypoints=Name:http Address::80 Redirect.EntryPoint:https"
      - "--entrypoints=Name:https Address::443 TLS"
      - "--defaultentrypoints=http,https"
      - "--acme"
      - "--acme.storage=/etc/traefik/acme/acme.json"
      - "--acme.entryPoint=https"
      - "--acme.httpChallenge.entryPoint=http"
      - "--acme.onHostRule=true"
      - "--acme.onDemand=false"
      - "--acme.email=me@example.com"
      - "--docker"
      - "--docker.swarmMode"
      - "--docker.domain=example.com"
      - "--docker.watch"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /mnt/traefik/acme.json:/etc/traefik/acme/acme.json
    networks:
      - appnet
    ports:
      - target: 80
        published: 80
        mode: host
      - target: 443
        published: 443
        mode: host
      - target: 8080
        published: 8080
        mode: host
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
networks:
  appnet:
    external: true

EOF
</code></pre>

<p>Create the Application Compose file, in this example we will be deploying a Ghost Blog:</p>

<pre><code class="bash">$ cat &gt; ghost-compose.yml &lt;&lt; EOF

version: '3.4'

services:
  blog:
    image: ghost:1.22.7-alpine
    networks:
      - appnet
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: 
          - node.role == worker
      labels:
        - "traefik.backend.loadbalancer.sticky=false"
        - "traefik.backend.loadbalancer.swarm=true"
        - "traefik.backend=blog-1"
        - "traefik.docker.network=appnet"
        - "traefik.entrypoints=https"
        - "traefik.frontend.passHostHeader=true"
        - "traefik.frontend.rule=Host:blog.example.com"
        - "traefik.port=2368"

networks:
  appnet:
    external: true

EOF
</code></pre>

<h2>Prepare the Path for Traefik:</h2>

<p>We have a <a href="https://sysadmins.co.za/tag/glusterfs/">replicated volume</a> under our <code>/mnt</code> partition, so that all our managers can read from that path, create the file and provide the sufficient permissions:</p>

<pre><code class="bash">$ mkdir -p /mnt/traefik
$ touch /mnt/traefik/acme.json
$ chmod 600 /mnt/traefik/acme.json
</code></pre>

<h2>Deploy the Stacks:</h2>

<p>Deploy the Traefik Stack:</p>

<pre><code class="bash">$ docker stack deploy -c traefik-compose.yml traefik
</code></pre>

<p>Wait until the services are deployed:</p>

<pre><code class="bash">$ docker stack services traefik
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
f8ru5gbcgd2v        traefik_proxy       global              3/3                 traefik:latest
</code></pre>

<p>Deploy the Application Stack:</p>

<pre><code class="bash">$ docker stack deploy -c ghost-compose.yml apps
</code></pre>

<p>Verify that the Application Stack has been deployed:</p>

<pre><code class="bash">$ docker stack services apps
ID                  NAME                MODE                REPLICAS            IMAGE                          PORTS
516zlfs2cfdv        apps_blog           replicated          1/1                 ghost:1.22.7-alpine
</code></pre>

<p>At the moment we will have 2 stacks in our Swarm:</p>

<pre><code class="bash">$ docker stack ls
NAME                SERVICES
apps                1
traefik             1
</code></pre>

<h2>Test the Application:</h2>

<p>Let&rsquo;s test our blog to see if we get redirected to <a href="HTTPS:">HTTPS:</a></p>

<pre><code class="bash">$ curl -iL http://blog.example.com
HTTP/1.1 302 Found
Location: https://blog.example.com:443/
Date: Mon, 28 May 2018 22:02:41 GMT
Content-Length: 5
Content-Type: text/plain; charset=utf-8

HTTP/1.1 200 OK
Cache-Control: public, max-age=0
Content-Type: text/html; charset=utf-8
Date: Mon, 28 May 2018 22:02:42 GMT
Etag: W/"4166-J2ooSIa8gtTkYjbnr7vnPUFlRJI"
Vary: Accept-Encoding
X-Powered-By: Express
Transfer-Encoding: chunked
</code></pre>

<p>Works like a charm! Traefik FTW!</p>
]]></content>
  </entry>
  
</feed>
