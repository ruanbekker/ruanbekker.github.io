<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-12-20T05:09:05-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setup a Gitlab Runner on Your Own Server to Run Your Jobs That Gets Triggered From Gitlab CI]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/12/20/setup-a-gitlab-runner-on-your-own-server-to-run-your-jobs-that-gets-triggered-from-gitlab-ci/"/>
    <updated>2018-12-20T04:21:16-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/12/20/setup-a-gitlab-runner-on-your-own-server-to-run-your-jobs-that-gets-triggered-from-gitlab-ci</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/50217968-0629f680-0393-11e9-8387-ad69937eb891.png" alt="" /></p>

<p>From our previous post, we went through the setup on setting up a <a href="https://blog.ruanbekker.com/blog/2018/12/19/setup-a-basic-ci-pipeline-on-gitlab/">Basic CI Pipeline on Gitlab</a>, in conjunction with Gitlab CI which coordinates your jobs, where we used the Shared Runners, which runs your jobs on Gitlab&rsquo;s Infrastructure.</p>

<p>In Gitlab, you have Shared Runners and your Own Runners, which is used to run your jobs and send the results back to GitLab.</p>

<p>In this tutorial we will Setup a Server with gitlab-runner and Docker on Ubuntu and then Setup a Basic Pipeline to Utilize your Gitlab Runner.</p>

<h2>Setup Docker</h2>

<p>Install Docker:</p>

<pre><code class="bash">$ sudo apt update &amp;&amp; sudo apt upgrade -y
$ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common -y
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

$ sudo apt update
$ sudo apt install docker-ce -y
$ docker run hello-world
</code></pre>

<h2>Install and Setup Gitlab Runner</h2>

<p>This setup is intended for Linux 64bit, for other distributions, have a look at their <a href="https://docs.gitlab.com/runner/install/">docs</a></p>

<p>Install the Runner:</p>

<pre><code class="bash">$ wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64
$ chmod +x /usr/local/bin/gitlab-runner
$ useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash
$ gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner
$ gitlab-runner start
</code></pre>

<p>Register the Runner. The Gitlab-CI Token is available in your CI/CD Settings panel from the UI: <code>https://gitlab.com/&lt;account&gt;/&lt;repo&gt;/settings/ci_cd</code></p>

<pre><code class="bash">$ gitlab-runner register
Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):
https://gitlab.com/

Please enter the gitlab-ci token for this runner:
__masked__

Please enter the gitlab-ci description for this runner:
Please enter the gitlab-ci tags for this runner (comma separated):
my-runner,foobar
Registering runner... succeeded                     runner=66m_339h

Please enter the executor: docker-ssh+machine, docker, docker-ssh, parallels, shell, ssh, virtualbox, docker+machine, kubernetes:
docker

Please enter the default Docker image (e.g. ruby:2.1):
alpine:latest

Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!
</code></pre>

<p>Verify the Status and check if Docker and Gitlab Runner is enabled on startup:</p>

<pre><code class="bash">$ gitlab-runner status
Runtime platform                                    arch=amd64 os=linux pid=30363 revision=7f00c780 version=11.5.1
gitlab-runner: Service is running!

$ systemctl is-enabled gitlab-runner
enabled

$ systemctl is-enabled docker
enabled
</code></pre>

<h2>Gitlab-CI Config for Shared Runners</h2>

<p>If you would like to use the shared runners that Gitlab Offers, the <code>.gitlab-ci.yml</code> config will look like this:</p>

<pre><code class="yaml">stages:
  - build
  - test

build:
  stage: build
  script:
    - echo "this is building"
    - hostname
    - mkdir builds
    - touch builds/data.txt
    - echo "true" &gt; builds/data.txt
  artifacts:
    paths:
      - builds/

test:
  stage: test
  script:
    - echo "this is testing"
    - hostname
    - test -f builds/data.txt
    - grep "true" builds/data.txt
</code></pre>

<h2>Gitlab-CI Config for your own Gitlab Runner</h2>

<p>Gitlab utilizes the tags that was specified on registration to determine where the jobs gets executed on, for more information on this, have a look at their <a href="https://docs.gitlab.com/ce/ci/yaml/README.html#tags">docs</a></p>

<p>The <code>.gitlab-ci.yml</code> config for using your gitlab runner:</p>

<pre><code class="yaml">stages:
  - build
  - test

build:
  stage: build
  tags:
    - my-runner
  script:
    - echo "this is building"
    - hostname
    - mkdir builds
    - touch builds/data.txt
    - echo "true" &gt; builds/data.txt
  artifacts:
    paths:
      - builds/

test:
  stage: test
  tags:
    - my-runner
  script:
    - echo "this is testing"
    - hostname
    - test -f builds/data.txt
    - grep "true" builds/data.txt
</code></pre>

<h2>Trigger and Check Docker</h2>

<p>Commit the config to master, let your pipeline run their jobs upon completion have a look at docker on your server for the containers that the jobs ran on:</p>

<pre><code class="bash">$ docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS                          PORTS               NAMES
04292a78de0b        c04b8be95e1e        "gitlab-runner-cache.."  About a minute ago   Exited (0) About a minute ago                       runner-xx-project-xx-concurrent-0-cache-3cxx0
49b1b3c4adf9        c04b8be95e1e        "gitlab-runner-cache.."  About a minute ago   Exited (0) About a minute ago                       runner-xx-project-xx-concurrent-0-cache-6cxxa
422b23191e8c        hello-world         "/hello"                 24 minutes ago       Exited (0) 24 minutes ago                           wizardly_meninsky
</code></pre>

<p>As we know each job gets executed in different containers, you can see from the output above that there was 2 different containers for the 2 jobs that was specified in our pipeline.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://docs.gitlab.com/ee/ci/quick_start/">https://docs.gitlab.com/ee/ci/quick_start/</a></li>
<li><a href="https://docs.gitlab.com/ee/ci/runners/">https://docs.gitlab.com/ee/ci/runners/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Local Dev Environment for Wordpress Using Docker Compose]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/12/19/local-dev-environment-for-wordpress-using-docker-compose/"/>
    <updated>2018-12-19T08:33:44-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/12/19/local-dev-environment-for-wordpress-using-docker-compose</id>
    <content type="html"><![CDATA[<p>Let&rsquo;s setup a local development environment with Docker, Wordpress, MySQL using Docker Compose</p>

<h2>Docker Compose File</h2>

<p>Let&rsquo;s look at our docker-compose.yml file:</p>

<pre><code class="yaml">version: '3.1'

services:

  wordpress:
    image: wordpress
    restart: always
    ports:
      - 8080:80
    environment:
      - WORDPRESS_DB_NAME=wordpress
      - WORDPRESS_DB_HOST=mysql
      - WORDPRESS_DB_USER=wordpress
      - WORDPRESS_DB_PASSWORD=wordpress
    networks:
      - wordpress

  mysql:
    image: mysql:5.7
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=password
      - MYSQL_DATABASE=wordpress
      - MYSQL_USER=wordpress
      - MYSQL_PASSWORD=wordpress
    networks:
      - wordpress

networks:
  wordpress:
</code></pre>

<p>Environment Variables for the MySQL Docker image is:</p>

<pre><code>- MYSQL_ROOT_PASSWORD
- MYSQL_DATABASE
- MYSQL_USER, MYSQL_PASSWORD
- MYSQL_ALLOW_EMPTY_PASSWORD
- MYSQL_RANDOM_ROOT_PASSWORD
- MYSQL_ONETIME_PASSWORD
</code></pre>

<p>More info can be viewed on this resource: <a href="https://hub.docker.com/_/mysql/">hub.docker.com/_/mysql/</a></p>

<h2>Launching our Wordpress Application:</h2>

<p>Lets deploy wordpress:</p>

<pre><code class="bash">$ docker-compose up 
Creating network "wordpress_wordpress" with the default driver
Creating wordpress_mysql_1_3e6e3cfe07b1     ... done
Creating wordpress_wordpress_1_a9cb16f277af ... done
Attaching to wordpress_wordpress_1_9227f3d3e587, wordpress_mysql_1_65cc98d222d0
</code></pre>

<h2>Accessing Wordpress</h2>

<p>You should be able to access Wordpress on <code>http://localhost:80/</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Local Dev Environment for Mediawiki Using Docker Compose]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/12/19/local-dev-environment-for-mediawiki-using-docker-compose/"/>
    <updated>2018-12-19T08:22:36-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/12/19/local-dev-environment-for-mediawiki-using-docker-compose</id>
    <content type="html"><![CDATA[<p>Let&rsquo;s setup a local development environment with Docker, Mediawiki, MySQL using Docker Compose</p>

<h2>Docker Compose File</h2>

<p>Let&rsquo;s look at our docker-compose.yml file:</p>

<pre><code class="yaml">version: "3.4"

services:

  db:
    image: mysql:5.6
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=password
      - MYSQL_USER=mw
      - MYSQL_DATABASE=mediawiki
      - MYSQL_PASSWORD=pass
    volumes:
      - /Users/ruan/workspace/docker/mediawiki/mediawiki-mysql-data:/var/lib/mysql
    networks:
      - mediawiki
    ports:
      - 3306:3306

  memcached:
    image: rbekker87/memcached:alpine
    environment:
      - MEMCACHED_USER=memcached
      - MEMCACHED_HOST=0.0.0.0
      - MEMCACHED_PORT=11211
      - MEMCACHED_MEMUSAGE=128
      - MEMCACHED_MAXCONN=1024
    networks:
      - mediawiki

  mediawiki:
    image: benhutchins/mediawiki:latest
    networks:
      - mediawiki
    environment:
      - MEDIAWIKI_DB_TYPE=mysql
      - MEDIAWIKI_DB_HOST=db
      - MEDIAWIKI_DB_USER=mw
      - MEDIAWIKI_DB_PASSWORD=pass
      - MEDIAWIKI_SITE_SERVER=http://localhost
      - MEDIAWIKI_SITE_NAME="My Lekke Wiki"
      - MEDIAWIKI_SITE_LANG=en
      - MEDIAWIKI_ADMIN_USER=admin
      - MEDIAWIKI_ADMIN_PASS=password123
      - MEDIAWIKI_UPDATE=true
      - MEDIAWIKI_ENABLE_SSL=false
    volumes:
      - /Users/ruan/workspace/docker/mediawiki/mediawiki-data:/data
    ports:
      - 80:80
    depends_on:
      - db
      - memcached

networks:
  mediawiki:
</code></pre>

<p>Your current working directory in this case: <code>/Users/ruan/workspace/docker/mediawiki</code></p>

<p>Environment Variables for the MySQL Docker image is:</p>

<pre><code>- MYSQL_ROOT_PASSWORD
- MYSQL_DATABASE
- MYSQL_USER, MYSQL_PASSWORD
- MYSQL_ALLOW_EMPTY_PASSWORD
- MYSQL_RANDOM_ROOT_PASSWORD
- MYSQL_ONETIME_PASSWORD
</code></pre>

<p>More info can be viewed on this resource: <a href="https://hub.docker.com/_/mysql/">hub.docker.com/_/mysql/</a></p>

<h2>Launching our Mediawiki Application:</h2>

<p>Lets deploy mediawiki:</p>

<pre><code class="bash">$ docker-compose up
Creating network "mediawiki_mediawiki" with the default driver
Creating mediawiki_memcached_1_bbbe8d3fa8b3 ... done
Creating mediawiki_db_1_257775fcf65b        ... done
Creating mediawiki_mediawiki_1_56813d66cbe2 ... done
</code></pre>

<h2>Accessing Mediawiki</h2>

<p>You should be able to access Mediawiki on <code>http://localhost:80/</code></p>

<h2>Resources:</h2>

<ul>
<li><a href="https://github.com/benhutchins/docker-mediawiki">https://github.com/benhutchins/docker-mediawiki</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Python Flask and JavaScript for Client Side Filtering Through Returned Data]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/24/using-python-flask-and-javascript-for-client-side-filtering-through-returned-data/"/>
    <updated>2018-10-24T05:39:33-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/24/using-python-flask-and-javascript-for-client-side-filtering-through-returned-data</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/python-logo.png" alt="" /></p>

<p>This post will cover 2 sections, using Python Flask and Javascript to filter returned data, where you could have a table that represents 100 items, and you want to have a search box to filter down your results as you type.</p>

<p>The other section will be used as a demo, with solving a problem with Amazon CloudWatch Logs. I&rsquo;m a Massive AWS Fanatic, but when it comes to CloudWatch Logs, I&rsquo;m not so big of a fan of that specific service. Especially when you use Docker Swarm for AWS and have your logdriver set to CloudWatch Logs.</p>

<script id="mNCC" language="javascript">
    medianet_width = "728";
    medianet_height = "90";
    medianet_crid = "218284798";
    medianet_versionId = "3111299"; 
  </script>


<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>


<h2>The Problem I have with CloudWatch Logs</h2>

<p>When you point to your CloudWatch LogGroups, you can search for your streams, and in my case searching for a specific swarm service, but you can&rsquo;t sort by date, like this:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/cloudwatch-logs-date-issue.png" alt="" /></p>

<p>This makes it really tedious when trying to search find your logs in a quick way.</p>

<h2>Python Flask to the Resque</h2>

<p>We will create a Python Flask application that retrieves your data about all your Docker Swarm Services and Container Id&rsquo;s running on each node. For this demonstration, I have hard coded the services and container id&rsquo;s, but using it in a real environment, you can utilise the Docker API or some logic that retrieves it from a datastore where a process populates it to.</p>

<p>The Application Code will do the following:</p>

<ul>
<li>returns a list of your swarm services (mock data in the code)</li>
<li>when you select a service, it will get a list of the container ids and run through a for loop unsing jinja templates and display them in table format</li>
<li>when you select the containerId, it will populate the containerId to the cloudwatch logs filter, giving you the exact logstream which you are looking for</li>
<li><p>this will do a redirect to the AWS Console, and you will see the data in the sorted time of interest</p></li>
<li><p><code>app.py</code></p></li>
</ul>


<pre><code class="python">from flask import Flask, render_template

app = Flask(__name__)

# faking datasets that can be returned from a api or database
swarm_services = ['my-web-service', 'my-api-service']
swarm_tasks = {
    "my-web-service": {
        "container_names": [
            "my-web-service.1.alfjshoehfosfn",
            "my-web-service.2.fuebchduehakjdu"
        ]
    },
    "my-api-service": {
        "container_names": [
            "my-api-service.1.oprudhyuythvbzx",
            "my-api-service.2.sjduebansifotuf"
        ]
    }
}

def get_container_name(app_name):
    data = []
    response = swarm_tasks[app_name]
    for container in response['container_names']:
        data.append(container)
    return render_template('index.html', app_name=app_name, number=len(data), data=data)

@app.route('/')
def list():
    return render_template('list.html', number=len(swarm_services), apps=swarm_services, aws_region='eu-west-1', cloudwatch_log_stream='docker-swarm-lg')

@app.route('/describe/&lt;string:app_name&gt;')
def get_app(app_name):
    app = get_container_name(app_name)
    return app

if __name__ == '__main__':
    app.run()
</code></pre>

<p>The <code>index.html</code>:</p>

<script src="https://gist.github.com/ruanbekker/08b02a3ef30367ea7306a31eb5f33cb1.js"></script>


<p>The <code>list.html</code> :</p>

<script src="https://gist.github.com/ruanbekker/98eab090e218bbbf0e46d5efc1595e04.js"></script>


<h2>Filtering the Data</h2>

<p>So at this moment all your data will be returned when a list is done, if you are in a case where you have lots of information, it can be overwelming and you will need to search for the service of interest. Using HTML and JavaScript, you can filter through the results:</p>

<p>The JavaScript Function: <code>assets/js/filter.js</code></p>

<pre><code class="javascript">function SearchAndFilterThingy() {
  var input, filter, table, tr, td, x;
  input = document.getElementById("UserInput");
  filter = input.value.toUpperCase();
  table = document.getElementById("ServicesTable");
  tr = table.getElementsByTagName("tr");

  for (x = 0; x &lt; tr.length; x++) {
    td = tr[x].getElementsByTagName("td")[0];
    if (td) {
      if (td.innerHTML.toUpperCase().indexOf(filter) &gt; -1) {
        tr[x].style.display = "";
      }
      else {
        tr[x].style.display = "none";
      }
    }
  }
}
</code></pre>

<h2>Screenshot</h2>

<p>Once you search for a specific keyword on the service you are looking for the output should more or less look like the following:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/docker-flask-running-services.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Ghost Version 2 Blog for the RaspberryPi]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/building-ghost-version-2-blog-for-the-raspberrypi/"/>
    <updated>2018-10-23T17:37:49-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/building-ghost-version-2-blog-for-the-raspberrypi</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/ghost-blog-main.png" alt="" /></p>

<p>In this post we will setup Ghost 2.0.3 for the Raspberry Pi on Docker Swarm</p>

<h2>Dockerfile</h2>

<p>Our dockerfile:</p>

<pre><code>FROM rbekker87/armhf-node:8.11

RUN apk add --no-cache 'su-exec&gt;=0.2' &amp;&amp; apk --update add bash gcc g++ make python &amp;&amp; npm install sqlite3 --build-from-source

ENV NODE_ENV production
ENV GHOST_CLI_VERSION 1.9.1
ENV GHOST_VERSION 2.0.3
ENV GHOST_INSTALL /var/lib/ghost
ENV GHOST_CONTENT /var/lib/ghost/content

RUN npm install -g "ghost-cli@$GHOST_CLI_VERSION"

RUN set -ex; \
        mkdir -p "$GHOST_INSTALL" \
        &amp;&amp; adduser -s /bin/sh -D node \
        &amp;&amp; chown node:node "$GHOST_INSTALL" \
        &amp;&amp; su-exec node ghost install "$GHOST_VERSION" --db sqlite3 --no-prompt --no-stack --no-setup --dir "$GHOST_INSTALL" \
        &amp;&amp; cd "$GHOST_INSTALL" \
        &amp;&amp; su-exec node ghost config --ip 0.0.0.0 --port 2368 --no-prompt --db sqlite3 --url http://localhost:2368 --dbpath "$GHOST_CONTENT/data/ghost.db" \
        &amp;&amp; su-exec node ghost config paths.contentPath "$GHOST_CONTENT" \
        &amp;&amp; su-exec node ln -s config.production.json "$GHOST_INSTALL/config.development.json" \
        &amp;&amp; readlink -f "$GHOST_INSTALL/config.development.json" \
        &amp;&amp; mv "$GHOST_CONTENT" "$GHOST_INSTALL/content.orig" \
        &amp;&amp; mkdir -p "$GHOST_CONTENT" &amp;&amp; chown node:node "$GHOST_CONTENT" \
        &amp;&amp; "$GHOST_INSTALL/current/node_modules/knex-migrator/bin/knex-migrator" --version

ENV PATH $PATH:$GHOST_INSTALL/current/node_modules/knex-migrator/bin

WORKDIR $GHOST_INSTALL

COPY docker-entrypoint.sh /usr/local/bin
RUN chmod +x /usr/local/bin/docker-entrypoint.sh

ENTRYPOINT ["docker-entrypoint.sh"]

CMD ["node", "current/index.js"]
</code></pre>

<h2>Our Boot Script</h2>

<p>Our entrypoint script <code>docker-entrypoint.sh</code>:</p>

<pre><code>#!/bin/bash
set -e

if [[ "$*" == node*current/index.js* ]] &amp;&amp; [ "$(id -u)" = '0' ];
  then
    chown -R node "$GHOST_CONTENT"
    exec su-exec node "$BASH_SOURCE" "$@"
fi

if [[ "$*" == node*current/index.js* ]];
  then
    baseDir="$GHOST_INSTALL/content.orig"
    for src in "$baseDir"/*/ "$baseDir"/themes/*;
      do
        src="${src%/}"
        target="$GHOST_CONTENT/${src#$baseDir/}"
        mkdir -p "$(dirname "$target")"
        if [ ! -e "$target" ];
          then
            tar -cC "$(dirname "$src")" "$(basename "$src")" | tar -xC "$(dirname "$target")"
        fi
      done

    knex-migrator-migrate --init --mgpath "$GHOST_INSTALL/current"
fi

prod() {
cat &gt; /var/lib/ghost/config.development.json &lt;&lt; EOF
{
  "url": "http://${SERVER_URL:-localhost}:${SERVER_PORT:-2368}",
  "server": {
    "port": ${SERVER_PORT:-2368},
    "host": "0.0.0.0"
  },
  "database": {
    "client": "sqlite3",
    "connection": {
      "filename": "/var/lib/ghost/content/data/ghost.db"
    }
  },
  "mail": {
    "transport": "SMTP",
    "from": "${FROM_NAME:-MyBlog} &lt;${FROM_EMAIL:-ghost-blog@localhost}&gt;",
    "options": {
      "service": "Mailgun",
      "host": "${SMTP_HOST:-localhost}",
      "port": ${SMTP_PORT:-25},
      "auth": {
        "user": "${SMTP_AUTH_USERNAME:-root}",
        "pass": "${SMTP_AUTH_PASSWORD:-password}"
      }
    }
  },
  "logging": {
    "transports": [
      "file",
      "stdout"
    ]
  },
  "process": "systemd",
  "paths": {
    "contentPath": "/var/lib/ghost/content"
  }
}
EOF
}

dev() {
cat &gt; /var/lib/ghost/config.development.json &lt;&lt; EOF
{
  "url": "http://${SERVER_URL:-localhost}:${SERVER_PORT:-2368}",
  "server": {
    "port": ${SERVER_PORT:-2368},
    "host": "0.0.0.0"
  },
  "database": {
    "client": "sqlite3",
    "connection": {
      "filename": "/var/lib/ghost/content/data/ghost.db"
    }
  },
  "mail": {
    "transport": "Direct"
  },
  "logging": {
    "transports": [
      "file",
      "stdout"
    ]
  },
  "process": "systemd",
  "paths": {
    "contentPath": "/var/lib/ghost/content"
  }
}
EOF
}

test(){
cat &gt; /var/lib/ghost/config.development.json &lt;&lt; EOF
{
  "url": "http://localhost:2368",
  "server": {
    "port": 2368,
    "host": "0.0.0.0"
  },
  "database": {
    "client": "sqlite3",
    "connection": {
      "filename": "/var/lib/ghost/content/data/ghost.db"
    }
  },
  "mail": {
    "transport": "Direct"
  },
  "logging": {
    "transports": [
      "file",
      "stdout"
    ]
  },
  "process": "systemd",
  "paths": {
    "contentPath": "/var/lib/ghost/content"
  }
}
EOF
}

if  [ "${ENV_TYPE}" = "PROD" ]
  then prod

elif [ "${ENV_TYPE}" = "DEV" ]
  then dev
  else test

fi

exec "$@"
</code></pre>

<p>The entrypoint script takes a couple of environment variables, as you can see if they are not defined, defaults will be inherited.</p>

<p>Configurable Environment Variables:</p>

<pre><code>      - ENV_TYPE=PROD
      - SERVER_PORT=2368
      - SERVER_URL=myblog.pistack.co.za
      - FROM_NAME=MyName
      - SMTP_HOST=mail.mydomain.co.za
      - SMTP_PORT=587
      - SMTP_AUTH_USERNAME=me@mydomain.co.za
      - SMTP_AUTH_PASSWORD=secret
</code></pre>

<h2>Building our Ghost Image</h2>

<p>I have a public image available if you dont want to build/push, but for building:</p>

<pre><code>$ docker build -t your-name/repo:tag
</code></pre>

<h2>Deploy Ghost with Traefik</h2>

<p>Our <code>ghost-compose.yml</code> with traefik will look like the following, note that I mounted the source path to the container&rsquo;s path, the source path is running on a replicated glusterfs volume, which can be setup following <a href="https://blog.ruanbekker.com/blog/2018/10/23/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes/">this post</a></p>

<p>Also for this demonstration I was using the domain pistack.co.za, where you need to utilize the domain of your choice.</p>

<pre><code>version: "3.4"

services:
  ghost:
    image: rbekker87/armhf-ghost:2.0.3
    networks:
      - appnet
    volumes:
      - type: bind
        source: /mnt/volumes/myblog/content/data
        target: /var/www/ghost/content/data
    environment:
      - ENV_TYPE=PROD
      - SERVER_PORT=2368
      - SERVER_URL=myblog.pistack.co.za
      - FROM_NAME=MyName
      - SMTP_HOST=mail.mydomain.co.za
      - SMTP_PORT=587
      - SMTP_AUTH_USERNAME=me@mydomain.co.za
      - SMTP_AUTH_PASSWORD=secret
    deploy:
      replicas: 1
      labels:
        - "traefik.enable=true"
        - "traefik.backend=ghost"
        - "traefik.backend.loadbalancer.swarm=true"
        - "traefik.docker.network=appnet"
        - "traefik.port=2368"
        - "traefik.frontend.passHostHeader=true"
        - "traefik.frontend.rule=Host:myblog.pistack.co.za"
      replicas: 3
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints: [node.role == worker]

networks:
  appnet:
    external: true
</code></pre>

<p>Deploy the stack:</p>

<pre><code>$ docker stack deploy -c ghost-compose.yml web
</code></pre>

<p>Once the service is up, you will be able to reach your blog on the provided <code>traefik.frontend.rule</code>. If you don&rsquo;t have traefik running, you can follow <a href="https://blog.ruanbekker.com/blog/2018/10/23/build-a-traefik-proxy-image-for-your-raspberry-pi-on-docker-swarm/">this post</a> to get traefik up and running.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/r/rbekker87/armhf-ghost/">https://hub.docker.com/r/rbekker87/armhf-ghost/</a></li>
<li><a href="https://github.com/ruanbekker/ghost-armhf">https://github.com/ruanbekker/ghost-armhf</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
