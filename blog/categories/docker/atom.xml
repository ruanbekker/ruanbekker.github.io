<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-10-23T16:38:02-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setting Up a Docker Swarm Cluster on 3 RaspberryPi Nodes]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes/"/>
    <updated>2018-10-23T16:24:00-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/rpi-docker-swarm.png" alt="" /></p>

<p>As the curious person that I am, I like to play around with new stuff that I stumble upon, and one of them was having a docker swarm cluster running on 3 Raspberry Pi&rsquo;s on my LAN.</p>

<p>The idea is to have 3 Raspberry Pi&rsquo;s (Model 3 B), a Manager Node, and 2 Worker Nodes, each with a 32 GB SanDisk SD Card, which I will also be part of a 3x Replicated GlusterFS Volume that will come in handy later for some data that needs persistent data.</p>

<p>More Inforamtion on: <a href="https://docs.docker.com/engine/swarm/">Docker Swarm</a></p>

<h2>Provision Raspbian on each RaspberryPi</h2>

<p>Grab the <a href="https://downloads.raspberrypi.org/raspbian_lite_latest">Latest Raspbian Lite ISO</a> and the following <a href="https://www.raspberrypi.org/documentation/installation/installing-images/">source</a> will help provisioning your RaspberryPi with Raspbian.</p>

<h2>Installing Docker on Raspberry PI</h2>

<p>On each node, run the following to install docker, and also add your user to the docker group, so that you can run docker commands with a normal user:</p>

<pre><code class="bash">$ apt-get update &amp;&amp; sudo apt-get upgrade -y
$ sudo apt-get remove docker.io
$ curl https://get.docker.com | sudo bash
$ sudo usermod -aG docker pi
</code></pre>

<p>If you have an internal DNS Server, set an A Record for each node, or for simplicity, set your hosts file on each node so that your hostname for each node responds to it&rsquo;s provisioned IP Address:</p>

<pre><code class="bash">$ cat /etc/hosts
192.168.0.2   rpi-01
192.168.0.3   rpi-02
192.168.0.4   rpi-03
</code></pre>

<p>Also, to have passwordless SSH, from each node:</p>

<pre><code class="bash">$ ssh-keygen -t rsa
$ ssh-copy-id rpi-01
$ ssh-copy-id rpi-02
$ ssh-copy-id rpi-03
</code></pre>

<h2>Initialize the Swarm</h2>

<p>Time to set up our swarm. As we have more than one network interface, we will need to setup our swarm by specifying the IP Address of our network interface that is accessible from our LAN:</p>

<pre><code class="bash">$ ifconfig eth0
eth0      Link encap:Ethernet  HWaddr a1:12:bc:d3:cd:4d
          inet addr:192.168.0.2  Bcast:192.168.0.255  Mask:255.255.255.0
</code></pre>

<p>Now that we have our IP Address, initialize the swarm on the manager node:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker swarm init --advertise-addr 192.168.0.2
Swarm initialized: current node (siqyf3yricsvjkzvej00a9b8h) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 \
    192.168.0.2:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.  
</code></pre>

<p>Then from <code>rpi-02</code> join the manager node of the swarm:</p>

<pre><code class="bash">pi@rpi-02:~ $ docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.168.0.2:2377
This node joined a swarm as a worker.  
</code></pre>

<p>Then from <code>rpi-03</code> join the manager node of the swarm:</p>

<pre><code class="bash">pi@rpi-03:~ $ docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.168.0.2:2377
This node joined a swarm as a worker.  
</code></pre>

<p>Then from the manager node: <code>rpi-01</code>, ensure that the nodes are checked in:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS
62s7gx1xdm2e3gp5qoca2ru0d     rpi-03              Ready               Active
6fhyfy9yt761ar9pl84dkxck3 *   rpi-01              Ready               Active              Leader
pg0nyy9l27mtfc13qnv9kywe7     rpi-02              Ready               Active
</code></pre>

<h2>Setting Up a Replicated GlusterFS Volume</h2>

<p>I have decided to setup a replicated glusterfs volume to have data replicated throughout the cluster if I would like to have some persistent data. From each node, install the GlusterFS Client and Server:</p>

<pre><code class="bash">$ sudo apt install glusterfs-server glusterfs-client -y &amp;&amp; sudo systemctl enable glusterfs-server
</code></pre>

<p>Probe the other nodes from the manager node:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster peer probe rpi-02
peer probe: success.

pi@rpi-01:~ $ sudo gluster peer probe rpi-03
peer probe: success.
</code></pre>

<p>Ensure that we can see all 3 nodes in our GlusterFS Pool:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster pool list
UUID                                    Hostname        State
778c7463-ba48-43de-9f97-83a960bba99e    rpi-02          Connected
00a20a3c-5902-477e-a8fe-da35aa955b5e    rpi-03          Connected
d82fb688-c50b-405d-a26f-9cb2922cce75    localhost       Connected
</code></pre>

<p>From each node, create the directory where GlusterFS will store the data for the bricks that we will specify when creating the volume:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo mkdir -p /gluster/brick 
pi@rpi-02:~ $ sudo mkdir -p /gluster/brick
pi@rpi-03:~ $ sudo mkdir -p /gluster/brick
</code></pre>

<p>Next, create a 3 Way Replicated GlusterFS Volume:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster volume create rpi-gfs replica 3 \
rpi-01:/gluster/brick \
rpi-02:/gluster/brick \
rpi-03:/gluster/brick \
force

volume create: rpi-gfs: success: please start the volume to access data
</code></pre>

<p>Start the GlusterFS Volume:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster volume start rpi-gfs
volume start: rpi-gfs: success
</code></pre>

<p>Verify the GlusterFS Volume Info, and from the below output you will see that the volume is replicated 3 ways from the 3 bricks that we specified</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster volume info

Volume Name: rpi-gfs
Type: Replicate
Volume ID: b879db15-63e9-44ca-ad76-eeaa3e247623
Status: Started
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: rpi-01:/gluster/brick
Brick2: rpi-02:/gluster/brick
Brick3: rpi-03:/gluster/brick
</code></pre>

<p>Mount the GlusterFS Volume on each Node, first on <code>rpi-01</code>:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo umount /mnt
pi@rpi-01:~ $ sudo echo 'localhost:/rpi-gfs /mnt glusterfs defaults,_netdev,backupvolfile-server=localhost 0 0' &gt;&gt; /etc/fstab
pi@rpi-01:~ $ sudo mount.glusterfs localhost:/rpi-gfs /mnt
pi@rpi-01:~ $ sudo chown -R pi:docker /mnt
</code></pre>

<p>Then on <code>rpi-02</code>:</p>

<pre><code class="bash">pi@rpi-02:~ $ sudo umount /mnt
pi@rpi-02:~ $ sudo echo 'localhost:/rpi-gfs /mnt glusterfs defaults,_netdev,backupvolfile-server=localhost 0 0' &gt;&gt; /etc/fstab
pi@rpi-02:~ $ sudo mount.glusterfs localhost:/rpi-gfs /mnt
pi@rpi-02:~ $ sudo chown -R pi:docker /mnt
</code></pre>

<p>And lastly on <code>rpi-03</code>:</p>

<pre><code class="bash">pi@rpi-03:~ $ sudo umount /mnt
pi@rpi-03:~ $ sudo echo 'localhost:/rpi-gfs /mnt glusterfs defaults,_netdev,backupvolfile-server=localhost 0 0' &gt;&gt; /etc/fstab
pi@rpi-03:~ $ sudo mount.glusterfs localhost:/rpi-gfs /mnt
pi@rpi-03:~ $ sudo chown -R pi:docker /mnt
</code></pre>

<p>Then your GlusterFS Volume will be mounted on all the nodes, and when a file is written to the <code>/mnt/</code> partition, data will be replicated to all the nodes in the Cluster:</p>

<pre><code class="bash">pi@rpi-01:~ $ df -h
Filesystem          Size  Used Avail Use% Mounted on
/dev/root            30G  4.5G   24G  16% /
localhost:/rpi-gfs   30G  4.5G   24G  16% /mnt
</code></pre>

<h2>Create a Web Service on Docker Swarm:</h2>

<p>Let&rsquo;s create a Web Service in our Swarm, called <code>web</code> and by specifying <code>1</code> replica and publishing the exposed port <code>80</code> to our containers port <code>80</code>:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service create --name web --replicas 1 --publish 80:80 hypriot/rpi-busybox-httpd
vsvyanuw6q6yf4jr52m5z7vr1
</code></pre>

<p>Verifying that our Service is Started and equals to the desired replica count:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
vsvyanuw6q6y        web                 replicated          1/1                 hypriot/rpi-busybox-httpd:latest                         *:891-&gt;80/tcp
</code></pre>

<p>Inspecting the Service:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service inspect web
[
    {
        "ID": "vsvyanuw6q6yf4jr52m5z7vr1",
        "Version": {
            "Index": 2493
        },
        "CreatedAt": "2017-07-16T21:20:00.017836646Z",
        "UpdatedAt": "2017-07-16T21:20:00.026359794Z",
        "Spec": {
            "Name": "web",
            "Labels": {},
            "TaskTemplate": {
                "ContainerSpec": {
                    "Image": "hypriot/rpi-busybox-httpd:latest@sha256:c00342f952d97628bf5dda457d3b409c37df687c859df82b9424f61264f54cd1",
                    "StopGracePeriod": 10000000000,
                    "DNSConfig": {}
                },
                "Resources": {
                    "Limits": {},
                    "Reservations": {}
                },
                "RestartPolicy": {
                    "Condition": "any",
                    "Delay": 5000000000,
                    "MaxAttempts": 0
                },
                "Placement": {},
                "ForceUpdate": 0
            },
            "Mode": {
                "Replicated": {
                    "Replicas": 1
                }
            },
            "UpdateConfig": {
                "Parallelism": 1,
                "FailureAction": "pause",
                "Monitor": 5000000000,
                "MaxFailureRatio": 0,
                "Order": "stop-first"
            },
            "RollbackConfig": {
                "Parallelism": 1,
                "FailureAction": "pause",
                "Monitor": 5000000000,
                "MaxFailureRatio": 0,
                "Order": "stop-first"
            },
            "EndpointSpec": {
                "Mode": "vip",
                "Ports": [
                    {
                        "Protocol": "tcp",
                        "TargetPort": 80,
                        "PublishedPort": 80,
                        "PublishMode": "ingress"
                    }
                ]
            }
        },
        "Endpoint": {
            "Spec": {
                "Mode": "vip",
                "Ports": [
                    {
                        "Protocol": "tcp",
                        "TargetPort": 80,
                        "PublishedPort": 80,
                        "PublishMode": "ingress"
                    }
                ]
            },
            "Ports": [
                {
                    "Protocol": "tcp",
                    "TargetPort": 80,
                    "PublishedPort": 80,
                    "PublishMode": "ingress"
                }
            ],
            "VirtualIPs": [
                {
                    "NetworkID": "zjerz0xsw39icnh24enja4cgk",
                    "Addr": "10.255.0.13/16"
                }
            ]
        }
    }
]
</code></pre>

<p>Docker Swarm&rsquo;s Routing mesh takes care of the internal routing, so requests will respond even if the container is not running on the node that you are making the request against.</p>

<p>With that said, verifying on which node our service is running:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ps web
ID                  NAME                IMAGE                              NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS
sd67cd18s5m0        web.1               hypriot/rpi-busybox-httpd:latest   rpi-02              Running             Running 2 minutes ago
</code></pre>

<p>When we make a HTTP Request to one of these Nodes IP Addresses, our request will be responded with this awesome static page:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/armed-with-hypriot.jpg" alt="" /></p>

<p>We can see we only have one container in our swarm, let&rsquo;s scale that up to <code>3</code> containers:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service scale web01=3
web01 scaled to 3
</code></pre>

<p>Now that the service is scaled to 3 containers, requests will be handled using the round-robin algorithm. To ensured that the service scaled, we will see that we will have 3 replicas:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
vsvyanuw6q6y        web                 replicated          3/3                 hypriot/rpi-busybox-httpd:latest                         *:891-&gt;80/tcp
</code></pre>

<p>Verifying where these containers are running on:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ps web01
ID                  NAME                IMAGE                              NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
sd67cd18s5m0        web.1               hypriot/rpi-busybox-httpd:latest   rpi-02              Running             Running 2 minutes ago
ope3ya7hh9j4        web.2               hypriot/rpi-busybox-httpd:latest   rpi-03              Running             Running 30 seconds ago
07m1ww7ptxro        web.3               hypriot/rpi-busybox-httpd:latest   rpi-01              Running             Running 28 seconds ago
</code></pre>

<p>Lastly, removing the service from our swarm:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service rm web01
web01
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My PiStack Blog Proudly Hosted on My RaspberryPi Swarm Cluster]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/my-pistack-blog-proudly-hosted-on-my-raspberrypi-swarm-cluster/"/>
    <updated>2018-10-23T16:11:19-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/my-pistack-blog-proudly-hosted-on-my-raspberrypi-swarm-cluster</id>
    <content type="html"><![CDATA[<p>This is a repost of my <a href="http://blog.pistack.co.za/my-blog-proudly-hosted-on-my-raspberrypi-cluster/">first blogpost which is hosted on my Raspberry Pi Cluster (04 July 2017)</a>, that runs Docker Swarm and is served from my Home in South Africa, and can be accessed on <a href="http://blog.pistack.co.za">http://blog.pistack.co.za</a></p>

<h2>Just Look at It!</h2>

<ul>
<li>3x Raspberry Pi 3 Model B</li>
<li>Quad Core 1.2GHz Broadcom BCM2837 64bit CPU</li>
<li>1GB RAM</li>
<li>BCM43438 wireless LAN and Bluetooth Low Energy (BLE) on board</li>
<li>3x 32GB Sandisk SD Cards (Replicated GlusterFS Volume for <code>/gluster</code> partition)</li>
<li>Upgraded switched Micro USB power source up to 2.5A</li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/rpi-cluster.jpg" alt="" /></p>

<h2>My Setup:</h2>

<p>I have 3x <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberrypi 3&rsquo;s</a>, each with a <a href="https://www.sandisk.com/home/memory-cards/sd-cards/ultra-sd">32GB SanDisk SD Card</a>, formatted with <a href="https://www.raspberrypi.org/downloads/raspbian/">Raspbian Jessie Lite</a>, powered by a <a href="https://www.pishop.co.za/store/rpi-power/anid%C3%A9es-6-port-50w-high-power-usb-hub-25aport">6 Port USB Hub</a> and networked with a <a href="https://m.takealot.com/#product_1?id=35258721">Totolink 5 Port Gigabit Switch</a>, but note that: <em>the Rpi does not support Gigabit Networking</em></p>

<p>For persistent storage I have setup a Replicated GlusterFS Volume across the 3 nodes.</p>

<p>More details on how I did the setup, can be found from the <a href="http://blog.pistack.co.za/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes/">Setting Up a Docker Swarm Cluster on RaspberryPi Nodes</a> blog post.</p>

<h2>Thanks!</h2>

<p>Thanks for the visit, I will blog about awesome Docker and RaspberryPi related stuff as my mind stumble along awesome ideas :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Capturing 54 Million Passwords With a Docker SSH Honeypot]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/11/capturing-54-million-passwords-with-a-docker-ssh-honeypot/"/>
    <updated>2018-10-11T16:38:52-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/11/capturing-54-million-passwords-with-a-docker-ssh-honeypot</id>
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/rbekker/image/upload/v1539291851/ssh-docker-honeypot_eyhzc7.png" alt="" /></p>

<p>The last couple of days I picked up on my ELK Stack a couple thousands of SSH Brute Force Attacks, so I decided I will just revisit my SSH Server configuration, and change my SSH Port to something else for the interim. The dashboard that showed me the results at that point in time:</p>

<p><img src="https://res.cloudinary.com/rbekker/image/upload/v1539292443/kibana-failed-ssh-auth_udkxkl.png" alt="" /></p>

<p>Then I decided I actually would like to setup a SSH Honeypot to listen on Port 22 and change my SSH Server to listen on 222 and capture their IP Addresses, Usernames and Passwords that they are trying to use and dump it all in a file so that I can build up my own password dictionary :D</p>

<h2>SSH Configuration:</h2>

<p>Changing the SSH Port:</p>

<pre><code class="bash">$ sudo vim /etc/ssh/sshd_config
</code></pre>

<p>Change the port to 222:</p>

<pre><code class="bash">Port 222
</code></pre>

<p>Restart the SSH Server:</p>

<pre><code class="bash">$ sudo /etc/init.d/ssh restart
</code></pre>

<p>Verify that the SSH Server is running on the new port:</p>

<pre><code class="bash">$ sudo netstat -tulpn | grep sshd
tcp        0      0 0.0.0.0:222            0.0.0.0:*               LISTEN      28838/sshd
</code></pre>

<h2>Docker SSH Honeypot:</h2>

<p>Thanks to <a href="https://github.com/random-robbie/docker-ssh-honey">random-robbie</a>, as he had everything I was looking for on Github.</p>

<p>Setup the SSH Honeypot:</p>

<pre><code class="bash">$ git clone https://github.com/random-robbie/docker-ssh-honey
$ cd docker-ssh-honey/
$ docker build . -t local:ssh-honepot
$ docker run -itd --name ssh-honeypot -p 22:22 local:ssh-honepot
</code></pre>

<p>Once people attempt to ssh, you will get the output to stdout:</p>

<pre><code class="bash">$ docker logs -f $(docker ps -f name=ssh-honeypot -q) | grep -v 'Error exchanging' | head -10
[Tue Jul 31 01:13:41 2018] ssh-honeypot 0.0.8 by Daniel Roberson started on port 22. PID 5
[Tue Jul 31 01:19:49 2018] 1xx.1xx.1xx.1x gambaa gambaa
[Tue Jul 31 01:23:26 2018] 1xx.9x.1xx.1xx root toor
[Tue Jul 31 01:25:57 2018] 1xx.2xx.1xx.1xx root Passw0rd1234
[Tue Jul 31 01:26:00 2018] 1xx.2xx.1xx.1xx root Qwer1234
[Tue Jul 31 01:26:00 2018] 1xx.2xx.1xx.1xx root Abcd1234
[Tue Jul 31 01:26:08 2018] 1xx.2xx.1xx.1xx root ubuntu
[Tue Jul 31 01:26:09 2018] 1xx.2xx.1xx.1xx root PassWord
[Tue Jul 31 01:26:10 2018] 1xx.2xx.1xx.1xx root password321
[Tue Jul 31 01:26:15 2018] 1xx.2xx.1xx.1xx root zxcvbnm
</code></pre>

<h2>Saving results to disk:</h2>

<p>Redirecting the output to a log file, running in the foreground as a screen session:</p>

<pre><code class="bash">$ screen -S honeypot
$ docker logs -f f6cb | grep -v 'Error exchanging' | awk '{print $6, $7, $8}' &gt;&gt; /var/log/ssh-honeypot.log
</code></pre>

<p>Detach from your screen session:</p>

<pre><code class="bash">Ctrl + a; d
</code></pre>

<p>Checking out the logs</p>

<pre><code class="bash">$ head -3 /var/log/ssh-honeypot.log
2.7.2x.1x root jiefan
4x.7.2x.1x root HowAreYou
4x.7.2x.1x root Sqladmin
</code></pre>

<p>Leaving this running for a couple of months, and I have a massive password database:</p>

<pre><code class="bash">$ wc -l /var/log/honeypot/ssh.log
54184260 /var/log/honeypot/ssh.log
</code></pre>

<p>That is correct, 54 million password attempts. 5372 Unique IPs, 4082 Unique Usernames, 88829 Unique Passwords.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dockerizing a Memcached Server for Docker on Alpine]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/09/01/dockerizing-a-memcached-server-for-docker-on-alpine/"/>
    <updated>2018-09-01T16:01:09-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/09/01/dockerizing-a-memcached-server-for-docker-on-alpine</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/memcached-logo.png" alt="" /></p>

<p>This post I will demostrate how to dockerize a memcached server on Alpine and how to create a boot script that allows you to pass environment variables through to the application.</p>

<h2>What is Memcached</h2>

<p>Memcached is a multi-threaded, in-memory key/value store for small chunks of arbitrary data (strings, objects) from results of database calls, API calls, etc. More on <a href="https://memcached.org/about">Memcached</a></p>

<h2>The Dockerfile:</h2>

<p>Our Dockerfile will consist of a simple install of memcached and add a boot script that we will start it from:</p>

<pre><code class="docker">FROM alpine:3.7

COPY boot.sh /boot.sh
RUN apk --no-cache add memcached &amp;&amp; chmod +x /boot.sh

USER memcached
CMD ["/boot.sh"]
</code></pre>

<h2>The Boot Script:</h2>

<p>As you can see we have set defaults so when the user does not specify any environment variables, that it will inherit the default values</p>

<pre><code class="bash">#!/bin/sh

/usr/bin/memcached \
  --user=${MEMCACHED_USER:-memcached} \
  --listen=${MEMCACHED_HOST:-0.0.0.0} \
  --port=${MEMCACHED_PORT:-11211} \
  --memory-limit=${MEMCACHED_MEMUSAGE:-64} \
  --conn-limit=${MEMCACHED_MAXCONN:-1024} \
  --threads=${MEMCACHED_THREADS:-4} \
  --max-reqs-per-event=${MEMCACHED_REQUESTS_PER_EVENT:-20} \
  --verbose
</code></pre>

<h2>Build and Deploy:</h2>

<p>Build the image, if you just want to run the container you can use my public image in the next step:</p>

<pre><code class="bash">$ docker build -t local/memcached:0.1 .
</code></pre>

<p>Run the Memcached Container:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 -e MEMCACHED_MEMUSAGE=32 local/memcached:0.1
</code></pre>

<p>Or my Public Image from Docker Hub:</p>

<pre><code class="bash">$ docker run -itd --name memcached -p 11211:11211 -e MEMCACHED_MEMUSAGE=32 rbekker87/memcached:alpine
</code></pre>

<h2>Check out the Stats:</h2>

<p>Pass the command <code>stats</code> through the exposed port:</p>

<pre><code>$ echo -e "stats" | nc localhost 11211                                                               
STAT pid 8
STAT uptime 2
STAT time 1535833177
STAT version 1.5.6
STAT libevent 2.1.8-stable
STAT pointer_size 64
STAT rusage_user 0.030000
STAT rusage_system 0.000000
STAT max_connections 1024
STAT curr_connections 1
STAT total_connections 2
STAT rejected_connections 0
STAT connection_structures 2
STAT reserved_fds 20
STAT cmd_get 0
STAT cmd_set 0
STAT cmd_flush 0
STAT cmd_touch 0
STAT get_hits 0
STAT get_misses 0
STAT get_expired 0
STAT get_flushed 0
STAT delete_misses 0
STAT delete_hits 0
STAT incr_misses 0
STAT incr_hits 0
STAT decr_misses 0
STAT decr_hits 0
STAT cas_misses 0
STAT cas_hits 0
STAT cas_badval 0
STAT touch_hits 0
STAT touch_misses 0
STAT auth_cmds 0
STAT auth_errors 0
STAT bytes_read 6
STAT bytes_written 0
STAT limit_maxbytes 33554432
STAT accepting_conns 1
STAT listen_disabled_num 0
STAT time_in_listen_disabled_us 0
STAT threads 4
STAT conn_yields 0
STAT hash_power_level 16
STAT hash_bytes 524288
STAT hash_is_expanding 0
STAT slab_reassign_rescues 0
STAT slab_reassign_chunk_rescues 0
STAT slab_reassign_evictions_nomem 0
STAT slab_reassign_inline_reclaim 0
STAT slab_reassign_busy_items 0
STAT slab_reassign_busy_deletes 0
STAT slab_reassign_running 0
STAT slabs_moved 0
STAT lru_crawler_running 0
STAT lru_crawler_starts 255
STAT lru_maintainer_juggles 155
STAT malloc_fails 0
STAT log_worker_dropped 0
STAT log_worker_written 0
STAT log_watcher_skipped 0
STAT log_watcher_sent 0
STAT bytes 0
STAT curr_items 0
STAT total_items 0
STAT slab_global_page_pool 0
STAT expired_unfetched 0
STAT evicted_unfetched 0
STAT evicted_active 0
STAT evictions 0
STAT reclaimed 0
STAT crawler_reclaimed 0
STAT crawler_items_checked 0
STAT lrutail_reflocked 0
STAT moves_to_cold 0
STAT moves_to_warm 0
STAT moves_within_lru 0
STAT direct_reclaims 0
STAT lru_bumps_dropped 0
END
</code></pre>

<p>Some descriptions:</p>

<p><code>evictions</code> - when items are evicted from the cache
<code>total_items</code> - the number of items the server has stored since it was started
<code>current_items</code> - the number of items in the cache
<code>bytes</code> - the current number of bytes used to store items
<code>limit_maxbytes</code> - the number of bytes the server is allowed to use for storage
<code>get_misses</code> - the number of times a item has been requested, but not found
<code>get_hits</code> - the number of times a item has been served from the cache</p>

<p>To get specific stats, like evictions:</p>

<pre><code class="bash">$ echo -e "stats" | nc localhost 11211 | grep -w evictions   
STAT evictions 0
</code></pre>

<p>When you see evictions value increases, this essentially means that memcache had to remove the oldest items from memory for new or more frequent used items. If this number remains high, consider increasing your memory allocated to memcache.</p>

<p>Slab Stats: returns information about each of the slabs created by memcached during runtime:</p>

<pre><code class="bash">$ echo -e "stats slabs" | nc localhost 11211                 
STAT active_slabs 0
STAT total_malloced 0
</code></pre>

<p><code>active_slabs</code> - Total number of slab classes allocated.
<code>total_malloced</code> - Total amount of memory allocated to slab pages.</p>

<p>For detailed description about statistics, have a look at their github resource:
- <a href="https://github.com/memcached/memcached/blob/master/doc/protocol.txt">https://github.com/memcached/memcached/blob/master/doc/protocol.txt</a></p>

<h2>Resources:</h2>

<ul>
<li><a href="https://memcached.org/">https://memcached.org/</a></li>
<li><a href="https://blog.serverdensity.com/monitor-memcached/">https://blog.serverdensity.com/monitor-memcached/</a></li>
<li><a href="https://wiki.mikejung.biz/Memcached">https://wiki.mikejung.biz/Memcached</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial on DynamoDB Using Bash and the AWS CLI Tools to Interact With a Music Dataset]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/14/tutorial-on-dynamodb-using-bash-and-the-aws-cli-tools-to-interact-with-a-music-dataset/"/>
    <updated>2018-08-14T16:33:22-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/14/tutorial-on-dynamodb-using-bash-and-the-aws-cli-tools-to-interact-with-a-music-dataset</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/aws-logo.png" alt="" /></p>

<p>In this tutorial we will be using Amazons DynamoDB (DynamoDB Local) to host a sample dataset consisting of music data that I retrieved from the iTunes API, which we will be using the aws cli tools to interact with the data.</p>

<p>We will be doing the following:</p>

<ul>
<li>Use Docker to provision a Local DynamoDB Server</li>
<li>Create a DynamoDB Table with a Hash and Range Key</li>
<li>List the Table</li>
<li>Create a Item in DynamoDB</li>
<li>Read a Item from DynamoDB</li>
<li>Read a Item from DynamoDB by specifying the details you would like to read</li>
<li>Batch Write multiple items to DynamoDB</li>
<li>Scan all your Items from DynamoDB</li>
<li>Query by Artist</li>
<li>Query by Artist and Song</li>
<li>Query all the Songs from an Artist starting with a specific letter</li>
<li>Indexes</li>
<li>Delete the Table</li>
</ul>


<p>If you are just getting started with DynamoDB, I recommend having a look at <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html">Amazons DynamoDB Documentation</a> Page first.</p>

<h2>The Music Dataset:</h2>

<p>I used the <a href="https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/">iTunes API</a> to get the music metadata, but I also have a post on <a href="http://blog.ruanbekker.com/blog/2018/05/08/use-python-requests-to-interact-with-the-itunes-api-to-search-for-music-info/">how to query the iTunes API</a> to get data from them to use.</p>

<p>a Quick way in Python to get the top 10 songs from Guns and Roses, will look like this:</p>

<pre><code class="python">&gt;&gt;&gt; a = 'https://itunes.apple.com/search?term=guns+and+roses&amp;limit=10'
&gt;&gt;&gt; b = requests.get(a).json()
&gt;&gt;&gt; print(json.dumps(b, indent=2))
</code></pre>

<h2>Create the DynamoDB Local Server on Docker:</h2>

<p>If you have a AWS Account you can provision your table from there, but if you want to test it locally, you can provision a local DynamoDB Server using Docker:</p>

<pre><code>$ docker run -it -p 8000:8000 --name dynamodb-local rbekker87/dynamodb-local
</code></pre>

<h2>Install the AWS CLI Tools:</h2>

<pre><code class="bash">$ pip install awscli
$ aws configure
# you can enter random data if you are using dynamodb-local
</code></pre>

<h2>Create the DynamoDB Table:</h2>

<p>Create a DynamoDB Table named <code>MusicCollection</code> with a <code>Artist (HASH)</code> and <code>SongTitle (RANGE)</code> key attributes:</p>

<pre><code class="bash">$ aws dynamodb create-table --table-name MusicCollection \
  --attribute-definitions AttributeName=Artist,AttributeType=S AttributeName=SongTitle,AttributeType=S \
  --key-schema AttributeName=Artist,KeyType=HASH AttributeName=SongTitle,KeyType=RANGE \
  --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
  --endpoint-url http://localhost:8000

Response:
{
    "TableDescription": {
        "TableArn": "arn:aws:dynamodb:ddblocal:000000000000:table/MusicCollection",
        "AttributeDefinitions": [
            {
                "AttributeName": "Artist",
                "AttributeType": "S"
            },
            {
                "AttributeName": "SongTitle",
                "AttributeType": "S"
            }
        ],
        "ProvisionedThroughput": {
            "NumberOfDecreasesToday": 0,
            "WriteCapacityUnits": 5,
            "LastIncreaseDateTime": 0.0,
            "ReadCapacityUnits": 5,
            "LastDecreaseDateTime": 0.0
        },
        "TableSizeBytes": 0,
        "TableName": "MusicCollection",
        "TableStatus": "ACTIVE",
        "KeySchema": [
            {
                "KeyType": "HASH",
                "AttributeName": "Artist"
            },
            {
                "KeyType": "RANGE",
                "AttributeName": "SongTitle"
            }
        ],
        "ItemCount": 0,
        "CreationDateTime": 1525339294.186
    }
}
</code></pre>

<h2>Listing the Tables:</h2>

<p>List the DynamoDB Table that you created:</p>

<pre><code class="bash">$ aws dynamodb list-tables --endpoint-url http://localhost:8000

{
    "TableNames": [
        "MusicCollection"
    ]
}
</code></pre>

<h2>Create a Item in DynamoDB:</h2>

<p>Add a song from the band <code>Bring me the Horizon</code> called <code>Sleepwalking</code> from the album <code>Sempiternal</code> to the table by using the <code>PutItem</code> call:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 put-item --table-name MusicCollection \
  --item '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}, "AlbumTitle": {"S": "Sempiternal"}}'
</code></pre>

<h2>Read a Item from DynamoDB</h2>

<p>Get the Song Details from the Table by using the <code>GetItem</code> call:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 get-item --table-name MusicCollection \
  --key  '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}}'

{
    "Item": {
        "Artist": {
            "S": "Bring me the Horizon"
        },
        "SongTitle": {
            "S": "Sleepwalking"
        },
        "AlbumTitle": {
            "S": "Sempiternal"
        }
    }
}
</code></pre>

<p>To only get specific attributes we can use <code>--aatributes-to-get</code>:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 get-item --table-name MusicCollection \
  --attributes-to-get '["AlbumTitle", "SongTitle"]' \
  --key  '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}}'

{
    "Item": {
        "SongTitle": {
            "S": "Sleepwalking"
        },
        "AlbumTitle": {
            "S": "Sempiternal"
        }
    }
}
</code></pre>

<p>However, AWS Recommends to use the <code>--projection-expression</code> parameter:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 get-item --table-name MusicCollection \
  --projection-expression "AlbumTitle, SongTitle" \
  --key  '{"Artist": {"S": "Bring me the Horizon"}, "SongTitle": {"S": "Sleepwalking"}}'

{
    "Item": {
        "SongTitle": {
            "S": "Sleepwalking"
        },
        "AlbumTitle": {
            "S": "Sempiternal"
        }
    }
}
</code></pre>

<ul>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.AttributesToGet.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.AttributesToGet.html</a></li>
</ul>


<h2>Batch Write</h2>

<p>Now lets use the <a href="https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/">iTunes API</a> to get a collection of some songs, which I will dump into a <a href="https://github.com/ruanbekker/dynamodb-local-docker/blob/master/demo/batch-write-songs.json">json file on github</a>. So now that we have a json file with a collection of songs from multiple artists, we can go ahead and write it into our table using the <code>BatchWriteItem</code> call:</p>

<pre><code class="bash">$ wget https://raw.githubusercontent.com/ruanbekker/dynamodb-local-docker/master/demo/batch-write-songs.json
$ aws dynamodb batch-write-item --request-items file://music-table/batch-write-songs.json --endpoint-url http://localhost:8000
</code></pre>

<h2>Scan the Table:</h2>

<p>This can be a very expensive call, as a <code>Scan</code> will return all the items from your table, and depending on the size of your table, you could be throttled, but since we are using dynamodb local and only having 16 items in our table, we can do a scan to return all the items in our table:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 scan --table-name MusicCollection
{
    "Count": 16,
</code></pre>

<h2>Query</h2>

<p>Let&rsquo;s start using the <code>Query</code> call to get all the songs from the Artist: AC/DC</p>

<ul>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.QueryFilter.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LegacyConditionalParameters.QueryFilter.html</a></li>
</ul>


<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --key-condition-expression "Artist = :a" \
  --expression-attribute-values  '{":a":{"S":"AC/DC"}}'

{
    "Count": 3,
    "Items": [
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "Back In Black"
            },
            "AlbumTitle": {
                "S": "Back In Black"
            }
        },
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "Thunderstruck"
            },
            "AlbumTitle": {
                "S": "The Razors Edge"
            }
        },
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "You Shook Me All Night Long"
            },
            "AlbumTitle": {
                "S": "Back in Black"
            }
        }
    ],
    "ScannedCount": 3,
    "ConsumedCapacity": null
}
</code></pre>

<p>Query to get the details of a specific Song from a specific Artist:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --key-condition-expression "Artist = :a and SongTitle = :t" \
  --expression-attribute-values  '{ ":a": {"S": "AC/DC"}, ":t": {"S": "You Shook Me All Night Long"}}'

{
    "Count": 1,
    "Items": [
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "You Shook Me All Night Long"
            },
            "AlbumTitle": {
                "S": "Back in Black"
            }
        }
    ],
    "ScannedCount": 1,
    "ConsumedCapacity": null
}
</code></pre>

<p>Query to get all the songs from the Beatles that starts with the letter &lsquo;H&rsquo;:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --key-condition-expression "Artist = :a and begins_with(SongTitle, :t)" \
  --expression-attribute-values  '{":a":{"S":"The Beatles"}, ":t": {"S": "h"}}'

{
    "Count": 2,
    "Items": [
        {
            "Artist": {
                "S": "The Beatles"
            },
            "SongTitle": {
                "S": "Happy Day"
            },
            "AlbumTitle": {
                "S": "The Beatles 1967-1970 (The Blue Album)"
            }
        },
        {
            "Artist": {
                "S": "The Beatles"
            },
            "SongTitle": {
                "S": "Help!"
            },
            "AlbumTitle": {
                "S": "The Beatles Box Set"
            }
        }
    ],
    "ScannedCount": 2,
    "ConsumedCapacity": null
}
</code></pre>

<p>So our table consists of Artist (HASH) and SongTitle (RANGE), so we can only query based on those attributes. You will find when you try to query on a attribute that is not part of the KeySchema, a exception will be received:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query --select ALL_ATTRIBUTES --table-name MusicCollection --key-condition-expression "Artist = :a and AlbumTitle = :t" --expression-attribute-values  '{":a":{"S":"AC/DC"}, ":t": {"S": "Back in Black"}}'

An error occurred (ValidationException) when calling the Query operation: Query condition missed key schema element
</code></pre>

<p>So how do we query on a attribute that is not part of the KeySchema? Let&rsquo;s say you want to query all the songs from a Artist and a specific Album.</p>

<h2>Global Secondary Indexes:</h2>

<p>Add Global Secondary Index, with the Attributes: Artist and AlbumTitle.</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 update-table --table-name MusicCollection \
  --attribute-definitions AttributeName=Artist,AttributeType=S AttributeName=SongTitle,AttributeType=S AttributeName=AlbumTitle,AttributeType=S \
  --global-secondary-index-updates "Create={"IndexName"="album-index", "KeySchema"=[ {"AttributeName"="Artist", "KeyType"="HASH"}, {"AttributeName"="AlbumTitle", "KeyType"="RANGE" }], "Projection"={"ProjectionType"="INCLUDE", "NonKeyAttributes"="AlbumTitle"}, "ProvisionedThroughput"= {"ReadCapacityUnits"=1, "WriteCapacityUnits"=1} }"

{
    "TableDescription": {
        "TableArn": "arn:aws:dynamodb:ddblocal:000000000000:table/MusicCollection",
        "AttributeDefinitions": [
            {
                "AttributeName": "Artist",
                "AttributeType": "S"
            },
            {
                "AttributeName": "SongTitle",
                "AttributeType": "S"
            },
            {
                "AttributeName": "AlbumTitle",
                "AttributeType": "S"
            }
        ],
        "GlobalSecondaryIndexes": [
            {
                "IndexName": "album-index",
                "Projection": {
                    "ProjectionType": "INCLUDE",
                    "NonKeyAttributes": [
                        "AlbumTitle"
                    ]
                },
                "ProvisionedThroughput": {
                    "WriteCapacityUnits": 1,
                    "ReadCapacityUnits": 1
                },
                "IndexStatus": "CREATING",
                "Backfilling": false,
                "KeySchema": [
                    {
                        "KeyType": "HASH",
                        "AttributeName": "Artist"
                    },
                    {
                        "KeyType": "RANGE",
                        "AttributeName": "AlbumTitle"
                    }
                ],
                "IndexArn": "arn:aws:dynamodb:ddblocal:000000000000:table/MusicCollection/index/album-index"
            }
        ],
        "ProvisionedThroughput": {
            "NumberOfDecreasesToday": 0,
            "WriteCapacityUnits": 5,
            "LastIncreaseDateTime": 0.0,
            "ReadCapacityUnits": 5,
            "LastDecreaseDateTime": 0.0
        },
        "TableSizeBytes": 984,
        "TableName": "MusicCollection",
        "TableStatus": "ACTIVE",
        "KeySchema": [
            {
                "KeyType": "HASH",
                "AttributeName": "Artist"
            },
            {
                "KeyType": "RANGE",
                "AttributeName": "SongTitle"
            }
        ],
        "ItemCount": 15,
        "CreationDateTime": 1525339294.186
    }
}
</code></pre>

<p>Now when we use the same query, but we specify our index, we will get the data:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 query \
  --select ALL_ATTRIBUTES \
  --table-name MusicCollection \
  --index-name album-index \
  --key-condition-expression "Artist = :a and AlbumTitle = :t" \
  --expression-attribute-values  '{":a":{"S":"AC/DC"}, ":t": {"S": "Back in Black"}}'

{
    "Count": 1,
    "Items": [
        {
            "Artist": {
                "S": "AC/DC"
            },
            "SongTitle": {
                "S": "You Shook Me All Night Long"
            },
            "AlbumTitle": {
                "S": "Back in Black"
            }
        }
    ],
    "ScannedCount": 1,
    "ConsumedCapacity": null
}
</code></pre>

<h2>Delete the Table:</h2>

<p>Delete the Table that we created:</p>

<pre><code class="bash">$ aws dynamodb --endpoint-url http://localhost:8000 delete-table --table-name MusicCollection
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.Query.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.ReadData.Query.html</a></li>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Indexes.html">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.Indexes.html</a></li>
<li><a href="https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/">https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
