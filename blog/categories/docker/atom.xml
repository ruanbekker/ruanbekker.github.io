<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2021-01-31T12:07:39-05:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reduce Docker Log Size on Disk]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/12/23/reduce-docker-log-size-on-disk/"/>
    <updated>2020-12-23T04:11:35-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/12/23/reduce-docker-log-size-on-disk</id>
    <content type="html"><![CDATA[<p>In cases where you are using the defaults for logging and your application logs a lot you can consume a lot of disk space and you can run out of disk space quite quickly.</p>

<p>If it&rsquo;s a case where you already ran out of disk space, we can investigate the disk space consumed by docker logs:</p>

<pre><code>$ cd /var/lib/docker/containers
$ du -sh *
6.0G    14052251a0f13f46f65bc73d10c01408130ee8ae71529600ba5bd6bee76af4ee
1.2G    e6b40b1d30c5cf05e8cb201ca9abf6bd283d7cf7ceaa3be2a0422be7cd750a33
</code></pre>

<p>Referenced from <a href="https://blog.birkhoff.me/devops-truncate-docker-container-logs-periodically-to-free-up-server-disk-space/">https://blog.birkhoff.me/devops-truncate-docker-container-logs-periodically-to-free-up-server-disk-space/</a> you can truncate those files:</p>

<pre><code>$ sh -c 'truncate -s 0 /var/lib/docker/containers/*/*-json.log'
</code></pre>

<p>Check the size again:</p>

<pre><code>$ du -sh *
40K 14052251a0f13f46f65bc73d10c01408130ee8ae71529600ba5bd6bee76af4ee
36K e6b40b1d30c5cf05e8cb201ca9abf6bd283d7cf7ceaa3be2a0422be7cd750a33
</code></pre>

<p>To overcome this issue you can use this in logging options in your compose:</p>

<pre><code>...
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
...
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTPS for Local Development With MiniCA]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/12/23/https-for-local-development-with-minica/"/>
    <updated>2020-12-23T03:11:08-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/12/23/https-for-local-development-with-minica</id>
    <content type="html"><![CDATA[<p>In this tutorial we will use <a href="https://github.com/jsha/minica">minica</a> to enable us to run our web applications over HTTPS for local development.</p>

<p>To read more about about <a href="https://github.com/jsha/minica">minica</a> check out their website.</p>

<h2>Generate Certificates</h2>

<p>You can use their binary from their github page or use my docker image to generate the certificates to a <code>./certs</code> directory:</p>

<pre><code>$ docker run --user "$(id -u):$(id -g)" -it -v $PWD/certs:/output ruanbekker/minica --domains 192.168.0.20.nip.io
</code></pre>

<p>In the case from above, we are generating certificates for the FQDN <code>192.168.0.20.nip.io</code>. You will find the generated certificates under <code>./certs/</code>.</p>

<h2>Application Stack</h2>

<p>We will use docker to create a nginx webserver to serve our content via https using the generated vertificates.</p>

<p>Our <code>docker-compose.yml</code>:</p>

<pre><code>version: '3.7'
services:
  nginx:
    image: nginx
    container_name: nginx
    ports:
      - 80:80
      - 443:443
    volumes:
      - ~/personal/docker-minica-nginx/nginx.conf:/etc/nginx/nginx.conf
      - ~/personal/docker-minica-nginx/ssl.conf:/etc/nginx/conf.d/ssl.conf
      - ~/personal/docker-minica-nginx/certs/192.168.0.6.nip.io:/etc/nginx/certs
      - ~/personal/docker-minica-nginx/html/index.html:/usr/share/nginx/html/index.html
</code></pre>

<p>Our <code>nginx.conf</code>:</p>

<pre><code>user  nginx;
worker_processes  1;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    keepalive_timeout  65;
    include /etc/nginx/conf.d/ssl.conf;
}
</code></pre>

<p>Our <code>ssl.conf</code>:</p>

<pre><code>server {
    listen 80;
    server_name 192.168.0.6.nip.io;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    server_name 192.168.0.6.nip.io;

    ssl_certificate /etc/nginx/certs/cert.pem;
    ssl_certificate_key /etc/nginx/certs/key.pem;

    location / {
        root   /usr/share/nginx/html;
        index  index.html;
    }
}
</code></pre>

<p>Our <code>html/index.html</code>:</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang="en-us"&gt;
&lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"&gt;
    &lt;script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"&gt;&lt;/script&gt;
    &lt;title&gt;Sample Page&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div class="container-fluid"&gt;
        &lt;div class="row"&gt;
            &lt;div class="bitProcessor"&gt;&lt;/div&gt;
            &lt;div class="col-md-12" style="background-color: white; position: absolute; top: 40%;width: 80%;left: 10%;"&gt;
                &lt;center&gt;
                    &lt;h1&gt;Hello, World!&lt;/h1&gt;
                    &lt;p&gt;This is sample text.&lt;/p&gt;
                &lt;/center&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<h2>Import Certificates</h2>

<p>We have a certificate <code>./certs/minica.pem</code> which we need to import and trust on our local workstation, I am using a Mac so it will be Keychain Access.</p>

<p><img src="https://user-images.githubusercontent.com/567298/101961866-5a2ee500-3c13-11eb-9f89-03fa1bd4670d.png" alt="image" /></p>

<p>Once you open Keychain Access, select &ldquo;file&rdquo;, &ldquo;import items&rdquo; and browse and import <code>./certs/minica.pem</code>, once you are done search for minica:</p>

<p><img src="https://user-images.githubusercontent.com/567298/101962064-d4f80000-3c13-11eb-9479-c043ba3ced2c.png" alt="image" /></p>

<p>Select the item, file -> get info, expand trust, change &ldquo;when using this certificate&rdquo; to Always trust and close.</p>

<p>You will now see the root ca is trusted:</p>

<p><img src="https://user-images.githubusercontent.com/567298/101962197-2dc79880-3c14-11eb-8d26-49874c9703fa.png" alt="image" /></p>

<h2>Boot the Application Stack</h2>

<p>As we have <code>docker-compose.yml</code> in our current working directory, we can use docker-compose to boot our application:</p>

<pre><code>$ docker-compose up
Creating network "docker-minica-nginx_default" with the default driver
Creating nginx ... done
Attaching to nginx
</code></pre>

<p>Now when we browse to <code>https://192.168.0.6.nip.io</code> we will see:</p>

<p><img src="https://user-images.githubusercontent.com/567298/101962367-a9c1e080-3c14-11eb-898b-688b50c1b9db.png" alt="image" /></p>

<p>And when we inspect the certificate, we can see its valid:</p>

<p><img src="https://user-images.githubusercontent.com/567298/101962411-c78f4580-3c14-11eb-80cd-cf8e449eca95.png" alt="image" /></p>

<h2>Thank You</h2>

<p>Thank you for reading.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploy Loki on Multipass]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/11/11/deploy-loki-on-multipass/"/>
    <updated>2020-11-11T14:19:05+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/11/11/deploy-loki-on-multipass</id>
    <content type="html"><![CDATA[<p><img src="https://sysadmins.co.za/content/images/size/w1600/2020/11/loki-banner-2.png" alt="" /></p>

<p>In this post I will demonstrate how to deploy Grafana Labs&rsquo;s <strong>Loki</strong> on <strong>Multipass</strong> using cloud-init so that you can run your own dev environment and run a couple of queries to get you started.</p>

<h2>About</h2>

<p>If you haven&rsquo;t heard of <a href="https://multipass.run/">Multipass</a>, it allows you to run Ubuntu VMs on your Mac or Windows workstation.</p>

<p>If you haven&rsquo;t heard of <a href="https://grafana.com/oss/loki/">Loki</a>, as described by Grafana Labs: <em>&ldquo;Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by Prometheus.&rdquo;</em></p>

<h2>Install Multipass</h2>

<p>Head over to <a href="https://multipass.run/">multipass.run</a> to get the installer for your operating system, and if you are curious about Multipass, I wrote a beginners guide on Multipass which can be <strong><a href="https://sysadmins.co.za/getting-started-with-multipass-vms/">found here</a></strong></p>

<h2>Cloud Init for Loki</h2>

<p>We will be making use of <strong><a href="https://cloudinit.readthedocs.io/en/latest/">cloud-init</a></strong> to bootstrap <strong><a href="https://github.com/grafana/loki/releases/tag/v2.0.0">Loki v2.0.0</a></strong> to our multipass instance.</p>

<p>V2.0.0 is the current release of the time of writing, so depending on the time when you read this, have a look at the <a href="https://github.com/grafana/loki/releases">Loki Releases</a> page for the latest version and adjust the cloud-init.yml according to the version if it differs from the one I&rsquo;m mentioning.</p>

<p>(Optional) If you want to use SSH to your Multipass VM, you can use your existing SSH key or generate a new one, if you want to create a new key, you can <a href="https://sysadmins.co.za/getting-started-with-multipass-vms/">follow this post</a></p>

<p>Copy your public key, in my case <code>~/.ssh/id_rsa.pub</code> and paste it under the ssh <code>authorized_keys</code> section.</p>

<p>Our <code>cloud-init.yml</code> has a couple of sections, but to break it down it will do the following:</p>

<ul>
<li>We provide it our public ssh key so that we can ssh with our private key</li>
<li>Updates the index repository</li>
<li>Installs the packages, unzip and wget</li>
<li>Creates the loki systemd unit file and places it under /etc/systemd/system/</li>
<li>When the vm boots it will create the user loki and creates the loki etc directory</li>
<li>Once that completes, we are downloading the loki, logcli and promtail binaries from github</li>
</ul>


<pre><code class="yaml">#cloud-config
ssh_authorized_keys:
  - ssh-rsa AAAA...Ha9 your-comment

package_update: true

packages:
 - unzip
 - wget

write_files:
  - content: |-
      [Unit]
      Description=Loki
      User=loki
      Group=loki
      Wants=network-online.target
      After=network-online.target
      [Service]
      Type=simple
      Restart=on-failure
      ExecStart=/usr/local/bin/loki -config.file /etc/loki/loki-local-config.yaml
      [Install]
      WantedBy=multi-user.target

    owner: root:root
    path: /etc/systemd/system/loki.service
    permissions: '0644'

bootcmd:
  - useradd --no-create-home --shell /bin/false loki
  - mkdir /etc/loki
  - chown -R loki:loki /etc/loki

runcmd:
 - for app in loki logcli promtail; do wget "https://github.com/grafana/loki/releases/download/v2.0.0/${app}-linux-amd64.zip"; done
 - for app in loki logcli promtail; do unzip "${app}-linux-amd64.zip"; done
 - for app in loki logcli promtail; do mv "${app}-linux-amd64" /usr/local/bin/${app}; done
 - for app in loki logcli promtail; do rm -f "${app}-linux-amd64.zip"; done
 - wget https://raw.githubusercontent.com/grafana/loki/v2.0.0/cmd/loki/loki-local-config.yaml
 - mv ./loki-local-config.yaml /etc/loki/loki-local-config.yaml
 - chown loki:loki /etc/loki/loki-local-config.yaml
 - systemctl daemon-reload
 - systemctl start loki
 - sleep 5
 - echo "this is a test" | promtail --stdin --client.url http://localhost:3100/loki/api/v1/push --client.external-labels=app=cli -server.disable
</code></pre>

<p>You will notice that the VM will have <code>loki</code>, <code>logcli</code> and <code>promtail</code> available on it, so you will have an environment to use all of them together.</p>

<p>As you can see once we start loki, we are piping <code>this is a test</code> to Loki using Promtail, so that we can verify that the data is visible in Loki. That step is not required, but just added it to this demo.</p>

<h2>Deploy Loki on Multipass</h2>

<p>We will provision a Multipass VM using the Ubuntu Focal distribution and spec our VM with 1 CPU, 512MB of Memory and 1GB of disk and then bootstrap our installation of Loki using cloud-init:</p>

<pre><code class="bash">$ multipass launch focal \
  --name loki \
  --cpus 1 \
  --mem 512m \
  --disk 1G \
  --cloud-init cloud-init.yml

Creating: loki
Waiting for initialization to complete 
Launched: loki
</code></pre>

<p>We can validate if our Multipass VM is running:</p>

<pre><code class="bash">$ multipass list
Name                    State             IPv4             Image
loki                    Running           192.168.64.19    Ubuntu 20.04 LTS
</code></pre>

<h2>Test Loki inside the VM</h2>

<p>First we will exec into the VM (or SSH), then we will test out Loki inside the VM since we already have logcli available:</p>

<pre><code class="bash">$ multipass exec loki -- bash
To run a command as administrator (user "root"), use "sudo &lt;command&gt;".
See "man sudo_root" for details.

ubuntu@loki:~$
</code></pre>

<p>Remembered in our cloud-init, we instructed this command to run:</p>

<pre><code class="bash">echo "this is a test" | promtail --stdin --client.url http://localhost:3100/loki/api/v1/push --client.external-labels=app=cli -server.disable
</code></pre>

<p>So if we use logcli, we can inspect our visible labels:</p>

<pre><code>$ logcli --quiet labels
__name__
app
hostname
job
</code></pre>

<p>And as we expect, we will see the app label from the <code>--client.external-labels=app=cli</code> argument that we passed. We can also look at the values for a given label:</p>

<pre><code class="bash">$ logcli --quiet labels app
cli
</code></pre>

<p>Now let&rsquo;s query our logs using the label selector: <code>{app="cli"}</code>:</p>

<pre><code class="bash">$ logcli --quiet --output raw query '{app="cli"}'
this is a test
</code></pre>

<p>If we remove the extra arguments, we will see more verbose output like the following:</p>

<pre><code class="bash">$ logcli query '{app="cli"}'

http://localhost:3100/loki/api/v1/query_range?direction=BACKWARD&amp;end=1605092055756745122&amp;limit=30&amp;query=%7Bapp%3D%22cli%22%7D&amp;start=1605088455756745122
Common labels: {app="cli", hostname="loki", job="stdin"}
2020-11-11T12:45:20+02:00 {} this is a test
http://localhost:3100/loki/api/v1/query_range?direction=BACKWARD&amp;end=1605091520778438972&amp;limit=30&amp;query=%7Bapp%3D%22cli%22%7D&amp;start=1605088455756745122
Common labels: {app="cli", hostname="loki", job="stdin"}
</code></pre>

<p>We can pipe some more output to Loki:</p>

<pre><code class="bash">$ echo "this is another test" | promtail --stdin --client.url http://localhost:3100/loki/api/v1/push --client.external-labels=app=cli -server.disable
</code></pre>

<p>And querying our logs:</p>

<pre><code class="bash">$ logcli --quiet --output raw query '{app="cli"}'
this is another test
this is a test
</code></pre>

<h2>Testing Loki Outside our VM</h2>

<p>Let&rsquo;s exit the VM and test Loki from our local workstation, first you will need to get the logcli for your OS, head over to the <a href="https://github.com/grafana/loki/releases">releases</a> page and get the binary of your choice.</p>

<p>I will be demonstrating using a mac:</p>

<pre><code class="bash">$ wget https://github.com/grafana/loki/releases/download/v2.0.0/logcli-darwin-amd64.zip
$ unzip logcli-darwin-amd64.zip
$ sudo mv logcli-darwin-amd64 /usr/local/bin/logcli
$ rm -f logcli-darwin-amd64.zip
</code></pre>

<p>Now we need to tell logcli where our Loki server resides, so let&rsquo;s get the IP address of Loki:</p>

<pre><code class="bash">$ multipass info --all --format json | jq -r '.info.loki.ipv4[]'
192.168.64.19
</code></pre>

<p>We can either set the Loki host as an environment variable:</p>

<pre><code class="bash">$ export LOKI_ADDR=http://192.168.64.19
</code></pre>

<p>or you can specify it using the <code>--addr</code> argument:</p>

<pre><code class="bash">$ logcli --addr="http://192.168.64.19:3100"
</code></pre>

<p>For the sake of simplicity and not having to type the <code>--addr</code> the whole time, I will be setting the Loki address as an environment variable:</p>

<pre><code class="bash">$ export LOKI_ADDR="http://$(multipass info --all --format json | jq -r '.info.loki.ipv4[]'):3100"
</code></pre>

<p>And when we inspect our labels using logcli, we can see that we are getting our labels from Loki on our Multipass VM:</p>

<pre><code class="bash">$ logcli labels
http://192.168.64.19:3100/loki/api/v1/labels?end=1605093229877731000&amp;start=1605089629877731000
__name__
app
hostname
job
</code></pre>

<h2>Write Logs to Loki using the Loki Docker Driver</h2>

<p>We have used promtail before to pipe logs to Loki and in this example we will be making use of the Loki Docker Logging Plugin to write data to Loki.</p>

<p>If you have docker installed, install the Loki plugin:</p>

<pre><code class="bash">$ docker plugin install \
  grafana/loki-docker-driver:latest \
  --alias loki \
  --grant-all-permissions
</code></pre>

<p>Now we will use a docker container to echo stdout to the loki docker driver, which will send the output to Loki.</p>

<p>Let&rsquo;s alias a command loki_echo that we will use to send our output to the docker container:</p>

<pre><code class="bash">$ alias 'loki_echo=docker run --rm -it --log-driver loki --log-opt loki-url="http://192.168.64.19:3100/loki/api/v1/push" --log-opt loki-external-labels="app=echo-container" busybox echo'
</code></pre>

<p>So every time we run <code>loki_echo {string}</code> we will run a docker container from the busybox image and pass the <code>{string}</code> as an argument to the echo command inside the container, which will be sent to the loki log driver and land up in Loki.</p>

<p>Let&rsquo;s push 100 log events to Loki:</p>

<pre><code class="bash">$ count=0
$ while [ ${count} != 100 ]
  do 
    for color in red blue white silver green;
    do 
      loki_echo "there are ${RANDOM} items of ${color} available";
      count=$((count+1))
    done
  done

there are 26890 items of green available
there are 14856 items of red available
there are 31162 items of blue available
there are 23993 items of white available
there are 22310 items of silver available
there are 10700 items of green available
there are 14077 items of red available
there are 20642 items of blue available
there are 31576 items of white available
there are 26053 items of silver available
there are 2973 items of green available
there are 2203 items of red available
there are 8557 items of blue available
...
</code></pre>

<p>We can verify how many log events we have with:</p>

<pre><code>$ logcli query '{app="echo-container"}' --quiet --limit 200 --output raw | wc -l
100
</code></pre>

<p>To see how many logs we have with the line &ldquo;blue&rdquo; in it:</p>

<pre><code class="bash">$ logcli query '{app="echo-container"} |= "blue"' --quiet --limit 200 --output raw | wc -l
20
</code></pre>

<p>Let&rsquo;s look for logs with blue or green and limit the results to 5:</p>

<pre><code class="bash">$ logcli query '{app="echo-container"} |~ "items of (blue|green)"' --quiet --limit 5 --output raw
there are 28985 items of green available
there are 10289 items of blue available
there are 12316 items of green available
there are 23775 items of blue available
there are 20 items of green available
</code></pre>

<h2>Teardown</h2>

<p>If you followed along, you can terminate your Multipass VM with:</p>

<pre><code class="bash">$ multipass delete --purge loki
</code></pre>

<p>You can get the example code in my <strong><a href="https://github.com/ruanbekker/multipassfiles/tree/master/loki">multipassfiles github repository</a></strong></p>

<h2>Thanks</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Setup Alerting With Loki]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/11/06/how-to-setup-alerting-with-loki/"/>
    <updated>2020-11-06T15:13:53+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/11/06/how-to-setup-alerting-with-loki</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/98380823-bd948880-2051-11eb-8ab4-c8d5f5d3e612.png" alt="image" /></p>

<p>Recently Grafana Labs announced <strong><a href="https://grafana.com/blog/2020/10/28/loki-2.0-released-transform-logs-as-youre-querying-them-and-set-up-alerts-within-loki/">Loki v2</a></strong> and its awesome! Definitely check out their blog post on more details.</p>

<p>Loki has a index option called <strong>boltdb-shipper</strong>, which allows you to run Loki with only a object store and you <strong>no longer need a dedicated index store</strong> such as DynamoDB. You can extract labels from log lines at query time, which is CRAZY! And I really like how they&rsquo;ve implemented it, you can parse, filter and format like mad. I really like that.</p>

<p>And then generating alerts from any query, which we will go into today. Definitely check out <a href="https://grafana.com/blog/2020/10/28/loki-2.0-released-transform-logs-as-youre-querying-them-and-set-up-alerts-within-loki/">this blogpost</a> and <a href="https://grafana.com/blog/2020/11/04/video-top-three-features-of-the-new-loki-2.0/">this video</a> for more details on the features of Loki v2.</p>

<h2>What will we be doing today</h2>

<p>In this tutorial we will setup a alert using the Loki local ruler to alert us when we have <strong>high number of log events coming in</strong>. For example, let&rsquo;s say someone has debug logging enabled in their application and we want to send a alert to slack when it breaches the threshold.</p>

<p>I will simulate this with a <code>http-client</code> container which runs <code>curl</code> in a while loop to fire a bunch of http requests against the nginx container which logs to Loki, so we can see how the alerting works, and in this scenario we will alert to Slack.</p>

<p>And after that we will stop our http-client container to see how the alarm resolves when the log rate comes down again.</p>

<p>All the components are available in the <code>docker-compose.yml</code> on my <a href="https://github.com/ruanbekker/loki-alerts-docker">github repository</a></p>

<h2>Components</h2>

<p>Let&rsquo;s break it down and start with the loki config:</p>

<pre><code>...
ruler:
  storage:
    type: local
    local:
      directory: /etc/loki/rules
  rule_path: /tmp/loki/rules-temp
  alertmanager_url: http://alertmanager:9093
  ring:
    kvstore:
      store: inmemory
  enable_api: true
  enable_alertmanager_v2: true
</code></pre>

<p>In the section of the loki config, I will be making use of the local ruler and map my alert rules under <code>/etc/loki/rules/</code> and we are also defining our alertmanager instance where these alerts should be shipped to.</p>

<p>In my rule definition <code>/etc/loki/rules/demo/rules.yml</code>:</p>

<pre><code>groups:
  - name: rate-alerting
    rules:
      - alert: HighLogRate
        expr: |
          sum by (compose_service)
            (rate({job="dockerlogs"}[1m]))
            &gt; 60
        for: 1m
        labels:
            severity: warning
            team: devops
            category: logs
        annotations:
            title: "High LogRate Alert"
            description: "something is logging a lot"
            impact: "impact"
            action: "action"
            dashboard: "https://grafana.com/service-dashboard"
            runbook: "https://wiki.com"
            logurl: "https://grafana.com/log-explorer"
</code></pre>

<p>In my expression, I am using LogQL to return per second rate of all my docker logs within the last minute per compose service for my dockerlogs job and we are specifying that it should alert when the threshold is above 60.</p>

<p>As you can see I have a couple of <strong>labels and annotations</strong>, which becomes <strong>very useful</strong> when you have dashboard links, runbooks etc and you would like to map that to your alert. I am doing the mapping in my <code>alertmanager.yml</code> config:</p>

<pre><code>route:
...
  receiver: 'default-catchall-slack'
  routes:
  - match:
      severity: warning
    receiver: warning-devops-slack
    routes:
    - match_re:
        team: .*(devops).*
      receiver: warning-devops-slack

receivers:
...
- name: 'warning-devops-slack'
  slack_configs:
    - send_resolved: true
      channel: '__SLACK_CHANNEL__'
      title: ':fire::white_check_mark: []  '
      text: &gt;-
        
          *Description:* 
          *Severity:* ``
          *Graph:* &lt;|:chart_with_upwards_trend:&gt;&lt;|:chart_with_upwards_trend:&gt; *Dashboard:* &lt;|:bar_chart:&gt; *Runbook:* &lt;|:spiral_note_pad:&gt;
          *Details:*
           - *:* ``
          
           - *Impact*: 
           - *Receiver*: warning--slack
        
</code></pre>

<p>As you can see, when my alert matches nothing it will go to my catchall receiver, but when my label contains <code>devops</code> and the route the alert to my <code>warning-devops-slack</code> receiver, and then we will be parsing our labels and annotations to include the values in our alarm on slack.</p>

<h2>Demo</h2>

<p>Enough with the background details, and it&rsquo;s time to get into the action.</p>

<p>All the code for this demonstration will be available in my github repository: <strong><a href="https://github.com/ruanbekker/loki-alerts-docker">github.com/ruanbekker/loki-alerts-docker</a></strong></p>

<p>The docker-compose will have a container of <strong>grafana</strong>, <strong>alertmanager</strong>, <strong>loki</strong>, <strong>nginx</strong> and a <strong>http-client</strong>.</p>

<p>The http-client is curl in a while loop that will just make a bunch of http requests against the nginx container, which will be logging to loki.</p>

<h2>Get the source</h2>

<p>Get the code from my github repository:</p>

<pre><code>$ git clone https://github.com/ruanbekker/loki-alerts-docker
$ cd loki-alerts-docker
</code></pre>

<p>You will need to replace the slack webhook url and the slack channel where you want your alerts to be sent to. This will take the environment variables and replace the values in <code>config/alertmanager.yml</code> (always check out the script first, before executing it)</p>

<pre><code>$ SLACK_WEBHOOK_URL="https://hooks.slack.com/services/xx/xx/xx" SLACK_CHANNEL="#notifications" ./parse_configs.sh
</code></pre>

<p>You can double check by running <code>cat config/alertmanager.yml</code>, once you are done, boot the stack:</p>

<pre><code>$ docker-compose up -d
</code></pre>

<p>Open up grafana:</p>

<pre><code>$ open http://grafana.localdns.xyz:3000
</code></pre>

<p>Use the initial user and password combination <code>admin/admin</code> and then reset your password:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98379039-7efdce80-204f-11eb-9c8a-3ed12a63cb14.png" alt="image" /></p>

<p>Browse for your labels on the log explorer section, in my example it will be <code>{job="dockerlogs"}</code>:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98379172-ace31300-204f-11eb-8e6c-3cf073afe771.png" alt="image" /></p>

<p>When we select our job=&ldquo;dockerlogs&rdquo; label, we will see our logs:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98379288-c71cf100-204f-11eb-911c-043a983bae6d.png" alt="image" /></p>

<p>As I explained earlier the query that we will be running in our ruler, can be checked what the rate currently is:</p>

<pre><code>sum by (compose_project, compose_service) (rate({job="dockerlogs"}[1m]))
</code></pre>

<p>Which will look like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98379765-54604580-2050-11eb-9c90-5e0adf2bb586.png" alt="image" /></p>

<p>In the configured expression in our ruler config, we have set to alarm once the value goes above 60, we can validate this by running:</p>

<pre><code>sum by (compose_project, compose_service) (rate({job="dockerlogs"}[1m])) &gt; 60
</code></pre>

<p>And we can verify that this is the case, and by now it should be alarming:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98379900-84a7e400-2050-11eb-87d0-ae52617d195e.png" alt="image" /></p>

<p>Head over to alertmanager:</p>

<pre><code>$ open http://alertmanager.localdns.xyz:9093
</code></pre>

<p>We can see alertmanager is showing the alarm:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98380013-af923800-2050-11eb-8585-f7489bf722cb.png" alt="image" /></p>

<p>When we head over to slack, we can see our notification:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98380158-de101300-2050-11eb-8d73-20828124fab5.png" alt="image" /></p>

<p>So let&rsquo;s stop our http client:</p>

<pre><code>$ docker-compose stop http-client
Stopping http-client ... done
</code></pre>

<p>Then we can see the logging stopped:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98380907-e0bf3800-2051-11eb-99c3-b3b9ac22bba5.png" alt="image" /></p>

<p>And in slack, we should see that the alarm recovered and we should see the notification:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98381360-722eaa00-2052-11eb-8bb4-07cdc8ffa7ee.png" alt="image" /></p>

<p>Then you can terminate your stack:</p>

<pre><code>$ docker-compose down
</code></pre>

<p>Pretty epic stuff right? I really love how cost effective Loki is as logging use to be so expensive to run and especially maintain, Grafana Labs are really doing some epic work and my hat goes off to them.</p>

<h2>Thanks</h2>

<p>I hope you found this useful, feel free to reach out to me on Twitter <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> or visit me on my website <strong><a href="https://ruan.dev">ruan.dev</a></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a NFS Server With Docker]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/09/20/setup-a-nfs-server-with-docker/"/>
    <updated>2020-09-20T16:07:09+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/09/20/setup-a-nfs-server-with-docker</id>
    <content type="html"><![CDATA[<p>In this tutorial we will setup a <strong>NFS Server</strong> using <strong>Docker</strong> for our development environment.</p>

<h2>Host Storage Path</h2>

<p>In this example we will be using our host path <code>/data/nfs-storage</code> which will host our storage for our NFS server, which will will mount to the container:</p>

<pre><code>$ mkdir -p /data/nfs-storage
</code></pre>

<h2>NFS Server</h2>

<p>Create the NFS Server with docker:</p>

<pre><code>$ docker run -itd --privileged \
  --restart unless-stopped \
  -e SHARED_DIRECTORY=/data \
  -v /data/nfs-storage:/data \
  -p 2049:2049 \
  itsthenetwork/nfs-server-alpine:12
</code></pre>

<p>We can do the same using docker-compose, for our <code>docker-compose.yml</code>:</p>

<pre><code>version: "2.1"
services:
  # https://hub.docker.com/r/itsthenetwork/nfs-server-alpine
  nfs:
    image: itsthenetwork/nfs-server-alpine:12
    container_name: nfs
    restart: unless-stopped
    privileged: true
    environment:
      - SHARED_DIRECTORY=/data
    volumes:
      - /data/nfs-storage:/data
    ports:
      - 2049:2049
</code></pre>

<p>To deploy using docker-compose:</p>

<pre><code>$ docker-compose up -d
</code></pre>

<h2>NFS Client</h2>

<p>To use a NFS Client to mount this to your filesystem, you can look at <a href="https://blog.ruanbekker.com/blog/2017/12/05/setup-a-nfs-server-on-a-raspberrypi/" rel="nofollow" target="_blank">this blogpost></a></p>

<p>In summary:</p>

<pre><code>$ sudo apt install nfs-client -y
$ sudo mount -v -o vers=4,loud 192.168.0.4:/ /mnt
</code></pre>

<p>Verify that the mount is showing:</p>

<pre><code>$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda2       109G   53G   51G  52% /
192.168.0.4:/   4.5T  2.2T  2.1T  51% /mnt
</code></pre>

<p>Now, create a test file on our NFS export:</p>

<pre><code>$ touch /mnt/file.txt
</code></pre>

<p>Verify that the test file is on the local path:</p>

<pre><code>$ ls /data/nfs-storage/
file.txt
</code></pre>

<p>If you want to load this into other client&rsquo;s <code>/etc/fstab</code>:</p>

<pre><code>192.168.0.4:/   /mnt   nfs4    _netdev,auto  0  0
</code></pre>

<h2>NFS Docker Volume Plugin</h2>

<p>You can use a NFS Volume Plugin for Docker or Docker Swarm for persistent container storage.</p>

<p>To use the NFS Volume plugin, we need to download <a href="https://github.com/ContainX/docker-volume-netshare/releases" target="_blank" rel="nofollow">docker-volume-netshare</a> from their github releases page.</p>

<pre><code>$ wget https://github.com/ContainX/docker-volume-netshare/releases/download/v0.36/docker-volume-netshare_0.36_amd64.deb
$ dpkg -i docker-volume-netshare_0.36_amd64.deb
$ service docker-volume-netshare start
</code></pre>

<p>Then your <code>docker-compose.yml</code>:</p>

<pre><code>version: '3.7'

services:
  mysql:
    image: mariadb:10.1
    networks:
      - private
    environment:
      - MYSQL_ROOT_PASSWORD=${DATABASE_PASSWORD:-admin}
      - MYSQL_DATABASE=testdb
      - MYSQL_USER=${DATABASE_USER:-admin}
      - MYSQL_PASSWORD=${DATABASE_PASSWORD:-admin}
    volumes:
      - mysql_data.vol:/var/lib/mysql

volumes:
  mysql_data.vol:
    driver: nfs
    driver_opts:
      share: 192.168.69.1:/mysql_data_vol
</code></pre>

<h2>Thank You</h2>

<p>That&rsquo;s it. Thanks for reading, follow me on Twitter and say hi! <a href="https://twitter.com/ruanbekker" rel="nofollow" target="_blank"><strong>@ruanbekker</strong></a></p><p><a href="https://saythanks.io/to/ruan.ru.bekker@gmail.com" rel="nofollow" target="_blank"><img src="https://svgshare.com/i/Pfy.svg" alt="Say Thanks!"></a></p></p>
]]></content>
  </entry>
  
</feed>
