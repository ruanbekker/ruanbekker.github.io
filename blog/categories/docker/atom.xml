<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2019-04-28T12:29:53-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Drone CI to Build a Jekyll Site and Deploy to Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/04/23/using-drone-ci-to-build-a-jekyll-site-and-deploy-to-docker-swarm/"/>
    <updated>2019-04-23T17:57:02-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/04/23/using-drone-ci-to-build-a-jekyll-site-and-deploy-to-docker-swarm</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/56618556-3de7ca00-6623-11e9-995f-c22792f0ab21.png" alt="image" /></p>

<p>CICD Pipelines! &lt;3</p>

<p>In this post I will show you how to setup a cicd pipeline using drone to build a jekyll site and deploy to docker swarm.</p>

<h2>Environment Overview</h2>

<p><strong>Jekyll&rsquo;s Codebase</strong>: Our code will be hosted on Github (I will demonstrate how to set it up from scratch)</p>

<p><strong>Secret Store</strong>: Our secrets such as ssh key, swarm host address etc will be stored in drones secrets manager</p>

<p><strong>Docker Swarm</strong>: Docker Swarm has Traefik as a HTTP Loadbalancer</p>

<p><strong>Drone Server and Agent</strong>: If you dont have drone, you can setup <a href="https://blog.ruanbekker.com/blog/2019/04/18/setup-a-drone-cicd-environment-on-docker-with-letsencrypt/">drone server and agent on docker</a> or have a look at <a href="https://cloud.drone.io">cloud.drone.io</a></p>

<p><strong>Workflow:</strong></p>

<pre><code>* Whenever a push to master is receive on github, the pipeline will be triggered
* The content from our github repository will be cloned to the agent on a container
* Jekyll will build and the output will be transferred to docker swarm using rsync
* The docker-compose.yml will be transferred to the docker swarm host using scp
* A docker stack deploy is ran via ssh
</code></pre>

<h2>Install Jekyll Locally</h2>

<p>Install Jekyll locally, as we will use it to create the initial site. I am using a mac, so I will be using <code>brew</code>. For other operating systems, have a look at <a href="https://jekyllrb.com/docs/installation/">this post</a>.</p>

<p>I will be demonstrating with a weightloss blog as an example.</p>

<p>Install jekyll:</p>

<pre><code>$ brew install jekyll
</code></pre>

<p>Go ahead and create a new site which will host the data for your jekyll site:</p>

<pre><code>$ jekyll new blog-weightloss
</code></pre>

<h2>Create a Github Repository</h2>

<p>First we need to create an empty github repository, in my example it was <code>github.com/ruanbekker/blog-weightloss.git</code>. Once you create the repo change into the directory created by the <code>jekyll new</code> command:</p>

<pre><code>$ cd blog-weightloss
</code></pre>

<p>Now initialize git, set the remote, add the jekyll data and push to github:</p>

<pre><code>$ git init
$ git remote add origin git@github.com:ruanbekker/blog-weightloss.git # &lt;== change to your repository
$ git add .
$ git commit -m "first commit"
$ git push origin master
</code></pre>

<p>You should see your data on your github repository.</p>

<h2>Create Secrets on Drone</h2>

<p>Logon to the Drone UI, sync repositories, activate the new repository and head over to settings where you will find the secrets section.</p>

<p>Add the following secrets:</p>

<pre><code>Secret Name: swarm_host
Secret Value: ip address of your swarm

Secret Name: swarm_key
Secret Value: contents of your private ssh key

Secret Name: swarm_user
Secret Value: the user that is allowed to ssh
</code></pre>

<p>You should see the following:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56619871-5c4fc480-6627-11e9-8820-c9d4ddff698c.png" alt="image" /></p>

<h2>Add the Drone Config</h2>

<p>Drone looks from a <code>.drone.yml</code> file in the root directory for instructions on how to do its tasks. Lets go ahead and declare our pipeline:</p>

<pre><code>$ vim .drone.yml
</code></pre>

<p>And populate the drone config:</p>

<pre><code>pipeline:
  jekyll-build:
    image: jekyll/jekyll:latest
    commands:
      - touch Gemfile.lock
      - chmod a+w Gemfile.lock
      - chown -R jekyll:jekyll /drone
      - gem update --system
      - gem install bundler
      - bundle install
      - bundle exec jekyll build

  transfer-build:
    image: drillster/drone-rsync
    hosts:
      from_secret: swarm_host
    key:
      from_secret: swarm_key
    user:
      from_secret: swarm_user
    source: ./*
    target: ~/my-weightloss-blog.com
    recursive: true
    delete: true
    when:
      branch: [master]
      event: [push]

  transfer-compose:
    image: appleboy/drone-scp
    host:
      from_secret: swarm_host
    username:
      from_secret: swarm_user
    key:
      from_secret: swarm_key
    target: /root/my-weightloss-blog.com
    source:
      - docker-compose.yml
    when:
      branch: [master]
      event: [push]

  deploy-jekyll-to-swarm:
    image: appleboy/drone-ssh
    host:
      from_secret: swarm_host
    username:
      from_secret: swarm_user
    key:
      from_secret: swarm_key
    port: 22
    script:
      - docker stack deploy --prune -c /root/my-weightloss-blog.com/docker-compose.yml apps
    when:
      branch: [master]
      event: [push]
</code></pre>

<h2>Notifications?</h2>

<p>If you want to be notified about your builds, you can add a slack notification step as the last step.</p>

<p>To do that, create a new webhook integration, you can <a href="https://blog.ruanbekker.com/blog/2019/04/18/setup-a-slack-webhook-for-sending-messages-from-applications/">follow this post for a step by step guide</a>. After you have the webhook, go to secrets and create a <code>slack_webhook</code> secret.</p>

<p>Then apply the notification step as shown below:</p>

<pre><code>  notify-via-slack:
    image: plugins/slack
    webhook:
      from_secret: slack_webhook
    channel: system_events
    template: &gt;
      
        [DRONE CI]: ** : /
        ( -  | )

      
        [DRONE CI]: ** : /
        ( -  | )
      
</code></pre>

<p>Based on the status, you should get a notification similar like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56622206-6e356580-662f-11e9-8d93-286c9c126d24.png" alt="image" /></p>

<h2>Add the Docker Compose</h2>

<p>Next we need to declare our docker compose file which is needed to deploy our jekyll service to the swarm:</p>

<pre><code>$ vim docker-compose.yml
</code></pre>

<p>And populate this info (just change the values for your own environment/settings):</p>

<pre><code class="yaml">version: '3.5'

services:
  myweightlossblog:
    image: ruanbekker/jekyll:contrast
    command: jekyll serve --watch --force_polling --verbose
    networks:
      - appnet
    volumes:
      - /root/my-weightloss-blog.com:/srv/jekyll
    deploy:
      mode: replicated
      replicas: 1
      labels:
        - "traefik.backend.loadbalancer.sticky=false"
        - "traefik.backend.loadbalancer.swarm=true"
        - "traefik.backend=myweightlossblog"
        - "traefik.docker.network=appnet"
        - "traefik.entrypoints=https"
        - "traefik.frontend.passHostHeader=true"
        - "traefik.frontend.rule=Host:www.my-weightloss-blog.com,my-weightloss-blog.com"
        - "traefik.port=4000"
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager
networks:
  appnet:
    external: true
</code></pre>

<h2>Push to Github</h2>

<p>Now we need to push our <code>.drone.yml</code> and <code>docker-compose.yml</code> to github. Since the repository is activated on drone, any push to master will trigger the pipeline, so after this push we should go to drone to look at our pipeline running.</p>

<p>Add the untracked files and push to github:</p>

<pre><code>$ git add .drone.yml
$ git add docker-compose.yml
$ git commit -m "add drone and docker config"
$ git push origin master
</code></pre>

<p>As you head over to your drone ui, you should see your pipeline output which will look more or less like this (just look how pretty it is! :D )</p>

<p><img src="https://user-images.githubusercontent.com/567298/56620236-91a8e200-6628-11e9-9278-38e3305fdcd7.png" alt="image" /></p>

<h2>Test Jekyll</h2>

<p>If your deployment has completed you should be able to access your application on the configured domain. A screenshot of my response when accessing Jekyll:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56620280-af764700-6628-11e9-9d4f-c2592e6cf561.png" alt="image" /></p>

<p>Absolutely Amazingness! I really love drone!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a Drone CICD Environment on Docker With Letsencrypt]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/04/18/setup-a-drone-cicd-environment-on-docker-with-letsencrypt/"/>
    <updated>2019-04-18T12:53:49-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/04/18/setup-a-drone-cicd-environment-on-docker-with-letsencrypt</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/56378979-ed313500-620e-11e9-9ac0-4fcd1df803e8.png" alt="drone-ci" /></p>

<h2>What is Drone?</h2>

<p>Drone is a self-service continuous delivery platform which can be used for CICD pipelines, devopsy stuff which is really awesome.</p>

<p>With Configuration as Code, Pipelines are configured with a simple, easy‑to‑read file that you commit to your git repository such as github, gitlab, gogs, gitea etc.</p>

<p>Each Pipeline step is executed inside an isolated Docker container that is automatically downloaded at runtime, if not found in cache.</p>

<h2>Show me pipelines!</h2>

<p>A pipeline can look as easy as:</p>

<pre><code class="yaml">kind: pipeline
steps:
- name: test
  image: node
  commands:
  - npm install
  - npm test
services:
- name: database
  image: mysql
  ports:
  - 3306
</code></pre>

<h2>Open for Testing!</h2>

<p>I have enabled public access, so please go ahead and launch your cicd pipelines on my drone setup as I want to test the stability of it:</p>

<p>==> <a href="https://drone.rbkr.xyz/">https://drone.rbkr.xyz/</a></p>

<h2>What are we doing?</h2>

<p>We will deploy a drone server which is responsible for the actual server and 2 drone agents which will receive instructions from the server whenever steps need to be executed. Steps run on agents.</p>

<h2>Deploy the Servers</h2>

<p>I&rsquo;m using VULTR to deploy 3 nodes on coreos, 1 drone server and 2 drone agents as seen below:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56371668-d0403600-61fd-11e9-8396-01c07c136518.png" alt="image" /></p>

<p>Documentation:
<a href="https://docs.drone.io/installation/github/multi-machine/">https://docs.drone.io/installation/github/multi-machine/</a>
<a href="https://github.com/settings/developers">https://github.com/settings/developers</a></p>

<p>We will use Github for version control and to delegate auth, therefore we need to register a new application on Github.</p>

<p>Register New Application on Github at <a href="https://github.com/settings/developer">https://github.com/settings/developer</a> :</p>

<p><img src="https://user-images.githubusercontent.com/567298/56375985-22398980-6207-11e9-911d-9595f8f85db9.png" alt="register-application" /></p>

<p>Get your Drone-Server Host Endpoint, and update the fields:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56374721-287a3680-6204-11e9-837f-a7751651c29a.png" alt="image" /></p>

<p>You will receive a Github Client ID, Secret which we will need later, which will look like this:</p>

<pre><code>Client ID:
xx
Client Secret:
yyy
</code></pre>

<p>Generate the shared secret which will be used on the server and agent:</p>

<pre><code>$ openssl rand -hex 16
eb83xxe19a3497f597f53044250df6yy
</code></pre>

<p>Create the Startup Script for Drone Server, which will just be a docker container running in detached mode. Note that you should use your own domain at <code>SERVER_HOST</code> and if you want to issue an certificate automatically keep <code>DRONE_TLS_AUTOCERT</code> to true.</p>

<pre><code>$ cat &gt; start_drone-server.sh &lt;&lt; EOF
#!/usr/bin/env bash

set -ex

GITHUB_CLIENT_ID=xx
GITHUB_CLIENT_SECRET=yyy
SHARED_SECRET=eb83xxe19a3497f597f53044250df6yy
SERVER_HOST=drone.yourdomain.com
SERVER_PROTOCOL=https

docker run \
  --volume=/var/run/docker.sock:/var/run/docker.sock \
  --volume=/var/lib/drone:/data \
  --env=DRONE_GITHUB_SERVER=https://github.com \
  --env=DRONE_GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID} \
  --env=DRONE_GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET} \
  --env=DRONE_AGENTS_ENABLED=true \
  --env=DRONE_RPC_SECRET=${SHARED_SECRET} \
  --env=DRONE_SERVER_HOST=${SERVER_HOST} \
  --env=DRONE_SERVER_PROTO=${SERVER_PROTOCOL} \
  --env=DRONE_TLS_AUTOCERT=true \
  --publish=80:80 \
  --publish=443:443 \
  --restart=always \
  --detach=true \
  --name=drone \
  drone/drone:1
EOF
</code></pre>

<p>Create the startup script for the drone agent, note that this script needs to be placed on the agent nodes:</p>

<pre><code>$ cat &gt; start_drone-agent.sh &lt;&lt; EOF
#!/usr/bin/env bash

set -ex

SHARED_SECRET=eb83xxe19a3497f597f53044250df6yy
AGENT_SERVER_HOST=https://drone.yourdomain.com
SERVER_PROTOCOL=https

docker run \
  --volume=/var/run/docker.sock:/var/run/docker.sock \
  --env=DRONE_RPC_SERVER=${AGENT_SERVER_HOST} \
  --env=DRONE_RPC_SECRET=${SHARED_SECRET} \
  --env=DRONE_RUNNER_CAPACITY=2 \
  --env=DRONE_RUNNER_NAME=${HOSTNAME} \
  --restart=always \
  --detach=true \
  --name=drone-agent-02 \
  drone/agent:1
EOF
</code></pre>

<p>Logon to the server node and start the drone server:</p>

<pre><code>$ bash start_drone-agent.sh
</code></pre>

<p>Login to the agent nodes and start the agents:</p>

<pre><code>$ bash start_drone-agent.sh
</code></pre>

<p>The server should show that it&rsquo;s listening on port 80 and 443:</p>

<pre><code>$ docker ps
CONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                                      NAMES
8ea70fc7b967        drone/drone:1       "/bin/drone-server"   12 minutes ago      Up 12 minutes       0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp   drone
</code></pre>

<h2>Access Drone</h2>

<p>Access your Drone instance on port 80 eg. <a href="http://drone.yourdomain.com">http://drone.yourdomain.com</a> you should be automatically redirected to port 443, which should direct you to a login page, which will look like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56375632-5eb8b580-6206-11e9-9ae8-92b2cd29abec.png" alt="drone-authorize" /></p>

<p>Login with your github account and allow drone some time to sync your repositories:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56373131-9e7c9e80-6200-11e9-83ce-e486b399468e.png" alt="image" /></p>

<h2>Add drone config to your repository:</h2>

<p>Clone this repository: <a href="https://github.com/ruanbekker/drone-ci-testing">https://github.com/ruanbekker/drone-ci-testing</a> which will contain the <code>.drone.yml</code> config which drone gets its instructions from.</p>

<p>Select a repository to activate, (drone-ci-testing in this case) head over to settings:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56373298-f1565600-6200-11e9-8262-ac3162fed4f2.png" alt="image" /></p>

<p>Adding secret:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56373209-c5d36b80-6200-11e9-90de-68c131480672.png" alt="image" /></p>

<p>Add more secrets:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56373443-3da19600-6201-11e9-85a9-083bfcbd604a.png" alt="image" /></p>

<p>Your build list should be empty:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56373533-6fb2f800-6201-11e9-8fa0-ab05e546c36e.png" alt="image" /></p>

<h2>Trigger a Build</h2>

<p>Edit any of the files in the clone repository and you should see your build running:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56374465-85c1b800-6203-11e9-8542-acd1d5729447.png" alt="image" /></p>

<p>When your build has completed:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56374511-a25df000-6203-11e9-9eb8-d94a777a8b4a.png" alt="image" /></p>

<p>You can also find out where the step ran:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56374667-084a7780-6204-11e9-9c5b-6672f6882411.png" alt="image" /></p>

<p>Run a couple of tests:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56376356-e3f09a00-6207-11e9-8ca0-16e06e7c0379.png" alt="image" /></p>

<p>Get notified via slack:</p>

<p><img src="https://user-images.githubusercontent.com/567298/56376376-eeab2f00-6207-11e9-9af9-194cb5a3023b.png" alt="image" /></p>

<h2>Debugging</h2>

<p>If your build fails, its most likely that you need the <code>slack_webhook</code> secret. You can remove the slack step which shouldhelp you get going with drone.</p>

<h2>More on Drone</h2>

<p>Have a look at <a href="https://github.com/ruanbekker/drone-ci-testing/blob/master/README.md">this document</a> for more examples or have a look at their <a href="https://docs.drone.io/">documentation</a> as well as their extensive list of <a href="http://plugins.drone.io/">plugins</a> and their <a href="https://docs.drone.io/installation/github/multi-machine/">setup documentation</a> to become familiar with their configuration.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build Small Golang Docker Containers]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/04/03/build-small-golang-docker-containers/"/>
    <updated>2019-04-03T08:24:08-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/04/03/build-small-golang-docker-containers</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/55478306-aabb0600-561b-11e9-9cc6-730fadb4beeb.png" alt="" /></p>

<p>In this tutorial I will show you how to build really small docker containers for golang applications. And I mean the difference between 310MB down to 2MB</p>

<h2>But Alpine..</h2>

<p>So we thinking lets go with alpine right? Yeah sure lets build a small, app running on go with alpine.</p>

<p>Our application code:</p>

<pre><code class="go app.go">package main

import (
  "fmt"
  "math/rand"
  "time"
)

func main() {
  lekkewords := []string{
    "dog", "cat", "fish", "giraffe",
    "moo", "spider", "lion", "apple",
    "tree", "moon", "snake", "mountain lion",
    "trooper", "burger", "nasa", "yes",
  }

  rand.Seed(time.Now().UnixNano())
  var zelength int = len(lekkewords)
  var indexnum int = rand.Intn(zelength-1)
  word := lekkewords[indexnum]

  fmt.Println("Number of words:", zelength)
  fmt.Println("Selected index number:", indexnum)
  fmt.Println("Selected word is:", word)
}
</code></pre>

<p>Our Dockerfile:</p>

<pre><code class="docker Dockerfile">FROM golang:alpine

WORKDIR $GOPATH/src/mylekkepackage/mylekkeapp/
COPY app.go .
RUN go build -o /go/app

CMD ["/go/app"]
</code></pre>

<p>Let&rsquo;s package our app to an image:</p>

<pre><code>❯ docker build -t mygolangapp:using-alpine .
</code></pre>

<p>Inspect the size of our image, as you can see it being <strong>310MB</strong></p>

<pre><code>❯ docker images "mygolangapp:*"
REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE
mygolangapp         using-alpine        eea1d7bde218        About a minute ago   310MB
</code></pre>

<p>Just make sure it actually works:</p>

<pre><code>❯ docker run mygolangapp:using-alpine
Number of words: 16
Selected index number: 11
Selected word is: mountain lion
</code></pre>

<p>But for something just returning random selected text, 310MB is a bit crazy.</p>

<h2>Multi Stage Builds</h2>

<p>As Go binaries are self-contained, we can make use of docker&rsquo;s multi stage builds, where we can build our application on alpine and use the binary on a scratch image:</p>

<p>Our multi stage Dockerfile:</p>

<pre><code class="docker Dockerfile.mult">FROM golang:alpine AS builder

WORKDIR $GOPATH/src/mylekkepackage/mylekkeapp/
COPY app.go .
RUN go build -o /go/app

FROM scratch

COPY --from=builder /go/app /go/app

CMD ["/go/app"]
</code></pre>

<p>Build it:</p>

<pre><code>❯ docker build -t mygolangapp:using-multistage -f Dockerfile.multi .
</code></pre>

<p>Notice that the image is only <strong>2.01MB</strong>, say w000t!</p>

<pre><code>❯ docker images "mygolangapp:*"
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
mygolangapp         using-multistage    31474c61ba5b        15 seconds ago      2.01MB
mygolangapp         using-alpine        eea1d7bde218        2 minutes ago       310MB
</code></pre>

<p>Run the app:</p>

<pre><code>❯ docker run mygolangapp:using-multistage
Number of words: 16
Selected index number: 5
Selected word is: spider
</code></pre>

<h2>Resources</h2>

<p>Source code for this demonstration can be found at <a href="https://github.com/ruanbekker/golang-build-small-images">github.com/ruanbekker/golang-build-small-images</a></p>

<p><img src="https://user-images.githubusercontent.com/567298/55478904-236e9200-561d-11e9-9382-f31b25a9ae03.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concourse Pipeline to Build a Docker Image Automatically on Git Commit]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/03/27/concourse-pipeline-to-build-a-docker-image-automatically-on-git-commit/"/>
    <updated>2019-03-27T17:50:54-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/03/27/concourse-pipeline-to-build-a-docker-image-automatically-on-git-commit</id>
    <content type="html"><![CDATA[<p><img src="https://i.snag.gy/gzkdu9.jpg?nocache=1511644783495" alt="" /></p>

<p>In this tutorial we will build a ci pipeline using concourse to build and push a image to dockerhub automatically, whenever a new git commit is made to the master branch.</p>

<h2>Our Project Setup</h2>

<p>Our Directory Tree:</p>

<pre><code class="bash">$ find .
./Dockerfile
./ci
./ci/pipeline.yml
./README.md
./docker-tunnel
</code></pre>

<p>The project used in this example is not important, but you can check it out at <a href="https://github.com/ruanbekker/docker-remote-tunnel">https://github.com/ruanbekker/docker-remote-tunnel</a></p>

<h2>Our Pipeline</h2>

<p>A visual to see how the pipeline will look like in concourse:</p>

<p><img src="https://user-images.githubusercontent.com/567298/55114996-1832d800-50ec-11e9-85ef-bc283711fbde.png" alt="" /></p>

<p>Our pipeline definition will consist of 3 resources, <code>github repo</code>, <code>dockerhub image</code> and a <code>slack resource</code> to inform use whether a build has completed.</p>

<p>Then we are specifying that the job should be triggered on a git commit for the master branch, build and push to our dockerhub repo.</p>

<p>Our pipeline definition <code>ci/pipeline.yml</code>:</p>

<pre><code class="yaml">resources:
- name: git-repo
  type: git
  source:
    uri: git@github.com:ruanbekker/docker-remote-tunnel.git
    branch: master
    private_key: ((github_private_key))

- name: docker-remote-tunnel-image
  type: docker-image
  source:
    repository: ruanbekker/docker-remote-tunnel
    tag: test
    username: ((dockerhub_user))
    password: ((dockerhub_password))

- name: slack-alert
  type: slack-notification
  source:
    url: ((slack_notification_url))

resource_types:
  - name: slack-notification
    type: docker-image
    source:
      repository: cfcommunity/slack-notification-resource
      tag: v1.3.0

jobs:
- name: build-cached-image
  plan:
  - get: git-repo
    trigger: true
  - task: build-cached-image-workspace
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: rbekker87/build-tools

      outputs:
      - name: workspace
      inputs:
      - name: git-repo

      run:
        path: /bin/sh
        args:
        - -c
        - |
          output_dir=workspace

          cat &lt;&lt; EOF &gt; "${output_dir}/Dockerfile"
          FROM alpine

          ADD git-repo /tmp/git-repo
          RUN mv /tmp/git-repo/docker-tunnel /usr/bin/docker-tunnel
          RUN apk --no-cache add screen docker openssl openssh-client apache2-utils
          RUN /usr/bin/docker-tunnel -h
          RUN rm -rf /tmp/git-repo
          EOF

          cp -R ./git-repo "${output_dir}/git-repo"

  - put: docker-remote-tunnel-image
    params:
      build: workspace

    on_failure:
      put: slack-alert
      params:
        channel: '#system_events'
        username: 'concourse'
        icon_emoji: ':concourse:'
        silent: true
        text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) FAILED to build image
            https://ci.domain.com/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME
    on_success:
      put: slack-alert
      params:
        channel: '#system_events'
        username: 'concourse'
        icon_emoji: ':concourse:'
        silent: true
        text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) SUCCESS - Image has been published
            https://ci.domain.com/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME

- name: test
  plan:
  - get: docker-remote-tunnel-image
    passed: [build-cached-image]
    trigger: true
  - get: git-repo
    passed: [build-cached-image]
  - task: run-tests
    image: docker-remote-tunnel-image
    config:
      platform: linux
      inputs:
      - name: git-repo
      run:
        dir: git-repo
        path: sh
        args:
        - /usr/bin/docker-tunnel
        - --help

    on_failure:
      put: slack-alert
      params:
        channel: '#system_events'
        username: 'concourse'
        icon_emoji: ':concourse:'
        silent: true
        text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) FAILED - Testing image failure
            https://ci.domain.com/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME
    on_success:
      put: slack-alert
      params:
        channel: '#system_events'
        username: 'concourse'
        icon_emoji: ':concourse:'
        silent: true
        text: |
            *$BUILD_PIPELINE_NAME/$BUILD_JOB_NAME* ($BUILD_NAME) SUCCESS - Testing image Succeeded
            https://ci.domain.com/teams/$BUILD_TEAM_NAME/pipelines/$BUILD_PIPELINE_NAME/jobs/$BUILD_JOB_NAME/builds/$BUILD_NAME
</code></pre>

<p>Note that our secret information is templatized and saved in our local <code>credentials.yml</code> which should never be stored in version control:</p>

<pre><code class="yaml">slack_notification_url: https://api.slack.com/aaa/bbb/ccc
dockerhub_user: myuser
dockerhub_password: mypasswd
github_private_key: |-
        -----BEGIN RSA PRIVATE KEY-----
        some-secret-data
        -----END RSA PRIVATE KEY------
</code></pre>

<h2>Set the Pipeline:</h2>

<p>Now that we have our pipeline definition, credentials and application code (stored in version control), go ahead and set the pipeline, which will save the pipeline configuration in concourse:</p>

<pre><code class="bash"># pipeline name: my-docker-app-pipeline
$ fly -t scw sp -n main -c pipeline.yml -p my-docker-app-pipeline -l credentials.yml
</code></pre>

<p>Now the pipeline is saved on concourse but in a paused state, go ahead and unpause the pipeline:</p>

<pre><code class="bash">$ fly -t scw up -p my-docker-app-pipeline
</code></pre>

<h2>Test your Pipeline</h2>

<p>Make a commit to master and head over to concourse and look at it go:</p>

<p><img src="https://user-images.githubusercontent.com/567298/55116018-a5772c00-50ee-11e9-861e-a5ddc74550e2.png" alt="" /></p>

<p>Thanks for reading, make sure to check out my other posts on <a href="https://blog.ruanbekker.com/blog/categories/concourse">#concourse</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Deploy a Docker Swarm Cluster on Scaleway With Terraform]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/03/21/how-to-deploy-a-docker-swarm-cluster-on-scaleway-with-terraform/"/>
    <updated>2019-03-21T02:15:07-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/03/21/how-to-deploy-a-docker-swarm-cluster-on-scaleway-with-terraform</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/54737111-09fa2e80-4bb7-11e9-97f4-a94a31fc9a3a.png" alt="" /></p>

<p>We will deploy a 3 node docker swarm cluster with terraform on scaleway. I have used the base source code from <a href="https://github.com/stefanprodan/scaleway-swarm-terraform">this</a> repository but tweaked the configuration to my needs.</p>

<h2>Pre-Requisites</h2>

<p>Ensure terraform and jq is instaled:</p>

<pre><code class="bash">$ brew install terraform
$ brew install jq
</code></pre>

<h2>Terraform</h2>

<p>You can have a look at the linked source at the top for the source code, but below I will provide each file that will make up our terraform deployment.</p>

<p>Ource <code>main.tf</code></p>

<pre><code>provider "scaleway" {
  region = "${var.region}"
}

data "scaleway_bootscript" "debian" {
  architecture = "x86_64"
  name = "x86_64 mainline 4.15.11 rev1"
}

data "scaleway_image" "debian_stretch" {
  architecture = "x86_64"
  name         = "Debian Stretch"
}

data "template_file" "docker_conf" {
  template = "${file("conf/docker.tpl")}"

  vars {
    ip = "${var.docker_api_ip}"
  }
}
</code></pre>

<p>The <code>outputs.tf</code></p>

<pre><code>output "swarm_manager_public_ip" {
  value = "${scaleway_ip.swarm_manager_ip.0.ip}"
}

output "swarm_manager_private_ip" {
  value = "${scaleway_server.swarm_manager.0.private_ip}"
}

output "swarm_workers_public_ip" {
  value = "${concat(scaleway_server.swarm_worker.*.name, scaleway_server.swarm_worker.*.public_ip)}"
}

output "swarm_workers_private_ip" {
  value = "${concat(scaleway_server.swarm_worker.*.name, scaleway_server.swarm_worker.*.private_ip)}"
}

output "workspace" {
  value = "${terraform.workspace}"
}
</code></pre>

<p>Our <code>security-groups.tf</code></p>

<pre><code>resource "scaleway_security_group" "swarm_managers" {
  name        = "swarm_managers"
  description = "Allow HTTP/S and SSH traffic"
}

resource "scaleway_security_group_rule" "ssh_accept" {
  security_group = "${scaleway_security_group.swarm_managers.id}"

  action    = "accept"
  direction = "inbound"
  ip_range  = "0.0.0.0/0"
  protocol  = "TCP"
  port      = 22
}

resource "scaleway_security_group_rule" "http_accept" {
  security_group = "${scaleway_security_group.swarm_managers.id}"

  action    = "accept"
  direction = "inbound"
  ip_range  = "0.0.0.0/0"
  protocol  = "TCP"
  port      = 80
}

resource "scaleway_security_group_rule" "https_accept" {
  security_group = "${scaleway_security_group.swarm_managers.id}"

  action    = "accept"
  direction = "inbound"
  ip_range  = "0.0.0.0/0"
  protocol  = "TCP"
  port      = 443
}

resource "scaleway_security_group" "swarm_workers" {
  name        = "swarm_workers"
  description = "Allow SSH traffic"
}

resource "scaleway_security_group_rule" "ssh_accept_workers" {
  security_group = "${scaleway_security_group.swarm_workers.id}"

  action    = "accept"
  direction = "inbound"
  ip_range  = "0.0.0.0/0"
  protocol  = "TCP"
  port      = 22
}
</code></pre>

<p>Our <code>variables.tf</code></p>

<pre><code>variable "docker_version" {
  default = "18.06.3~ce~3-0~debian"
}

variable "region" {
  default = "ams1"
}

variable "manager_instance_type" {
  default = "START1-M"
}

variable "worker_instance_type" {
  default = "START1-M"
}

variable "worker_instance_count" {
  default = 2
}

variable "docker_api_ip" {
  default = "127.0.0.1"
}
</code></pre>

<p>Our <code>managers.tf</code></p>

<pre><code>resource "scaleway_ip" "swarm_manager_ip" {
  count = 1
}

resource "scaleway_server" "swarm_manager" {
  count          = 1
  name           = "${terraform.workspace}-manager-${count.index + 1}"
  image          = "${data.scaleway_image.debian_stretch.id}"
  type           = "${var.manager_instance_type}"
  bootscript     = "${data.scaleway_bootscript.debian.id}"
  security_group = "${scaleway_security_group.swarm_managers.id}"
  public_ip      = "${element(scaleway_ip.swarm_manager_ip.*.ip, count.index)}"

  volume {
    size_in_gb = 50
    type       = "l_ssd"
  }

  provisioner "remote-exec" {
    script = "scripts/mount-disk.sh"
  }

  connection {
    type = "ssh"
    user = "root"
    private_key = "${file("~/.ssh/id_rsa")}"
  }

  provisioner "remote-exec" {
    inline = [
      "mkdir -p /etc/systemd/system/docker.service.d",
    ]
  }

  provisioner "file" {
    content     = "${data.template_file.docker_conf.rendered}"
    destination = "/etc/systemd/system/docker.service.d/docker.conf"
  }

  provisioner "file" {
    source      = "scripts/install-docker-ce.sh"
    destination = "/tmp/install-docker-ce.sh"
  }

  provisioner "file" {
    source      = "scripts/local-persist-plugin.sh"
    destination = "/tmp/local-persist-plugin.sh"
  }

  provisioner "remote-exec" {
    inline = [
      "chmod +x /tmp/install-docker-ce.sh",
      "/tmp/install-docker-ce.sh ${var.docker_version}",
      "docker swarm init --advertise-addr ${self.private_ip}",
      "chmod +x /tmp/local-persist-plugin.sh",
      "/tmp/local-persist-plugin.sh"
    ]
  }
}
</code></pre>

<p>Our <code>workers.tf</code></p>

<pre><code>resource "scaleway_ip" "swarm_worker_ip" {
  count = "${var.worker_instance_count}"
}

resource "scaleway_server" "swarm_worker" {
  count          = "${var.worker_instance_count}"
  name           = "${terraform.workspace}-worker-${count.index + 1}"
  image          = "${data.scaleway_image.debian_stretch.id}"
  type           = "${var.worker_instance_type}"
  bootscript     = "${data.scaleway_bootscript.debian.id}"
  security_group = "${scaleway_security_group.swarm_workers.id}"
  public_ip      = "${element(scaleway_ip.swarm_worker_ip.*.ip, count.index)}"

  volume {
    size_in_gb = 50
    type       = "l_ssd"
  }

  provisioner "remote-exec" {
    script = "scripts/mount-disk.sh"
  }

  connection {
    type = "ssh"
    user = "root"
    private_key = "${file("~/.ssh/id_rsa")}"
  }

  provisioner "remote-exec" {
    inline = [
      "mkdir -p /etc/systemd/system/docker.service.d",
    ]
  }

  provisioner "file" {
    content     = "${data.template_file.docker_conf.rendered}"
    destination = "/etc/systemd/system/docker.service.d/docker.conf"
  }

  provisioner "file" {
    source      = "scripts/install-docker-ce.sh"
    destination = "/tmp/install-docker-ce.sh"
  }

  provisioner "file" {
    source      = "scripts/local-persist-plugin.sh"
    destination = "/tmp/local-persist-plugin.sh"
  }

  provisioner "remote-exec" {
    inline = [
      "chmod +x /tmp/install-docker-ce.sh",
      "/tmp/install-docker-ce.sh ${var.docker_version}",
      "docker swarm join --token ${data.external.swarm_tokens.result.worker} ${scaleway_server.swarm_manager.0.private_ip}:2377",
      "chmod +x /tmp/local-persist-plugin.sh",
      "/tmp/local-persist-plugin.sh",
    ]
  }

  provisioner "remote-exec" {
    when = "destroy"

    inline = [
      "docker node update --availability drain ${self.name}",
    ]

    on_failure = "continue"

    connection {
      type = "ssh"
      user = "root"
      host = "${scaleway_ip.swarm_manager_ip.0.ip}"
    }
  }

  provisioner "remote-exec" {
    when = "destroy"

    inline = [
      "docker swarm leave",
    ]

    on_failure = "continue"
  }

  provisioner "remote-exec" {
    when = "destroy"

    inline = [
      "docker node rm --force ${self.name}",
    ]

    on_failure = "continue"

    connection {
      type = "ssh"
      user = "root"
      host = "${scaleway_ip.swarm_manager_ip.0.ip}"
    }
  }
}

data "external" "swarm_tokens" {
  program = ["./scripts/fetch-tokens.sh"]

  query = {
    host = "${scaleway_ip.swarm_manager_ip.0.ip}"
  }

  depends_on = ["scaleway_server.swarm_manager"]
}
</code></pre>

<p>Our config for the docker daemon: <code>conf/docker.tpl</code></p>

<pre><code>[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -H fd:// \
  -H tcp://${ip}:2375 \
  --storage-driver=overlay2 \
  --dns 8.8.4.4 --dns 8.8.8.8 \
  --log-driver json-file \
  --log-opt max-size=50m --log-opt max-file=10 \
  --experimental=true \
  --metrics-addr 172.17.0.1:9323
</code></pre>

<p>Our script to mount our additional disk: <code>scripts/mount-disk.sh</code></p>

<pre><code class="bash">#!/bin/bash
apt update
apt install xfsprogs attr -y
mkfs -t xfs /dev/vdb
echo "/dev/vdb /mnt xfs defaults 0 0" &gt;&gt; /etc/fstab
mount -a
</code></pre>

<p>Our script to install docker: <code>scripts/install-docker-ce.sh</code></p>

<pre><code class="bash">#!/usr/bin/env bash

DOCKER_VERSION=$1
DEBIAN_FRONTEND=noninteractive apt-get -qq update
apt-get -qq install apt-transport-https ca-certificates curl software-properties-common
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"

apt-get -q update -y
apt-get -q install -y docker-ce=$DOCKER_VERSION containerd.io
</code></pre>

<p>Our script that retrieves the swarm tokens: <code>scripts/fetch-tokens.sh</code></p>

<pre><code class="bash">#!/usr/bin/env bash

# Processing JSON in shell scripts
# https://www.terraform.io/docs/providers/external/data_source.html#processing-json-in-shell-scripts

set -e

# Extract "host" argument from the input into HOST shell variable
eval "$(jq -r '@sh "HOST=\(.host)"')"

MANAGER=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$HOST docker swarm join-token manager -q)
WORKER=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@$HOST docker swarm join-token worker -q)

# produce a json object containing the tokens
jq -n --arg manager "$MANAGER" --arg worker "$WORKER" '{"manager":$manager,"worker":$worker}'
</code></pre>

<p>Our script to install the <a href="https://github.com/CWSpear/local-persist">local-persist docker volume</a> plugin: <code>scripts/local-persist-plugin.sh</code></p>

<pre><code>#!/usr/bin/env bash
set -e
curl -fsSL https://raw.githubusercontent.com/CWSpear/local-persist/master/scripts/install.sh | bash
</code></pre>

<h2>Deploy your Swarm</h2>

<p>Note that we will be deploying 3x SMART1-M servers with Debian Stretch. At this moment the image id is the one of debian stretch but may change in the future. If you want to change the distro, update the install script, and the terraform files.</p>

<p><a href="https://www.scaleway.com/docs/generate-an-api-token/">Generate API Token on Scaleway</a> then export it to your current shell:</p>

<pre><code class="bash">export SCALEWAY_ORGANIZATION="&lt;organization-id&gt;"
export SCALEWAY_TOKEN="&lt;secret&gt;"
</code></pre>

<p>Make sure that your ssh private key is the intended one as in the config, in my example: <code>~/.ssh/id_rsa</code> and that they are allowed in your servers <code>authorized_keys</code> file</p>

<p>Create a new workspace:</p>

<pre><code class="bash">$ terraform new workspace swarm
</code></pre>

<p>Pull down the providers and initialize:</p>

<pre><code class="bash">$ terraform init
</code></pre>

<p>Deploy!</p>

<pre><code class="bash">$ terraform apply
...
...
scaleway_server.swarm_worker[0]: Creation complete after 4m55s (ID: xx-xx-xx-xx-xx)

Apply complete! Resources: 14 added, 0 changed, 0 destroyed.
Outputs:

swarm_manager_private_ip = 10.21.x.x
swarm_manager_public_ip = 51.xx.xx.xx
swarm_workers_private_ip = [
    swarm-worker-1,
    swarm-worker-2,
    10.20.xx.xx,
    10.20.xx.xx,
]
swarm_workers_public_ip = [
    swarm-worker-1,
    swarm-worker-2,
    51.xx.xx.xx,
    51.xx.xx.xx,
]
workspace = swarm
</code></pre>

<p>Once your deployment is done you will be prompted with the public/private ip addresses of your nodes as seen above, you can also manually retrieve them:</p>

<pre><code>$ terraform terraform output
</code></pre>

<p>Or for a specific node, such as the manager:</p>

<pre><code>$ terraform terraform output swarm-manager
51.xx.xx.xx
</code></pre>

<p>Go ahead and ssh to your manager nodes and list the swarm nodes, boom, easy right.</p>

<pre><code>$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
2696o0vrt93x8qf2gblbfc8pf *   swarm-manager       Ready               Active              Leader              18.09.3
72ava7rrp2acnyadisg52n7ym     swarm-worker-1      Ready               Active                                  18.09.3
sy2otqn20qe9jc2v9io3a21jm     swarm-worker-2      Ready               Active                                  18.09.3
</code></pre>

<p>When you want to destroy the environment:</p>

<pre><code>$ terraform destroy -force
</code></pre>

<h2>References:</h2>

<p>Big thanks goes to <a href="https://github.com/stefanprodan">@stefanprodan</a></p>

<ul>
<li><a href="https://www.terraform.io/docs/index.html">https://www.terraform.io/docs/index.html</a></li>
<li><a href="https://docs.docker.com/engine/swarm/">https://docs.docker.com/engine/swarm/</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
