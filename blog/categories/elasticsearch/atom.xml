<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Elasticsearch | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/elasticsearch/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-04-18T13:36:57-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Monitor a Amazon Elasticsearch Service Cluster Update Process]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/04/16/how-to-monitor-a-amazon-elasticsearch-service-cluster-update-process/"/>
    <updated>2018-04-16T03:24:09-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/04/16/how-to-monitor-a-amazon-elasticsearch-service-cluster-update-process</id>
    <content type="html"><![CDATA[<p>When you make a configuration change on Amazon&rsquo;s Elasticsearch, it does a blue/green deployment. So new nodes will be allocated to the cluster (which you will notice from CloudWatch when looking at the nodes metrics). Once these nodes are deployed, data gets copied accross to the new nodes, and traffic gets directed to the new nodes, and once its done, the old nodes gets terminated.</p>

<p>Note: While there will be more nodes in the cluster, you will not get billed for the extra nodes.</p>

<p>While this process is going, you can monitor your cluster to see the progress:</p>

<h2>The Shards API:</h2>

<p>Using the <code>/_cat/shards</code> API, you will find that the shards are in a RELOCATING state (keeping in mind, this is when the change is still busy)</p>

<pre><code class="bash">curl -s -XGET 'https://search-example-elasticsearch-cluster-6-abc123defghijkl5airxticzvjaqy.eu-west-1.es.amazonaws.com/_cat/shards?v' | grep -v 'STARTED'
index                                   shard prirep state         docs    store ip            node
example-app1-2018.02.23                 4     r      RELOCATING  323498 1018.3mb x.x.x.x x2mKoe_ -&gt; x.x.x.x GyNiRJyeSTifN_9JZisGuQ GyNiRJy
example-app1-2018.02.28                 2     p      RELOCATING  477609    1.5gb x.x.x.x x2mKoe_ -&gt; x.x.x.x sOihejw1SrKtag_LO1RGIA sOihejw
example-app1-2018.03.01                 3     r      RELOCATING  463143    1.5gb x.x.x.x  ZZfv-Ha -&gt; x.x.x.x jOchdCZWQq-TAPZNTadNoA jOchdCZ
fortinet-syslog-2018.02                 0     p      RELOCATING 1218556  462.2mb x.x.x.x  moQA57Y -&gt; x.x.x.x sOihejw1SrKtag_LO1RGIA sOihejw
example-app1-2018.03.23                 3     r      RELOCATING  821254    2.4gb x.x.x.x  moQA57Y -&gt; x.x.x.x GyNiRJyeSTifN_9JZisGuQ GyNiRJy
example-app1-2018.04.02                 2     p      RELOCATING 1085279    3.4gb x.x.x.x x2mKoe_ -&gt; x.x.x.x jOchdCZWQq-TAPZNTadNoA jOchdCZ
example-app1-2018.02.08                 3     p      RELOCATING  136321    125mb x.x.x.x ZUZSFWu -&gt; x.x.x.x tyU_V_KLS5mZXEwnF-YEAQ tyU_V_K
fortinet-syslog-2018.04                 4     r      RELOCATING 7513842    2.8gb x.x.x.x  ZZfv-Ha -&gt; x.x.x.x il1WsroNSgGmXJugds_aMQ il1Wsro
example-app1-2018.04.09                 1     r      RELOCATING 1074581    3.5gb x.x.x.x  ZRzKGe5 -&gt; x.x.x.x il1WsroNSgGmXJugds_aMQ il1Wsro
example-app1-2018.04.09                 0     p      RELOCATING 1074565    3.5gb x.x.x.x  moQA57Y -&gt; x.x.x.x tyU_V_KLS5mZXEwnF-YEAQ tyU_V_K
</code></pre>

<h2>The Recovery API:</h2>

<p>We can then use the <code>/_cat/recovery</code> API, which will show the progress of the shards transferring to the other nodes, you will find the following:</p>

<ul>
<li><code>index, shard, time, type, stage, source_host, target_host, files, files_percent, bytes, bytes_percent</code></li>
</ul>


<p>As Amazon masks their node ip addresses, we will find that the ips are not available. To make it more human readable, we will only pass the columns that we are interested in and not to show the shards that has been set to <code>done</code>:</p>

<pre><code>$ curl -s -XGET 'https://search-example-elasticsearch-cluster-6-abc123defghijkl5airxticzvjaqy.eu-west-1.es.amazonaws.com/_cat/recovery?v&amp;h=i,s,t,ty,st,shost,thost,f,fp,b,bp' | grep -v 'done'
i                                       s t     ty          st       shost         thost         f   fp     b          bp
example-app1-2018.04.11                 1 2m    peer        index    x.x.x.x x.x.x.x  139 97.1%  3435483673 65.9%
web-syslog-2018.04                 4 7.6m  peer        finalize x.x.x.x x.x.x.x  109 100.0% 2854310892 100.0%
example-app1-2018.04.16                 3 2.9m  peer        translog x.x.x.x x.x.x.x  130 100.0% 446180036  100.0%
example-app1-2018.03.30                 3 2.1m  peer        index    x.x.x.x  x.x.x.x  127 97.6%  3862498583 62.5%
example-app1-2018.04.01                 0 4.4m  peer        index    x.x.x.x  x.x.x.x  140 99.3%  3410543270 87.9%
example-app1-2018.04.06                 0 5.1m  peer        index    x.x.x.x x.x.x.x  128 97.7%  4291421948 66.3%
example-app1-2018.04.07                 0 52.2s peer        index    x.x.x.x x.x.x.x 149 91.9%  3969581277 27.4%
network-capture-2018.04.01               2 11.4s peer        index    x.x.x.x  x.x.x.x 107 95.3%  359987163  55.0%
example-app1-2018.03.17                 1 1.7m  peer        index    x.x.x.x  x.x.x.x 117 98.3%  2104196548 74.5%
example-app1-2018.02.25                 3 58.4s peer        index    x.x.x.x  x.x.x.x 102 98.0%  945437614  74.7%
</code></pre>

<p>We can also see the human readable output, which is displayed in json format, with much more detail:</p>

<pre><code>$ curl -s -XGET 'https://search-example-elasticsearch-cluster-6-abc123defghijkl5airxticzvjaqy.eu-west-1.es.amazonaws.com/example-app1-2018.04.03/_recovery?human' | python -m json.tool
{
    "example-app1-2018.04.03": {
        "shards": [
            {
                "id": 0,
                "index": {
                    "files": {
                        "percent": "100.0%",
                        "recovered": 103,
                        "reused": 0,
                        "total": 103
                    },
                    "size": {
                        "percent": "100.0%",
                        "recovered": "3.6gb",
                        "recovered_in_bytes": 3926167091,
                        "reused": "0b",
                        "reused_in_bytes": 0,
                        "total": "3.6gb",
                        "total_in_bytes": 3926167091
                    },
                    "source_throttle_time": "2m",
                    "source_throttle_time_in_millis": 121713,
                    "target_throttle_time": "2.1m",
                    "target_throttle_time_in_millis": 126170,
                    "total_time": "7.2m",
                    "total_time_in_millis": 434142
                },
                "primary": true,
                "source": {
                    "host": "x.x.x.x",
                    "id": "ZRzKGe5WSg2SzilZGb3RbA",
                    "ip": "x.x.x.x",
                    "name": "ZRzKGe5",
                    "transport_address": "x.x.x.x:9300"
                },
                "stage": "DONE",
                "start_time": "2018-04-10T19:26:48.668Z",
                "start_time_in_millis": 1523388408668,
                "stop_time": "2018-04-10T19:34:04.980Z",
                "stop_time_in_millis": 1523388844980,
                "target": {
                    "host": "x.x.x.x",
                    "id": "x2mKoe_GTpe3b1CnXOKisA",
                    "ip": "x.x.x.x",
                    "name": "x2mKoe_",
                    "transport_address": "x.x.x.x:9300"
                },
                "total_time": "7.2m",
                "total_time_in_millis": 436311,
                "translog": {
                    "percent": "100.0%",
                    "recovered": 0,
                    "total": 0,
                    "total_on_start": 0,
                    "total_time": "1.1s",
                    "total_time_in_millis": 1154
                },
                "type": "PEER",
                "verify_index": {
                    "check_index_time": "0s",
                    "check_index_time_in_millis": 0,
                    "total_time": "0s",
                    "total_time_in_millis": 0
                }
            },
</code></pre>

<h2>The Cluster Health API:</h2>

<p>Amazon restricts most of the <code>/_cluster</code> API actions, but we can however see the health endpoint, where we can see the number of <code>nodes</code>, <code>active_shards</code>, <code>relocating_shards</code>, <code>number_of_pending_tasks</code> etc:</p>

<pre><code>$ curl -XGET https://search-example-elasticsearch-cluster-6-abc123defghijkl5airxticzvjaqy.eu-west-1.es.amazonaws.com/_cluster/health?pretty
{
  "cluster_name" : "0123456789012:example-elasticsearch-cluster-6",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 16,
  "number_of_data_nodes" : 10,
  "active_primary_shards" : 803,
  "active_shards" : 1606,
  "relocating_shards" : 10,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
</code></pre>

<h2>The Pending Tasks API:</h2>

<p>We also have some insights into the <code>/_cat/pending_tasks</code> API:</p>

<pre><code>$ curl -s -XGET 'https://search-example-elasticsearch-cluster-6-abc123defghijkl5airxticzvjaqy.eu-west-1.es.amazonaws.com/_cat/pending_tasks?v'
insertOrder timeInQueue priority source
1757        53ms URGENT   shard-started shard id [[network-metrics-2018.04.13][0]], allocation id [Qh91o_OGRX-lFnY8KxYgQw], primary term [0], message [after peer recovery]
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-recovery.html#cat-recovery">https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-recovery.html#cat-recovery</a></li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-recovery.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-recovery.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch Curator to Manage and Curate Your Elasticsearch Indexes]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/04/elasticsearch-curator-to-manage-and-curate-your-elasticsearch-indexes/"/>
    <updated>2017-12-04T08:39:06-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/04/elasticsearch-curator-to-manage-and-curate-your-elasticsearch-indexes</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/elasticsearch-2.jpg" alt="" /></p>

<p>Elasticsearch Curator helps you to manage and curate your Elasticsearch Indices. I will show how to use the Curator in the following ways:</p>

<ul>
<li>Create Indexes</li>
<li>Reindex Indexes</li>
<li>Set Replica Counts on Indexes</li>
<li>Delete Indexes</li>
</ul>


<h2>Install Elasticsearch Curator</h2>

<p>Install Elasticsearch Curator as follows:</p>

<pre><code class="bash">$ virtualenv .venv
$ source .venv/bin/activate
$ pip install elasticsearch-curator
</code></pre>

<p>Populate the configuration whith your Elasticsearch Host details:</p>

<pre><code class="yml config.yml">---
client:
  hosts:
    - es.domain.com
  port: 443
  use_ssl: True
  ssl_no_validate: False
  http_auth:
  timeout: 30
  master_only: False

logging:
  loglevel: INFO
  logfile:
  logformat: default
  blacklist: ['urllib3']
</code></pre>

<h2>Action: Create Indices</h2>

<p>Use Curator to Create Elasticsearch Indexes:</p>

<pre><code class="yml action-create-indices.yml">---
actions:
  create_web-app1-metrics:
    action: create_index
    description: &gt;-
      Create Elasticsearch Index based on Todays Date
      Specify Number of Primary and Replica Shards
      web-app1-metrics-2017.12.04
    options:
      name: '&lt;web-app1-metrics-{now/d}&gt;'
      extra_settings:
        settings:
          number_of_shards: 5
          number_of_replicas: 1
        continue_if_exception: True
        disable_action: False

  create_web-app2-metrics:
    action: create_index
    description: "Create Index with the 1st of this Month in Daily Format - web-app2-metrics-2017.12.01"
    options:
      name: '&lt;web-app2-metrics-{now/M}&gt;'
      extra_settings:
        settings:
          number_of_shards: 5
          number_of_replicas: 2
        continue_if_exception: True
        disable_action: False

  create_web-app3-metrics:
    action: create_index
    description: "Create Index with Last Months Date in Month Format - web-app3-metrics-2017.11"
    options:
      name: '&lt;web-app2-metrics-{now/M-1M{YYYY.MM}}&gt;'
      extra_settings:
        settings:
          number_of_shards: 5
          number_of_replicas: 2
        continue_if_exception: True
        disable_action: False

  create_web-app4-metrics:
    action: create_index
    description: "Create Index with Daily Format 12 Hours from Now - web-app4-metrics-2017.12.05"
    options:
      name: '&lt;web-app2-metrics-{now/d{YYYY.MM.dd|+12:00}}&gt;'
      extra_settings:
        settings:
          number_of_shards: 5
          number_of_replicas: 2
        continue_if_exception: True
        disable_action: False
</code></pre>

<p>When Running curator, you can append <code>--dry-run</code> to test your config/action without touching your data. To create these indexes:</p>

<pre><code class="bash ">$ curator --config config.yml action-create-indices.yml

2017-12-04 14:22:40,252 INFO      Preparing Action ID: create_web-app1-metrics, "create_index"
2017-12-04 14:22:40,303 INFO      GET https://es.domain.com:443/ [status:200 request:0.036s]
2017-12-04 14:22:40,304 INFO      Trying Action ID: create_web-app1-metrics, "create_index": Create Elasticsearch Index based on Todays Date Specify Number of Primary and Replica Shards web-app1-metrics-2017.12.04
2017-12-04 14:22:40,304 INFO      "&lt;web-app1-metrics-{now/d}&gt;" is using Elasticsearch date math.
2017-12-04 14:22:40,304 INFO      Creating index "&lt;web-app1-metrics-{now/d}&gt;" with settings: {'continue_if_exception': True, 'settings': {'number_of_replicas': 1, 'number_of_shards': 5}, 'disable_action': False}
2017-12-04 14:22:41,490 INFO      PUT https://es.domain.com:443/%3Cweb-app1-metrics-%7Bnow%2Fd%7D%3E [status:200 request:1.185s]
2017-12-04 14:22:41,490 INFO      Action ID: create_web-app1-metrics, "create_index" completed.
2017-12-04 14:22:41,490 INFO      Preparing Action ID: create_web-app2-metrics, "create_index"
2017-12-04 14:22:41,533 INFO      GET https://es.domain.com:443/ [status:200 request:0.033s]
2017-12-04 14:22:41,534 INFO      Trying Action ID: create_web-app2-metrics, "create_index": Create Index with the 1st of this Month in Daily Format - web-app2-metrics-2017.12.01
2017-12-04 14:22:41,534 INFO      "&lt;web-app2-metrics-{now/M}&gt;" is using Elasticsearch date math.
2017-12-04 14:22:41,534 INFO      Creating index "&lt;web-app2-metrics-{now/M}&gt;" with settings: {'continue_if_exception': True, 'settings': {'number_of_replicas': 2, 'number_of_shards': 5}, 'disable_action': False}
2017-12-04 14:22:41,634 INFO      PUT https://es.domain.com:443/%3Cweb-app2-metrics-%7Bnow%2FM%7D%3E [status:200 request:0.099s]
2017-12-04 14:22:41,634 INFO      Action ID: create_web-app2-metrics, "create_index" completed.
2017-12-04 14:22:41,634 INFO      Preparing Action ID: create_web-app3-metrics, "create_index"
2017-12-04 14:22:41,673 INFO      GET https://es.domain.com:443/ [status:200 request:0.028s]
2017-12-04 14:22:41,674 INFO      Trying Action ID: create_web-app3-metrics, "create_index": Create Index with Last Months Date in Month Format - web-app3-metrics-2017.11
2017-12-04 14:22:41,674 INFO      "&lt;web-app2-metrics-{now/M-1M{YYYY.MM}}&gt;" is using Elasticsearch date math.
2017-12-04 14:22:41,674 INFO      Creating index "&lt;web-app2-metrics-{now/M-1M{YYYY.MM}}&gt;" with settings: {'continue_if_exception': True, 'settings': {'number_of_replicas': 2, 'number_of_shards': 5}, 'disable_action': False}
2017-12-04 14:22:41,750 INFO      PUT https://es.domain.com:443/%3Cweb-app2-metrics-%7Bnow%2FM-1M%7BYYYY.MM%7D%7D%3E [status:200 request:0.076s]
2017-12-04 14:22:41,751 INFO      Action ID: create_web-app3-metrics, "create_index" completed.
2017-12-04 14:22:41,751 INFO      Preparing Action ID: create_web-app4-metrics, "create_index"
2017-12-04 14:22:41,785 INFO      GET https://es.domain.com:443/ [status:200 request:0.027s]
2017-12-04 14:22:41,786 INFO      Trying Action ID: create_web-app4-metrics, "create_index": Create Index with Daily Format 12 Hours from Now - web-app4-metrics-2017.12.05
2017-12-04 14:22:41,786 INFO      "&lt;web-app2-metrics-{now/d{YYYY.MM.dd|+12:00}}&gt;" is using Elasticsearch date math.
2017-12-04 14:22:41,786 INFO      Creating index "&lt;web-app2-metrics-{now/d{YYYY.MM.dd|+12:00}}&gt;" with settings: {'continue_if_exception': True, 'settings': {'number_of_replicas': 2, 'number_of_shards': 5}, 'disable_action': False}
2017-12-04 14:22:42,182 INFO      PUT https://es.domain.com:443/%3Cweb-app2-metrics-%7Bnow%2Fd%7BYYYY.MM.dd%7C%2B12%3A00%7D%7D%3E [status:200 request:0.396s]
2017-12-04 14:22:42,183 INFO      Action ID: create_web-app4-metrics, "create_index" completed.
2017-12-04 14:22:42,183 INFO      Job completed.
</code></pre>

<p>Lets have a look at our indices to confirm that our indices was created:</p>

<pre><code class="bash">$ curl -s -XGET "https://es.domain.com/_cat/indices/web-*?v"
health status index                       uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   web-app2-metrics-2017.12.01 qJHVyft1THemh1qGvA8u0w   5   2          0            0       810b           810b
green  open   web-app2-metrics-2017.11    y5R4vNfOSh2tiC-yGtkgLg   5   2          0            0       810b           810b
green  open   web-app2-metrics-2017.12.05 -ohbgD6-TmmCeJtVv84dPw   5   2          0            0       810b           810b
green  open   web-app1-metrics-2017.12.04 WeGkgB9FSq-cuLVR7ccQFQ   5   1          0            0       810b           810b
</code></pre>

<h2>Action: Reindex Indices based on Timestring</h2>

<p>I would like to reindex a months worth of index data to a monthly index:</p>

<pre><code class="yml action-reindex.yml">---
actions:
  re-index_web-app1-metrics:
    action: reindex
    description: "reindex web-app1-metrics to monthly index of last months date - archive-web-app1-metrics-2017.11"
    options:
      continue_if_exception: False
      disable_action: False
      wait_interval: 9
      max_wait: -1
      request_body:
        source:
          index: '&lt;web-app1-metrics-{now/d-31d{YYYY.MM.dd}}&gt;'
        dest:
          index: '&lt;archive-web-app1-metrics-{now/M-1M{YYYY.MM}}&gt;'
    filters:
    - filtertype: none
</code></pre>

<p>Running the Curator to reindex all last months data: <code>web-app1-metrics-2017.11.{01-31}</code> to the index: <code>web-app1-metrics-2017.11</code>:</p>

<pre><code class="bash">$ curator --config config action-reindex.yml
</code></pre>

<h2>Curator to Change Replica Counts on your Indices:</h2>

<p>We will change all our indices settings to replica count of 2, that is matched with our prefix pattern. We are using <code>wait_for_completion</code> so the job will only be completed once the replica count number is updated and data has been replicated to the replica shards.</p>

<p>Our action file:</p>

<pre><code class="yml action-replicas.yml">---
actions:
  increase_replica_2:
    action: replicas
    description: &gt;-
      Increase the replica count to 2 for logstash- prefixed indices older than
      10 days (based on index creation_date)
    options:
      count: 2
      max_wait: -1
      wait_interval: 10
      wait_for_completion: True
      disable_action: False
    filters:
    - filtertype: pattern
      kind: prefix
      value: packet-capture-2017.11.
</code></pre>

<p>Using Curator to increase our replica count on all the matched indices:</p>

<pre><code>$ curator --config config.yml action-replicas.yml
2017-12-04 13:42:41,322 INFO      Health Check for all provided keys passed.
2017-12-04 13:42:41,323 INFO      Action ID: increase_replica_2, "replicas" completed.
2017-12-04 13:42:41,323 INFO      Job completed.
</code></pre>

<h2>Curator to Delete your Indices:</h2>

<pre><code>---
# documentation:
# https://www.elastic.co/guide/en/elasticsearch/client/curator/current/ex_delete_indices.html

actions:
  delete-index_web-app1-metrics:
    action: delete_indices
    description: &gt;-
      Delete indices older than 21 days - based on index name, web-app1-metrics-
      prefixed indices. Ignore the error if the filter does not result in an
      actionable list of indices (ignore_empty_list) and exit cleanly.
    options:
      ignore_empty_list: True
      disable_action: False
    filters:
    - filtertype: pattern
      kind: prefix
      value: web-app1-metrics-
    - filtertype: age
      source: name
      direction: older
      timestring: '%Y.%m.%d'
      unit: days
      unit_count: 21
      exclude:

  delete-index_web-app2-metrics:
    action: delete_indices
    description: &gt;-
      Delete indices older than 1 month - based on index name, web-app2-metrics-
      prefixed indices. Ignore the error if the filter does not result in an
      actionable list of indices (ignore_empty_list) and exit cleanly.
    options:
      ignore_empty_list: True
      disable_action: False
    filters:
    - filtertype: pattern
      kind: prefix
      value: web-app2-metrics-
    - filtertype: age
      source: name
      direction: older
      timestring: '%Y.%m.%d'
      unit: months
      unit_count: 1
      exclude:
</code></pre>

<p>First we will execute a Dry Run:</p>

<pre><code>$ curator --config /opt/curator/es-dev/config.yml /opt/curator/es-dev/actions/action-delete.yml --dry-run

2017-12-04 14:43:19,789 INFO      Preparing Action ID: delete-index_web-app1-metrics, "delete_indices"
2017-12-04 14:43:19,850 INFO      GET https://es.domain.com:443/ [status:200 request:0.037s]
2017-12-04 14:43:19,851 INFO      Trying Action ID: delete-index_web-app1-metrics, "delete_indices": Delete indices older than 21 days - based on index name, web-app1-metrics- prefixed indices. Ignore the error if the filter does not result in an actionable list of indices (ignore_empty_list) and exit cleanly.
2017-12-04 14:43:19,859 INFO      GET https://es.domain.com:443/_all/_settings?expand_wildcards=open%2Cclosed [status:200 request:0.008s]
2017-12-04 14:43:19,862 INFO      GET https://es.domain.com:443/ [status:200 request:0.002s]
2017-12-04 14:43:19,957 INFO      DRY-RUN MODE.  No changes will be made.
2017-12-04 14:43:19,957 INFO      (CLOSED) indices may be shown that may not be acted on by action "delete_indices".
2017-12-04 14:43:19,957 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.01 with arguments: {}
2017-12-04 14:43:19,958 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.02 with arguments: {}
2017-12-04 14:43:19,958 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.03 with arguments: {}
2017-12-04 14:43:19,958 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.04 with arguments: {}
2017-12-04 14:43:19,958 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.05 with arguments: {}
2017-12-04 14:43:19,958 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.06 with arguments: {}
2017-12-04 14:43:19,958 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.07 with arguments: {}
2017-12-04 14:43:19,958 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.08 with arguments: {}
2017-12-04 14:43:19,959 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.09 with arguments: {}
2017-12-04 14:43:19,959 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.10 with arguments: {}
2017-12-04 14:43:19,959 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.11 with arguments: {}
2017-12-04 14:43:19,959 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.12 with arguments: {}
2017-12-04 14:43:19,959 INFO      DRY-RUN: delete_indices: web-app1-metrics-2017.11.13 with arguments: {}
2017-12-04 14:43:19,959 INFO      Action ID: delete-index_web-app1-metrics, "delete_indices" completed.
2017-12-04 14:43:19,959 INFO      Preparing Action ID: delete-index_web-app2-metrics, "delete_indices"
2017-12-04 14:43:20,025 INFO      GET https://es.domain.com:443/ [status:200 request:0.050s]
2017-12-04 14:43:20,026 INFO      Trying Action ID: delete-index_web-app2-metrics, "delete_indices": Delete indices older than 1 month - based on index name, web-app2-metrics- prefixed indices. Ignore the error if the filter does not result in an actionable list of indices (ignore_empty_list) and exit cleanly.
2017-12-04 14:43:20,034 INFO      GET https://es.domain.com:443/_all/_settings?expand_wildcards=open%2Cclosed [status:200 request:0.008s]
2017-12-04 14:43:20,039 INFO      GET https://es.domain.com:443/ [status:200 request:0.003s]
2017-12-04 14:43:20,090 INFO      DRY-RUN MODE.  No changes will be made.
2017-12-04 14:43:20,090 INFO      (CLOSED) indices may be shown that may not be acted on by action "delete_indices".
2017-12-04 14:43:20,090 INFO      DRY-RUN: delete_indices: web-app2-metrics-2017.11.01 with arguments: {}
2017-12-04 14:43:20,090 INFO      DRY-RUN: delete_indices: web-app2-metrics-2017.11.02 with arguments: {}
2017-12-04 14:43:20,090 INFO      DRY-RUN: delete_indices: web-app2-metrics-2017.11.03 with arguments: {}
2017-12-04 14:43:20,090 INFO      DRY-RUN: delete_indices: web-app2-metrics-2017.11.04 with arguments: {}
2017-12-04 14:43:20,090 INFO      Action ID: delete-index_web-app2-metrics, "delete_indices" completed.
2017-12-04 14:43:20,090 INFO      Job completed.
</code></pre>

<p>Everything seems to be as expected, lets run the Curator without the Dry-Run mode:</p>

<pre><code class="bash">$ curator --config config.yml action-delete.yml

2017-12-04 14:43:40,042 INFO      Deleting selected indices: [u'web-app1-metrics-2017.11.06', u'web-app1-metrics-2017.11.07', u'web-app1-metrics-2017.11.04', u'web-app1-metrics-2017.11.05', u'web-app1-metrics-2017.11.02', u'web-app1-metrics-2017.11.03', u'web-app1-metrics-2017.11.01', u'web-app1-metrics-2017.11.08', u'web-app1-metrics-2017.11.09', u'web-app1-metrics-2017.11.11', u'web-app1-metrics-2017.11.10', u'web-app1-metrics-2017.11.13', u'web-app1-metrics-2017.11.12']
2017-12-04 14:43:40,043 INFO      ---deleting index web-app1-metrics-2017.11.06
2017-12-04 14:43:40,043 INFO      ---deleting index web-app1-metrics-2017.11.07
2017-12-04 14:43:40,043 INFO      ---deleting index web-app1-metrics-2017.11.04
2017-12-04 14:43:40,043 INFO      ---deleting index web-app1-metrics-2017.11.05
2017-12-04 14:43:40,043 INFO      ---deleting index web-app1-metrics-2017.11.02
2017-12-04 14:43:40,043 INFO      ---deleting index web-app1-metrics-2017.11.03
2017-12-04 14:43:40,043 INFO      ---deleting index web-app1-metrics-2017.11.01
2017-12-04 14:43:40,044 INFO      ---deleting index web-app1-metrics-2017.11.08
2017-12-04 14:43:40,044 INFO      ---deleting index web-app1-metrics-2017.11.09
2017-12-04 14:43:40,044 INFO      ---deleting index web-app1-metrics-2017.11.11
2017-12-04 14:43:40,044 INFO      ---deleting index web-app1-metrics-2017.11.10
2017-12-04 14:43:40,044 INFO      ---deleting index web-app1-metrics-2017.11.13
2017-12-04 14:43:40,044 INFO      ---deleting index web-app1-metrics-2017.11.12
2017-12-04 14:43:40,287 INFO      DELETE https://es.domain.com:443/web-app1-metrics-2017.11.01,web-app1-metrics-2017.11.02,web-app1-metrics-2017.11.03,web-app1-metrics-2017.11.04,web-app1-metrics-2017.11.05,web-app1-metrics-2017.11.06,web-app1-metrics-2017.11.07,web-app1-metrics-2017.11.08,web-app1-metrics-2017.11.09,web-app1-metrics-2017.11.10,web-app1-metrics-2017.11.11,web-app1-metrics-2017.11.12,web-app1-metrics-2017.11.13?master_timeout=30s [status:200 request:0.243s]
2017-12-04 14:43:40,417 INFO      Action ID: delete-index_web-app1-metrics, "delete_indices" completed.
2017-12-04 14:43:40,417 INFO      Preparing Action ID: delete-index_web-app2-metrics, "delete_indices"
2017-12-04 14:43:40,453 INFO      Trying Action ID: delete-index_web-app2-metrics, "delete_indices": Delete indices older than 1 month - based on index name, web-app2-metrics- prefixed indices. Ignore the error if the filter does not result in an actionable list of indices (ignore_empty_list) and exit cleanly.
2017-12-04 14:43:40,491 INFO      Deleting selected indices: [u'web-app2-metrics-2017.11.03', u'web-app2-metrics-2017.11.01', u'web-app2-metrics-2017.11.02', u'web-app2-metrics-2017.11.04']
2017-12-04 14:43:40,492 INFO      ---deleting index web-app2-metrics-2017.11.03
2017-12-04 14:43:40,492 INFO      ---deleting index web-app2-metrics-2017.11.01
2017-12-04 14:43:40,492 INFO      ---deleting index web-app2-metrics-2017.11.02
2017-12-04 14:43:40,492 INFO      ---deleting index web-app2-metrics-2017.11.04
2017-12-04 14:43:40,566 INFO      DELETE https://es.domain.com:443/web-app2-metrics-2017.11.01,web-app2-metrics-2017.11.02,web-app2-metrics-2017.11.03,web-app2-metrics-2017.11.04?master_timeout=30s [status:200 request:0.074s]
2017-12-04 14:43:40,595 INFO      GET https://es.domain.com:443/ [status:200 request:0.002s]
2017-12-04 14:43:40,596 INFO      Action ID: delete-index_web-app2-metrics, "delete_indices" completed.
2017-12-04 14:43:40,596 INFO      Job completed.
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html">Elasticsearch Curator</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use the Reindex API on Elasticsearch to Reindex Your Data]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/22/use-the-reindex-api-on-elasticsearch-to-reindex-your-data/"/>
    <updated>2017-11-22T09:32:00-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/22/use-the-reindex-api-on-elasticsearch-to-reindex-your-data</id>
    <content type="html"><![CDATA[<p>A Basic Example of Reindexing Data with the <code>/_reindex</code> API on Elasticsearch:</p>

<h2>Provision Elasticsearch with Docker:</h2>

<p>I will be using Elasticsearch on Docker for this Example:</p>

<pre><code class="bash">$ docker run -itd --name elasticsearch --publish 9200:9200 elasticsearch:alpine
</code></pre>

<h2>Create Indexes:</h2>

<p>Create 3 Indexes and POST 2 Documents to each Index:</p>

<pre><code class="bash">$ curl -XPUT http://127.0.0.1:9200/animals-2017.11.20
$ curl -XPUT http://127.0.0.1:9200/animals-2017.11.21
$ curl -XPUT http://127.0.0.1:9200/animals-2017.11.21
</code></pre>

<p>Create the Index where we will reindex the data to:</p>

<pre><code class="bash">$ curl -XPUT http://127.0.0.1:9200/animals-2017.11 -d '{"settings": {"number_of_shards": 5, "number_of_replicas": 0}}'
</code></pre>

<p>POST 2 documents to each index:</p>

<pre><code class="bash">$ curl -XPOST http://127.0.0.1:9200/animals-2017.11.20/name/ -d '{"name": "max", "type": "labrador"}'
$ curl -XPOST http://127.0.0.1:9200/animals-2017.11.20/name/ -d '{"name": "sam", "type": "pooch"}'

$ curl -XPOST http://127.0.0.1:9200/animals-2017.11.21/name/ -d '{"name": "doggie", "type": "bulldog"}'
$ curl -XPOST http://127.0.0.1:9200/animals-2017.11.21/name/ -d '{"name": "james", "type": "huskey"}'

$ curl -XPOST http://127.0.0.1:9200/animals-2017.11.22/name/ -d '{"name": "sarah", "type": "poodle"}'
$ curl -XPOST http://127.0.0.1:9200/animals-2017.11.22/name/ -d '{"name": "frank", "type": "alsation"}'
</code></pre>

<h2>View the Indexes:</h2>

<p>As you can see we have 2 documents per index, and a empty index for the data that we would like to reindex to:</p>

<pre><code class="bash">$ curl -XGET http://127.0.0.1:9200/_cat/indices?v
health status index               uuid                     pri rep docs.count docs.deleted store.size pri.store.size
yellow open   animals-2017.11.20  AxRYUfNpQ5ev2mdZf0bYrw   5   1          2            0      8.9kb          8.9kb
green  open   animals-2017.11     1T6TkYWwRuerIZ5_np1B0w   5   0          0            0      1.5kb          1.5kb
yellow open   animals-2017.11.22  fCdaRyBZRiWyQ3tZLhdBrw   5   1          2            0      8.9kb          8.9kb
yellow open   animals-2017.11.21  4Ei9zMDITHy1dI8lIzfjjA   5   1          2            0      8.9kb          8.9kb
</code></pre>

<h2>Reindex the Data to our Monthly Index:</h2>

<p>We will define our query to match all the indexes that has the data and reindex to our new index <code>animals-2017.11</code>:</p>

<pre><code class="bash">$ curl -XPOST http://127.0.0.1:9200/_reindex -d '{"source": {"index": "animals-2017.11.*"}, "dest": {"index": "animals-2017.11"} }'
{"took":219,"timed_out":false,"total":6,"updated":0,"created":6,"deleted":0,"batches":1,"version_conflicts":0,"noops":0,"retries":{"bulk":0,"search":0},"throttled_millis":0,"requests_per_second":-1.0,"throttled_until_millis":0,"failures":[]}
</code></pre>

<h2>View the Indexes:</h2>

<pre><code class="bash">$ curl -XGET http://127.0.0.1:9200/_cat/indices?v
health status index               uuid                     pri rep docs.count docs.deleted store.size pri.store.size
yellow open   animals-2017.11.20  AxRYUfNpQ5ev2mdZf0bYrw   5   1          2            0      8.9kb          8.9kb
green  open   animals-2017.11     1T6TkYWwRuerIZ5_np1B0w   5   0          6            0     20.2kb         20.2kb
yellow open   animals-2017.11.22  fCdaRyBZRiWyQ3tZLhdBrw   5   1          2            0      8.9kb          8.9kb
yellow open   animals-2017.11.21  4Ei9zMDITHy1dI8lIzfjjA   5   1          2            0      8.9kb          8.9kb
</code></pre>

<h2>Delete the Old Indexes:</h2>

<p>As your data is now reindexed, we can safely remove our old indexes:</p>

<pre><code class="bash">$ curl -XDELETE 'http://127.0.0.1:9200/animals-2017.11.*'
</code></pre>

<p>To verify:</p>

<pre><code class="bash">$ curl -XGET http://127.0.0.1:9200/_cat/indices?v
health status index               uuid                     pri rep docs.count docs.deleted store.size pri.store.size
green  open   animals-2017.11     1T6TkYWwRuerIZ5_np1B0w   5   0          6            0     20.2kb         20.2kb
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Elasticsearch Curator to Reindex Data]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/22/using-elasticsearch-curator-to-reindex-data/"/>
    <updated>2017-11-22T09:09:28-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/22/using-elasticsearch-curator-to-reindex-data</id>
    <content type="html"><![CDATA[<p>Today I was using Elasticsearch Curator to reindex indices that was created on a daily basis, to reindex all the data to one index. I used this route as the old data will not be accessed frequently.</p>

<h2>Install Elasticsearch Curator</h2>

<pre><code class="bash">$ docker run -it python:2.7-alpine sh
$ pip install elasticsearch-curator
</code></pre>

<h2>Create Configs:</h2>

<p>Create the curator config:</p>

<pre><code class="yaml config.yml">---
# Remember, leave a key empty if there is no value.  None will be a string,
# not a Python "NoneType"
client:
  hosts:
    - es.endpoint.com
  port: 443
  use_ssl: True
  ssl_no_validate: False
  http_auth: admin:pass
  timeout: 30
  master_only: False

logging:
  loglevel: INFO
  logfile:
  logformat: default
  blacklist: ['urllib3']
</code></pre>

<p>Create the action config:</p>

<pre><code class="yaml action-reindex.yml">---
# Remember, leave a key empty if there is no value.  None will be a string,
# not a Python "NoneType"
#
# Also remember that all examples have 'disable_action' set to True.  If you
# want to use this action as a template, be sure to set this to False after
# copying it.
actions:
  1:
    description: "Reindex index-2017.10.{30,31} into new-index-2017.10"
    action: reindex
    options:
      disable_action: False
      wait_interval: 9
      max_wait: -1
      request_body:
        source:
          index: ['index-2017.10.*']
        dest:
          index: new-index-2017.10
    filters:
    - filtertype: none
</code></pre>

<h2>Create the Elasticsearch Index:</h2>

<p>Create the Index where we will reindex the data to:</p>

<pre><code class="bash">$ curl -XPUT http://es.endpoint.com/new-index-2017.10 -d '{"settings": {"number_of_shards": 5, "number_of_replicas": 1}}'
</code></pre>

<h2>Run the Curator:</h2>

<pre><code class="bash">$ curator --config curator.yml action-reindex.yml

2017-11-22 14:18:15,138 INFO      Task "reindex from [index-2017.10.*] to [index-2017.10]" with task_id "Za-sn0z3Q9-75xCMRwJ3-A:15782886" has been running for 928.948195354 seconds
2017-11-22 14:18:24,152 INFO      GET https://es.endpoint.com:443/_tasks/Za-sn0z3Q9-75xCMRwJ3-A%3A15782886 [status:200 request:0.005s]
2017-11-22 14:18:24,153 INFO      Task "reindex from [index-2017.10.*] to [new-index-2017.10]" with task_id "Za-sn0z3Q9-75xCMRwJ3-A:15782886" has been running for 937.962740393 seconds
2017-11-22 14:22:23,171 INFO      Action ID: 1, "reindex" completed.
2017-11-22 14:22:23,171 INFO      Job completed.
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html">https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html</a></li>
<li><a href="https://qbox.io/blog/logstash-elasticsearch-curator-data-retention">https://qbox.io/blog/logstash-elasticsearch-curator-data-retention</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Elasticdump to Backup Elasticsearch Indexes to JSON]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/22/using-elasticdump-to-backup-elasticsearch-indexes-to-json/"/>
    <updated>2017-11-22T08:35:28-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/22/using-elasticdump-to-backup-elasticsearch-indexes-to-json</id>
    <content type="html"><![CDATA[<p>We will use Elasticdump to dump data from Elasticsearch to json files on disk, then delete the index, then restore data back to elasticsearch</p>

<h2>Install Elasticdump:</h2>

<pre><code class="bash">$ docker run -it node:alpine sh
$ npm install elasticdump -g
</code></pre>

<h2>Create a Index:</h2>

<pre><code class="bash">$ curl -XPUT http://10.79.2.193:9200/test-index
{"acknowledged":true}
</code></pre>

<p>Ingest Some Data into the Index:</p>

<pre><code class="bash">$ curl -XPUT http://10.79.2.193:9200/test-index/docs/doc1 -d '{"name": "ruan", "age": 30}'
{"_index":"test-index","_type":"docs","_id":"doc1","_version":1,"_shards":{"total":2,"successful":1,"failed":0},"created":true}

$ curl -XPUT http://10.79.2.193:9200/test-index/docs/doc2 -d '{"name": "stefan", "age": 29}'
{"_index":"test-index","_type":"docs","_id":"doc2","_version":1,"_shards":{"total":2,"successful":1,"failed":0},"created":true}
</code></pre>

<h2>Elasticdump to dump the ata</h2>

<p>First dump the mappings:</p>

<pre><code class="bash">$ elasticdump --input=http://10.79.2.193:9200/test-index --output=/opt/backup/elasticsearch/es_test-index_mapping.json --type=mapping
Mon, 26 Jun 2017 14:15:34 GMT | starting dump
Mon, 26 Jun 2017 14:15:34 GMT | got 1 objects from source elasticsearch (offset: 0)
Mon, 26 Jun 2017 14:15:34 GMT | sent 1 objects to destination file, wrote 1
Mon, 26 Jun 2017 14:15:34 GMT | got 0 objects from source elasticsearch (offset: 1)
Mon, 26 Jun 2017 14:15:34 GMT | Total Writes: 1
Mon, 26 Jun 2017 14:15:34 GMT | dump complete
</code></pre>

<p>Then dump the data:</p>

<pre><code class="bash">$ elasticdump --input=http://10.79.2.193:9200/test-index --output=/opt/backup/elasticsearch/es_test-index.json --type=data
Mon, 26 Jun 2017 14:15:43 GMT | starting dump
Mon, 26 Jun 2017 14:15:43 GMT | got 2 objects from source elasticsearch (offset: 0)
Mon, 26 Jun 2017 14:15:43 GMT | sent 2 objects to destination file, wrote 2
Mon, 26 Jun 2017 14:15:43 GMT | got 0 objects from source elasticsearch (offset: 2)
Mon, 26 Jun 2017 14:15:43 GMT | Total Writes: 2
Mon, 26 Jun 2017 14:15:43 GMT | dump complete
</code></pre>

<p>Preview the Metadata</p>

<pre><code class="bash">$ cat /opt/backup/elasticsearch/es_test-index_mapping.json | python -m json.tool
{
    "test-index": {
        "mappings": {
            "docs": {
                "properties": {
                    "age": {
                        "type": "long"
                    },
                    "name": {
                        "type": "string"
                    }
                }
            }
        }
    }
}
</code></pre>

<p>Preview the Data</p>

<pre><code class="bash">$ cat /opt/backup/elasticsearch/es_test-index.json | jq
{
  "_index": "test-index",
  "_type": "docs",
  "_id": "doc1",
  "_score": 1,
  "_source": {
    "name": "ruan",
    "age": 30
  }
}
{
  "_index": "test-index",
  "_type": "docs",
  "_id": "doc2",
  "_score": 1,
  "_source": {
    "name": "stefan",
    "age": 29
  }
}
</code></pre>

<h2>Restore The Data</h2>

<p>Let&rsquo;s test the restoring part, go ahead and delete The index:</p>

<pre><code class="bash">$ curl -XDELETE http://10.79.2.193:9200/test-index
{"acknowledged":true}
</code></pre>

<p>Restore the Index by Importing the Mapping:</p>

<pre><code class="bash">$ elasticdump --input=/opt/backup/elasticsearch/es_test-index_mapping.json --output=http://10.79.2.193:9200/test-index --type=mapping
Mon, 26 Jun 2017 14:51:48 GMT | starting dump
Mon, 26 Jun 2017 14:51:48 GMT | got 1 objects from source file (offset: 0)
Mon, 26 Jun 2017 14:51:48 GMT | sent 1 objects to destination elasticsearch, wrote 1
Mon, 26 Jun 2017 14:51:48 GMT | got 0 objects from source file (offset: 1)
Mon, 26 Jun 2017 14:51:48 GMT | Total Writes: 1
Mon, 26 Jun 2017 14:51:48 GMT | dump complete
</code></pre>

<p>Verify to see if the Index Exist:</p>

<pre><code class="bash">$ curl -s -XGET http://10.79.2.193:9200/_cat/indices?v | grep -E '(docs.count|test)'
health status index                     pri rep docs.count docs.deleted store.size pri.store.size
yellow open   test-index                  5   1          0            0       650b           650b
</code></pre>

<h2>Restore the Data for the Index:</h2>

<p>Use elasticdump to restore the data from json to elasticsearch:</p>

<pre><code class="bash">$ elasticdump --input=/opt/backup/elasticsearch/es_test-index.json --output=http://10.79.2.193:9200/test-index --type=data
Mon, 26 Jun 2017 14:53:56 GMT | starting dump
Mon, 26 Jun 2017 14:53:56 GMT | got 2 objects from source file (offset: 0)
Mon, 26 Jun 2017 14:53:56 GMT | sent 2 objects to destination elasticsearch, wrote 2
Mon, 26 Jun 2017 14:53:56 GMT | got 0 objects from source file (offset: 2)
Mon, 26 Jun 2017 14:53:56 GMT | Total Writes: 2
Mon, 26 Jun 2017 14:53:56 GMT | dump complete
</code></pre>

<p>Verify to see if the Documents was Ingested:</p>

<pre><code class="bash">$ curl -s -XGET http://10.79.2.193:9200/_cat/indices?v | grep -E '(docs.count|test)'
health status index                     pri rep docs.count docs.deleted store.size pri.store.size
yellow open   test-index                  5   1          2            0       650b           650b
</code></pre>

<p>Preview the Data from Elasticsearch:</p>

<pre><code class="bash">$ curl -s -XGET http://10.79.2.193:9200/test-index/_search?pretty

{
  "took" : 3,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 2,
    "max_score" : 1.0,
    "hits" : [ {
      "_index" : "test-index",
      "_type" : "docs",
      "_id" : "doc1",
      "_score" : 1.0,
      "_source" : {
        "name" : "ruan",
        "age" : 30
      }
    }, {
      "_index" : "test-index",
      "_type" : "docs",
      "_id" : "doc2",
      "_score" : 1.0,
      "_source" : {
        "name" : "stefan",
        "age" : 29
      }
    } ]
  }
}
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.npmjs.com/package/elasticdump">https://www.npmjs.com/package/elasticdump</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
