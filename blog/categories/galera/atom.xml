<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Galera | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/galera/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2023-07-15T18:00:35-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Running a HA MySQL Galera Cluster on Docker Swarm]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/05/10/running-a-ha-mysql-galera-cluster-on-docker-swarm/"/>
    <updated>2019-05-10T07:02:39-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/05/10/running-a-ha-mysql-galera-cluster-on-docker-swarm</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/57523982-c904d780-7326-11e9-981a-7a9cb9552c2f.png" alt="image" /></p>

<p>In this post we will setup a highly available mysql galera cluster on docker swarm.</p>

<h2>About</h2>

<p>The service is based of <a href="https://github.com/toughIQ/docker-mariadb-cluster">docker-mariadb-cluster</a> repository and it&rsquo;s designed not to have any persistent data attached to the service, but rely on the &ldquo;nodes&rdquo; to replicate the data.</p>

<p>Note, that however this proof of concept works, I always recommend to use a remote mysql database outside your cluster, such as RDS etc.</p>

<p>Since we don&rsquo;t persist any data on the mysql cluster, I have associated a dbclient service that will run continious backups, which we will persist the path where the backups reside to disk.</p>

<h2>Deploy the MySQL Cluster</h2>

<p>The <a href="https://raw.githubusercontent.com/ruanbekker/dockerfiles/master/mysql-cluster/docker-compose.yml">docker-compose.yml</a> that we will use looks like this:</p>

<pre><code class="yaml">version: '3.5'
services:
  dbclient:
    image: alpine
    environment:
      - BACKUP_ENABLED=1
      - BACKUP_INTERVAL=3600
      - BACKUP_PATH=/data
      - BACKUP_FILENAME=db_backup
    networks:
      - dbnet
    entrypoint: |
      sh -c 'sh -s &lt;&lt; EOF
      apk add --no-cache mysql-client
      while true
        do
          if [ $$BACKUP_ENABLED == 1 ]
            then
              sleep $$BACKUP_INTERVAL
              mkdir -p $$BACKUP_PATH/$$(date +%F)
              echo "$$(date +%FT%H.%m) - Making Backup to : $$BACKUP_PATH/$$(date +%F)/$$BACKUP_FILENAME-$$(date +%FT%H.%m).sql.gz"
              mysqldump -u root -ppassword -h dblb --all-databases | gzip &gt; $$BACKUP_PATH/$$(date +%F)/$$BACKUP_FILENAME-$$(date +%FT%H.%m).sql.gz
              find $$BACKUP_PATH -mtime 7 -delete
          fi
        done
      EOF'
    volumes:
      - vol_dbclient:/data
    deploy:
      mode: replicated
      replicas: 1

  dbcluster:
    image: toughiq/mariadb-cluster
    networks:
      - dbnet
    environment:
      - DB_SERVICE_NAME=dbcluster
      - MYSQL_ROOT_PASSWORD=password
      - MYSQL_DATABASE=mydb
      - MYSQL_USER=mydbuser
      - MYSQL_PASSWORD=mydbpass
    deploy:
      mode: replicated
      replicas: 1

  dblb:
    image: toughiq/maxscale
    networks:
      - dbnet
    ports:
      - 3306:3306
    environment:
      - DB_SERVICE_NAME=dbcluster
      - ENABLE_ROOT_USER=1
    deploy:
      mode: replicated
      replicas: 1

volumes:
  vol_dbclient:
    driver: local

networks:
  dbnet:
    name: dbnet
    driver: overlay
</code></pre>

<p>The dbclient is configured to be in the same network as the cluster so it can reach the mysql service. The default behavior is that it will make a backup every hour (3600 seconds) to the <code>/data/{date}/</code> path.</p>

<p>Deploy the stack:</p>

<pre><code>$ docker stack deploy -c docker-compose.yml galera
Creating network dbnet
Creating service galera_dbcluster
Creating service galera_dblb
Creating service galera_dbclient
</code></pre>

<p>Have a look to see if all the services is running:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
jm7p70qre72u        galera_dbclient     replicated          1/1                 alpine:latest
p8kcr5y7szte        galera_dbcluster    replicated          1/1                 toughiq/mariadb-cluster:latest
1hu3oxhujgfm        galera_dblb         replicated          1/1                 toughiq/maxscale:latest          :3306-&gt;3306/tcp
</code></pre>

<h2>The Backup Client</h2>

<p>As mentioned the backup client backs up to the <code>/data/</code> path:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) find /data/
/data/
/data/2019-05-10
/data/2019-05-10/db_backup-2019-05-10T10.05.sql.gz
</code></pre>

<p>Let&rsquo;s go ahead and populate some data into our mysql database:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb
MySQL [(none)]&gt; create table mydb.foo (name varchar(10));
MySQL [(none)]&gt; insert into mydb.foo values('ruan');
MySQL [(none)]&gt; exit
</code></pre>

<h2>Scale the Cluster</h2>

<p>At the moment we only have 1 replica for our mysql cluster, let&rsquo;s go ahead and scale the cluster to 3 replicas:</p>

<pre><code>$ docker service scale galera_dbcluster=3
galera_dbcluster scaled to 3
overall progress: 3 out of 3 tasks
1/3: running   [==================================================&gt;]
2/3: running   [==================================================&gt;]
3/3: running   [==================================================&gt;]
verify: Service converged
</code></pre>

<p>Verify that the service has been scaled:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
jm7p70qre72u        galera_dbclient     replicated          1/1                 alpine:latest
p8kcr5y7szte        galera_dbcluster    replicated          3/3                 toughiq/mariadb-cluster:latest
1hu3oxhujgfm        galera_dblb         replicated          1/1                 toughiq/maxscale:latest          :3306-&gt;3306/tcp
</code></pre>

<p>Test, by reading from the database:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<h2>Simulate a Node Failure:</h2>

<p>Simulate a node failure by killing one of the mysql containers:</p>

<pre><code>$ docker kill 9e336032ab52
</code></pre>

<p>Verify that one container is missing from our service:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
p8kcr5y7szte        galera_dbcluster    replicated          2/3                 toughiq/mariadb-cluster:latest
</code></pre>

<p>While the container is provisioning, as we have 2 out of 3 running containers, read the data 3 times so test that the round robin queries dont hit the affected container (the dblb wont route traffic to the affected container):</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+

$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+

$ docker exec -it $(docker ps -f name=galera_dbclient -q) mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<p>Verify that the 3rd container has checked in:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                            PORTS
p8kcr5y7szte        galera_dbcluster    replicated          3/3                 toughiq/mariadb-cluster:latest
</code></pre>

<h2>How to Restore?</h2>

<p>I&rsquo;m deleting the database to simulate the scenario where we need to restore:</p>

<pre><code>$ docker exec -it $(docker ps -f name=galera_dbclient -q) sh
&gt; mysql -uroot -ppassword -h dblb -e'drop database mydb;'
</code></pre>

<p>Ensure the db is not present:</p>

<pre><code>&gt; mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
ERROR 1146 (42S02) at line 1: Table 'mydb.foo' doesn't exist
</code></pre>

<p>Find the archive and extract:</p>

<pre><code>&gt; find /data/
/data/
/data/2019-05-10
/data/2019-05-10/db_backup-2019-05-10T10.05.sql.gz

&gt; gunzip /data/2019-05-10/db_backup-2019-05-10T10.05.sql.gz
</code></pre>

<p>Restore the backed up database to MySQL:</p>

<pre><code>&gt; mysql -uroot -ppassword -h dblb &lt; /data/2019-05-10/db_backup-2019-05-10T10.05.sql
</code></pre>

<p>Test that we can read our data:</p>

<pre><code>&gt; mysql -uroot -ppassword -h dblb -e'select * from mydb.foo;'
+------+
| name |
+------+
| ruan |
+------+
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rejoining or Bootstrapping MySQL Galera Cluster Nodes After Shutdown]]></title>
    <link href="https://blog.ruanbekker.com/blog/2017/12/10/rejoining-or-bootstrapping-mysql-galera-cluster-nodes-after-shutdown/"/>
    <updated>2017-12-10T18:03:44-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2017/12/10/rejoining-or-bootstrapping-mysql-galera-cluster-nodes-after-shutdown</id>
    <content type="html"><![CDATA[<p>I have a 3 Node MySQL Galera Cluster that faced a shutdown on all 3 nodes at the same time, luckily this is only a testing environment, but at that time it was down and did not want to start up.</p>

<h2>Issues Faced</h2>

<p>When trying to start MySQL the only error visible was:</p>

<pre><code class="bash">$ /etc/init.d/mysql restart
 * MySQL server PID file could not be found!
Starting MySQL
........ * The server quit without updating PID file (/var/run/mysqld/mysqld.pid).
 * Failed to restart server.
</code></pre>

<p>At that time I can see that the galera port is started, but not mysql:</p>

<pre><code class="bash">$ ps aux | grep mysql
root     23580  0.0  0.0   4508  1800 pts/0    S    00:37   0:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --pid-file=/var/run/mysqld/mysqld.pid
mysql    24144  0.7 22.2 1185116 455660 pts/0  Sl   00:38   0:00 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib/mysql/plugin --user=mysql --log-error=/var/log/mysql/error.log --pid-file=/var/run/mysqld/mysqld.pid --socket=/var/run/mysqld/mysqld.sock --port=3306 --wsrep_start_position=long:string

$ netstat -tulpn
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 0.0.0.0:4567            0.0.0.0:*               LISTEN      25507/mysqld
</code></pre>

<h2>Why?</h2>

<p>More in detail is explained on a <a href="https://severalnines.com/blog/how-bootstrap-mysqlmariadb-galera-cluster">SeveralNines Blog Post</a>, but due to the fact that all the nodes left the cluster, one of the nodes needs to be started as a referencing point, before the other nodes can rejoin or bootstrapped to the cluster.</p>

<h2>Rejoining the Cluster</h2>

<p>Consult the blog for more information, but from my end, I had a look at the node with the highest seqno and then updated <code>safe_to_bootstrap</code> to <code>1</code>:</p>

<pre><code class="bash">$ cat /var/lib/mysql/grastate.dat
# GALERA saved state
version: 2.1
uuid:    e9f9cf6a-87a1-11e7-9fb4-52612b906897
seqno:   123512
safe_to_bootstrap: 1
</code></pre>

<p>Then made sure that no mysql processes are running, then did a bootstrap:</p>

<pre><code class="bash">$ /etc/init.d/mysql bootstrap
Bootstrapping the cluster
Starting MySQL
</code></pre>

<p>Then restarted mysql on the other nodes.</p>

<h2>Verifying</h2>

<p>To verify that all your nodes has checked in, I have 3 nodes:</p>

<pre><code class="sql">mysql&gt; SHOW STATUS LIKE 'wsrep_%';
+------------------------------+---------------------------------------------------+
| Variable_name                | Value                                             |
+------------------------------+---------------------------------------------------+
| wsrep_local_recv_queue_avg   | 0.000000                                          |
| wsrep_local_state_comment    | Synced                                            |
| wsrep_incoming_addresses     | 10.3.132.91:3306,10.4.1.201:3306,10.4.113.21:3306 |
| wsrep_evs_state              | OPERATIONAL                                       |
| wsrep_cluster_size           | 3                                                 |
| wsrep_cluster_status         | Primary                                           |
| wsrep_connected              | ON                                                |
+------------------------------+---------------------------------------------------+
</code></pre>

<p>or a shorter version:</p>

<pre><code class="sql">mysql&gt; SHOW GLOBAL STATUS LIKE 'wsrep_cluster_size';
+------------------------------+---------------------------------------------------+
| Variable_name                | Value                                             |
+------------------------------+---------------------------------------------------+
| wsrep_cluster_size           | 3                                                 |
+------------------------------+---------------------------------------------------+
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a 3 Node Galera MariaDB Cluster on Ubuntu 16]]></title>
    <link href="https://blog.ruanbekker.com/blog/2017/11/22/setup-a-3-node-galera-mariadb-cluster-on-ubuntu-16/"/>
    <updated>2017-11-22T18:17:14-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2017/11/22/setup-a-3-node-galera-mariadb-cluster-on-ubuntu-16</id>
    <content type="html"><![CDATA[<p><img src="https://i.snag.gy/lpT6Du.jpg" alt="" /></p>

<p>Today we will setup a 3-Node Galera MariaDB Cluster which is a Multi Master MySQL/MariaDB Cluster on Ubuntu 16.04</p>

<h2>Our Server Details:</h2>

<pre><code class="bash">172.31.11.174     mysql-1
172.31.13.206     mysql-2
172.31.6.93       mysql-3
</code></pre>

<h2>Update Repo Index and Upgrade:</h2>

<p>Update the repository indexes and install the needed packages:</p>

<pre><code class="bash">$ sudo apt update &amp;&amp; sudo apt upgrade -y
</code></pre>

<p>Install the needed repository and packages:</p>

<pre><code class="bash">$ apt install software-properties-common -y
$ apt-key adv --recv-keys --keyserver hkp://keyserver.ubuntu.com:80 0xF1656F24C74CD1D8
$ add-apt-repository 'deb [arch=amd64,i386,ppc64el] http://mirror.lstn.net/mariadb/repo/10.1/ubuntu xenial main'
$ apt update
$ apt install mariadb-server rsync -y
</code></pre>

<h2>Configuration:</h2>

<pre><code class="bash">cat &gt; /etc/mysql/conf.d/galera.cnf &lt;&lt; EOF
[mysqld]
binlog_format=ROW
default-storage-engine=innodb
innodb_autoinc_lock_mode=2
bind-address=0.0.0.0

# Galera Provider Configuration
wsrep_on=ON
wsrep_provider=/usr/lib/galera/libgalera_smm.so

# Galera Cluster Configuration
wsrep_cluster_name="my-galera-cluster"
wsrep_cluster_address="gcomm://172.31.11.174,172.31.13.206,172.31.6.93"
# Galera Synchronization Configuration
wsrep_sst_method=rsync

# Galera Node Configuration
wsrep_node_address="172.31.11.174"
wsrep_node_name="mysql-1"
EOF
</code></pre>

<p>Comment out bind-address, so that MariaDB process is reachable from other nodes, by default it wont be in the config, but just to make sure, if it is uncommented, comment the config:</p>

<pre><code class="bash /etc/mysql/my.cnf"># bind-address = 127.0.0.1
</code></pre>

<p>Stop the MariaDB Process:</p>

<pre><code class="bash">$ systemctl stop mariadb
</code></pre>

<p>Note: Repeat the above steps on all 3 nodes.</p>

<h2>Initialize the Cluster:</h2>

<p>On the First Node, Initialize the Galera Cluster:</p>

<pre><code class="bash">$ /usr/bin/galera_new_cluster
$ systemctl enable mariadb
</code></pre>

<p>Check how many nodes are active in the Cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 1     |
+--------------------+-------+
</code></pre>

<h2>Node-2: Start and Enable MariaDB</h2>

<pre><code class="bash">$ systemctl start mariadb
$ systemctl enable mariadb
</code></pre>

<p>Verify that the Node has checked in with the Cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 2     |
+--------------------+-------+
</code></pre>

<h2>Node-3: Start and Enable MariaDB</h2>

<pre><code class="bash">$ systemctl start mariadb
$ systemctl enable mariadb
</code></pre>

<p>Verify that the Node has checked in with the Cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 3     |
+--------------------+-------+
</code></pre>

<h2>Create a Database, Table and Record:</h2>

<p>Write some data to the table, then reboot the node, in this example on node-1, then logon to node-2 check the number of nodes that&rsquo;s active in the cluster, which should be 2, then at the same time, look if the data is replicated:</p>

<h2>Node-1: Writing the Data to Our Galera Cluster</h2>

<pre><code class="mysql">MariaDB [(none)]&gt; create database test;
MariaDB [(none)]&gt; use test;
MariaDB [test]&gt;   create database test;
MariaDB [test]&gt;   create table foo (name VARCHAR(20));
MariaDB [test]&gt;   insert into foo values('ruan');
MariaDB [test]&gt;   select * from foo;
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<p>Now that our data is in our database, reboot the node, logon to node-2 and check if the data is replicated:</p>

<pre><code class="mysql">$ mysql -u root -p
MariaDB [(none)]&gt; use test;
MariaDB [test]&gt;   select * from foo;
+------+
| name |
+------+
| ruan |
+------+
</code></pre>

<p>While the one node is rebooting, check how many nodes are checked into our cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 2     |
+--------------------+-------+
</code></pre>

<p>Our data is replicated, and after waiting for a couple of seconds, we retry our command to see if the rebooted node checked into the cluster:</p>

<pre><code class="mysql">$ mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
Enter password:
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| wsrep_cluster_size | 3     |
+--------------------+-------+
</code></pre>

<p>We can confirm that the node that was rebooted, has checked in with the cluster again.</p>

<h2>Firewall Rules opened while testing:</h2>

<p>TCP: <code>3306, 4567, 4568, 4444</code>
UDP: <code>4567</code></p>
]]></content>
  </entry>
  
</feed>
