<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Kubernetes | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/kubernetes/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2020-05-07T13:57:46+02:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Persistent Volumes With K3d Kubernetes]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/21/persistent-volumes-with-k3d-kubernetes/"/>
    <updated>2020-02-21T00:07:48+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/21/persistent-volumes-with-k3d-kubernetes</id>
    <content type="html"><![CDATA[<p>With k3d we can mount the host to container path, and with persistent volumes we can set a hostPath for our persistent volumes. With k3d, all the nodes will be using the same volume mapping which maps back to the host.</p>

<p>We will test the data persistence by writing a file inside a container, kill the pod, then exec into the pod again and test if the data persisted</p>

<h2>The k3d Cluster</h2>

<p>Create the directory on the host where we will persist the data:</p>

<pre><code>&gt; mkdir -p /tmp/k3dvol
</code></pre>

<p>Create the cluster:</p>

<pre><code>&gt; k3d create --name "k3d-cluster" --volume /tmp/k3dvol:/tmp/k3dvol --publish "80:80" --workers 2
&gt; export KUBECONFIG="$(k3d get-kubeconfig --name='k3d-cluster')"
</code></pre>

<p>Our application will be a busybox container which will keep running with a ping command, map the persistent volume to <code>/data</code> inside the pod.</p>

<p>Our <code>app.yml</code></p>

<pre><code>apiVersion: v1
kind: PersistentVolume
metadata:
  name: task-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/tmp/k3dvol"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: task-pv-claim
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo
spec:
  selector:
    matchLabels:
      app: echo
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: echo
    spec:
      volumes:
        - name: task-pv-storage
          persistentVolumeClaim:
            claimName: task-pv-claim
      containers:
      - image: busybox
        name: echo
        volumeMounts:
          - mountPath: "/data"
            name: task-pv-storage
        command: ["ping", "127.0.0.1"]
</code></pre>

<p>Deploy the workload:</p>

<pre><code>&gt; kubectl apply -f app.yml
persistentvolume/task-pv-volume created
persistentvolumeclaim/task-pv-claim created
deployment.apps/echo created
</code></pre>

<p>View the persistent volumes:</p>

<pre><code>&gt; kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS   REASON   AGE
task-pv-volume                             1Gi        RWO            Retain           Bound    default/task-pv-claim    manual                  6s
</code></pre>

<p>View the Persistent Volume Claims:</p>

<pre><code>&gt; kubectl get pvc
NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
task-pv-claim    Bound    task-pv-volume                             1Gi        RWO            manual         11s
</code></pre>

<p>View the pods:</p>

<pre><code>&gt; kubectl get pods
NAME                   READY   STATUS    RESTARTS   AGE
echo-58fd7d9b6-x4rxj   1/1     Running   0          16s
</code></pre>

<p>Exec into the pod:</p>

<pre><code>&gt; kubectl exec -it echo-58fd7d9b6-x4rxj sh
/ # df -h
Filesystem                Size      Used Available Use% Mounted on
overlay                  58.4G     36.1G     19.3G  65% /
osxfs                   233.6G    139.7G     86.3G  62% /data
/dev/sda1                58.4G     36.1G     19.3G  65% /etc/hosts
/dev/sda1                58.4G     36.1G     19.3G  65% /dev/termination-log
/dev/sda1                58.4G     36.1G     19.3G  65% /etc/hostname
/dev/sda1                58.4G     36.1G     19.3G  65% /etc/resolv.conf
</code></pre>

<p>Write the hostname of the current pod to the persistent volume path:</p>

<pre><code>/ # echo $(hostname)
echo-58fd7d9b6-x4rxj
/ # echo $(hostname) &gt; /data/hostname.txt
/ # exit
</code></pre>

<p>Exit the pod and read the content from the host (workstation/laptop):</p>

<pre><code>&gt; cat /tmp/k3dvol/hostname.txt
echo-58fd7d9b6-x4rxj
</code></pre>

<p>Look at the host where the pod is running on:</p>

<pre><code>&gt; kubectl get nodes -o wide
NAME                       STATUS   ROLES    AGE   VERSION        INTERNAL-IP    EXTERNAL-IP   OS-IMAGE   KERNEL-VERSION     CONTAINER-RUNTIME
k3d-k3d-cluster-server     Ready    master   13m   v1.17.2+k3s1   192.168.32.2   &lt;none&gt;        Unknown    4.9.184-linuxkit   containerd://1.3.3-k3s1
k3d-k3d-cluster-worker-1   Ready    &lt;none&gt;   13m   v1.17.2+k3s1   192.168.32.4   &lt;none&gt;        Unknown    4.9.184-linuxkit   containerd://1.3.3-k3s1
k3d-k3d-cluster-worker-0   Ready    &lt;none&gt;   13m   v1.17.2+k3s1   192.168.32.3   &lt;none&gt;        Unknown    4.9.184-linuxkit   containerd://1.3.3-k3s1
</code></pre>

<p>Delete the pod:</p>

<pre><code>&gt; kubectl delete pod/echo-58fd7d9b6-x4rxj
pod "echo-58fd7d9b6-x4rxj" deleted
</code></pre>

<p>Wait until the pod is rescheduled again and verify if the pod is running on a different node:</p>

<pre><code>&gt; kubectl get pods -o wide
NAME                   READY   STATUS    RESTARTS   AGE   IP          NODE                       NOMINATED NODE   READINESS GATES
echo-58fd7d9b6-fkvbs   1/1     Running   0          35s   10.42.2.9   k3d-k3d-cluster-worker-1   &lt;none&gt;           &lt;none&gt;
</code></pre>

<p>Exec into the new pod:</p>

<pre><code>&gt; kubectl exec -it echo-58fd7d9b6-fkvbs sh
</code></pre>

<p>View if the data is persisted:</p>

<pre><code>/ # hostname
echo-58fd7d9b6-fkvbs

/ # cat /data/hostname.txt
echo-58fd7d9b6-x4rxj
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Traefik Ingress for OpenFaas on Kubernetes (K3d)]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/17/traefik-ingress-for-openfaas-on-kubernetes-k3d/"/>
    <updated>2020-02-17T23:36:33+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/17/traefik-ingress-for-openfaas-on-kubernetes-k3d</id>
    <content type="html"><![CDATA[<p>In this post we will deploy <a href="https://www.openfaas.com/">OpenFaas</a> on Kubernetes locally using <a href="https://github.com/alexellis/k3sup">k3sup</a> and <a href="https://github.com/rancher/k3d">k3d</a>, then deploy a Traefik Ingress so that we can access the OpenFaas Gateway on HTTP over the standard port 80.</p>

<p>K3d is a amazing wrapper that deploys a k3s cluster on docker, and k3sup makes it very easy to provision OpenFaas to your Kubernetes cluster.</p>

<h2>Deploy a Kubernetes Cluster</h2>

<p>If you have not installed k3d, you can install k3d on mac with brew:</p>

<pre><code>$ brew install k3d
</code></pre>

<p>We will deploy our cluster with 2 worker nodes and publish port 80 to the containers port 80:</p>

<pre><code>$ k3d create --name="demo" --workers="2" --publish="80:80"
</code></pre>

<p>Point the kubeconfig to the location that k3d generated:</p>

<pre><code>$ export KUBECONFIG="$(k3d get-kubeconfig --name='demo')"
</code></pre>

<h2>Deploy OpenFaas</h2>

<p>First we need to get k3sup:</p>

<pre><code>$ curl -sLfS https://get.k3sup.dev | sudo sh
</code></pre>

<p>Once k3sup is installed, deploy OpenFaas to your cluster:</p>

<pre><code>$ k3sup app install openfaas
</code></pre>

<p>Give it a minute or so and check if everything is running:</p>

<pre><code>$ kubectl get pods -n openfaas
NAMESPACE     NAME                                 READY   STATUS      RESTARTS   AGE
openfaas      alertmanager-546f66b6c6-qtb69        1/1     Running     0          5m
openfaas      basic-auth-plugin-79b9878b7b-7vlln   1/1     Running     0          4m59s
openfaas      faas-idler-db8cd9c7d-8xfpp           1/1     Running     2          4m57s
openfaas      gateway-7dcc6d694d-dmvqn             2/2     Running     0          4m56s
openfaas      nats-d6d574749-rt9vw                 1/1     Running     0          4m56s
openfaas      prometheus-d99669d9b-mfxc8           1/1     Running     0          4m53s
openfaas      queue-worker-75f44b56b9-mhhbv        1/1     Running     0          4m52s
</code></pre>

<h2>Traefik Ingress</h2>

<p>In my scenario, I am using <code>openfaas.localdns.xyz</code> which resolves to <code>127.0.0.1</code>. Next we need to know to which service to route the traffic to, we can find that by:</p>

<pre><code>$ kubectl get svc/gateway -n openfaas
NAME      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
gateway   ClusterIP   10.43.174.57   &lt;none&gt;        8080/TCP   23m
</code></pre>

<p>Below is our ingress.yml:</p>

<pre><code>apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: openfaas-gateway-ingress
  namespace: openfaas
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: openfaas.localdns.xyz
    http:
      paths:
      - backend:
          serviceName: gateway
          servicePort: 8080
</code></pre>

<p>Apply the ingress:</p>

<pre><code>$ kubectl apply -f ingress.yml
ingress.extensions/openfaas-gateway-ingress created
</code></pre>

<p>We can the verify that our ingress is visible:</p>

<pre><code>$ kubectl get ingress -n openfaas
NAMESPACE   NAME                       HOSTS               ADDRESS      PORTS   AGE
openfaas    openfaas-gateway-ingress   openfaas.co.local   172.25.0.4   80      28s
</code></pre>

<h2>OpenFaas CLI</h2>

<p>Install the OpenFaas CLI:</p>

<pre><code>$ curl -SLsf https://cli.openfaas.com | sudo sh
</code></pre>

<p>Export the <code>OPENFAAS_URL</code> to our ingress endpoint and <code>OPENFAAS_PREFIX</code> for your dockerhub username:</p>

<pre><code>$ export OPENFAAS_URL=http://openfaas.localdns.xyz
$ export OPENFAAS_PREFIX=ruanbekker # change to your username
</code></pre>

<p>Get your credentials for the OpenFaas Gateway and login with the OpenFaas CLI:</p>

<pre><code>$ PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode; echo)
$ echo -n $PASSWORD | faas-cli login --username admin --password-stdin
</code></pre>

<h2>Deploy a Function</h2>

<p>Deploy the figlet function as an example:</p>

<pre><code>$ faas-cli store deploy figlet

Deployed. 202 Accepted.
URL: http://openfaas.localdns.xyz/function/figlet
</code></pre>

<p>Invoke the function:</p>

<pre><code>$ curl http://openfaas.localdns.xyz/function/figlet -d 'hello, world'
 _          _ _                             _     _
| |__   ___| | | ___    __      _____  _ __| | __| |
| '_ \ / _ \ | |/ _ \   \ \ /\ / / _ \| '__| |/ _` |
| | | |  __/ | | (_) |   \ V  V / (_) | |  | | (_| |
|_| |_|\___|_|_|\___( )   \_/\_/ \___/|_|  |_|\__,_|
                    |/
</code></pre>

<h2>Delete the Cluster</h2>

<p>Delete your k3d Kubernetes Cluster:</p>

<pre><code>$ k3d delete --name demo
</code></pre>

<h2>Thank You</h2>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Install OpenFaas on K3d Kubernetes]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/12/install-openfaas-on-k3d-kubernetes/"/>
    <updated>2020-02-12T00:57:47+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/12/install-openfaas-on-k3d-kubernetes</id>
    <content type="html"><![CDATA[<p>In this post we will deploy i<a href="https://www.openfaas.com">openfaas</a> on kubernetes (<a href="https://github.com/rancher/k3d">k3d</a>)</p>

<h2>Kubernetes on k3d</h2>

<p>k3d is a helper tool that provisions a kubernetes distribution, called k3s on docker. To deploy a kubernetes cluster on k3d, you can follow <a href="https://blog.ruanbekker.com/blog/2020/02/12/lightweight-development-kubernetes-options-k3d/">this blog post</a></p>

<h2>Deploy a 3 Node Kubernetes Cluster</h2>

<p>Using k3d, let&rsquo;s deploy a kubernetes cluster:</p>

<pre><code class="bash">$ k3d create --name="demo" --workers="2" --publish="80:80"
</code></pre>

<p>Export the kubeconfig:</p>

<pre><code class="bash">$ export KUBECONFIG="$(k3d get-kubeconfig --name='demo')"
</code></pre>

<p>Verify that you are able to communicate with your kubernetes cluster:</p>

<pre><code class="bash">$ kubectl get nodes
</code></pre>

<h2>Deploy OpenFaas</h2>

<p>First we need to get <a href="https://k3sup.dev">k3sup</a> :</p>

<pre><code class="bash">$ curl -sLfS https://get.k3sup.dev | sudo sh
</code></pre>

<p>Once k3sup is installed, deploy openfaas to your cluster:</p>

<pre><code class="bash">$ k3sup app install openfaas
</code></pre>

<p>Give it a minute or so and check if everything is running:</p>

<pre><code class="bash">$ kubectl get pods -n openfaas
NAMESPACE     NAME                                 READY   STATUS      RESTARTS   AGE
openfaas      alertmanager-546f66b6c6-qtb69        1/1     Running     0          5m
openfaas      basic-auth-plugin-79b9878b7b-7vlln   1/1     Running     0          4m59s
openfaas      faas-idler-db8cd9c7d-8xfpp           1/1     Running     2          4m57s
openfaas      gateway-7dcc6d694d-dmvqn             2/2     Running     0          4m56s
openfaas      nats-d6d574749-rt9vw                 1/1     Running     0          4m56s
openfaas      prometheus-d99669d9b-mfxc8           1/1     Running     0          4m53s
openfaas      queue-worker-75f44b56b9-mhhbv        1/1     Running     0          4m52s
</code></pre>

<p>Install the openfaas-cli:</p>

<pre><code class="bash">$ curl -SLsf https://cli.openfaas.com | sudo sh
</code></pre>

<p>In a screen session, forward port 8080 to the gateway service:</p>

<pre><code class="bash">$ screen -S portfwd-process -m -d sh -c "kubectl port-forward -n openfaas svc/gateway 8080:8080"
</code></pre>

<p>Expose the gateway password as an environment variable:</p>

<pre><code class="bash">$ PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode; echo)
</code></pre>

<p>Then login to the gateway:</p>

<pre><code class="bash">$ echo -n $PASSWORD | faas-cli login --username admin --password-stdin
</code></pre>

<h2>Deploy a OpenFaas Function</h2>

<p>To list all the functions:</p>

<pre><code class="bash">$ faas-cli store list
</code></pre>

<p>To deploy the figlet function:</p>

<pre><code class="bash">$ faas-cli store deploy figlet

Deployed. 202 Accepted.
URL: http://127.0.0.1:8080/function/figlet
</code></pre>

<p>List your deployed functions:</p>

<pre><code class="bash">$ faas-cli list
Function                        Invocations     Replicas
figlet                          0               1
</code></pre>

<p>Invoke your function:</p>

<pre><code class="bash">$ curl http://127.0.0.1:8080/function/figlet -d 'hello, world'
 _          _ _                             _     _
| |__   ___| | | ___    __      _____  _ __| | __| |
| '_ \ / _ \ | |/ _ \   \ \ /\ / / _ \| '__| |/ _` |
| | | |  __/ | | (_) |   \ V  V / (_) | |  | | (_| |
|_| |_|\___|_|_|\___( )   \_/\_/ \___/|_|  |_|\__,_|
                    |/
</code></pre>

<h2>Delete your Cluster</h2>

<p>When you are done, delete your kubernetes cluster:</p>

<pre><code class="bash">$ k3d delete --name demo
</code></pre>

<h2>Thank You</h2>

<p>Thank you for reading. If you like my content, feel free to visit me at <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<p><a href="https://twitter.com/ruanbekker"><img src="https://user-images.githubusercontent.com/567298/71188576-e2410f80-2289-11ea-8667-08f0c14ab7b5.png" alt="" /></a></p>

<p><a href="https://ko-fi.com/A6423ZIQ"><img src="https://www.ko-fi.com/img/githubbutton_sm.svg" alt="ko-fi" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lightweight Development Kubernetes Options: K3d]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/12/lightweight-development-kubernetes-options-k3d/"/>
    <updated>2020-02-12T00:27:00+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/12/lightweight-development-kubernetes-options-k3d</id>
    <content type="html"><![CDATA[<p>In this post we will cover a lightweight development kubernetes called, &ldquo;<a href="https://github.com/rancher/k3d">k3d</a>&rdquo; which we will deploy on a mac.</p>

<h2>What is k3d</h2>

<p><a href="https://github.com/rancher/k3d">k3d</a> is a binary that provisions a <a href="https://github.com/rancher/k3s">k3s</a> kubernetes cluster on docker</p>

<h2>Pre-Requirements</h2>

<p>You will require docker and we will be using brew to install k3d on a mac.</p>

<h2>Install k3d</h2>

<p>Installing k3d is as easy as:</p>

<pre><code class="bash">$ brew install k3d
</code></pre>

<p>Verify your installation:</p>

<pre><code>$ k3d --version
k3d version v1.3.1
</code></pre>

<h2>Deploy a 3 Node Cluster</h2>

<p>Using k3d, we will deploy a 3 node k3s cluster:</p>

<pre><code class="bash">$ k3d create --name="demo" --workers="2" --publish="80:80"
</code></pre>

<p>This will deploy a master and 2 worker nodes and we will also publish our host port 80 to our container port 80 (k3s comes default with traefik)</p>

<p>Set your kubeconfig:</p>

<pre><code class="bash">$ export KUBECONFIG="$(k3d get-kubeconfig --name='demo')"
</code></pre>

<p>Test it out by listing your nodes:</p>

<pre><code class="bash">$ kubectl get nodes
NAME                STATUS   ROLES    AGE    VERSION
k3d-demo-server     Ready    master   102s   v1.14.6-k3s.1
k3d-demo-worker-0   Ready    worker   102s   v1.14.6-k3s.1
k3d-demo-worker-1   Ready    worker   102s   v1.14.6-k3s.1
</code></pre>

<p>That was easy right?</p>

<h2>Deploy a Sample App</h2>

<p>We will deploy a simple golang web application that will return the container name upon a http request. We will also make use of the traefik ingress for demonstration.</p>

<p>Our deployment manifest that I will save as <code>app.yml</code>:</p>

<pre><code class="yaml">apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: k3s-demo
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: k3d-demo
  template:
    metadata:
      labels:
        app: k3d-demo
    spec:
      containers:
      - name: k3d-demo
        image: ruanbekker/hostname:latest
---
apiVersion: v1
kind: Service
metadata:
  name: k3d-demo
  namespace: default
spec:
  ports:
  - name: http
    targetPort: 8000
    port: 80
  selector:
    app: k3d-demo
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: k3d-demo
  annotations:
    kubernetes.io/ingress.class: "traefik"

spec:
  rules:
  - host: k3d-demo.example.org
    http:
      paths:
      - path: /
        backend:
          serviceName: k3d-demo
          servicePort: http
</code></pre>

<p>Deploy our application:</p>

<pre><code class="bash">$ kubectl apply -f app.yml
deployment.extensions/k3s-demo created
service/k3d-demo created
ingress.extensions/k3d-demo created
</code></pre>

<p>Verify that the pods are running:</p>

<pre><code class="bash">$ kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
k3s-demo-f76d866b9-dv5z9   1/1     Running   0          10s
k3s-demo-f76d866b9-qxltk   1/1     Running   0          10s
</code></pre>

<p>Make a http request:</p>

<pre><code class="bash">$ curl -H "Host: k3d-demo.example.org" http://localhost
Hostname: k3d-demo-f76d866b9-qxltk
</code></pre>

<h2>Deleting your Cluster</h2>

<p>To delete your cluster:</p>

<pre><code class="bash">$ k3d delete --name demo
</code></pre>

<h2>Thank You</h2>

<p>Thank you for reading. If you like my content, feel free to visit me at <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<p><a href="https://twitter.com/ruanbekker"><img src="https://user-images.githubusercontent.com/567298/71188576-e2410f80-2289-11ea-8667-08f0c14ab7b5.png" alt="" /></a></p>

<p><a href="https://ko-fi.com/A6423ZIQ"><img src="https://www.ko-fi.com/img/githubbutton_sm.svg" alt="ko-fi" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Run Kubernetes (K3s) as a Service Container on Drone CI]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/04/run-kubernetes-k3s-as-a-service-container-on-drone-ci/"/>
    <updated>2020-02-04T22:37:06+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/04/run-kubernetes-k3s-as-a-service-container-on-drone-ci</id>
    <content type="html"><![CDATA[<p><a href="https://docs.drone.io/pipeline/docker/syntax/services/">Drone services</a> allow you to run a service container and will be available for the duration of your build, which is great if you want a ephemeral service to test your applications against.</p>

<p>Today we will experiment with services on <a href="https://github.com/drone/drone">drone</a>  and will deploy a <a href="https://github.com/rancher/k3s">k3s</a> (a kubernetes distribution built by rancher) cluster as a drone service and interact with our cluster using kubectl.</p>

<p>I will be using multiple pipelines, where we will first deploy our &ldquo;dev cluster&rdquo;, when it&rsquo;s up, we will use kubectl to interact with the cluster, once that is done, we will deploy our &ldquo;staging cluster&rdquo; and do the same.</p>

<p>This is very basic and we are not doing anything special, but this is a starting point and you can do pretty much whatever you want.</p>

<h2>What is Drone</h2>

<p>If you are not aware of Drone, Drone is a container-native continious deliver platform built on Go and you can check them out <a href="https://github.com/drone/drone">here: github.com/drone</a></p>

<h2>Setup Gitea and Drone</h2>

<p>If you don&rsquo;t have the stack setup, have a look at <a href="https://blog.ruanbekker.com/blog/2020/02/04/setup-gitea-and-drone-on-docker-2020-edition/">this post</a> where I go into detail on how to get that setup.</p>

<h2>Create your Git Repo</h2>

<p>Go ahead and create a git repo, you can name it anything, then it should look something like this:</p>

<p><img width="1171" alt="image" src="https://user-images.githubusercontent.com/567298/73783555-90ead200-479c-11ea-8386-12518fb21b22.png"></p>

<p>Create a drone configuration, <code>.drone.yml</code> my pipeline will look like this:</p>

<pre><code>---
kind: pipeline
type: docker
name: dev

platform:
  os: linux
  arch: amd64

steps:
  - name: wait-for-k3s
    image: ruanbekker/build-tools
    commands:
      - sleep 30

  - name: prepare-k3s-kubeconfig
    image: alpine
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    detach: false
    commands:
      - sed -i -e "s/127.0.0.1/k3s/g" /k3s-kubeconfig/kubeconfig.yaml

  - name: test-kubernetes
    image: ruanbekker/kubectl
    volumes:
      - name: k3s-kubeconfig
        path: /tmp
    environment:
      KUBECONFIG: /tmp/kubeconfig.yaml
    commands:
      - kubectl get nodes -o wide

services:
  - name: k3s
    image: rancher/k3s:v0.9.1
    privileged: true
    command:
      - server
    environment:
      K3S_KUBECONFIG_OUTPUT: /k3s-kubeconfig/kubeconfig.yaml
      K3S_KUBECONFIG_MODE: 777
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    ports:
      - 6443

volumes:
- name: k3s-kubeconfig
  temp: {}

---
kind: pipeline
type: docker
name: staging

platform:
  os: linux
  arch: amd64

steps:
  - name: wait-for-k3s
    image: ruanbekker/build-tools
    commands:
      - sleep 30

  - name: prepare-k3s-kubeconfig
    image: alpine
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    detach: false
    commands:
      - sed -i -e "s/127.0.0.1/k3s/g" /k3s-kubeconfig/kubeconfig.yaml

  - name: test-kubernetes
    image: ruanbekker/kubectl
    volumes:
      - name: k3s-kubeconfig
        path: /tmp
    environment:
      KUBECONFIG: /tmp/kubeconfig.yaml
    commands:
      - kubectl get nodes -o wide


services:
  - name: k3s
    image: rancher/k3s:v0.9.1
    privileged: true
    command:
      - server
    environment:
      K3S_KUBECONFIG_OUTPUT: /k3s-kubeconfig/kubeconfig.yaml
      K3S_KUBECONFIG_MODE: 777
    volumes:
      - name: k3s-kubeconfig
        path: /k3s-kubeconfig
    ports:
      - 6443

volumes:
- name: k3s-kubeconfig
  temp: {}

depends_on:
- dev
</code></pre>

<p>In this pipeline you can see that the staging pipeline depends on dev, so dev pipeline will start by creating the k3s service container, once its up I am using a step just to sleep for 30 seconds to allow it to boot.</p>

<p>Then I have defined a volume that will be persistent during the build time, which we will use to dump our kubeconfig file and update the hostname of our kubernetes endpoint. Once that is done our last step will set that file to the environment and use kubectl to interact with kubernetes.</p>

<p>Once our dev pipeline has finished, our staging pipeline will start.</p>

<h2>Activate the Repo in Drone</h2>

<p>Head over to drone on port <code>80</code> and activate the newly created git repo (and make sure that you select &ldquo;Trusted&rdquo;) and you will see the activity feed being empty:</p>

<p><img width="1008" alt="image" src="https://user-images.githubusercontent.com/567298/73784085-80872700-479d-11ea-9005-4cac54ac000d.png"></p>

<p>Commit a dummy file to git and you should see your pipeline being triggered:</p>

<p><img width="1013" alt="image" src="https://user-images.githubusercontent.com/567298/73784286-dd82dd00-479d-11ea-93f4-6363da53c1c1.png"></p>

<p>Once your pipeline has finished and everything succeeded, you should see the output of your nodes in your kubernetes service container:</p>

<p><img width="1068" alt="image" src="https://user-images.githubusercontent.com/567298/73784435-220e7880-479e-11ea-8f9d-a9856632302d.png"></p>

<p>As I mentioned earlier, we are not doing anything special but service containers allows us to do some awesome things.</p>

<p>Thank you for reading. If you like my content, feel free to visit me at <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<p><a href="https://twitter.com/ruanbekker"><img src="https://user-images.githubusercontent.com/567298/71188576-e2410f80-2289-11ea-8667-08f0c14ab7b5.png" alt="" /></a></p>

<p><a href="https://ko-fi.com/A6423ZIQ"><img src="https://www.ko-fi.com/img/githubbutton_sm.svg" alt="ko-fi" /></a></p>
]]></content>
  </entry>
  
</feed>
