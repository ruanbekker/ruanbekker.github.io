<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/linux/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2022-07-31T05:00:00-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Create a RAID5 Array With Mdadm on Linux]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/06/29/create-a-raid5-array-with-mdadm-on-linux/"/>
    <updated>2022-06-29T05:02:13-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/06/29/create-a-raid5-array-with-mdadm-on-linux</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ruanbekker-raid5-array-linux.png" alt="setup-raid5-array-ubuntu-linux" /></p>

<p>In this tutorial we will setup a <a href="https://en.wikipedia.org/wiki/Standard_RAID_levels#RAID_5">RAID5</a> array, which is striping across multiple drives with distributed paritiy, which is good for redundancy. We will be using Ubuntu for our Linux Distribution, but the technique applies to other Linux Distributions as well.</p>

<h2>What are we trying to achieve</h2>

<p>We will run a server with one root disk and 6 extra disks, where we will first create our raid5 array with three disks, then I will show you how to expand your raid5 array by adding three other disks.</p>

<p>Things fail all the time, and it&rsquo;s not fun when hard drives breaks, therefore we want to do our best to prevent our applications from going down due to hardware failures. To achieve data redundancy, we want to use three hard drives, which we want to add into a raid configuration that will proviide us:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Data_striping">striping</a>, which is the technique of segmenting logically sequential data, so that consecutive segments are stored on different physical storage devices.</li>
<li><a href="https://en.wikipedia.org/wiki/Parity_bit#RAID">distributed parity</a>, where parity data are distributed between the physical disks, where there is only one parity block per disk, this provide protection against one physical disk failure, where the minimum number of disks are three.</li>
</ul>


<p>This is how a RAID5 array looks like (image from diskpart.com):</p>

<p><img src="https://user-images.githubusercontent.com/567298/176410333-0ff98867-dfb5-4fe3-a037-cc5d20014ab5.png" alt="raid5" /></p>

<h2>Hardware Overview</h2>

<p>We will have a Linux server with one root disk and six extra disks:</p>

<pre><code class="bash">$ lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
xvda    202:0    0    8G  0 disk
└─xvda1 202:1    0    8G  0 part /
xvdb    202:16   0   10G  0 disk
xvdc    202:32   0   10G  0 disk
xvdd    202:48   0   10G  0 disk
xvde    202:64   0   10G  0 disk
xvdf    202:80   0   10G  0 disk
xvdg    202:96   0   10G  0 disk
</code></pre>

<h2>Dependencies</h2>

<p>We require <code>mdadm</code> to create our raid configuration:</p>

<pre><code class="bash">$ sudo apt update
$ sudo apt install mdadm -y
</code></pre>

<h2>Format Disks</h2>

<p>First we will format and partition the following disks: <code>/dev/xvdb</code>, <code>/dev/xvdc</code>, <code>/dev/xvdd</code>, I will demonstrate the process for one disk, but repeat them for the other as well:</p>

<pre><code class="bash">$ fdisk /dev/xvdc

Welcome to fdisk (util-linux 2.34).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

The old ext4 signature will be removed by a write command.

Device does not contain a recognized partition table.
Created a new DOS disklabel with disk identifier 0x26a2d2f6.

Command (m for help): n
Partition type
   p   primary (0 primary, 0 extended, 4 free)
   e   extended (container for logical partitions)
Select (default p): p
Partition number (1-4, default 1): 1
First sector (2048-20971519, default 2048):
Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-20971519, default 20971519):

Created a new partition 1 of type 'Linux' and of size 10 GiB.

Command (m for help): t
Selected partition 1
Hex code (type L to list all codes): fd
Changed type of partition 'Linux' to 'Linux raid autodetect'.

Command (m for help): w
The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks.
</code></pre>

<h2>Create RAID5 Array</h2>

<p>Using <code>mdadm</code>, create the <code>/dev/md0</code> device, by specifying the raid level and the disks that we want to add to the array:</p>

<pre><code class="bash">$ mdadm --create /dev/md0 --level=5 --raid-devices=3 /dev/xvdb1 /dev/xvdc1 /dev/xvdd1
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
</code></pre>

<p>Now that our device has been added, we can monitor the process:</p>

<pre><code class="bash">$ cat /proc/mdstat
Personalities : [raid6] [raid5] [raid4]
md0 : active raid5 xvdd1[3] xvdc1[1] xvdb1[0]
      20951040 blocks super 1.2 level 5, 512k chunk, algorithm 2 [3/2] [UU_]
      [==&gt;..................]  recovery = 11.5% (1212732/10475520) finish=4.7min speed=32103K/sec

unused devices: &lt;none&gt;
</code></pre>

<p>As you can see, currently its at 11.5%, give it some time to let it complete, you should treat the following as a completed state:</p>

<pre><code class="bash">$ cat /proc/mdstat
Personalities : [raid6] [raid5] [raid4]
md0 : active raid5 xvdd1[3] xvdc1[1] xvdb1[0]
      20951040 blocks super 1.2 level 5, 512k chunk, algorithm 2 [3/3] [UUU]

unused devices: &lt;none&gt;
</code></pre>

<p>We can also inspect devices with <code>mdadm</code>:</p>

<pre><code class="bash">$ mdadm -E /dev/xvd[b-d]1
/dev/xvdb1:
          Magic : a92b4efc
        Version : 1.2
    Feature Map : 0x0
     Array UUID : ea997bce:a530519c:ae41022e:0f4306bf
           Name : ip-172-31-3-57:0  (local to host ip-172-31-3-57)
  Creation Time : Wed Jan 12 13:36:39 2022
     Raid Level : raid5
   Raid Devices : 3

 Avail Dev Size : 20951040 (9.99 GiB 10.73 GB)
     Array Size : 20951040 (19.98 GiB 21.45 GB)
    Data Offset : 18432 sectors
   Super Offset : 8 sectors
   Unused Space : before=18280 sectors, after=0 sectors
          State : clean
    Device UUID : 8305a179:3ef96520:6c7b41dd:bdc7401f

    Update Time : Wed Jan 12 13:42:14 2022
  Bad Block Log : 512 entries available at offset 136 sectors
       Checksum : 1f9b4887 - correct
         Events : 18

         Layout : left-symmetric
     Chunk Size : 512K

   Device Role : Active device 0
   Array State : AAA ('A' == active, '.' == missing, 'R' == replacing)
</code></pre>

<p>To get information about your raid5 device:</p>

<pre><code>$ mdadm --detail /dev/md0
/dev/md0:
           Version : 1.2
     Creation Time : Wed Jan 12 13:36:39 2022
        Raid Level : raid5
        Array Size : 20951040 (19.98 GiB 21.45 GB)
     Used Dev Size : 10475520 (9.99 GiB 10.73 GB)
      Raid Devices : 3
     Total Devices : 3
       Persistence : Superblock is persistent

       Update Time : Wed Jan 12 13:42:14 2022
             State : clean
    Active Devices : 3
   Working Devices : 3
    Failed Devices : 0
     Spare Devices : 0

            Layout : left-symmetric
        Chunk Size : 512K

Consistency Policy : resync

              Name : ip-172-31-3-57:0  (local to host ip-172-31-3-57)
              UUID : ea997bce:a530519c:ae41022e:0f4306bf
            Events : 18

    Number   Major   Minor   RaidDevice State
       0     202       17        0      active sync   /dev/xvdb1
       1     202       33        1      active sync   /dev/xvdc1
       3     202       49        2      active sync   /dev/xvdd1
</code></pre>

<h2>Create Filesystems</h2>

<p>We will use our <code>/dev/md0</code> device and create a <code>ext4</code> filesystem:</p>

<pre><code class="bash">$ mkfs.ext4 /dev/md0
mke2fs 1.45.5 (07-Jan-2020)
Creating filesystem with 5237760 4k blocks and 1310720 inodes
Filesystem UUID: 579f045e-d270-4ff2-b36b-8dc506c27c5f
Superblock backups stored on blocks:
    32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,
    4096000

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done
</code></pre>

<p>We can then verify that by looking at our block devices using <code>lsblk</code>:</p>

<pre><code class="bash">$ lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
xvda    202:0    0    8G  0 disk
└─xvda1 202:1    0    8G  0 part  /
xvdb    202:16   0   10G  0 disk
└─xvdb1 202:17   0   10G  0 part
  └─md0   9:0    0   20G  0 raid5
xvdc    202:32   0   10G  0 disk
└─xvdc1 202:33   0   10G  0 part
  └─md0   9:0    0   20G  0 raid5
xvdd    202:48   0   10G  0 disk
└─xvdd1 202:49   0   10G  0 part
  └─md0   9:0    0   20G  0 raid5
xvde    202:64   0   10G  0 disk
xvdf    202:80   0   10G  0 disk
xvdg    202:96   0   10G  0 disk
</code></pre>

<p>Now we can mount our device to <code>/mnt</code>:</p>

<pre><code class="bash">$ mount /dev/md0 /mnt
</code></pre>

<p>We can verify that the device is mounted by using <code>df</code>:</p>

<pre><code class="bash">$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/root       7.7G  1.5G  6.3G  19% /
/dev/md0         20G   45M   19G   1% /mnt
</code></pre>

<p>To persist the device across reboots, add it to the <code>/etc/fstab</code> file:</p>

<pre><code class="bash">$ cat /etc/fstab
/dev/md0                /mnt     ext4   defaults                0 0
</code></pre>

<p>Now our filesystem which is mounted at <code>/mnt</code> is ready to be used.</p>

<h2>RAID Configuration (across reboots)</h2>

<p>By default RAID doesn’t have a config file, therefore we need to save it manually. If this step is not followed RAID device will not be in md0, but perhaps something else.</p>

<p>So, we must have to save the configuration to persist across reboots, when it reboot it gets loaded to the kernel and RAID will also get loaded.</p>

<pre><code class="bash">$ mdadm --detail --scan --verbose &gt;&gt; /etc/mdadm.conf
</code></pre>

<p>Note: Saving the configuration will keep the RAID level stable in the md0 device.</p>

<h2>Adding Spare Devices</h2>

<p>Earlier I mentioned that we have spare disks that we can use to expand our raid device. After they have been formatted we can add them as spare devices to our raid setup:</p>

<pre><code class="bash">$ mdadm --add /dev/md0 /dev/xvde1 /dev/xvdf1 /dev/xvdg1
mdadm: added /dev/xvde1
mdadm: added /dev/xvdf1
mdadm: added /dev/xvdg1
</code></pre>

<p>Verify our change by viewing the detail of our device:</p>

<pre><code class="bash">$ mdadm --detail /dev/md0
/dev/md0:
           Version : 1.2
     Creation Time : Wed Jan 12 13:36:39 2022
        Raid Level : raid5
        Array Size : 20951040 (19.98 GiB 21.45 GB)
     Used Dev Size : 10475520 (9.99 GiB 10.73 GB)
      Raid Devices : 3
     Total Devices : 6
       Persistence : Superblock is persistent

       Update Time : Wed Jan 12 14:28:23 2022
             State : clean
    Active Devices : 3
   Working Devices : 6
    Failed Devices : 0
     Spare Devices : 3

            Layout : left-symmetric
        Chunk Size : 512K

Consistency Policy : resync

              Name : ip-172-31-3-57:0  (local to host ip-172-31-3-57)
              UUID : ea997bce:a530519c:ae41022e:0f4306bf
            Events : 27

    Number   Major   Minor   RaidDevice State
       0     202       17        0      active sync   /dev/xvdb1
       1     202       33        1      active sync   /dev/xvdc1
       3     202       49        2      active sync   /dev/xvdd1

       4     202       65        -      spare   /dev/xvde1
       5     202       81        -      spare   /dev/xvdf1
       6     202       97        -      spare   /dev/xvdg1
</code></pre>

<p>As you can see it&rsquo;s only spares at this moment, we can use the spares for data storage, by growing our device:</p>

<pre><code class="bash">$ mdadm --grow --raid-devices=6 /dev/md0
</code></pre>

<p>Verify:</p>

<pre><code class="bash">$ mdadm --detail /dev/md0
/dev/md0:
           Version : 1.2
     Creation Time : Wed Jan 12 13:36:39 2022
        Raid Level : raid5
        Array Size : 20951040 (19.98 GiB 21.45 GB)
     Used Dev Size : 10475520 (9.99 GiB 10.73 GB)
      Raid Devices : 6
     Total Devices : 6
       Persistence : Superblock is persistent

       Update Time : Wed Jan 12 15:15:31 2022
             State : clean, reshaping
    Active Devices : 6
   Working Devices : 6
    Failed Devices : 0
     Spare Devices : 0

            Layout : left-symmetric
        Chunk Size : 512K

Consistency Policy : resync

    Reshape Status : 0% complete
     Delta Devices : 3, (3-&gt;6)

              Name : ip-172-31-3-57:0  (local to host ip-172-31-3-57)
              UUID : ea997bce:a530519c:ae41022e:0f4306bf
            Events : 36

    Number   Major   Minor   RaidDevice State
       0     202       17        0      active sync   /dev/xvdb1
       1     202       33        1      active sync   /dev/xvdc1
       3     202       49        2      active sync   /dev/xvdd1
       6     202       97        3      active sync   /dev/xvdg1
       5     202       81        4      active sync   /dev/xvdf1
       4     202       65        5      active sync   /dev/xvde1
</code></pre>

<p>Wait for the raid to rebuild, by viewing the <code>mdstat</code>::</p>

<pre><code class="bash">$ cat /proc/mdstat
Personalities : [raid6] [raid5] [raid4]
md0 : active raid5 xvdg1[6] xvdf1[5] xvde1[4] xvdd1[3] xvdc1[1] xvdb1[0]
      20951040 blocks super 1.2 level 5, 512k chunk, algorithm 2 [6/6] [UUUUUU]
      [&gt;....................]  reshape =  0.7% (76772/10475520) finish=18.0min speed=9596K/sec

unused devices: &lt;none&gt;
</code></pre>

<h2>Resizing our Filesystem</h2>

<p>Once we added the spares and growed our device, we need to run integrity checks, then we can resize the volume. But first, we need to unmount our filesystem:</p>

<pre><code class="bash">$ umount /mnt
</code></pre>

<p>Run a integrity check:</p>

<pre><code class="bash">$ e2fsck -f /dev/md0
e2fsck 1.45.5 (07-Jan-2020)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information
/dev/md0: 12/1310720 files (0.0% non-contiguous), 126323/5237760 blocks
</code></pre>

<p>Once that has passed, resize the file system:</p>

<pre><code class="bash">$ resize2fs /dev/md0
resize2fs 1.45.5 (07-Jan-2020)
Resizing the filesystem on /dev/md0 to 13094400 (4k) blocks.
The filesystem on /dev/md0 is now 13094400 (4k) blocks long.
</code></pre>

<p>Then we remount our filesystem:</p>

<pre><code class="bash">$ mount /dev/md0 /mnt
</code></pre>

<p>After the filesystem has been mounted, we can view the disk size and confirm that the size increased:</p>

<pre><code class="bash">$ df -h /mnt
Filesystem      Size  Used Avail Use% Mounted on
/dev/md0         50G   52M   47G   1% /mnt
</code></pre>

<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Install a Specific Python Version on Ubuntu]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/06/23/install-a-specific-python-version-on-ubuntu/"/>
    <updated>2022-06-23T17:53:46-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/06/23/install-a-specific-python-version-on-ubuntu</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ruanbekker-install-specific-python-version.png" alt="install-specific-python-version" /></p>

<p>In this short tutorial, I will demonstrate how to install a spcific version of Python on Ubuntu Linux.</p>

<p><a href="https://ruan.dev"><img src="https://img.shields.io/badge/website-ruan.dev-red.svg" alt="" /></a> <a href="https://twitter.com/ruanbekker"><img src="https://img.shields.io/badge/twitter-@ruanbekker-00acee.svg" alt="" /></a> <a href="https://github.com/ruanbekker"><img src="https://img.shields.io/badge/github-cheatsheets-orange.svg" alt="" /></a> <a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/dm-saythanks.io-07B63F.svg" alt="Say Thanks!" /></a>  <a href="https://ko-fi.com/ruanbekker"><img src="https://img.shields.io/badge/-Buy%20Me%20a%20Coffee-ff5f5f?logo=ko-fi&amp;logoColor=white" alt="Ko-fi" /></a></p>

<h2>Dependencies</h2>

<p>Update the apt repositories:</p>

<pre><code class="bash">$ sudo apt update
</code></pre>

<p>Then install the required dependencies:</p>

<pre><code class="bash">$ sudo apt install libssl-dev openssl wget build-essential zlib1g-dev -y
</code></pre>

<h2>Python Versions</h2>

<p>Head over to the <a href="https://www.python.org/downloads/">Python Downloads</a> section and select the version of your choice, in my case I will be using Python 3.8.13, once you have the download link, download it:</p>

<pre><code class="bash">$ wget https://www.python.org/ftp/python/3.8.13/Python-3.8.13.tgz
</code></pre>

<p>Then extract the tarball:</p>

<pre><code class="bash">$ tar -xvf Python-3.8.13.tgz
</code></pre>

<p>Once it completes, change to the directory:</p>

<pre><code class="bash">$ cd Python-3.8.13
</code></pre>

<h2>Installation</h2>

<p>Compile and add <code>--enable-optimizations</code> flag as an argument:</p>

<pre><code class="bash">$ ./configure --enable-optimizations
</code></pre>

<p>Run make and make install:</p>

<pre><code class="bash">$ make 
$ sudo make install 
</code></pre>

<p>Once it completes, you can symlink the python binary so that it&rsquo;s detected by your <code>PATH</code>, if you have no installed python versions or want to use it as the default, you can force overwriting the symlink:</p>

<pre><code class="bash">$ sudo ln -fs /usr/local/bin/python3 /usr/bin/python3
</code></pre>

<p>Then we can test it by running:</p>

<pre><code class="bash">$ python3 --version
Python 3.8.13
</code></pre>

<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Persist Iptables Rules After Reboots]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/06/15/how-to-persist-iptables-rules-after-reboots/"/>
    <updated>2022-06-15T06:10:12-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/06/15/how-to-persist-iptables-rules-after-reboots</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ruanbekker-blog-persist-iptables.png" alt="persist-iptables-after-reboot" /></p>

<p>In this tutorial we will demonstrate how to persist iptables rules across reboots.</p>

<h2>Rules Peristence</h2>

<p>By default, when you create iptables rules its active, but as soon as you restart your server, the rules will be gone. Therefore we need to persist these rules across reboots.</p>

<h2>Dependencies</h2>

<p>We require the package <code>iptables-persistent</code> and I will install it on a debian system so I will be using <code>apt</code>:</p>

<pre><code class="bash">sudo apt update
sudo apt install iptables-persistent -y
</code></pre>

<p>Ensure that the service is enabled to start on boot:</p>

<pre><code class="bash">sudo systemctl enable netfilter-persistent
</code></pre>

<h2>Creating Iptables Rules</h2>

<p>In this case I will allow port 80 on TCP from all sources:</p>

<pre><code class="bash">sudo iptables -I INPUT -p tcp --dport 80 -j ACCEPT
</code></pre>

<p>To persist our current rules, we need to save them to <code>/etc/iptables/rules.v4</code> with <code>iptables-save</code>:</p>

<pre><code class="bash">sudo iptables-save &gt; /etc/iptables/rules.v4
</code></pre>

<p>Now when we restart, our rules will be loaded and our previous defined rules will be active.</p>

<h2>Thank You</h2>

<p>Thanks for reading, feel free to check out my <a href="https://ruan.dev/">website</a>, feel free to subscribe to my <a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a> or follow me at <a href="https://twitter.com/ruanbekker">@ruanbekker</a> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Customize VIM Editor With a Brand New Look]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/05/11/customize-vim-editor-with-a-brand-new-look/"/>
    <updated>2022-05-11T17:10:16-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/05/11/customize-vim-editor-with-a-brand-new-look</id>
    <content type="html"><![CDATA[<p>In this tutorial we will customize the vim editor, by adding the molokai color scheme, change a couple of basic settings (more suited for my preference - not too much) and add a couple of plugins that will change the look to something like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/161967893-c19e460a-a8f6-4841-b3cd-de8419522790.png" alt="image" /></p>

<h2>About Vim</h2>

<p><strong><a href="https://www.vim.org/">vim</a></strong> has always been my favorite linux text editor, which is super powerful and highly customizable</p>

<h2>Install Vim</h2>

<p>Update indexes:</p>

<pre><code class="bash">sudo apt update
</code></pre>

<p>Install vim:</p>

<pre><code class="bash">sudo apt install vim -y
</code></pre>

<h2>Color Scheme</h2>

<p>To find all existing vim color schemes installed:</p>

<pre><code class="bash">find /usr/share/vim/vim*/colors/ -type f -name "*.vim"
</code></pre>

<p>The output on mine shows:</p>

<pre><code>/usr/share/vim/vim81/colors/desert.vim
/usr/share/vim/vim81/colors/default.vim
/usr/share/vim/vim81/colors/murphy.vim
...
</code></pre>

<p>I will be opting for <a href="https://github.com/tomasr/molokai">molokai</a>, so first create the directory where we will download our color scheme:</p>

<pre><code class="bash">mkdir -p ~/.vim/colors
</code></pre>

<p>Then download the color scheme:</p>

<pre><code>curl -o ~/.vim/colors/molokai.vim https://raw.githubusercontent.com/tomasr/molokai/master/colors/molokai.vim
</code></pre>

<p>By default our color scheme will look like this when we create <code>foo.py</code>:</p>

<p><img src="https://user-images.githubusercontent.com/567298/161961784-ff536963-baca-492b-989b-5d61bc4dfa71.png" alt="image" /></p>

<p>When we hit the &ldquo;esc&rdquo; button, and enter <code>:colorscheme molokai</code> we can change the colorscheme to molokai, and then we should have the following:</p>

<p><img src="https://user-images.githubusercontent.com/567298/161962129-434f42ff-c894-4388-9d2e-5dbf1c80e1f5.png" alt="image" /></p>

<p>To persist these changes, open up <code>~/.vimrc</code> and paste the following as a starter:</p>

<pre><code>colorscheme molokai
syntax on
</code></pre>

<p>Now when we open up <code>foo.py</code> we will see that it defaults to the <code>molokai</code> color scheme.</p>

<h2>Vim Configuration</h2>

<p>Everyone has their own personal preference on vim configs, but I like to keep mine basic, and this is the content of my <code>~/.vimrc</code>:</p>

<pre><code class="bash">colorscheme molokai
syntax on
set mouse-=a

filetype on
filetype indent plugin on
set noexpandtab " tabs ftw
set smarttab " tab respects 'tabstop', 'shiftwidth', and 'softtabstop'
set tabstop=4 " the visible width of tabs
set softtabstop=4 " edit as if the tabs are 4 characters wide
set shiftwidth=4 " number of spaces to use for indent and unindent
set shiftround " round indent to a multiple of 'shiftwidth'

autocmd FileType yml setlocal ts=2 sts=2 sw=2 expandtab
autocmd FileType yaml setlocal ts=2 sts=2 sw=2 expandtab
</code></pre>

<h2>Plugins</h2>

<p>The <code>~/.vimrc</code>:</p>

<pre><code>"" https://github.com/VundleVim/Vundle.vim
set nocompatible
filetype off
" set the runtime path to include Vundle and initialize
set rtp+=~/.vim/bundle/Vundle.vim
call vundle#begin()
" alternatively, pass a path where Vundle should install plugins
"call vundle#begin('~/some/path/here')

" let Vundle manage Vundle, required
Plugin 'VundleVim/Vundle.vim'

" The following are examples of different formats supported.
" Keep Plugin commands between vundle#begin/end.
" plugin on GitHub repo
Plugin 'tpope/vim-fugitive'
" plugin from http://vim-scripts.org/vim/scripts.html
" Plugin 'L9'
" Git plugin not hosted on GitHub
Plugin 'git://git.wincent.com/command-t.git'
" git repos on your local machine (i.e. when working on your own plugin)
" Plugin 'file:///home/gmarik/path/to/plugin'
" The sparkup vim script is in a subdirectory of this repo called vim.
" Pass the path to set the runtimepath properly.
Plugin 'rstacruz/sparkup', {'rtp': 'vim/'}
" Install L9 and avoid a Naming conflict if you've already installed a
" different version somewhere else.
" Plugin 'ascenator/L9', {'name': 'newL9'}

" All of your Plugins must be added before the following line
call vundle#end()            " required
filetype plugin indent on    " required
" To ignore plugin indent changes, instead use:
"filetype plugin on
"
" Brief help
" :PluginList       - lists configured plugins
" :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate
" :PluginSearch foo - searches for foo; append `!` to refresh local cache
" :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal
"
" see :h vundle for more details or wiki for FAQ
" Put your non-Plugin stuff after this line

" colorscheme duo-mini
" sets color themes
colorscheme molokai
syntax on

" sets the filename at the bottom
set laststatus=2
" https://github.com/itchyny/lightline.vim
Plugin 'itchyny/lightline.vim'

" https://github.com/Shougo/neobundle.vim
" Note: Skip initialization for vim-tiny or vim-small.
if 0 | endif

if &amp;compatible
  set nocompatible               " Be iMproved
endif

" Required:
set runtimepath+=~/.vim/bundle/neobundle.vim/

" Required:
call neobundle#begin(expand('~/.vim/bundle/'))

" Let NeoBundle manage NeoBundle
" Required:
NeoBundleFetch 'Shougo/neobundle.vim'

" My Bundles here:
" Refer to |:NeoBundle-examples|.
" Note: You don't set neobundle setting in .gvimrc!
NeoBundle 'itchyny/lightline.vim'
call neobundle#end()

" Required:
filetype plugin indent on

" If there are uninstalled bundles found on startup,
" this will conveniently prompt you to install them.
NeoBundleCheck

" https://github.com/junegunn/vim-plug
" Specify a directory for plugins
" - For Neovim: stdpath('data') . '/plugged'
" - Avoid using standard Vim directory names like 'plugin'
call plug#begin('~/.vim/plugged')

" Make sure you use single quotes

" Shorthand notation; fetches https://github.com/junegunn/vim-easy-align
Plug 'junegunn/vim-easy-align'

" Any valid git URL is allowed
Plug 'https://github.com/junegunn/vim-github-dashboard.git'

" Multiple Plug commands can be written in a single line using | separators
"Plug 'SirVer/ultisnips' | Plug 'honza/vim-snippets'

" On-demand loading
Plug 'scrooloose/nerdtree', { 'on':  'NERDTreeToggle' }
Plug 'tpope/vim-fireplace', { 'for': 'clojure' }

" Using a non-master branch
Plug 'rdnetto/YCM-Generator', { 'branch': 'stable' }

" Using a tagged release; wildcard allowed (requires git 1.9.2 or above)
Plug 'fatih/vim-go', { 'tag': '*' }

" Plugin options
Plug 'nsf/gocode', { 'tag': 'v.20150303', 'rtp': 'vim' }

" Plugin outside ~/.vim/plugged with post-update hook
Plug 'junegunn/fzf', { 'dir': '~/.fzf', 'do': './install --all' }

" Unmanaged plugin (manually installed and updated)
Plug '~/my-prototype-plugin'

Plug 'itchyny/lightline.vim'

" Initialize plugin system
call plug#end()

" sets the filename as the title up top
" set title
" let g:airline#extensions#tabline#enabled = 1

set noexpandtab " tabs ftw
set smarttab " tab respects 'tabstop', 'shiftwidth', and 'softtabstop'
set tabstop=4 " the visible width of tabs
set softtabstop=4 " edit as if the tabs are 4 characters wide
set shiftwidth=4 " number of spaces to use for indent and unindent
set shiftround " round indent to a multiple of 'shiftwidth'
autocmd FileType yml setlocal ts=2 sts=2 sw=2 expandtab
autocmd FileType yaml setlocal ts=2 sts=2 sw=2 expandtab
</code></pre>

<p>Install the dependencies:</p>

<pre><code>git clone https://github.com/Shougo/neobundle.vim ~/.vim/bundle/neobundle.vim
curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim
git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim
</code></pre>

<p>Install the plugins:</p>

<pre><code>vim +NeoBundleInstall +qall
vim +PluginInstall +qall
</code></pre>

<p>Your vim editor should look like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/161967893-c19e460a-a8f6-4841-b3cd-de8419522790.png" alt="image" /></p>

<h2>Thank You</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong>, read my <strong><a href="http://digests.ruanbekker.com/?via=ruanbekker-blog">newsletter</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create DNS Records With Terraform on Cloudflare]]></title>
    <link href="https://blog.ruanbekker.com/blog/2022/02/20/create-dns-records-with-terraform-on-cloudflare/"/>
    <updated>2022-02-20T13:11:06-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2022/02/20/create-dns-records-with-terraform-on-cloudflare</id>
    <content type="html"><![CDATA[<p>In this tutorial we will use <strong>Terraform</strong> to create DNS records on <strong>Cloudflare</strong>.</p>

<h2>Installing Terraform</h2>

<p>I will be installing terraform for linux, but you can follow terraform&rsquo;s documentation if you are using a different operating system:
- <a href="https://learn.hashicorp.com/tutorials/terraform/install-cli">https://learn.hashicorp.com/tutorials/terraform/install-cli</a></p>

<pre><code class="bash">&gt; curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
&gt; sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
&gt; sudo apt update &amp;&amp; sudo apt install terraform -y
</code></pre>

<p>Verify that terraform was installed:</p>

<pre><code class="bash">&gt; terraform version
Terraform v1.1.6
on linux_amd64
</code></pre>

<h2>Cloudflare Authentication</h2>

<p>We need to create an API Token in order to authenticate terraform to make the required API calls to create the DNS Record.</p>

<p>They have a great post on this, which you can follow below:
- <a href="https://developers.cloudflare.com/api/tokens/create">https://developers.cloudflare.com/api/tokens/create</a></p>

<p>You will need access to &ldquo;Edit DNS Zones&rdquo; and also include the Domain that you would like to edit.</p>

<p>Ensure that you save the API Token in a safe place.</p>

<h2>Terraform Code</h2>

<p>First we will create a project directory:</p>

<pre><code class="bash">&gt; mkdir terraform-cloudflare-dns
&gt; cd terraform-cloudflare-dns
</code></pre>

<p>First we will create the <code>providers.tf</code> which we define our provider and the required parameters for the provider:</p>

<pre><code>terraform {
  required_providers {
    cloudflare = {
      source = "cloudflare/cloudflare"
      version = "~&gt; 3.0"
    }
  }
}

provider "cloudflare" {
  email   = var.cloudflare_email
  api_token = var.cloudflare_api_token
}
</code></pre>

<p>As you can see, we are referencing <code>email</code> and <code>api_token</code> as variables, therefore we need to define those variables in <code>variables.tf</code>:</p>

<pre><code>variable "cloudflare_email" {
  type        = string
  description = "clouflare email address"
}

variable "cloudflare_api_token" {
  type        = string
  description = "cloudflare api token"
}
</code></pre>

<p>In our <code>main.tf</code>, we are first using a data resource to query cloudflare for our domain <code>rbkr.xyz</code> and then access the attribute <code>id</code> which we will be using in our <code>cloudflare_record</code> resource so that it knows which domain to add the DNS record for.</p>

<p>Then we are going to create the A record <code>foobar</code> and provide the value of <code>127.0.0.1</code>:</p>

<pre><code>data "cloudflare_zone" "this" {
  name = "rbkr.xyz"
}

resource "cloudflare_record" "foobar" {
  zone_id = data.cloudflare_zone.this.id
  name    = "foobar"
  value   = "127.0.0.1"
  type    = "A"
  proxied = false
}
</code></pre>

<p>Then we are defining our outputs in <code>outputs.tf</code>:</p>

<pre><code>output "record" {
  value = cloudflare_record.foobar.hostname
}

output "metadata" {
  value       = cloudflare_record.foobar.metadata
  sensitive   = true
}
</code></pre>

<h2>Creating the Record</h2>

<p>Once our configuration code is in place we can run a <code>init</code> which will download the providers:</p>

<pre><code class="bash">&gt; terraform init
</code></pre>

<p>Once that is done, we can run a <code>plan</code> so we can see what will be deployed, but since our <code>variables.tf</code> has no <code>default</code> values, we will either have to define this in <code>terraform.tfvars</code> or use it in-line.</p>

<p>I will be using it in-line for this demonstration:</p>

<pre><code class="bash">&gt; terraform plan -var "cloudflare_email=$EMAIL" -var "cloudflare_api_token=$API_TOKEN"
</code></pre>

<p>Once you are happy, you can run a <code>apply</code> which will deploy the changes:</p>

<pre><code class="bash">&gt; terraform apply -var "cloudflare_email=$EMAIL" -var "cloudflare_api_token=$API_TOKEN"

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # cloudflare_record.foobar will be created
  + resource "cloudflare_record" "foobar" {
      + allow_overwrite = false
      + created_on      = (known after apply)
      + hostname        = (known after apply)
      + id              = (known after apply)
      + metadata        = (known after apply)
      + modified_on     = (known after apply)
      + name            = "foobar"
      + proxiable       = (known after apply)
      + proxied         = false
      + ttl             = (known after apply)
      + type            = "A"
      + value           = "127.0.0.1"
      + zone_id         = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    }

Plan: 1 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + metadata = (sensitive value)
  + record   = (known after apply)

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

cloudflare_record.foobar: Creating...
cloudflare_record.foobar: Creation complete after 4s [id=xxxxxxxxxxxxxxxxxxxxx]

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

Outputs:

metadata = &lt;sensitive&gt;
record = "foobar.rbkr.xyz"
</code></pre>

<h2>Test DNS</h2>

<p>We can now test if this is working as expected with a dns utility like dig:</p>

<pre><code class="bash">&gt; dig foobar.rbkr.xyz

; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; foobar.rbkr.xyz
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 20800
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;foobar.rbkr.xyz.       IN      A

;; ANSWER SECTION:
foobar.rbkr.xyz. 300    IN      A       127.0.0.1

;; Query time: 262 msec
;; SERVER: 172.31.0.2#53(172.31.0.2)
;; WHEN: Wed Feb 02 13:57:59 SAST 2022
;; MSG SIZE  rcvd: 68
</code></pre>

<h2>Thank You</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
</feed>
