<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-02-20T08:42:52-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setup a KVM Hypervisor on Ubuntu to Host Virtual Machines]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/02/20/setup-a-kvm-hypervisor-on-ubuntu-to-host-virtual-machines/"/>
    <updated>2018-02-20T06:21:56-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/02/20/setup-a-kvm-hypervisor-on-ubuntu-to-host-virtual-machines</id>
    <content type="html"><![CDATA[<p>Today we will setup a KVM (Kernel Virtual Machine) Hypervisor, where we can host Virtual Machines. In order to do so, your host needs to Support Hardware Virtualization.</p>

<h2>What we will be doing today:</h2>

<ul>
<li>Check if your host supports Hardware Virtualization</li>
<li>Setup the KVM Hypervisor</li>
<li>Setup a Alpine VM</li>
</ul>


<h2>Check for Hardware Virtualization Support:</h2>

<p>We will install the package required to do the check:</p>

<pre><code class="bash">$ sudo apt update &amp;&amp; sudo apt install cpu-checker -y
</code></pre>

<p>Once that is installed, run <code>kvm-ok</code> and if its supported, your output should look something like this:</p>

<pre><code class="bash">$ kvm-ok
INFO: /dev/kvm exists
KVM acceleration can be used
</code></pre>

<h2>Installing KVM</h2>

<p>Update your System and get the Packages required to Setup KVM:</p>

<pre><code class="bash">$ sudo apt update &amp;&amp; sudo apt upgrade -y
$ apt install bridge-utils qemu-kvm libvirt-bin virtinst -y
</code></pre>

<p>Add your user to the libvirtd group:</p>

<pre><code class="bash">$ sudo usermod -G libvirtd $USER
</code></pre>

<p>Check that the libvirtd service is running:</p>

<pre><code class="bash">$ sudo systemctl is-active libvirtd
active
</code></pre>

<p>You will also find that there is a new interface configured called <code>virbr0</code> in my case.</p>

<h2>Provision the Alpine VM and Setup OpenSSH:</h2>

<p>Get the ISO:</p>

<ul>
<li><a href="https://alpinelinux.org/downloads/">https://alpinelinux.org/downloads/</a></li>
</ul>


<pre><code class="bash">$ wget http://dl-cdn.alpinelinux.org/alpine/v3.7/releases/x86_64/alpine-virt-3.7.0-x86_64.iso
</code></pre>

<p>Provision the VM:</p>

<pre><code class="bash">$ virt-install \
--name alpine1 \
--ram 256 \
--disk path=/var/lib/libvirt/images/alpine1.img,size=8 \
--vcpus 1 \
--os-type linux \
--os-variant generic \
--network bridge:virbr0,model=virtio \
--graphics none \
--console pty,target_type=serial \
--cdrom ./alpine-virt-3.7.0-x86_64.iso 
</code></pre>

<p>After this, you will be dropped into the console:</p>

<pre><code class="bash">Starting install...
Allocating 'alpine1.img'                                                                                                           |   8 GB  00:00:01
Creating domain...                                                                                                                 |    0 B  00:00:00
Connected to domain alpine1
Escape character is ^]

ISOLINUX 6.04 6.04-pre1  Copyright (C) 1994-2015 H. Peter Anvin et al
boot:

   OpenRC 0.24.1.a941ee4a0b is starting up Linux 4.9.65-1-virthardened (x86_64)

Welcome to Alpine Linux 3.7
Kernel 4.9.65-1-virthardened on an x86_64 (/dev/ttyS0)

localhost login:
</code></pre>

<p>Login with the <code>root</code> user and no password, then setup the VM by running <code>setup-alpine</code>:</p>

<pre><code class="bash">localhost login: root
Welcome to Alpine!

localhost:~# setup-alpine
</code></pre>

<p>After completing the prompts reboot the VM by running <code>reboot</code>, then you will be dropped out of the console. Check the status of the reboot:</p>

<pre><code class="bash">$ virsh list
 Id    Name                           State
----------------------------------------------------
 2     alpine1                        running
</code></pre>

<p>As we can see our guest is running, lets console to our guest, provide the root user and password that you provided during the setup phase:</p>

<pre><code class="bash">$ virsh console 2
Connected to domain alpine1
Escape character is ^]

alpine1 login: root
Password:
Welcome to Alpine!
</code></pre>

<p>Setup OpenSSH so that we can SSH to our guest over the network:</p>

<pre><code class="bash">$ apk update
$ apk add openssh
</code></pre>

<p>Configure SSH to accept Root Passwords, this is not advisable for production environments, but for testing this is okay. For Production servers, we will rather look at Key Based Authentication etc.</p>

<pre><code class="bash">$ sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/g' /etc/ssh/sshd_config
$ /etc/init.d/sshd restart
</code></pre>

<p>Get the IP Address:</p>

<pre><code>$ ifconfig
eth0      Link encap:Ethernet  HWaddr 52:54:00:D0:48:0C
          inet addr:192.168.122.176  Bcast:192.168.122.255  Mask:255.255.255.0
          inet6 addr: fe80::5054:ff:fed0:480c/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:55 errors:0 dropped:28 overruns:0 frame:0
          TX packets:34 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:4545 (4.4 KiB)  TX bytes:3345 (3.2 KiB)
</code></pre>

<p>Exit the guest by running <code>exit</code> and <code>Ctrl + ]</code> to exit the console session.</p>

<p>Now SSH to your Alpine VM:</p>

<pre><code class="bash">$ ssh root@192.168.122.176
root@192.168.122.176's password:
Welcome to Alpine!
</code></pre>

<h2>Some Useful Commands:</h2>

<p>List Running VMs:</p>

<pre><code>$ virsh list
 Id    Name                           State
----------------------------------------------------
 3     alpine1                        running
</code></pre>

<p>Shutdown a VM:</p>

<pre><code class="bash">$ virsh shutdown alpine1
Domain alpine1 is being shutdown
</code></pre>

<p>List all VMs:</p>

<pre><code class="bash">$ virsh list --all
 Id    Name                           State
----------------------------------------------------
 -     alpine1                        shut off
</code></pre>

<p>Delete a VM:</p>

<pre><code class="bash">$ virsh shutdown alpine1 #or to force shutdown:
$ virsh destroy alpine1
$ virsh undefine alpine1
</code></pre>

<p>Any future KVM posts will be tagged under <a href="http://blog.ruanbekker.com/blog/categories/kvm?source_site=blog.ruanbekker.com?source_category=kvm">KVM</a> and Alpine posts will be available under the <a href="http://blog.ruanbekker.com/blog/categories/alpine?source_site=blog.ruanbekker.com?source_category=kvm">Alpine</a> tag.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Change Your Relayhost on Postfix Using Sed]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/14/change-your-relayhost-on-postfix-using-sed/"/>
    <updated>2017-12-14T10:11:33-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/14/change-your-relayhost-on-postfix-using-sed</id>
    <content type="html"><![CDATA[<p>a Quick post on how to change your relayhost on Postfix to a External SMTP Provider and aswell how to revert back the changes so the Relay server sends out mail directly.</p>

<h2>Checking your current relayhost configuration:</h2>

<p>We will assume your <code>/etc/postfix/main.cf</code> has a relayhost entry of <code>#relayhost =</code>, in my example it will look like this:</p>

<pre><code class="bash">$ cat /etc/postfix/main.cf
#relayhost =
</code></pre>

<p>If not, you can just adjust your sed command accordingly.</p>

<h2>Changing your relayhost configuration to a External SMTP Provider:</h2>

<p>We will use sed to change the relayhost to <code>za-smtp-outbound-1.mimecast.co.za</code> for example:</p>

<pre><code class="bash">$ sed -i 's/#relayhost\ =/relayhost\ =\ \[za-smtp-outbound-1.mimecast.co.za\]/g' /etc/postfix/main.cf
</code></pre>

<p>to verify that we have set the config, look at the config:</p>

<pre><code class="bash">$ cat /etc/postfix/main.cf | grep relayhost 
relayhost = [za-smtp-outbound-1.mimecast.co.za]
</code></pre>

<p>Once you see the changes looks as expected, you can restart postfix:</p>

<pre><code class="bash">$ /etc/init.d/postfix restart
</code></pre>

<p>Then you can tail the logs to see if the mail gets delivered:</p>

<pre><code class="bash">$ tail -f /var/log/maillog
</code></pre>

<h2>Revert your changes so that postfix sends out directly:</h2>

<p>To revert your changes, let&rsquo;s change the config back to what it was:</p>

<pre><code class="bash">$ sed -i 's/relayhost\ =\ \[za-smtp-outbound-1.mimecast.co.za\]/#relayhost\ =/g' /etc/postfix/main.cf
</code></pre>

<p>To verify your changes:</p>

<pre><code class="bash">$ cat /etc/postfix/main.cf | grep relayhost
#relayhost =
</code></pre>

<p>As you can see the relayhost is commented out, meaning that the relayhost property will not be active, go ahead and restart the service for the changes to take effect:</p>

<pre><code class="bash">$ /etc/init.d/postfix restart
</code></pre>

<p>Same as before, look at the logs to confirm mailflow is as expected:</p>

<pre><code class="bash">$ tail -f /var/log/maillog
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH Host Key Warnings With Strict Checking Enabled]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/13/ssh-host-key-warnings-with-strict-checking-enabled/"/>
    <updated>2017-12-13T02:07:29-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/13/ssh-host-key-warnings-with-strict-checking-enabled</id>
    <content type="html"><![CDATA[<p>When you format / reload a server and the host gets the same IP, when you try to SSH to that host, you might get a warning like this:</p>

<pre><code class="bash">$ ssh 192.168.1.104
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that a host key has just been changed.
The fingerprint for the ECDSA key sent by the remote host is
a1:a2:a3:a4:a5:a6:a7:a8:a9:b0:b1:b2:b3:b4:b5:b6.
Please contact your system administrator.
Add correct host key in /home/pi/.ssh/known_hosts to get rid of this message.
Offending ECDSA key in /home/pi/.ssh/known_hosts:10
ECDSA host key for 192.168.1.104 has changed and you have requested strict checking.
Host key verification failed.
</code></pre>

<p>This is because we have <code>StrictMode</code> enabled in our SSH Configuration:</p>

<pre><code class="bash">$ cat /etc/ssh/sshd_config | grep -i stric
StrictModes yes
</code></pre>

<p>To remove the offending key from your <code>known_hosts</code> file, without opening it, you can use <code>ssh-keygen</code> to remove it:</p>

<pre><code class="bash">$ ssh-keygen -f .ssh/known_hosts -R 192.168.1.104
# Host 192.168.1.104 found: line 10 type ECDSA
.ssh/known_hosts updated.
Original contents retained as .ssh/known_hosts.old
</code></pre>

<p>Now when you SSH the warning should be removed.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unmask a Masked Service in Systemd]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/09/unmask-a-masked-service-in-systemd/"/>
    <updated>2017-12-09T02:02:21-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/09/unmask-a-masked-service-in-systemd</id>
    <content type="html"><![CDATA[<p>I was busy setting up a <code>docker-volume-netshare</code> plugin to use NFS Volumes for Docker, which relies on the <code>nfs-utils/nfs-common</code> package, and when trying to start the service, I found that the <code>nfs-common</code> service is <code>masked</code>:</p>

<pre><code class="bash">$ sudo systemctl start docker-volume-netshare.service
Failed to start docker-volume-netshare.service: Unit nfs-common.service is masked.
</code></pre>

<p>Looking at the <code>nfs-common</code> service:</p>

<pre><code class="bash">sudo systemctl is-enabled nfs-common
masked

$ sudo systemctl enable nfs-common
Synchronizing state of nfs-common.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable nfs-common
Failed to enable unit: Unit file /lib/systemd/system/nfs-common.service is masked.
</code></pre>

<p>It appears that the unit file has a symbolic link to /dev/null:</p>

<pre><code class="bash">$ file /lib/systemd/system/nfs-common.service 
/lib/systemd/system/nfs-common.service: symbolic link to /dev/null
</code></pre>

<p>I was able to unmask the service by removing the file:</p>

<pre><code class="bash">$ sudo rm /lib/systemd/system/nfs-common.service 
</code></pre>

<p>Then reloading the daemon:</p>

<pre><code class="bash">$ sudo systemctl daemon-reload
</code></pre>

<p>As we can see the <code>nfs-common</code> service is not running:</p>

<pre><code class="bash">$ sudo systemctl status nfs-common
● nfs-common.service - LSB: NFS support files common to client and server
   Loaded: loaded (/etc/init.d/nfs-common; generated; vendor preset: enabled)
   Active: inactive (dead)
     Docs: man:systemd-sysv-generator(8)
</code></pre>

<p>Let&rsquo;s go ahead and start the service:</p>

<pre><code class="bash">$ sudo systemctl start nfs-common
$ sudo systemctl status nfs-common
● nfs-common.service - LSB: NFS support files common to client and server
   Loaded: loaded (/etc/init.d/nfs-common; generated; vendor preset: enabled)
   Active: active (running) since Sat 2017-12-09 08:59:47 SAST; 2s ago
     Docs: man:systemd-sysv-generator(8)
  Process: 7382 ExecStart=/etc/init.d/nfs-common start (code=exited, status=0/SUCCESS)
      CPU: 162ms
   CGroup: /system.slice/nfs-common.service
           └─7403 /usr/sbin/rpc.idmapd
</code></pre>

<p>Now we can see the serive is unmasked and started, also remember to enable to service on boot:</p>

<pre><code class="bash">$ sudo systemctl enable nfs-common
nfs-common.service is not a native service, redirecting to systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable nfs-common

$ sudo systemctl is-enabled nfs-common
enabled
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a NFS Server on a RaspberryPi]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/05/setup-a-nfs-server-on-a-raspberrypi/"/>
    <updated>2017-12-05T10:45:35-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/05/setup-a-nfs-server-on-a-raspberrypi</id>
    <content type="html"><![CDATA[<p>Setup a NFS Server/Client on RaspberryPi 3</p>

<h2>Setup the Server Side - Disks and Directories</h2>

<p>Prepare the directories:</p>

<pre><code class="bash">$ sudo mkdir -p /opt/nfs
$ sudo chown pi:pi /opt/nfs
$ sudo chmod 755 /opt/nfs
</code></pre>

<p>For demonstration, I will be using the same disk as my OS, but if you have other disks that you would like to mount, mount them like the following:</p>

<pre><code class="bash">$ sudo lsblk
$ sudo mount /dev/sda2 /opt/nfs
$ sudo chown -R pi:pi /opt/nfs/existing_dirs
$ sudo find /opt/nfs/existing_dirs/ -type d -exec chmod 755 {} \;
$ sudo find /opt/nfs/existing_dirs/ -type f -exec chmod 644 {} \;
</code></pre>

<p>If you mounted the disk, and you would like to mount the disk on boot, we need to add it to our <code>/etc/fstab</code>. We can get the disk by running either:</p>

<pre><code class="bash">$ sudo lsblk
# or
$ sudo blkid
</code></pre>

<p>Populate the <code>/etc/fstab</code> with your disk info, it will look more or less like:</p>

<pre><code class="bash">/dev/sda2 /opt/nfs ext4 defaults,noatime 0 0
</code></pre>

<p>Append <code>rootdelay=10</code> after <code>rootwait</code> in <code>/boot/cmdline.txt</code>, then reboot for the changes to become active.</p>

<h2>Setup the Server Side - Installing NFS Server</h2>

<p>Install the NFS Server packages:</p>

<pre><code class="bash">$ sudo apt install nfs-kernel-server nfs-common rpcbind -y
</code></pre>

<p>Configure the paths in <code>/etc/exports</code>, we need to uid gid for the user that owns permission that we need to pass to the NFS Client. To get that:</p>

<pre><code class="bash">$ id pi
uid=1000(pi) gid=1000(pi)
</code></pre>

<p>Setup our path that we would like to be accessible via NFS:</p>

<pre><code class="bash">/opt/nfs 192.168.1.0/24(rw,all_squash,no_hide,insecure,async,no_subtree_check,anonuid=1000,anongid=1000)
</code></pre>

<p>If you would like to have open access:</p>

<pre><code class="bash">/opt/nfs *(rw,all_squash,no_hide,insecure,async,no_subtree_check,anonuid=1000,anongid=1000)
</code></pre>

<p>Export the config, enable the services on boot and start NFS:</p>

<pre><code class="bash">$ sudo exportfs -ra
$ sudo systemctl enable rpcbind
$ sudo systemctl enable nfs-kernel-server
$ sudo systemctl enable nfs-common
$ sudo systemctl start rpcbind
$ sudo systemctl start nfs-kernel-server
$ sudo systemctl start nfs-common
</code></pre>

<h2>Setup the NFS Client</h2>

<p>On the client install the NFS Client packages:</p>

<pre><code class="bash">$ sudo apt install nfs-common -y
</code></pre>

<p>Create the mountpoint of choice and change the ownership:</p>

<pre><code class="bash">$ sudo chown pi:pi /mnt
</code></pre>

<p>Setup the <code>/etc/idmapd.conf</code> to match the user:</p>

<pre><code>[Mapping]
Nobody-User = pi
Nobody-Group = pi
</code></pre>

<p>Mount the NFS Share to your local mount point:</p>

<pre><code class="bash">$ sudo mount 192.168.1.2:/opt/nfs /mnt
</code></pre>

<p>Enable mount on boot via <code>/etc/fstab</code>:</p>

<pre><code class="bash">192.168.1.2:/opt/nfs /mnt nfs rw 0 0
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://zsiti.eu/nfs-file-sharing-server-raspberry-pi/">Great Resource on NFS</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
