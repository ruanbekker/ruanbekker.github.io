<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Nginx | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/nginx/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2020-02-04T23:44:37+02:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Secure Your Elasticsearch Cluster With Basic Auth Using Nginx and SSL From Letsencrypt]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/04/02/secure-your-elasticsearch-cluster-with-basic-auth-using-nginx/"/>
    <updated>2019-04-02T20:55:58+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/04/02/secure-your-elasticsearch-cluster-with-basic-auth-using-nginx</id>
    <content type="html"><![CDATA[<p>In this tutorial we will setup a reverse proxy using nginx to translate and load balance traffic through to our elasticsearch nodes. We will also protect our elasticsearch cluster with basic auth and use letsencrypt to retrieve free ssl certificates.</p>

<p>We want to allow certain requests to be bypassed from authentication such as getting status from the cluster and certain requests we want to enforce authentication, such as indexing and deleting data.</p>

<h2>Install Nginx:</h2>

<p>Install nginx and the dependency package to create basic auth:</p>

<pre><code class="bash">$ apt install nginx apache2-utils -y
</code></pre>

<h2>Configure Nginx for Reverse Proxy</h2>

<p>We want to access our nginx proxy on port 80: <code>0.0.0.0:80</code> and the requests should be proxied through to elasticsearch private addresses: <code>10.0.0.10:9200</code> and <code>10.0.0.11:9200</code>. Traffic will be load balanced between our 2 nodes.</p>

<p>Edit the main nginx configuration:</p>

<pre><code>$ vim /etc/nginx/nginx.conf
</code></pre>

<p>and populate the information as shown below:</p>

<pre><code>user www-data;
worker_processes auto;
pid /run/nginx.pid;

events {
    worker_connections 1024;
    # multi_accept on;
}

http {

    # basic Settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # ssl settings
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;

    # logging settings
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # gzip settings
    gzip on;
    gzip_disable "msie6";

    # virtual host configs
    include /etc/nginx/conf.d/*.conf;
}
</code></pre>

<p>Next, edit the virtual host config:</p>

<pre><code>$ vim /etc/nginx/conf.d/elasticsearch.conf
</code></pre>

<p>And populate the following config:</p>

<pre><code># https://gist.github.com/sahilsk/b16cb51387847e6c3329

upstream elasticsearch {
    # define your es nodes
    server 10.0.0.10:9200;
    server 10.0.0.11:9200;
    # persistent http connections
    # https://www.elastic.co/blog/playing-http-tricks-nginx
    keepalive 15;
}

server {
  listen 80;
  server_name elasticsearch.domain.com;

  auth_basic "server auth";
  auth_basic_user_file /etc/nginx/passwords;

  location / {

    # deny node shutdown api
    if ($request_filename ~ "_shutdown") {
      return 403;
      break;
    }

    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_redirect off;
  }

  location = / {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_redirect off;
    auth_basic "off";
  }

  location ~* ^(/_cluster/health|/_cat/health) {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_redirect off;
    auth_basic "off";
  }
}
</code></pre>

<p>Set your username and password to protect your endpoint:</p>

<pre><code class="bash">$ htpasswd -c /etc/nginx/passwords admin
</code></pre>

<p>Enable nginx on boot and restart the process:</p>

<pre><code class="bash">$ systemctl enable nginx
$ systemctl restart nginx
</code></pre>

<h2>Test it</h2>

<p>Now make requests to elasticsearch via your nginx reverse proxy:</p>

<pre><code class="bash">$ curl -H 'Content-Type: application/json' -u 'admin:admin' http://myproxy.domain.com/_cat/indices?v
health status index       uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   first-index 1o6yM7tCSqagqoeihKM7_g   5   1          3            0     40.6kb         20.3kb
</code></pre>

<h2>Letsencrypt SSL Certificates</h2>

<p>Add free SSL Certificates to your reverse proxy. Install certbot:</p>

<pre><code class="bash">$ apt-get update
$ apt-get install software-properties-common -y
$ add-apt-repository universe
$ add-apt-repository ppa:certbot/certbot
$ apt-get update
$ apt-get install certbot python-certbot-nginx -y
</code></pre>

<p>Request a Certificate for your domain:</p>

<pre><code class="bash">$ certbot --manual certonly -d myproxy.domain.com -m my@email.com --preferred-challenges dns --agree-tos

Obtaining a new certificate
Performing the following challenges:
dns-01 challenge for myproxy.domain.com
</code></pre>

<p>You will be prompted to make a dns change, since we requested the dns challenge. While this screen is here, we can go our dns provider and make the TXT record change as shown below:</p>

<pre><code>Please deploy a DNS TXT record under the name
_acme-challenge.myproxy.domain.com with the following value:

xLP4y_YJvdAK7_aZMJ50gkudTDeIC3rX0x83aNJctGw

Before continuing, verify the record is deployed.
Press Enter to Continue
Waiting for verification...
Cleaning up challenges

IMPORTANT NOTES:
 - Congratulations! Your certificate and chain have been saved at:
   /etc/letsencrypt/live/myproxy.domain.com/fullchain.pem
   Your key file has been saved at:
   /etc/letsencrypt/live/myproxy.domain.com/privkey.pem
   Your cert will expire on 2019-07-01. To obtain a new or tweaked
   version of this certificate in the future, simply run certbot
   again. To non-interactively renew *all* of your certificates, run
   "certbot renew"
 - If you like Certbot, please consider supporting our work by:

   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate
   Donating to EFF:                    https://eff.org/donate-le
</code></pre>

<h2>Update Nginx Config</h2>

<p>Now that we have our ssl certificates, we need to update our nginx config to enable ssl, redirect http to https and point the ssl certificates and ssl private keys to the certificates that we retrieved from letsencrypt.</p>

<p>Open up the virtual host nginx configuration:</p>

<pre><code class="bash">$ vim /etc/nginx/conf.d/elasticsearch.conf
</code></pre>

<p>Update the config like the one below:</p>

<pre><code>upstream elasticsearch {
    server 10.0.0.10:9200;
    server 10.0.0.11:9200;
    keepalive 15;
}

server {
  listen 80;
  server_name myproxy.domain.com;
  return 301 https://$host$request_uri;
}

server {
  listen 443 ssl;
  server_name myproxy.domain.com;

  ssl_certificate /etc/letsencrypt/live/myproxy.domain.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/myproxy.domain.com/privkey.pem;

  auth_basic "server auth";
  auth_basic_user_file /etc/nginx/passwords;

  location ^~ /.well-known/acme-challenge/ {
    auth_basic off;
  }

  location / {

    # deny node shutdown api
    if ($request_filename ~ "_shutdown") {
      return 403;
      break;
    }

    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $http_host;
    proxy_redirect off;
  }

  location = / {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $http_host;
    proxy_redirect off;
    auth_basic "off";
  }

  location ~* ^(/_cluster/health|/_cat/health) {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $http_host;
    proxy_redirect off;
    auth_basic "off";
  }
}
</code></pre>

<p>Restart the nginx process:</p>

<pre><code class="bash">$ systemctl restart nginx
</code></pre>

<h2>Test the Nginx Proxy with SSL</h2>

<p>Test the proxy with HTTP so that we can see that our nginx config redirects us to <a href="HTTPS:">HTTPS:</a></p>

<pre><code class="bash">$ curl -iL -u 'admin:admin' http://myproxy.domain.com/_cat/nodes?v
HTTP/1.1 301 Moved Permanently
Server: nginx/1.14.0 (Ubuntu)
Date: Tue, 02 Apr 2019 21:40:09 GMT
Content-Type: text/html
Content-Length: 194
Connection: keep-alive
Location: https://myproxy.domain.com/_cat/nodes?v

HTTP/1.1 200 OK
Server: nginx/1.14.0 (Ubuntu)
Date: Tue, 02 Apr 2019 21:40:10 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 276
Connection: keep-alive

ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.0.0.10               40          97   3    0.15    0.10     0.08 mdi       -      Lq9P7eP
10.0.0.11               44          96   3    0.21    0.10     0.09 mdi       *      F5edOwK
</code></pre>

<p>Test the proxy with <a href="HTTPS:">HTTPS:</a></p>

<pre><code class="bash">$ curl -i -u 'admin:admin' https://myproxy.domain.com/_cat/nodes?v
HTTP/1.1 200 OK
Server: nginx/1.14.0 (Ubuntu)
Date: Tue, 02 Apr 2019 21:40:22 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 276
Connection: keep-alive

ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.0.0.10               44          96   4    0.18    0.10     0.09 mdi       *      F5edOwK
10.0.0.11               39          97   5    0.13    0.09     0.08 mdi       -      Lq9P7eP
</code></pre>

<p>Setup a cronjob to auto renew the certificates:</p>

<pre><code class="bash">$ crontab -e
</code></pre>

<p>Populate the following line:</p>

<pre><code class="bash">6 1,13 * * * /usr/bin/certbot renew --post-hook "systemctl restart nginx" --quiet
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://certbot.eff.org/lets-encrypt/ubuntuxenial-nginx.html">https://certbot.eff.org/lets-encrypt/ubuntuxenial-nginx.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a Reverse Proxy on Nginx for Your Backend Applications]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/03/10/setup-a-reverse-proxy-on-nginx-for-your-backend-applications/"/>
    <updated>2019-03-10T00:50:32+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/03/10/setup-a-reverse-proxy-on-nginx-for-your-backend-applications</id>
    <content type="html"><![CDATA[<p><img src="https://www.nginx.com/wp-content/uploads/2018/08/NGINX-logo-rgb-large.png" alt="" /></p>

<p>Nginx is a great product! And today we will use nginx to setup a http reverse proxy to access our backend applications.</p>

<script id="mNCC" language="javascript">
    medianet_width = "728";
    medianet_height = "90";
    medianet_crid = "218284798";
    medianet_versionId = "3111299";
  </script>


<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>


<h2>Our Setup</h2>

<p>We will have a flask backend application listening on <code>127.0.0.1:5000</code> and our nginx reverse proxy will listen on <code>0.0.0.0:80</code> which will proxy requests through to our flask upstream.</p>

<h2>Our Backend Application</h2>

<p>Our Flask application:</p>

<pre><code>from flask import Flask
app = Flask(__name__)

@app.route('/')
def index():
    return 'Hello'

if __name__ == '__main__':
    app.run(host='127.0.0.1', port=5000)
</code></pre>

<h2>Nginx</h2>

<p>Install nginx:</p>

<pre><code class="bash">$ apt install nginx -y
</code></pre>

<p>Our main nginx configuration:</p>

<pre><code># /etc/nginx/nginx.conf
user www-data;
worker_processes auto;
pid /run/nginx.pid;
include /etc/nginx/modules-enabled/*.conf;

events {
    worker_connections 768;
}

http {
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_names_hash_bucket_size 64;

    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
    ssl_prefer_server_ciphers on;
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;
    gzip on;
    gzip_disable "msie6";

    include /etc/nginx/conf.d/backend-*.conf;
}
</code></pre>

<p>Our application&rsquo;s configuration:</p>

<pre><code># /etc/nginx/conf.d/backend-flask.conf
upstream backend_flask {
    server 127.0.0.1:5000;
}

server {
    listen 80 default_server;
    listen [::]:80;
    server_name _;

    location / {
        include proxy_params;
        proxy_http_version 1.1;
        proxy_read_timeout 90;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_pass http://backend_flask;
        proxy_buffering off;
    }
}
</code></pre>

<p>Restart nginx and enable nginx on boot:</p>

<pre><code class="bash">$ systemctl restart nginx
$ systemctl enable nginx
</code></pre>

<h2>Test your Application:</h2>

<p>Access your server on port 80 and you should receive the response from your flask application:</p>

<pre><code class="bash">$ curl http://nginx-public-ip:80/
Hello
</code></pre>

<h2>Resoures</h2>

<ul>
<li><a href="https://itnext.io/step-over-nginx-buffer-issue-94a498bedb82">https://itnext.io/step-over-nginx-buffer-issue-94a498bedb82</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a Raspberry Pi Nginx Image With Caching on Alpine for Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm/"/>
    <updated>2018-10-23T23:00:02+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm</id>
    <content type="html"><![CDATA[<p>In this guide, we will be creating a nginx reverse proxy with the ability to cache static content using a alpine image.</p>

<p>We will then push the image to gitlab&rsquo;s private registry, and then run the service on docker swarm.</p>

<h2>Create the backend service:</h2>

<p>We will upstream to our blog using ghost, which you can deploy using:</p>

<pre><code class="bash">$ docker service create --name blog --network docknet rbekker87/armhf-ghost:2.0.3
</code></pre>

<h2>Current File Structure:</h2>

<p>Our file structure for the assets we need to build the reverse proxy:</p>

<pre><code>$ find .
./conf.d
./conf.d/blog.conf
./Dockerfile
./nginx.conf
</code></pre>

<ul>
<li><code>Dockerfile</code></li>
</ul>


<pre><code>FROM hypriot/rpi-alpine-scratch
MAINTAINER Ruan Bekker

RUN apk update &amp;&amp; \
    apk add nginx &amp;&amp; \
    rm -rf /etc/nginx/nginx.conf &amp;&amp; \
    chown -R nginx:nginx /var/lib/nginx &amp;&amp; \
    rm -rf /var/cache/apk/*

ADD nginx.conf /etc/nginx/
ADD conf.d/blog.conf /etc/nginx/conf.d/

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
</code></pre>

<ul>
<li><code>nginx.conf</code></li>
</ul>


<pre><code>user nginx;
worker_processes 1;

events {
    worker_connections 1024;
    }

error_log  /var/log/nginx/nginx_error.log warn;

http {

    sendfile          on;
    tcp_nodelay       on;

    gzip              on;
    gzip_http_version 1.0;
    gzip_proxied      any;
    gzip_min_length   500;
    gzip_disable      "MSIE [1-6]\.";
    gzip_types        text/plain text/xml text/css
                      text/comma-separated-values
                      text/javascript
                      application/x-javascript
                      application/atom+xml;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;
    error_log   /var/log/nginx/error.log;

    proxy_cache_path /var/cache/nginx/ levels=1:2 keys_zone=nginx_cache:5m max_size=128m inactive=60m;

    keepalive_timeout  60;
    server_tokens      off;

    include /etc/nginx/conf.d/*.conf;

}
</code></pre>

<p>Hostname resolution to our Ghost Blog Service: In our swarm we have a service called blog which is associated to the docknet network, so the dns resolution will resolve to the vip of the service. As seen in the figure below:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
nq42a6jfwx3d        blog                replicated          1/1                 rbekker87/armhf-ghost:2.0.3
</code></pre>

<ul>
<li><code>conf.d/blog.conf</code></li>
</ul>


<pre><code>upstream ghost_blog {
    server blog:2368;
    }

server {
    listen 80;
    server_name blog.yourdomain.com;

    access_log  /var/log/nginx/blog_access.log  main;
    error_log   /var/log/nginx/blog_error.log;

    location / {

        proxy_cache                 nginx_cache;
        add_header                  X-Proxy-Cache $upstream_cache_status;
        proxy_ignore_headers        Cache-Control;
        proxy_cache_valid any       10m;
        proxy_cache_use_stale       error timeout http_500 http_502 http_503 http_504;

        proxy_pass                  http://ghost_blog;
        proxy_redirect              off;

        proxy_set_header            Host $host;
        proxy_set_header            X-Real-IP $remote_addr;
        proxy_set_header            X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header            X-Forwarded-Host $server_name;
    }
}
</code></pre>

<h2>Building the Image and Pushing to Gitlab</h2>

<p>I&rsquo;m using Gitlab in this demonstration, but you can use the registry of your choice:</p>

<pre><code>$ docker login registry.gitlab.com
$ docker build -t registry.gitlab.com/user/docker/arm-nginx:caching .
$ docker tag registry.gitlab.com/user/docker/arm-nginx:caching registry.gitlab.com/user/docker/arm-nginx:caching
$ docker push registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<h2>Deploy</h2>

<p>Create the Nginx Reverse Proxy Service on Docker Swarm:</p>

<pre><code>$ docker service create --name nginx_proxy \
--network docknet \
--publish 80:80 \
--replicas 1 \
--with-registry-auth registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<p>Listing our Services:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
je7x21l7egoh        nginx_proxy         replicated          1/1                 registry.gitlab.com/user/docker/arm-nginx:caching   *:80-&gt;80/tcp
nq42a6jfwx3d        blog                replicated          1/1                 rbekker87/armhf-ghost:2.0.3
</code></pre>

<p>Once you access your proxy on port 80, you should see your Ghost Blog Homepage like below:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/ghost-blog-main.png" alt="" /></p>

<p>Have a look at the <a href="https://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/">benchmark performance</a> when using Nginx with caching enabled</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/r/rbekker87/armhf-ghost/">https://hub.docker.com/r/rbekker87/armhf-ghost/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx Caching Performance for Static Content on Docker Swarm With RaspberryPi]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/"/>
    <updated>2018-10-23T22:41:41+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/nginx-logo.png" alt="" /></p>

<h2>The Environment:</h2>

<p>I had my Ghost Blog listening on port 2368 and exposing port 80 on Docker so that the port translation directs port 80 traffic to port 2368 on Ghost directly.</p>

<p>Alex responded on my tweet and introduced Nginx Caching:</p>

<ul>
<li><a href="https://twitter.com/alexellisuk/status/882347698636165121">https://twitter.com/alexellisuk/status/882347698636165121</a></li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/tweet-alexellis-04072017.png" alt="" /></p>

<p>With this approach benchmarking results was not so great in terms of requests per second, and as this hostname will be only used for a blog, its a great idea to cache the content, this was achieved with the help from Alex&rsquo;s blog: <a href="https://blog.alexellis.io/save-and-boost-with-nginx/">blog.alexellis.io/save-and-boost-with-nginx/</a></p>

<h2>How Nginx was Configured:</h2>

<p>I have a <a href="http://rbkr.ddns.net/building-nginx-on-alpine-image-for-docker-swarm-with-caching-enabled-config/">blogpost</a> on how I setup Nginx on an Alpine Image, where I setup caching and proxy-pass the connections through to my ghost blog.</p>

<h2>Benchmarking: Before Nginx with Caching was Implemented:</h2>

<p>When doing an apache benchmark I got <b>9.31 requests per second</b> performing the test on my LAN:</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://rbkr.ddns.net/

This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking rbkr.ddns.net (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   53.725 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2863000 bytes
HTML transferred:       2735000 bytes
Requests per second:    9.31 [#/sec] (mean)
Time per request:       1074.501 [ms] (mean)
Time per request:       107.450 [ms] (mean, across all concurrent requests)
Transfer rate:          52.04 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    2   0.5      2       6
Processing:   685 1068  68.7   1057    1306
Waiting:      683 1067  68.6   1056    1306
Total:        689 1070  68.7   1058    1312

Percentage of the requests served within a certain time (ms)
  50%   1058
  66%   1088
  75%   1102
  80%   1110
  90%   1163
  95%   1218
  98%   1240
  99%   1247
 100%   1312 (longest request)
</code></pre>

<h2>Benchmarking: After Nginx Caching was Implemented:</h2>

<p>After Nginx Caching was Implemented, I got <b>1067.73 requests per second</b> using apache benchmark over a LAN connection! Absolutely awesome!</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://blog.pistack.co.za/
This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking blog.pistack.co.za (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:        nginx
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   0.468 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2880500 bytes
HTML transferred:       2735000 bytes
Requests per second:    1067.73 [#/sec] (mean)
Time per request:       9.366 [ms] (mean)
Time per request:       0.937 [ms] (mean, across all concurrent requests)
Transfer rate:          6007.05 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        3    4   1.4      4      10
Processing:     3    5   1.6      4      10
Waiting:        2    4   1.6      4      10
Total:          6    9   2.7      8      17

Percentage of the requests served within a certain time (ms)
  50%      8
  66%      8
  75%      9
  80%      9
  90%     15
  95%     15
  98%     15
  99%     16
 100%     17 (longest request)
</code></pre>

<h2>Resources:</h2>

<p>Thanks to Alex Ellis for the suggestion on this, and definitely have a look at <a href="https://blog.alexellis.io/tag/nginx/">blog.alexellis.io</a> as he has some epic content on his blog!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx Basic Authentication With Source IP Whitelisting]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/03/19/nginx-basic-authentication-with-source-ip-whitelisting/"/>
    <updated>2018-03-19T16:57:36+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/03/19/nginx-basic-authentication-with-source-ip-whitelisting</id>
    <content type="html"><![CDATA[<p>Quick post on how to setup HTTP Basic Authentication and whitelist IP Based Sources to not get prompted for Authentication.</p>

<p>This could be useful for systems interacting with Nginx, so that they don&rsquo;t have to provide authentication.</p>

<h2>Dependencies:</h2>

<p>Install nginx and the package required to create the auth file:</p>

<pre><code>$ apt install nginx apache2-utils -y
</code></pre>

<p>Create the Password file:</p>

<pre><code>$ htpasswd -c /etc/ngins/secrets admin
</code></pre>

<h2>Configuration:</h2>

<p>Create the site config:</p>

<pre><code>$ rm -rf /etc/nginx/conf.d/*.conf
$ vim /etc/nginx/conf.d/default.conf
</code></pre>

<pre><code>server {
    listen       80;
    server_name  localhost;

    location / {
        satisfy any;
        allow 127.0.0.1;
        deny all;

        auth_basic "restricted";
        auth_basic_user_file /etc/nginx/secrets;
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }
}
</code></pre>

<p>Reload the Changes:</p>

<pre><code>$ nginx -s reload
</code></pre>

<h2>Testing:</h2>

<p>Testing from our Whitelisted location (localhost):</p>

<pre><code>curl -i http://127.0.0.1 
HTTP/1.1 200 OK
</code></pre>

<p>Testing from remote location:</p>

<pre><code>$ curl -i http://localhost
HTTP/1.1 401 Unauthorized

$ curl -i http://admin:password@localhost
HTTP/1.1 200 OK
</code></pre>
]]></content>
  </entry>
  
</feed>
