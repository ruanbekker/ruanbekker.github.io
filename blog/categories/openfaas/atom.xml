<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Openfaas | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/openfaas/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2022-07-31T05:00:00-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Asynchronous Function With OpenFaas]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/17/python-asynchronous-function-with-openfaas/"/>
    <updated>2020-02-17T23:51:22+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/17/python-asynchronous-function-with-openfaas</id>
    <content type="html"><![CDATA[<p>In this post we will explore how to use asynchronous functions in OpenFaas.</p>

<h2>What are we doing</h2>

<p>A synchronous request blocks the client until operation completes, where a asynchronous request doesnâ€™t block the client, which is nice to use for long-running tasks or function invocations to run in the background through the use of NATS Streaming.</p>

<p>We will be building a Python Flask API Server which will act as our webhook service. When we invoke our function by making a http request, we also include a callback url as a header which will be the address where the queue worker will post it&rsquo;s results.</p>

<p>Then we will make a http request to the synchronous function where we will get the response from the function and a http request to the asynchronous function, where we will get the response from the webhook service&rsquo;s logs</p>

<h2>Deploy OpenFaas</h2>

<p>Deploy OpenFaas on a k3d Kubernetes Cluster if you want to follow along on your laptop. You can follow this post to deploy a kubernetes cluster and deploying openfaas:</p>

<ul>
<li><a href="https://blog.ruanbekker.com/blog/2020/02/17/traefik-ingress-for-openfaas-on-kubernetes-k3d/">https://blog.ruanbekker.com/blog/2020/02/17/traefik-ingress-for-openfaas-on-kubernetes-k3d/</a></li>
</ul>


<h2>Webhook Service</h2>

<p>Lets build the Python Flask Webhook Service, our application code:</p>

<pre><code class="python">from flask import Flask, request
from logging.config import dictConfig

dictConfig({
    'version': 1,
    'formatters': {'default': {
        'format': '[%(asctime)s] %(levelname)s in %(module)s: %(message)s',
    }},
    'handlers': {'wsgi': {
        'class': 'logging.StreamHandler',
        'stream': 'ext://flask.logging.wsgi_errors_stream',
        'formatter': 'default'
    }},
    'root': {
        'level': 'INFO',
        'handlers': ['wsgi']
    }
})

app = Flask(__name__)

@app.route("/", methods=["POST", "GET"])
def main():
    response = {}

    if request.method == "GET":
        response["event"] = "GET"
        app.logger.info("Received Event: GET")

    if request.method == "POST":
        response["event"] = request.get_data()
        app.logger.info("Receveid Event: {}".format(response))

    else:
        response["event"] == "OTHER"

    print("Received Event:")
    print(response)
    return "event: {} \n".format(response)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
</code></pre>

<p>Our <code>Dockerfile</code>:</p>

<pre><code>FROM python:3.7-alpine
RUN pip install flask
ADD app.py /app.py
EXPOSE 5000
CMD ["python", "/app.py"]
</code></pre>

<p>Building and Pushing to Docker Hub (or you can use my docker image):</p>

<pre><code>$ docker build -t yourusername/python-flask-webhook:openfaas .
$ docker push yourusername/python-flask-webhook:openfaas
</code></pre>

<p>Create the deployment manifest <code>webhook.yml</code> for our webhook service:</p>

<pre><code>$ cat &gt; webhook.yml &lt;&lt; EOF
apiVersion: v1
kind: Service
metadata:
  name: webhook-service
spec:
  selector:
    app: webhook
  ports:
    - protocol: TCP
      port: 5000
      targetPort: 5000
      name: web
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: webhook-ingress
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: webhook.localdns.xyz
    http:
      paths:
      - backend:
          serviceName: webhook-service
          servicePort: 5000
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: webhook
  name: webhook
spec:
  replicas: 1
  selector:
    matchLabels:
      app: webhook
  template:
    metadata:
      labels:
        app: webhook
    spec:
      containers:
      - name: webhook
        image: ruanbekker/python-flask-webhook:openfaas
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5000
          name: http
          protocol: TCP
EOF
</code></pre>

<p>Now deploy to kubernetes:</p>

<pre><code>$ kubectl apply -f webhook.yml
</code></pre>

<p>After a minute or so, verify that you get a response when making a http request:</p>

<pre><code>$ curl http://webhook.localdns.xyz
event: {'event': 'GET'}
</code></pre>

<h2>Deploy the OpenFaas Function</h2>

<p>We will deploy a dockerfile type function which will return the data that we feed it:</p>

<pre><code>$ faas-cli new --lang dockerfile function-async-task
$ faas-cli up -f function-async-task.yml

Deploying: function-async-task.

Deployed. 202 Accepted.
URL: http://openfaas.localdns.xyz/function/function-async-task
</code></pre>

<p>List the functions:</p>

<pre><code>$ faas-cli list
Function                        Invocations     Replicas
function-async-task             0               1
</code></pre>

<p>Describe the function:</p>

<pre><code>$ faas-cli describe function-async-task
Name:                function-async-task
Status:              Ready
Replicas:            1
Available replicas:  1
Invocations:         0
Image:               ruanbekker/function-async-task:latest
Function process:
URL:                 http://openfaas.localdns.xyz/function/function-async-task
Async URL:           http://openfaas.localdns.xyz/async-function/function-async-task
Labels:              faas_function : function-async-task
Annotations:         prometheus.io.scrape : false
</code></pre>

<h2>Testing</h2>

<p>Test synchronous function:</p>

<pre><code>$ curl http://openfaas.localdns.xyz/function/function-async-task -d "test"
test
</code></pre>

<p>Test asynchronous function, remember, here we need to provide the callback url which the queue worker will inform, which will be our webhook service:</p>

<pre><code>$ curl -i -H "X-Callback-Url: http://webhook-service.default.svc.cluster.local:5000" http://openfaas.localdns.xyz/async-async-function/function-async-task -d "asyyyyync"
HTTP/1.1 202 Accepted
Content-Length: 0
Date: Mon, 17 Feb 2020 13:57:26 GMT
Vary: Accept-Encoding
X-Call-Id: d757c10f-4293-4daa-bf52-bbdc17b7dea3
X-Start-Time: 1581947846737501600
</code></pre>

<p>Check the logs of the webhook pod:</p>

<pre><code>$ kubectl logs -f pod/$(kubectl get pods --selector=app=webhook --output=jsonpath="{.items..metadata.name}")
[2020-02-17 13:57:26,774] INFO in app: Receveid Event: {'event': b'asyyyyync'}
[2020-02-17 13:57:26,775] INFO in internal: 10.42.0.6 - - [17/Feb/2020 13:57:26] "POST / HTTP/1.1" 200 -
</code></pre>

<p>Check the logs of the queue worker:</p>

<pre><code>$ kubectl logs -f deployment/queue-worker -n openfaas
[45] Received on [faas-request]: 'sequence:45 subject:"faas-request" data:"{\"Header\":{\"Accept\":[\"*/*\"],\"Accept-Encoding\":[\"gzip\"],\"Content-Length\":[\"9\"],\"Content-Type\":[\"application/x-www-form-urlencoded\"],\"User-Agent\":[\"curl/7.54.0\"],\"X-Call-Id\":[\"d757c10f-4293-4daa-bf52-bbdc17b7dea3\"],\"X-Callback-Url\":[\"http://webhook-service.default.svc.cluster.local:5000\"],\"X-Forwarded-For\":[\"10.42.0.0\"],\"X-Forwarded-Host\":[\"openfaas.localdns.xyz\"],\"X-Forwarded-Port\":[\"80\"],\"X-Forwarded-Proto\":[\"http\"],\"X-Forwarded-Server\":[\"traefik-6787cddb4b-87zss\"],\"X-Real-Ip\":[\"10.42.0.0\"],\"X-Start-Time\":[\"1581947846737501600\"]},\"Host\":\"openfaas.localdns.xyz\",\"Body\":\"YXN5eXl5eW5j\",\"Method\":\"POST\",\"Path\":\"\",\"QueryString\":\"\",\"Function\":\"openfaas-function-cat\",\"CallbackUrl\":{\"Scheme\":\"http\",\"Opaque\":\"\",\"User\":null,\"Host\":\"webhook-service.default.svc.cluster.local:5000\",\"Path\":\"\",\"RawPath\":\"\",\"ForceQuery\":false,\"RawQuery\":\"\",\"Fragment\":\"\"}}" timestamp:1581947846738308800 '
Invoking: openfaas-function-cat with 9 bytes, via: http://gateway.openfaas.svc.cluster.local:8080/function/openfaas-function-cat/
Invoked: openfaas-function-cat [200] in 0.029029s
Callback to: http://webhook-service.default.svc.cluster.local:5000
openfaas-function-cat returned 9 bytes
Posted result for openfaas-function-cat to callback-url: http://webhook-service.default.svc.cluster.local:5000, status: 200
</code></pre>

<p>Make 1000 Requests:</p>

<pre><code>$ date &gt; time.date 
  for x in {1..1000}
    do 
      curl -i -H "X-Callback-Url: http://webhook-service.default.svc.cluster.local:5000" http://openfaas.localdns.xyz/async-function/openfaas-function-cat -d "asyyyyync"
    done
  date &gt;&gt; time.date
</code></pre>

<p>View the log file that we wrote before we started and finished our requests:</p>

<pre><code>$ cat time.date
Mon Feb 17 16:03:16 SAST 2020
Mon Feb 17 16:03:48 SAST 2020
</code></pre>

<p>The last request was actioned at:</p>

<pre><code>[2020-02-17 14:03:52,421] INFO in internal: 10.42.0.6 - - [17/Feb/2020 14:03:52] "POST / HTTP/1.1" 200 -
</code></pre>

<h2>Thank You</h2>

<p>This was a basic example to demonstrate async functions using OpenFaas</p>

<h2>OpenFaas Documentation:</h2>

<ul>
<li><a href="https://docs.openfaas.com">https://docs.openfaas.com</a></li>
<li><a href="https://docs.openfaas.com/reference/async/">https://docs.openfaas.com/reference/async/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Traefik Ingress for OpenFaas on Kubernetes (K3d)]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/17/traefik-ingress-for-openfaas-on-kubernetes-k3d/"/>
    <updated>2020-02-17T23:36:33+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/17/traefik-ingress-for-openfaas-on-kubernetes-k3d</id>
    <content type="html"><![CDATA[<p>In this post we will deploy <a href="https://www.openfaas.com/">OpenFaas</a> on Kubernetes locally using <a href="https://github.com/alexellis/k3sup">k3sup</a> and <a href="https://github.com/rancher/k3d">k3d</a>, then deploy a Traefik Ingress so that we can access the OpenFaas Gateway on HTTP over the standard port 80.</p>

<p>K3d is a amazing wrapper that deploys a k3s cluster on docker, and k3sup makes it very easy to provision OpenFaas to your Kubernetes cluster.</p>

<h2>Deploy a Kubernetes Cluster</h2>

<p>If you have not installed k3d, you can install k3d on mac with brew:</p>

<pre><code>$ brew install k3d
</code></pre>

<p>We will deploy our cluster with 2 worker nodes and publish port 80 to the containers port 80:</p>

<pre><code>$ k3d create --name="demo" --workers="2" --publish="80:80"
</code></pre>

<p>Point the kubeconfig to the location that k3d generated:</p>

<pre><code>$ export KUBECONFIG="$(k3d get-kubeconfig --name='demo')"
</code></pre>

<h2>Deploy OpenFaas</h2>

<p>First we need to get k3sup:</p>

<pre><code>$ curl -sLfS https://get.k3sup.dev | sudo sh
</code></pre>

<p>Once k3sup is installed, deploy OpenFaas to your cluster:</p>

<pre><code>$ k3sup app install openfaas
</code></pre>

<p>Give it a minute or so and check if everything is running:</p>

<pre><code>$ kubectl get pods -n openfaas
NAMESPACE     NAME                                 READY   STATUS      RESTARTS   AGE
openfaas      alertmanager-546f66b6c6-qtb69        1/1     Running     0          5m
openfaas      basic-auth-plugin-79b9878b7b-7vlln   1/1     Running     0          4m59s
openfaas      faas-idler-db8cd9c7d-8xfpp           1/1     Running     2          4m57s
openfaas      gateway-7dcc6d694d-dmvqn             2/2     Running     0          4m56s
openfaas      nats-d6d574749-rt9vw                 1/1     Running     0          4m56s
openfaas      prometheus-d99669d9b-mfxc8           1/1     Running     0          4m53s
openfaas      queue-worker-75f44b56b9-mhhbv        1/1     Running     0          4m52s
</code></pre>

<h2>Traefik Ingress</h2>

<p>In my scenario, I am using <code>openfaas.localdns.xyz</code> which resolves to <code>127.0.0.1</code>. Next we need to know to which service to route the traffic to, we can find that by:</p>

<pre><code>$ kubectl get svc/gateway -n openfaas
NAME      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
gateway   ClusterIP   10.43.174.57   &lt;none&gt;        8080/TCP   23m
</code></pre>

<p>Below is our ingress.yml:</p>

<pre><code>apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: openfaas-gateway-ingress
  namespace: openfaas
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: openfaas.localdns.xyz
    http:
      paths:
      - backend:
          serviceName: gateway
          servicePort: 8080
</code></pre>

<p>Apply the ingress:</p>

<pre><code>$ kubectl apply -f ingress.yml
ingress.extensions/openfaas-gateway-ingress created
</code></pre>

<p>We can the verify that our ingress is visible:</p>

<pre><code>$ kubectl get ingress -n openfaas
NAMESPACE   NAME                       HOSTS               ADDRESS      PORTS   AGE
openfaas    openfaas-gateway-ingress   openfaas.co.local   172.25.0.4   80      28s
</code></pre>

<h2>OpenFaas CLI</h2>

<p>Install the OpenFaas CLI:</p>

<pre><code>$ curl -SLsf https://cli.openfaas.com | sudo sh
</code></pre>

<p>Export the <code>OPENFAAS_URL</code> to our ingress endpoint and <code>OPENFAAS_PREFIX</code> for your dockerhub username:</p>

<pre><code>$ export OPENFAAS_URL=http://openfaas.localdns.xyz
$ export OPENFAAS_PREFIX=ruanbekker # change to your username
</code></pre>

<p>Get your credentials for the OpenFaas Gateway and login with the OpenFaas CLI:</p>

<pre><code>$ PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode; echo)
$ echo -n $PASSWORD | faas-cli login --username admin --password-stdin
</code></pre>

<h2>Deploy a Function</h2>

<p>Deploy the figlet function as an example:</p>

<pre><code>$ faas-cli store deploy figlet

Deployed. 202 Accepted.
URL: http://openfaas.localdns.xyz/function/figlet
</code></pre>

<p>Invoke the function:</p>

<pre><code>$ curl http://openfaas.localdns.xyz/function/figlet -d 'hello, world'
 _          _ _                             _     _
| |__   ___| | | ___    __      _____  _ __| | __| |
| '_ \ / _ \ | |/ _ \   \ \ /\ / / _ \| '__| |/ _` |
| | | |  __/ | | (_) |   \ V  V / (_) | |  | | (_| |
|_| |_|\___|_|_|\___( )   \_/\_/ \___/|_|  |_|\__,_|
                    |/
</code></pre>

<h2>Delete the Cluster</h2>

<p>Delete your k3d Kubernetes Cluster:</p>

<pre><code>$ k3d delete --name demo
</code></pre>

<h2>Thank You</h2>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Install OpenFaas on K3d Kubernetes]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/02/12/install-openfaas-on-k3d-kubernetes/"/>
    <updated>2020-02-12T00:57:47+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/02/12/install-openfaas-on-k3d-kubernetes</id>
    <content type="html"><![CDATA[<p>In this post we will deploy i<a href="https://www.openfaas.com">openfaas</a> on kubernetes (<a href="https://github.com/rancher/k3d">k3d</a>)</p>

<h2>Kubernetes on k3d</h2>

<p>k3d is a helper tool that provisions a kubernetes distribution, called k3s on docker. To deploy a kubernetes cluster on k3d, you can follow <a href="https://blog.ruanbekker.com/blog/2020/02/12/lightweight-development-kubernetes-options-k3d/">this blog post</a></p>

<h2>Deploy a 3 Node Kubernetes Cluster</h2>

<p>Using k3d, let&rsquo;s deploy a kubernetes cluster:</p>

<pre><code class="bash">$ k3d create --name="demo" --workers="2" --publish="80:80"
</code></pre>

<p>Export the kubeconfig:</p>

<pre><code class="bash">$ export KUBECONFIG="$(k3d get-kubeconfig --name='demo')"
</code></pre>

<p>Verify that you are able to communicate with your kubernetes cluster:</p>

<pre><code class="bash">$ kubectl get nodes
</code></pre>

<h2>Deploy OpenFaas</h2>

<p>First we need to get <a href="https://k3sup.dev">k3sup</a> :</p>

<pre><code class="bash">$ curl -sLfS https://get.k3sup.dev | sudo sh
</code></pre>

<p>Once k3sup is installed, deploy openfaas to your cluster:</p>

<pre><code class="bash">$ k3sup app install openfaas
</code></pre>

<p>Give it a minute or so and check if everything is running:</p>

<pre><code class="bash">$ kubectl get pods -n openfaas
NAMESPACE     NAME                                 READY   STATUS      RESTARTS   AGE
openfaas      alertmanager-546f66b6c6-qtb69        1/1     Running     0          5m
openfaas      basic-auth-plugin-79b9878b7b-7vlln   1/1     Running     0          4m59s
openfaas      faas-idler-db8cd9c7d-8xfpp           1/1     Running     2          4m57s
openfaas      gateway-7dcc6d694d-dmvqn             2/2     Running     0          4m56s
openfaas      nats-d6d574749-rt9vw                 1/1     Running     0          4m56s
openfaas      prometheus-d99669d9b-mfxc8           1/1     Running     0          4m53s
openfaas      queue-worker-75f44b56b9-mhhbv        1/1     Running     0          4m52s
</code></pre>

<p>Install the openfaas-cli:</p>

<pre><code class="bash">$ curl -SLsf https://cli.openfaas.com | sudo sh
</code></pre>

<p>In a screen session, forward port 8080 to the gateway service:</p>

<pre><code class="bash">$ screen -S portfwd-process -m -d sh -c "kubectl port-forward -n openfaas svc/gateway 8080:8080"
</code></pre>

<p>Expose the gateway password as an environment variable:</p>

<pre><code class="bash">$ PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode; echo)
</code></pre>

<p>Then login to the gateway:</p>

<pre><code class="bash">$ echo -n $PASSWORD | faas-cli login --username admin --password-stdin
</code></pre>

<h2>Deploy a OpenFaas Function</h2>

<p>To list all the functions:</p>

<pre><code class="bash">$ faas-cli store list
</code></pre>

<p>To deploy the figlet function:</p>

<pre><code class="bash">$ faas-cli store deploy figlet

Deployed. 202 Accepted.
URL: http://127.0.0.1:8080/function/figlet
</code></pre>

<p>List your deployed functions:</p>

<pre><code class="bash">$ faas-cli list
Function                        Invocations     Replicas
figlet                          0               1
</code></pre>

<p>Invoke your function:</p>

<pre><code class="bash">$ curl http://127.0.0.1:8080/function/figlet -d 'hello, world'
 _          _ _                             _     _
| |__   ___| | | ___    __      _____  _ __| | __| |
| '_ \ / _ \ | |/ _ \   \ \ /\ / / _ \| '__| |/ _` |
| | | |  __/ | | (_) |   \ V  V / (_) | |  | | (_| |
|_| |_|\___|_|_|\___( )   \_/\_/ \___/|_|  |_|\__,_|
                    |/
</code></pre>

<h2>Delete your Cluster</h2>

<p>When you are done, delete your kubernetes cluster:</p>

<pre><code class="bash">$ k3d delete --name demo
</code></pre>

<h2>Thank You</h2>

<p>Thank you for reading. If you like my content, feel free to visit me at <strong><a href="https://ruan.dev/">ruan.dev</a></strong> or follow me on twitter at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>

<p><a href="https://twitter.com/ruanbekker"><img src="https://user-images.githubusercontent.com/567298/71188576-e2410f80-2289-11ea-8667-08f0c14ab7b5.png" alt="" /></a></p>

<p><a href="https://ko-fi.com/A6423ZIQ"><img src="https://www.ko-fi.com/img/githubbutton_sm.svg" alt="ko-fi" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making Deploying Functions Even Easier With Faas-cli Up Using OpenFaaS]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/07/07/making-deploying-functions-even-easier-with-faas-cli-up-using-openfaas/"/>
    <updated>2019-07-07T03:53:59-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/07/07/making-deploying-functions-even-easier-with-faas-cli-up-using-openfaas</id>
    <content type="html"><![CDATA[<p><img src="https://camo.githubusercontent.com/cf01eefb5b6905f3774376d6d1ed55b8f052d211/68747470733a2f2f626c6f672e616c6578656c6c69732e696f2f636f6e74656e742f696d616765732f323031372f30382f666161735f736964652e706e67" alt="" /></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /> <img src="https://img.shields.io/twitter/follow/ruanbekker.svg?style=social" alt="Twitter Follow" /></p>

<p>I recently discovered that the <code>faas-cli</code> allows you to append your function&rsquo;s yaml to an existing file when generating a new function. And that <code>faas-cli up</code> does the build, push and deploy for you.</p>

<h2>The way I always did it:</h2>

<p>Usually, I will go through this flow: create, build, push, deploy, when creating 2 functions that will be in the same stack:</p>

<pre><code>$ faas-cli new --lang python3 fn-old-foo \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

$ faas-cli build -f fn-old-foo.yml &amp;&amp; \
faas-cli push -f fn-old-foo.yml &amp;&amp; \
faas-cli deploy -f fn-old-foo.yml
</code></pre>

<p>And for my other function:</p>

<pre><code>$ faas-cli new --lang python3 fn-old-bar \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

$ faas-cli build -f fn-old-bar.yml &amp;&amp; \
faas-cli push -f fn-old-bar.yml &amp;&amp; \
faas-cli deploy -f fn-old-bar.yml
</code></pre>

<p>And then you are ready to invoke those functions.</p>

<h2>The new discovered way</h2>

<p>So recently I discovered that you can append the yaml definition of your function to an existing yaml file, and use <code>faas-cli up</code> to build, push and deploy your functions:</p>

<p>Generating the first function:</p>

<pre><code>$ faas-cli new --lang python3 fn-foo \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

Stack file written: fn-foo.yml
</code></pre>

<p>Now that we have <code>fn-foo.yml</code> in our current work directory, we will append the second function the that file:</p>

<pre><code>$ faas-cli new --lang python3 fn-bar \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com \
--append fn-foo.yml

Stack file updated: fn-foo.yml
</code></pre>

<p>Now, when using <code>faas-cli up</code> it expects by default that the filename is <code>stack.yml</code> which we can change with <code>-f</code> but to keep this as easy as possible, we will change the filename to <code>stack.yml</code>:</p>

<pre><code>$ mv fn-foo.yml stack.yml
</code></pre>

<p>At the moment, our <code>stack.yml</code> will look like this:</p>

<pre><code>$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-foo:
    lang: python3
    handler: ./fn-foo
    image: ruanbekker/fn-foo:latest
  fn-bar:
    lang: python3
    handler: ./fn-bar
    image: ruanbekker/fn-bar:latest
</code></pre>

<p>Deploying our functions is as easy as:</p>

<pre><code>$ faas-cli up
...
Deploying: fn-foo.

Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-foo

Deploying: fn-bar.

Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-bar
</code></pre>

<p>Simply amazing. OpenFaaS done a great job in making it as simple and easy as possible to get your functions from zero to deployed in seconds.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using OpenFaas With Amazon DynamoDB]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/07/06/using-openfaas-with-amazon-dynamodb/"/>
    <updated>2019-07-06T19:11:23-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/07/06/using-openfaas-with-amazon-dynamodb</id>
    <content type="html"><![CDATA[<p><img width="1105" alt="image" src="https://user-images.githubusercontent.com/567298/60761941-f4205480-a053-11e9-9ad5-9e45948c9833.png"></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /> <img src="https://img.shields.io/twitter/follow/ruanbekker.svg?style=social" alt="Twitter Follow" /></p>

<h1>Using OpenFaaS with Amazon DynamoDB</h1>

<p>You can use your OpenFaaS functions to store and retrieve data to and from a persistent layer that sits outside the OpenFaaS framework. The database that we will use in this tutorial is Amazon&rsquo;s DynamoDB.</p>

<p>If you are not familiar with the service, Amazon&rsquo;s DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.</p>

<p>At the end of this tutorial you will be able to invoke your functions to read and write items to DynamoDB with a dedicated IAM User that is only allowed to access DynamoDB, and secrets managed by your OpenFaaS framework.</p>

<h2>What we will be doing in this Tutorial</h2>

<p>In this tutorial we will cover a couple of things, and a summary on the to do list is:</p>

<ul>
<li>Create a OpenFaaS IAM User, DynamoDB IAM Policy, associate the Policy to the User using the AWS CLI</li>
<li>Create a AWS Access Key, and save the Access Key and Secret key to file</li>
<li>Create OpenFaaS Secrets of the Access Key and Secret Key, remove the files from disk</li>
<li>Create 3 OpenFaaS Functions: write, lookup and get</li>
<li>Invoke the functions, read and write from DynamoDB</li>
</ul>


<p>Our 3 functions will do very basic operations for this demonstration, but I believe this is a good starting point.</p>

<p>All the examples of this blog post is available in <a href="https://github.com/ruanbekker/blog-assets/tree/master/openfaas-dynamodb">this github repository</a></p>

<h2>The Use-Case Scenario</h2>

<p>In this scenario we want to store user information into DynamoDB, we will use a hash that we will calculate using the users ID Number + Lastname. So when we have thousands or millions of items, we dont need to search through the entire table, but since we can re-calculate the sha hash, we can do a single GetItem operation to find the entry about the user in question.</p>

<ul>
<li>Lookup Function:</li>
</ul>


<p>The lookup function will calculate the hash by passing the users ID Number and Lastname, this will return a hash which will be teh primary key attribute of our table design. This hash value is required to do a GetItem on the user in question.</p>

<ul>
<li>Get Function:</li>
</ul>


<p>The Get function will interface with DynamoDB, it reads the AWS access key and secret key from the secrets path to authenticate with AWS and utilizes environment variables for the region and table name. This will do a GetItem on the DynamoDB Table and retrieve the Item. If the item is not found, it will return it in the response.</p>

<ul>
<li>Write Function:</li>
</ul>


<p>The write function will also interface with DynamoDB, the ID, Name and Payload will be included in the request body on our POST Request.</p>

<h2>Note on Secrets and Environment Variables</h2>

<p>I am treating my environment variables and secrets different from each other. The secrets such as my AWS access keys are stored on the cluster and the application reads them and stores the values in memory.</p>

<p>The environment variables such as non-secret information, such as my dynamodb table name and aws region, is defined in my environment variables.</p>

<p>This <a href="http://movingfast.io/articles/environment-variables-considered-harmful/">post</a> and this <a href="https://diogomonica.com/2017/03/27/why-you-shouldnt-use-env-variables-for-secret-data/">post</a> goes a bit more into detail on why you should not use environment variables for secret data, which I found from <a href="https://github.com/openfaas/faas-netes/issues/153#issuecomment-370924478">this link</a></p>

<p>Enough info, let&rsquo;s get to the fun stuff</p>

<h2>Pre-Requirements:</h2>

<p>You need a AWS Account (or you can use dynamodb-local), OpenFaaS and faas-cli. Documentation available below:
- <a href="https://docs.openfaas.com/contributing/get-started/">https://docs.openfaas.com/contributing/get-started/</a></p>

<h2>Provision a DynamoDB Table</h2>

<p>I have a admin IAM account configured on my default profile, using the aws-cli tools generate the cli-skeleton that is required to provision a dynamodb table:</p>

<pre><code class="bash">$ aws dynamodb create-table --generate-cli-skeleton &gt; ddb.json
</code></pre>

<p>My table name will be <code>lookup-table</code> with the primary key <code>hash_value</code> and provisoned my throughput to 1 Read and Write Capacity Unit. Which will enable us 4KB/s for reads and 1KB/s for writes.</p>

<p>For demonstration purposes, I am sharing my altered <code>ddb.json</code> file:</p>

<pre><code class="json">{
    "AttributeDefinitions": [
        {
            "AttributeName": "hash_value",
            "AttributeType": "S"
        }
    ],
    "TableName": "lookup_table",
    "KeySchema": [
        {
            "AttributeName": "hash_value",
            "KeyType": "HASH"
        }
    ],
    "ProvisionedThroughput": {
        "ReadCapacityUnits": 1,
        "WriteCapacityUnits": 1
    },
    "Tags": [
        {
            "Key": "Name",
            "Value": "lookup-table"
        }
    ]
}
</code></pre>

<p>Now that we have the file saved, create the dynamodb table:</p>

<pre><code class="bash">$ aws dynamodb create-table --cli-input-json file://ddb.json
</code></pre>

<p>List the tables:</p>

<pre><code class="bash">$ aws dynamodb list-tables
{
    "TableNames": [
        "lookup_table"
    ]
}
</code></pre>

<p>Check if the table is provisioned:</p>

<pre><code class="bash">$ aws dynamodb describe-table --table-name lookup_table | jq -r '.Table.TableStatus'
ACTIVE
</code></pre>

<p>Getting the ARN string, as we will need it when we create our IAM Policy:</p>

<pre><code class="bash">$ aws dynamodb describe-table --table-name lookup_table | jq -r '.Table.TableArn'
arn:aws:dynamodb:eu-west-1:x-x:table/lookup_table
</code></pre>

<h2>Create the OpenFaaS IAM User</h2>

<p>Create the IAM Policy document which defines the access that we want to grant. You can see that we are only allowing Put and GetItem on the provisioned DynamoDB resource:</p>

<pre><code class="bash">$ cat dynamodb-iam-policy.json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "OpenFaasFunctionAceessForDynamoDB",
            "Effect": "Allow",
            "Action": [
                "dynamodb:PutItem",
                "dynamodb:GetItem"
            ],
            "Resource": "arn:aws:dynamodb:eu-west-1:x-accountid-x:table/lookup_table"
        }
    ]
}
</code></pre>

<p>Create the IAM Policy and provide the policy document for the given policy name:</p>

<pre><code class="bash">$ aws iam create-policy --policy-name openfaas-dynamodb-access --policy-document file://dynamodb-iam-policy.json
{
    "Policy": {
        "PolicyName": "openfaas-dynamodb-access",
        "PolicyId": "ANPATPRT2G4SL4K63SUWQ",
        "Arn": "arn:aws:iam::x-accountid-x:policy/openfaas-dynamodb-access",
        "Path": "/",
        "DefaultVersionId": "v1",
        "AttachmentCount": 0,
        "PermissionsBoundaryUsageCount": 0,
        "IsAttachable": true,
        "CreateDate": "2019-07-06T11:54:26Z",
        "UpdateDate": "2019-07-06T11:54:26Z"
    }
}
</code></pre>

<p>Create the IAM User that will be used to authenticate requests against DynamoDB:</p>

<pre><code class="bash">$ aws iam create-user --user-name openfaas-user
{
    "User": {
        "Path": "/",
        "UserName": "openfaas-user",
        "UserId": "AIDATPRT2G4SIRYTNHLZK",
        "Arn": "arn:aws:iam::x-accountid-x:user/openfaas-user",
        "CreateDate": "2019-07-06T11:56:53Z"
    }
}
</code></pre>

<p>Create the Access Key, which will be our API keys for our application to authenticate requests. Save the AccessKeyId and SecretAccessKey temporarily to 2 seperate files, which we will delete after we create our secrets to our cluster:</p>

<pre><code class="bash">$ aws iam create-access-key --user-name openfaas-user
{
    "AccessKey": {
        "UserName": "openfaas-user",
        "AccessKeyId": "AKIAT..redacted.x",
        "Status": "Active",
        "SecretAccessKey": "b..redacted.x",
        "CreateDate": "2019-07-06T11:57:37Z"
    }
}
</code></pre>

<p>Associate the IAM Policy to the IAM User:</p>

<pre><code class="bash">$ aws iam attach-user-policy --user-name openfaas-user --policy-arn arn:aws:iam::x-x:policy/openfaas-dynamodb-access
</code></pre>

<p>To test if the access keys work, save them to a new profile using the aws-cli tools:</p>

<pre><code class="bash">$ aws configure --profile openfaas
AWS Access Key ID [None]: AKIAT..
AWS Secret Access Key [None]: b..x
Default region name [None]: eu-west-1
Default output format [None]: json
</code></pre>

<p>Write an Item to DynamoDB:</p>

<pre><code class="bash">$ aws --profile openfaas dynamodb put-item \
--table-name lookup_table \
--item '{"hash_value": {"S": "aGVsbG8td29ybGQK"}, "message": {"S": "hello-world"}}'
</code></pre>

<p>Read the Item from DynamoDB:</p>

<pre><code class="bash">$ aws --profile openfaas dynamodb get-item \
--table-name lookup_table \
--key '{"hash_value": {"S": "aGVsbG8td29ybGQK"}}'
{
    "Item": {
        "hash_value": {
            "S": "aGVsbG8td29ybGQK"
        },
        "message": {
            "S": "hello-world"
        }
    }
}
</code></pre>

<p>We can now confirm our permissions are in place to continue.</p>

<h3>Create OpenFaaS Secrets</h3>

<p>The AccessKeyId and SecretKey has been saved to disk, and we will use those files to create secrets from:</p>

<pre><code class="bash">$ faas-cli secret create openfaas-aws-access-key --from-file=openfaas_aws_access_key.txt
Creating secret: openfaas-aws-access-key
Created: 201 Created
</code></pre>

<pre><code class="bash">$ faas-cli secret create openfaas-aws-secret-key --from-file=openfaas_aws_secret_key.txt
Creating secret: openfaas-aws-secret-key
Created: 201 Created
</code></pre>

<p>Now that the secrets are securely stored in our cluster, we can delete the temporary files:</p>

<pre><code>$ rm -f ./openfaas_aws_*_key.txt
</code></pre>

<h2>Login to OpenFaaS</h2>

<p>Login to OpenFaasS using faas-cli:</p>

<pre><code class="bash">$ faas-cli login \
--gateway https://openfaas.domain.com \
--username ${OPENFAAS_USER} \
--password ${OPENFAAS_PASSWORD}
</code></pre>

<p>Export the OPENFAAS_URL:</p>

<pre><code class="bash">$ export OPENFAAS_URL=https://openfaas.domain.com
</code></pre>

<h2>One Stack File for All 3 Functions:</h2>

<p>We will create our first function to generate the yaml definition, then we will rename our generated filename to <code>stack.yml</code> then the next 2 functions, we will use the append flag to append the functions yaml to our <code>stack.yml</code> file, so that we can simply use <code>faas-cli up</code></p>

<h2>Create the Lookup Function:</h2>

<p>Create a Python3 Function, and prefix it with your dockerhub user:</p>

<pre><code class="bash">$ faas-cli new \
--lang python3 fn-dynamodb-lookup \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

Function created in folder: fn-foo
Stack file written: fn-dynamodb-lookup.yml
</code></pre>

<p>As we will be using one stack file, rename the generated stack file:</p>

<pre><code class="bash">$ mv fn-dynamodb-lookup.yml stack.yml
</code></pre>

<p>Open the stack file and set the environment variables:</p>

<pre><code class="bash">$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-dynamodb-lookup:
    lang: python3
    handler: ./fn-dynamodb-lookup
    image: ruanbekker/fn-dynamodb-lookup:latest
    environment:
      dynamodb_region: eu-west-1
      dynamodb_table: lookup_table
</code></pre>

<p>The python code for our function:</p>

<pre><code class="bash">$ cat fn-dynamodb-lookup/handler.py
</code></pre>

<pre><code class="python">import json
import hashlib

def calc_sha(id_number, lastname):
    string = json.dumps({"id": id_number, "lastname": lastname}, sort_keys=True)
    hash_value = hashlib.sha1(string.encode("utf-8")).hexdigest()
    return hash_value

def handle(req):
    event = json.loads(req)
    hash_value = calc_sha(event['id'], event['lastname'])
    return hash_value
</code></pre>

<h2>Create the Write Function:</h2>

<p>Create a Python3 Function, and prefix it with your dockerhub user, and use the append flag to update our stack file:</p>

<pre><code class="bash">$ faas-cli new \
--lang python3 fn-dynamodb-write \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com
--append stack.yml

Function created in folder: fn-dynamodb-write
Stack file updated: stack.yml
</code></pre>

<p>Open the stack file and set the environment variables and include the secrets that was created:</p>

<pre><code class="bash">$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-dynamodb-lookup:
  # ...
  fn-dynamodb-write:
    lang: python3
    handler: ./fn-dynamodb-write
    image: ruanbekker/fn-dynamodb-write:latest
    environment:
      dynamodb_region: eu-west-1
      dynamodb_table: lookup_table
    secrets:
      - openfaas-aws-access-key
      - openfaas-aws-secret-key
</code></pre>

<p>Our function relies on a external dependency which we need to install to interact with aws:</p>

<pre><code class="bash">$ cat fn-dynamodb-write/requirements.txt
boto3
</code></pre>

<p>Our python code for our function:</p>

<pre><code class="bash">$ cat fn-dynamodb-write/handler.py
</code></pre>

<pre><code class="python">import boto3
import os
import json
import hashlib
import datetime

aws_key = open('/var/openfaas/secrets/openfaas-aws-access-key', 'r').read()
aws_secret = open('/var/openfaas/secrets/openfaas-aws-secret-key', 'r').read()
dynamodb_region = os.environ['dynamodb_region']
dynamodb_table  = os.environ['dynamodb_table']

client = boto3.Session(region_name=dynamodb_region).resource('dynamodb', aws_access_key_id=aws_key, aws_secret_access_key=aws_secret)
table = client.Table(dynamodb_table)

def calc_sha(id_number, lastname):
    string = json.dumps({"id": id_number, "lastname": lastname}, sort_keys=True)
    hash_value = hashlib.sha1(string.encode("utf-8")).hexdigest()
    return hash_value

def create_timestamp():
    response = datetime.datetime.now().strftime("%Y-%m-%dT%H:%M")
    return response

def handle(req):
    event = json.loads(req)
    unique_id = calc_sha(event['id'], event['lastname'])
    response = table.put_item(
        Item={
            'hash_value': unique_id,
            'timestamp': create_timestamp(),
            'payload': event['payload']
        }
    )
    return response
</code></pre>

<h2>Create the Get Function:</h2>

<p>Create a Python3 Function, and prefix it with your dockerhub user, and use the append flag to specify the stack file:</p>

<pre><code class="bash">$ faas-cli new \
--lang python3 fn-dynamodb-get \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com
--append stack.yml

Function created in folder: fn-dynamodb-get
Stack file updated: stack.yml
</code></pre>

<p>Open the stack file and set the environment variables and include the secrets that was created:</p>

<pre><code class="bash">$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-dynamodb-lookup:
  # .. 
  fn-dynamodb-write:
  # ..
  fn-dynamodb-get:
    lang: python3
    handler: ./fn-dynamodb-get
    image: ruanbekker/fn-dynamodb-get:latest
    environment:
      dynamodb_region: eu-west-1
      dynamodb_table: lookup_table
    secrets:
      - openfaas-aws-access-key
      - openfaas-aws-secret-key
</code></pre>

<p>Include the external dependency for aws:</p>

<pre><code class="bash">$ cat fn-dynamodb-get/requirements.txt
boto3
</code></pre>

<p>Our python code for our function:</p>

<pre><code class="bash">$ cat fn-dynamodb-get/handler.py
</code></pre>

<pre><code class="python">import boto3
import os
import json

aws_key = open('/var/openfaas/secrets/openfaas-aws-access-key', 'r').read()
aws_secret = open('/var/openfaas/secrets/openfaas-aws-secret-key', 'r').read()
dynamodb_region = os.environ['dynamodb_region']
dynamodb_table  = os.environ['dynamodb_table']

client = boto3.Session(region_name=dynamodb_region).resource('dynamodb', aws_access_key_id=aws_key, aws_secret_access_key=aws_secret)
table = client.Table(dynamodb_table)

def handle(req):
    event = json.loads(req)
    response = table.get_item(
        Key={
            'hash_value': event['hash_value']
        }
    )

    if 'Item' not in response:
        item_data = 'Item not found'
    else:
        item_data = response['Item']

    return item_data
</code></pre>

<h2>Build, Push and Deploy:</h2>

<p>It&rsquo;s time to deploy our functions and since we have all our stack info in one file, we can use <code>faas-cli up</code> which will build, push and deploy our functions.</p>

<p>By default it expects the filename to be <code>stack.yml</code> therefore we don&rsquo;t need to specify the filename, but if you had a different filename, you can overwrite the default behaviour with <code>-f</code>:</p>

<pre><code class="bash">$ faas-cli up

Deploying: fn-dynamodb-lookup.
Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-dynamodb-lookup

Deploying: fn-dynamodb-write.
Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-dynamodb-write

Deploying: fn-dynamodb-get.
Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-dynamodb-get
</code></pre>

<h2>Time for our Functions to interact with DynamoDB:</h2>

<p>Write an Item to DynamoDB:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-write -d '{"id": 8700000000001, "lastname": "smith", "payload": {"name": "james", "role": "reader"}}'
{'ResponseMetadata': {'RequestId': 'CNHEFHMSL4KGRDE0HRVQ69D5H7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'Server', 'date': 'Sat, 06 Jul 2019 20:47:00 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': 'CNHEFHMSL4KGRDE0HRVQ69D5H7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'x-amz-crc32': '2745614147'}, 'RetryAttempts': 0}}
</code></pre>

<p>Write another Item to DynamoDB:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.doamin.com/function/fn-dynamodb-write -d '{"id": 8700000000002, "lastname": "adams", "payload": {"name": "samantha", "role": "admin"}}'
{'ResponseMetadata': {'RequestId': 'KRQL838BVGC9LIUSCOUB7MOEQ7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'Server', 'date': 'Sat, 06 Jul 2019 20:48:09 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': 'KRQL838BVGC9LIUSCOUB7MOEQ7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'x-amz-crc32': '2745614147'}, 'RetryAttempts': 0}}
</code></pre>

<p>Now recalculate the hash by passing the ID Number and Lastname to get the hash value for the primary key:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-lookup -d '{"id": 8700000000002, "lastname": "adams"}'
bd0a248aff2b50b288ba504bd7142ef11b164901
</code></pre>

<p>Now that we have the hash value, do a GetItem by using the hash value in the request body:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-get -d '{"hash_value": "bd0a248aff2b50b288ba504bd7142ef11b164901"}'
{'payload': {'name': 'samantha', 'role': 'admin'}, 'hash_value': 'bd0a248aff2b50b288ba504bd7142ef11b164901', 'timestamp': '2019-07-06T20:48'}
</code></pre>

<p>Note that the lookup function calculates a hash based on the input that you provide it, for example calculating a hash with userdata that does not exist in our table:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-lookup -d '{"id": 8700000000003, "lastname": "williams"}'
c68dc272873140f4ae93bb3a3317772a6bdd9aa1
</code></pre>

<p>Using that hash value in our request body to read from dynamodb, will show us that the item has not been found:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-get -d '{"hash_value": "c68dc272873140f4ae93bb3a3317772a6bdd9aa1"}'
Item not found
</code></pre>

<p>You might want to change this behavior but this is just for the demonstration of this post.</p>

<p>When you head over to DynamoDB&rsquo;s console you will see this in your table:</p>

<p><img width="873" alt="image" src="https://user-images.githubusercontent.com/567298/60761025-9e8e7c80-a040-11e9-83a3-ad5b474a28ff.png"></p>

<h2>Thanks</h2>

<p>This was a basic example using OpenFaaS with Amazon DynamoDB with Python and secrets managed with OpenFaas. I really like the way OpenFaaS let&rsquo;s you work with secrets, it works great and don&rsquo;t need an additional resource to manage your sensitive data.</p>

<p>Although this was basic usage with OpenFaaS and DynamoDB, the sky is the limit what you can do with it.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/">DynamoDB: Choosing the right Partition Key</a></li>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html">Designing Partition Keys to Distribute Your Workload Evenly</a></li>
<li><a href="https://docs.openfaas.com/contributing/get-started/">OpenFaaS: Getting Started</a></li>
<li><a href="https://docs.openfaas.com/reference/secrets/">OpenFaaS: Secrets</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
