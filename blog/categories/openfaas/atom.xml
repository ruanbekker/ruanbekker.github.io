<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Openfaas | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/openfaas/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2020-01-24T19:34:07+02:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Making Deploying Functions Even Easier With Faas-cli Up Using OpenFaaS]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/07/07/making-deploying-functions-even-easier-with-faas-cli-up-using-openfaas/"/>
    <updated>2019-07-07T09:53:59+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/07/07/making-deploying-functions-even-easier-with-faas-cli-up-using-openfaas</id>
    <content type="html"><![CDATA[<p><img src="https://camo.githubusercontent.com/cf01eefb5b6905f3774376d6d1ed55b8f052d211/68747470733a2f2f626c6f672e616c6578656c6c69732e696f2f636f6e74656e742f696d616765732f323031372f30382f666161735f736964652e706e67" alt="" /></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /> <img src="https://img.shields.io/twitter/follow/ruanbekker.svg?style=social" alt="Twitter Follow" /></p>

<p>I recently discovered that the <code>faas-cli</code> allows you to append your function&rsquo;s yaml to an existing file when generating a new function. And that <code>faas-cli up</code> does the build, push and deploy for you.</p>

<h2>The way I always did it:</h2>

<p>Usually, I will go through this flow: create, build, push, deploy, when creating 2 functions that will be in the same stack:</p>

<pre><code>$ faas-cli new --lang python3 fn-old-foo \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

$ faas-cli build -f fn-old-foo.yml &amp;&amp; \
faas-cli push -f fn-old-foo.yml &amp;&amp; \
faas-cli deploy -f fn-old-foo.yml
</code></pre>

<p>And for my other function:</p>

<pre><code>$ faas-cli new --lang python3 fn-old-bar \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

$ faas-cli build -f fn-old-bar.yml &amp;&amp; \
faas-cli push -f fn-old-bar.yml &amp;&amp; \
faas-cli deploy -f fn-old-bar.yml
</code></pre>

<p>And then you are ready to invoke those functions.</p>

<h2>The new discovered way</h2>

<p>So recently I discovered that you can append the yaml definition of your function to an existing yaml file, and use <code>faas-cli up</code> to build, push and deploy your functions:</p>

<p>Generating the first function:</p>

<pre><code>$ faas-cli new --lang python3 fn-foo \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

Stack file written: fn-foo.yml
</code></pre>

<p>Now that we have <code>fn-foo.yml</code> in our current work directory, we will append the second function the that file:</p>

<pre><code>$ faas-cli new --lang python3 fn-bar \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com \
--append fn-foo.yml

Stack file updated: fn-foo.yml
</code></pre>

<p>Now, when using <code>faas-cli up</code> it expects by default that the filename is <code>stack.yml</code> which we can change with <code>-f</code> but to keep this as easy as possible, we will change the filename to <code>stack.yml</code>:</p>

<pre><code>$ mv fn-foo.yml stack.yml
</code></pre>

<p>At the moment, our <code>stack.yml</code> will look like this:</p>

<pre><code>$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-foo:
    lang: python3
    handler: ./fn-foo
    image: ruanbekker/fn-foo:latest
  fn-bar:
    lang: python3
    handler: ./fn-bar
    image: ruanbekker/fn-bar:latest
</code></pre>

<p>Deploying our functions is as easy as:</p>

<pre><code>$ faas-cli up
...
Deploying: fn-foo.

Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-foo

Deploying: fn-bar.

Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-bar
</code></pre>

<p>Simply amazing. OpenFaaS done a great job in making it as simple and easy as possible to get your functions from zero to deployed in seconds.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using OpenFaas With Amazon DynamoDB]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/07/07/using-openfaas-with-amazon-dynamodb/"/>
    <updated>2019-07-07T01:11:23+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/07/07/using-openfaas-with-amazon-dynamodb</id>
    <content type="html"><![CDATA[<p><img width="1105" alt="image" src="https://user-images.githubusercontent.com/567298/60761941-f4205480-a053-11e9-9ad5-9e45948c9833.png"></p>

<p><a href="https://saythanks.io/to/ruanbekker"><img src="https://img.shields.io/badge/Say%20Thanks-!-1EAEDB.svg" alt="Say Thanks!" /></a> <a href="https://linux-hackers-slack.herokuapp.com/"><img src="https://linux-hackers-slack.herokuapp.com/badge.svg" alt="Slack Status" /></a> <a href="https://linux-hackers.slack.com/"><img src="https://img.shields.io/badge/chat-on_slack-orange.svg" alt="Chat on Slack" /></a> <img src="https://img.shields.io/github/followers/ruanbekker.svg?label=Follow&amp;style=social" alt="GitHub followers" /> <img src="https://img.shields.io/twitter/follow/ruanbekker.svg?style=social" alt="Twitter Follow" /></p>

<h1>Using OpenFaaS with Amazon DynamoDB</h1>

<p>You can use your OpenFaaS functions to store and retrieve data to and from a persistent layer that sits outside the OpenFaaS framework. The database that we will use in this tutorial is Amazon&rsquo;s DynamoDB.</p>

<p>If you are not familiar with the service, Amazon&rsquo;s DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.</p>

<p>At the end of this tutorial you will be able to invoke your functions to read and write items to DynamoDB with a dedicated IAM User that is only allowed to access DynamoDB, and secrets managed by your OpenFaaS framework.</p>

<h2>What we will be doing in this Tutorial</h2>

<p>In this tutorial we will cover a couple of things, and a summary on the to do list is:</p>

<ul>
<li>Create a OpenFaaS IAM User, DynamoDB IAM Policy, associate the Policy to the User using the AWS CLI</li>
<li>Create a AWS Access Key, and save the Access Key and Secret key to file</li>
<li>Create OpenFaaS Secrets of the Access Key and Secret Key, remove the files from disk</li>
<li>Create 3 OpenFaaS Functions: write, lookup and get</li>
<li>Invoke the functions, read and write from DynamoDB</li>
</ul>


<p>Our 3 functions will do very basic operations for this demonstration, but I believe this is a good starting point.</p>

<p>All the examples of this blog post is available in <a href="https://github.com/ruanbekker/blog-assets/tree/master/openfaas-dynamodb">this github repository</a></p>

<h2>The Use-Case Scenario</h2>

<p>In this scenario we want to store user information into DynamoDB, we will use a hash that we will calculate using the users ID Number + Lastname. So when we have thousands or millions of items, we dont need to search through the entire table, but since we can re-calculate the sha hash, we can do a single GetItem operation to find the entry about the user in question.</p>

<ul>
<li>Lookup Function:</li>
</ul>


<p>The lookup function will calculate the hash by passing the users ID Number and Lastname, this will return a hash which will be teh primary key attribute of our table design. This hash value is required to do a GetItem on the user in question.</p>

<ul>
<li>Get Function:</li>
</ul>


<p>The Get function will interface with DynamoDB, it reads the AWS access key and secret key from the secrets path to authenticate with AWS and utilizes environment variables for the region and table name. This will do a GetItem on the DynamoDB Table and retrieve the Item. If the item is not found, it will return it in the response.</p>

<ul>
<li>Write Function:</li>
</ul>


<p>The write function will also interface with DynamoDB, the ID, Name and Payload will be included in the request body on our POST Request.</p>

<h2>Note on Secrets and Environment Variables</h2>

<p>I am treating my environment variables and secrets different from each other. The secrets such as my AWS access keys are stored on the cluster and the application reads them and stores the values in memory.</p>

<p>The environment variables such as non-secret information, such as my dynamodb table name and aws region, is defined in my environment variables.</p>

<p>This <a href="http://movingfast.io/articles/environment-variables-considered-harmful/">post</a> and this <a href="https://diogomonica.com/2017/03/27/why-you-shouldnt-use-env-variables-for-secret-data/">post</a> goes a bit more into detail on why you should not use environment variables for secret data, which I found from <a href="https://github.com/openfaas/faas-netes/issues/153#issuecomment-370924478">this link</a></p>

<p>Enough info, let&rsquo;s get to the fun stuff</p>

<h2>Pre-Requirements:</h2>

<p>You need a AWS Account (or you can use dynamodb-local), OpenFaaS and faas-cli. Documentation available below:
- <a href="https://docs.openfaas.com/contributing/get-started/">https://docs.openfaas.com/contributing/get-started/</a></p>

<h2>Provision a DynamoDB Table</h2>

<p>I have a admin IAM account configured on my default profile, using the aws-cli tools generate the cli-skeleton that is required to provision a dynamodb table:</p>

<pre><code class="bash">$ aws dynamodb create-table --generate-cli-skeleton &gt; ddb.json
</code></pre>

<p>My table name will be <code>lookup-table</code> with the primary key <code>hash_value</code> and provisoned my throughput to 1 Read and Write Capacity Unit. Which will enable us 4KB/s for reads and 1KB/s for writes.</p>

<p>For demonstration purposes, I am sharing my altered <code>ddb.json</code> file:</p>

<pre><code class="json">{
    "AttributeDefinitions": [
        {
            "AttributeName": "hash_value",
            "AttributeType": "S"
        }
    ],
    "TableName": "lookup_table",
    "KeySchema": [
        {
            "AttributeName": "hash_value",
            "KeyType": "HASH"
        }
    ],
    "ProvisionedThroughput": {
        "ReadCapacityUnits": 1,
        "WriteCapacityUnits": 1
    },
    "Tags": [
        {
            "Key": "Name",
            "Value": "lookup-table"
        }
    ]
}
</code></pre>

<p>Now that we have the file saved, create the dynamodb table:</p>

<pre><code class="bash">$ aws dynamodb create-table --cli-input-json file://ddb.json
</code></pre>

<p>List the tables:</p>

<pre><code class="bash">$ aws dynamodb list-tables
{
    "TableNames": [
        "lookup_table"
    ]
}
</code></pre>

<p>Check if the table is provisioned:</p>

<pre><code class="bash">$ aws dynamodb describe-table --table-name lookup_table | jq -r '.Table.TableStatus'
ACTIVE
</code></pre>

<p>Getting the ARN string, as we will need it when we create our IAM Policy:</p>

<pre><code class="bash">$ aws dynamodb describe-table --table-name lookup_table | jq -r '.Table.TableArn'
arn:aws:dynamodb:eu-west-1:x-x:table/lookup_table
</code></pre>

<h2>Create the OpenFaaS IAM User</h2>

<p>Create the IAM Policy document which defines the access that we want to grant. You can see that we are only allowing Put and GetItem on the provisioned DynamoDB resource:</p>

<pre><code class="bash">$ cat dynamodb-iam-policy.json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "OpenFaasFunctionAceessForDynamoDB",
            "Effect": "Allow",
            "Action": [
                "dynamodb:PutItem",
                "dynamodb:GetItem"
            ],
            "Resource": "arn:aws:dynamodb:eu-west-1:x-accountid-x:table/lookup_table"
        }
    ]
}
</code></pre>

<p>Create the IAM Policy and provide the policy document for the given policy name:</p>

<pre><code class="bash">$ aws iam create-policy --policy-name openfaas-dynamodb-access --policy-document file://dynamodb-iam-policy.json
{
    "Policy": {
        "PolicyName": "openfaas-dynamodb-access",
        "PolicyId": "ANPATPRT2G4SL4K63SUWQ",
        "Arn": "arn:aws:iam::x-accountid-x:policy/openfaas-dynamodb-access",
        "Path": "/",
        "DefaultVersionId": "v1",
        "AttachmentCount": 0,
        "PermissionsBoundaryUsageCount": 0,
        "IsAttachable": true,
        "CreateDate": "2019-07-06T11:54:26Z",
        "UpdateDate": "2019-07-06T11:54:26Z"
    }
}
</code></pre>

<p>Create the IAM User that will be used to authenticate requests against DynamoDB:</p>

<pre><code class="bash">$ aws iam create-user --user-name openfaas-user
{
    "User": {
        "Path": "/",
        "UserName": "openfaas-user",
        "UserId": "AIDATPRT2G4SIRYTNHLZK",
        "Arn": "arn:aws:iam::x-accountid-x:user/openfaas-user",
        "CreateDate": "2019-07-06T11:56:53Z"
    }
}
</code></pre>

<p>Create the Access Key, which will be our API keys for our application to authenticate requests. Save the AccessKeyId and SecretAccessKey temporarily to 2 seperate files, which we will delete after we create our secrets to our cluster:</p>

<pre><code class="bash">$ aws iam create-access-key --user-name openfaas-user
{
    "AccessKey": {
        "UserName": "openfaas-user",
        "AccessKeyId": "AKIAT..redacted.x",
        "Status": "Active",
        "SecretAccessKey": "b..redacted.x",
        "CreateDate": "2019-07-06T11:57:37Z"
    }
}
</code></pre>

<p>Associate the IAM Policy to the IAM User:</p>

<pre><code class="bash">$ aws iam attach-user-policy --user-name openfaas-user --policy-arn arn:aws:iam::x-x:policy/openfaas-dynamodb-access
</code></pre>

<p>To test if the access keys work, save them to a new profile using the aws-cli tools:</p>

<pre><code class="bash">$ aws configure --profile openfaas
AWS Access Key ID [None]: AKIAT..
AWS Secret Access Key [None]: b..x
Default region name [None]: eu-west-1
Default output format [None]: json
</code></pre>

<p>Write an Item to DynamoDB:</p>

<pre><code class="bash">$ aws --profile openfaas dynamodb put-item \
--table-name lookup_table \
--item '{"hash_value": {"S": "aGVsbG8td29ybGQK"}, "message": {"S": "hello-world"}}'
</code></pre>

<p>Read the Item from DynamoDB:</p>

<pre><code class="bash">$ aws --profile openfaas dynamodb get-item \
--table-name lookup_table \
--key '{"hash_value": {"S": "aGVsbG8td29ybGQK"}}'
{
    "Item": {
        "hash_value": {
            "S": "aGVsbG8td29ybGQK"
        },
        "message": {
            "S": "hello-world"
        }
    }
}
</code></pre>

<p>We can now confirm our permissions are in place to continue.</p>

<h3>Create OpenFaaS Secrets</h3>

<p>The AccessKeyId and SecretKey has been saved to disk, and we will use those files to create secrets from:</p>

<pre><code class="bash">$ faas-cli secret create openfaas-aws-access-key --from-file=openfaas_aws_access_key.txt
Creating secret: openfaas-aws-access-key
Created: 201 Created
</code></pre>

<pre><code class="bash">$ faas-cli secret create openfaas-aws-secret-key --from-file=openfaas_aws_secret_key.txt
Creating secret: openfaas-aws-secret-key
Created: 201 Created
</code></pre>

<p>Now that the secrets are securely stored in our cluster, we can delete the temporary files:</p>

<pre><code>$ rm -f ./openfaas_aws_*_key.txt
</code></pre>

<h2>Login to OpenFaaS</h2>

<p>Login to OpenFaasS using faas-cli:</p>

<pre><code class="bash">$ faas-cli login \
--gateway https://openfaas.domain.com \
--username ${OPENFAAS_USER} \
--password ${OPENFAAS_PASSWORD}
</code></pre>

<p>Export the OPENFAAS_URL:</p>

<pre><code class="bash">$ export OPENFAAS_URL=https://openfaas.domain.com
</code></pre>

<h2>One Stack File for All 3 Functions:</h2>

<p>We will create our first function to generate the yaml definition, then we will rename our generated filename to <code>stack.yml</code> then the next 2 functions, we will use the append flag to append the functions yaml to our <code>stack.yml</code> file, so that we can simply use <code>faas-cli up</code></p>

<h2>Create the Lookup Function:</h2>

<p>Create a Python3 Function, and prefix it with your dockerhub user:</p>

<pre><code class="bash">$ faas-cli new \
--lang python3 fn-dynamodb-lookup \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com

Function created in folder: fn-foo
Stack file written: fn-dynamodb-lookup.yml
</code></pre>

<p>As we will be using one stack file, rename the generated stack file:</p>

<pre><code class="bash">$ mv fn-dynamodb-lookup.yml stack.yml
</code></pre>

<p>Open the stack file and set the environment variables:</p>

<pre><code class="bash">$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-dynamodb-lookup:
    lang: python3
    handler: ./fn-dynamodb-lookup
    image: ruanbekker/fn-dynamodb-lookup:latest
    environment:
      dynamodb_region: eu-west-1
      dynamodb_table: lookup_table
</code></pre>

<p>The python code for our function:</p>

<pre><code class="bash">$ cat fn-dynamodb-lookup/handler.py
</code></pre>

<pre><code class="python">import json
import hashlib

def calc_sha(id_number, lastname):
    string = json.dumps({"id": id_number, "lastname": lastname}, sort_keys=True)
    hash_value = hashlib.sha1(string.encode("utf-8")).hexdigest()
    return hash_value

def handle(req):
    event = json.loads(req)
    hash_value = calc_sha(event['id'], event['lastname'])
    return hash_value
</code></pre>

<h2>Create the Write Function:</h2>

<p>Create a Python3 Function, and prefix it with your dockerhub user, and use the append flag to update our stack file:</p>

<pre><code class="bash">$ faas-cli new \
--lang python3 fn-dynamodb-write \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com
--append stack.yml

Function created in folder: fn-dynamodb-write
Stack file updated: stack.yml
</code></pre>

<p>Open the stack file and set the environment variables and include the secrets that was created:</p>

<pre><code class="bash">$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-dynamodb-lookup:
  # ...
  fn-dynamodb-write:
    lang: python3
    handler: ./fn-dynamodb-write
    image: ruanbekker/fn-dynamodb-write:latest
    environment:
      dynamodb_region: eu-west-1
      dynamodb_table: lookup_table
    secrets:
      - openfaas-aws-access-key
      - openfaas-aws-secret-key
</code></pre>

<p>Our function relies on a external dependency which we need to install to interact with aws:</p>

<pre><code class="bash">$ cat fn-dynamodb-write/requirements.txt
boto3
</code></pre>

<p>Our python code for our function:</p>

<pre><code class="bash">$ cat fn-dynamodb-write/handler.py
</code></pre>

<pre><code class="python">import boto3
import os
import json
import hashlib
import datetime

aws_key = open('/var/openfaas/secrets/openfaas-aws-access-key', 'r').read()
aws_secret = open('/var/openfaas/secrets/openfaas-aws-secret-key', 'r').read()
dynamodb_region = os.environ['dynamodb_region']
dynamodb_table  = os.environ['dynamodb_table']

client = boto3.Session(region_name=dynamodb_region).resource('dynamodb', aws_access_key_id=aws_key, aws_secret_access_key=aws_secret)
table = client.Table(dynamodb_table)

def calc_sha(id_number, lastname):
    string = json.dumps({"id": id_number, "lastname": lastname}, sort_keys=True)
    hash_value = hashlib.sha1(string.encode("utf-8")).hexdigest()
    return hash_value

def create_timestamp():
    response = datetime.datetime.now().strftime("%Y-%m-%dT%H:%M")
    return response

def handle(req):
    event = json.loads(req)
    unique_id = calc_sha(event['id'], event['lastname'])
    response = table.put_item(
        Item={
            'hash_value': unique_id,
            'timestamp': create_timestamp(),
            'payload': event['payload']
        }
    )
    return response
</code></pre>

<h2>Create the Get Function:</h2>

<p>Create a Python3 Function, and prefix it with your dockerhub user, and use the append flag to specify the stack file:</p>

<pre><code class="bash">$ faas-cli new \
--lang python3 fn-dynamodb-get \
--prefix=ruanbekker \
--gateway https://openfaas.domain.com
--append stack.yml

Function created in folder: fn-dynamodb-get
Stack file updated: stack.yml
</code></pre>

<p>Open the stack file and set the environment variables and include the secrets that was created:</p>

<pre><code class="bash">$ cat stack.yml
provider:
  name: openfaas
  gateway: https://openfaas.domain.com
functions:
  fn-dynamodb-lookup:
  # .. 
  fn-dynamodb-write:
  # ..
  fn-dynamodb-get:
    lang: python3
    handler: ./fn-dynamodb-get
    image: ruanbekker/fn-dynamodb-get:latest
    environment:
      dynamodb_region: eu-west-1
      dynamodb_table: lookup_table
    secrets:
      - openfaas-aws-access-key
      - openfaas-aws-secret-key
</code></pre>

<p>Include the external dependency for aws:</p>

<pre><code class="bash">$ cat fn-dynamodb-get/requirements.txt
boto3
</code></pre>

<p>Our python code for our function:</p>

<pre><code class="bash">$ cat fn-dynamodb-get/handler.py
</code></pre>

<pre><code class="python">import boto3
import os
import json

aws_key = open('/var/openfaas/secrets/openfaas-aws-access-key', 'r').read()
aws_secret = open('/var/openfaas/secrets/openfaas-aws-secret-key', 'r').read()
dynamodb_region = os.environ['dynamodb_region']
dynamodb_table  = os.environ['dynamodb_table']

client = boto3.Session(region_name=dynamodb_region).resource('dynamodb', aws_access_key_id=aws_key, aws_secret_access_key=aws_secret)
table = client.Table(dynamodb_table)

def handle(req):
    event = json.loads(req)
    response = table.get_item(
        Key={
            'hash_value': event['hash_value']
        }
    )

    if 'Item' not in response:
        item_data = 'Item not found'
    else:
        item_data = response['Item']

    return item_data
</code></pre>

<h2>Build, Push and Deploy:</h2>

<p>It&rsquo;s time to deploy our functions and since we have all our stack info in one file, we can use <code>faas-cli up</code> which will build, push and deploy our functions.</p>

<p>By default it expects the filename to be <code>stack.yml</code> therefore we don&rsquo;t need to specify the filename, but if you had a different filename, you can overwrite the default behaviour with <code>-f</code>:</p>

<pre><code class="bash">$ faas-cli up

Deploying: fn-dynamodb-lookup.
Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-dynamodb-lookup

Deploying: fn-dynamodb-write.
Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-dynamodb-write

Deploying: fn-dynamodb-get.
Deployed. 202 Accepted.
URL: https://openfaas.domain.com/function/fn-dynamodb-get
</code></pre>

<h2>Time for our Functions to interact with DynamoDB:</h2>

<p>Write an Item to DynamoDB:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-write -d '{"id": 8700000000001, "lastname": "smith", "payload": {"name": "james", "role": "reader"}}'
{'ResponseMetadata': {'RequestId': 'CNHEFHMSL4KGRDE0HRVQ69D5H7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'Server', 'date': 'Sat, 06 Jul 2019 20:47:00 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': 'CNHEFHMSL4KGRDE0HRVQ69D5H7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'x-amz-crc32': '2745614147'}, 'RetryAttempts': 0}}
</code></pre>

<p>Write another Item to DynamoDB:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.doamin.com/function/fn-dynamodb-write -d '{"id": 8700000000002, "lastname": "adams", "payload": {"name": "samantha", "role": "admin"}}'
{'ResponseMetadata': {'RequestId': 'KRQL838BVGC9LIUSCOUB7MOEQ7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'HTTPStatusCode': 200, 'HTTPHeaders': {'server': 'Server', 'date': 'Sat, 06 Jul 2019 20:48:09 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '2', 'connection': 'keep-alive', 'x-amzn-requestid': 'KRQL838BVGC9LIUSCOUB7MOEQ7VV4KQNSO5AEMVJF66Q9ASUAAJG', 'x-amz-crc32': '2745614147'}, 'RetryAttempts': 0}}
</code></pre>

<p>Now recalculate the hash by passing the ID Number and Lastname to get the hash value for the primary key:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-lookup -d '{"id": 8700000000002, "lastname": "adams"}'
bd0a248aff2b50b288ba504bd7142ef11b164901
</code></pre>

<p>Now that we have the hash value, do a GetItem by using the hash value in the request body:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-get -d '{"hash_value": "bd0a248aff2b50b288ba504bd7142ef11b164901"}'
{'payload': {'name': 'samantha', 'role': 'admin'}, 'hash_value': 'bd0a248aff2b50b288ba504bd7142ef11b164901', 'timestamp': '2019-07-06T20:48'}
</code></pre>

<p>Note that the lookup function calculates a hash based on the input that you provide it, for example calculating a hash with userdata that does not exist in our table:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-lookup -d '{"id": 8700000000003, "lastname": "williams"}'
c68dc272873140f4ae93bb3a3317772a6bdd9aa1
</code></pre>

<p>Using that hash value in our request body to read from dynamodb, will show us that the item has not been found:</p>

<pre><code class="bash">$ curl -XPOST https://openfaas.domain.com/function/fn-dynamodb-get -d '{"hash_value": "c68dc272873140f4ae93bb3a3317772a6bdd9aa1"}'
Item not found
</code></pre>

<p>You might want to change this behavior but this is just for the demonstration of this post.</p>

<p>When you head over to DynamoDB&rsquo;s console you will see this in your table:</p>

<p><img width="873" alt="image" src="https://user-images.githubusercontent.com/567298/60761025-9e8e7c80-a040-11e9-83a3-ad5b474a28ff.png"></p>

<h2>Thanks</h2>

<p>This was a basic example using OpenFaaS with Amazon DynamoDB with Python and secrets managed with OpenFaas. I really like the way OpenFaaS let&rsquo;s you work with secrets, it works great and don&rsquo;t need an additional resource to manage your sensitive data.</p>

<p>Although this was basic usage with OpenFaaS and DynamoDB, the sky is the limit what you can do with it.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/">DynamoDB: Choosing the right Partition Key</a></li>
<li><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html">Designing Partition Keys to Distribute Your Workload Evenly</a></li>
<li><a href="https://docs.openfaas.com/contributing/get-started/">OpenFaaS: Getting Started</a></li>
<li><a href="https://docs.openfaas.com/reference/secrets/">OpenFaaS: Secrets</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Python Serverless Slack Apps on OpenFaas]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/02/21/building-python-serverless-slack-apps-on-openfaas/"/>
    <updated>2019-02-21T23:29:15+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/02/21/building-python-serverless-slack-apps-on-openfaas</id>
    <content type="html"><![CDATA[<p><img src="https://camo.githubusercontent.com/cf01eefb5b6905f3774376d6d1ed55b8f052d211/68747470733a2f2f626c6f672e616c6578656c6c69732e696f2f636f6e74656e742f696d616765732f323031372f30382f666161735f736964652e706e67" alt="" /></p>

<p>If you are not familliar with OpenFaas, it&rsquo;s definitely time that you should have a look at it, plus, they are doing some pretty awesome work!</p>

<script src="//ap.lijit.com/www/delivery/fpi.js?z=601358&width=300&height=250"></script>


<p></p>

<p>From their documentation: &ldquo;OpenFaaS (Functions as a Service) is a framework for building serverless functions with Docker and Kubernetes which has first class support for metrics. Any process can be packaged as a function enabling you to consume a range of web events without repetitive boiler-plate coding.&rdquo;</p>

<p>Make sure to give them a visit at <a href="https://docs.openfaas.com">openfaas.com</a> and while you are there, in the world of serverless, have a look at how Alex outlines architecture and patterns he applies in a real-world example, <a href="https://www.openfaas.com/blog/serverless-single-page-app/">absolutely great read!</a></p>

<h2>What are we doing today?</h2>

<p>Today we will build a slack app using python which we will deploy as a function on OpenFaas!</p>

<p>Our slash command will make a request to our <code>slack-request</code> function, which will respond with a json string, which will then be parsed in a slack attachment message, then based on your button decision, it will then invoke our <code>slack-interaction</code> function, which will then respond with another message that will allow you to follow the embedded link.</p>

<p>The slack messages are really basic, but you can create a awesome workflow using slack apps. And the best of all, its running on OpenFaas!</p>

<h2>Deploying OpenFaas</h2>

<p>Docker Swarm and Kubernetes are supported, but since I am using Docker Swarm at the moment of writing, this tutorial will show how to deploy OpenFaas to your cluster. Have a look at <a href="https://docs.openfaas.com/deployment/docker-swarm/">OpenFaas Documentation</a> for more detailed information.</p>

<p>Installing OpenFaas CLI for Mac:</p>

<pre><code class="bash">$ brew install faas-cli
</code></pre>

<p>Deploy the OpenFaas Stack:</p>

<pre><code class="bash">$ git clone https://github.com/openfaas/faas
$ cd faas 
$ ./deploy_stack.sh
</code></pre>

<p>Credentials: The default configuration will create credentials for you and returns instructions on how to authorize faas-cli, for demonstration it will look more or less like the following:</p>

<pre><code class="bash">$ echo -n &lt;some_hash_secret&gt; | faas-cli login --username=admin --password-stdin
</code></pre>

<p>The UI will be available at: <a href="http://127.0.0.1:8080.">http://127.0.0.1:8080.</a> For this demonstration we will only use the cli.</p>

<h2>Create the Functions</h2>

<p>I will create 2 python functions:</p>

<ul>
<li>The <code>slack-request</code> function, which will be associated to the slash command</li>
<li>The <code>slack-interactive</code> function, which will be used for interactivity</li>
</ul>


<p>Create a home directory for your functions and create 2 functions:</p>

<pre><code class="bash">$ mkdir -p ~/functions &amp;&amp; cd ~/functions
$ faas-cli new --lang python slack-request
$ faas-cli new --lang python slack-interactive
</code></pre>

<p>Read the <a href="https://docs.openfaas.com/tutorials/first-python-function/">documentation</a> if you&rsquo;d like to learn more.</p>

<p>Configure the first function:</p>

<pre><code class="bash">$ vim slack-request/handler.py
</code></pre>

<p>And our function code:</p>

<pre><code class="python">import json

def handle(req):
    data = {
        "text": "Serverless Message",
        "attachments": [{
            "title": "The Awesome world of Serverless introduces: OpenFaas!",
            "fields": [{
                "title": "Amazing Level",
                "value": "10",
                "short": True
            },
        {
                "title": "Github Stars",
                "value": "15k +",
                "short": True
            }],
            "author_name": "OpenFaas",
            "author_icon": "",
            "image_url": "https://blog.alexellis.io/content/images/2017/08/small.png"
        },
        {
            "title": "About OpenFaas",
            "text": "OpenFaaS is a framework for packaging code, binaries or containers as Serverless functions on any platform."
        },
        {
            "fallback": "Would you recommend OpenFaas to your friends?",
            "title": "Would you recommend OpenFaas to your friends?",
            "callback_id": "response123",
            "color": "#3AA3E3",
            "attachment_type": "default",
            "actions": [
                {
                    "name": "recommend",
                    "text": "Ofcourse!",
                    "type": "button",
                    "value": "recommend"
                },
                {
                    "name": "definitely",
                    "text": "Most Definitely!",
                    "type": "button",
                    "value": "definitely"
                }
            ]
        }]
    }
    return json.dumps(data)
</code></pre>

<p>Since our response needs to be parsed as json, we need to set the content type for our environment in our yaml configuration. Read more on it <a href="https://docs.openfaas.com/reference/yaml/">here</a>. Edit the <code>slack-request.yml</code> :</p>

<pre><code class="yaml">provider:
  name: faas
  gateway: http://&lt;your.gw.address&gt;:8080
functions:
  slack-request:
    lang: python
    handler: ./slack-request
    image: &lt;your-repo&gt;/slack-request:latest
    environment:
      content_type: application/json
</code></pre>

<p>Now we need to build our image, push it to our repository like dockerhub, then deploy to openfaas:</p>

<pre><code class="bash">$ faas-cli build -f ./slack-request.yml 
$ faas-cli push -f ./slack-request.yml 
$ faas-cli deploy -f ./slack-request.yml
Deploying: slack-request.

Deployed. 202 Accepted.
URL: http://your.gw.address:8080/function/slack-interactive
</code></pre>

<p>Configure the <code>slack-interactive</code> function:</p>

<pre><code class="bash">$ vim slack-interactive/handler.py
</code></pre>

<p>Note that whenever your interact with the first message, a post request will be made against the interactivity request url, you will notice that I decoded the payload (but not doing anything with it), where you will find the callback_id, request_url etc. But for simplicity, I am just using a static json message to respond. Our function code:</p>

<pre><code class="python">import json
import urllib

def handle(req):
    urlstring = urllib.unquote(req).decode('utf8').strip('payload=')
    response = json.loads(urlstring)
    data = {
        "attachments": [
            {
                "replace_original": True,
                "response_type": "ephemeral",
                "fallback": "Required plain-text summary of the attachment.",
                "color": "#36a64f",
                "pretext": "Ahh yeah! Great choice, OpenFaas is absolutely brilliant!",
                "author_name": "",
                "author_link": "https://github.com/openfaas/faas",
                "author_icon": "http://flickr.com/icons/bobby.jpg",
                "title": "OpenFaas",
                "title_link": "https://github.com/openfaas/faas",
                "text": "Head over to OpenFaas",
                "image_url": "https://avatars2.githubusercontent.com/u/27013154?s=400&amp;v=4",
                "thumb_url": "https://github.com/openfaas/faas",
                "footer": "Slack Apps built on OpenFaas",
                "footer_icon": "https://a.slack-edge.com/45901/marketing/img/_rebrand/meta/slack_hash_256.png",
                "ts": 123456789
            }
        ]
    }
    return json.dumps(data)
</code></pre>

<p>We also need to set the content type to json:</p>

<pre><code class="bash">provider:
  name: faas
  gateway: http://&lt;your.gw.address&gt;:8080
functions:
  slack-interactive:
    lang: python
    handler: ./slack-interactive
    image: &lt;repo&gt;/slack-interactive:latest
    environment:
      content_type: application/json
</code></pre>

<p>Build, deploy and ship:</p>

<pre><code class="bash">$ faas-cli build -f ./slack-interactive.yml 
$ faas-cli push -f ./slack-interactive.yml
$ faas-cli deploy -f ./slack-interactive.yml

Deploying: slack-interactive.

Deployed. 202 Accepted.
URL: http://&lt;your.gw.address&gt;:8080/function/slack-interactive
</code></pre>

<p>When your functions are deployed, go ahead and create the slack app.</p>

<h2>Create the Slack App</h2>

<ul>
<li>Head over to <a href="https://api.slack.com/apps">https://api.slack.com/apps</a> and create a new app</li>
<li>Create a incoming webhook</li>
<li>Head over to slash commands and create a new command, in my case it was <code>/supersam</code>, set the request url to the public endpoint of your function: <code>http://pub-ip:8080/function/slack-request</code></li>
<li>Head over to interactive components, set the request url for the interactivity: <code>http://pub-ip:8080/function/slack-interactive</code></li>
<li>If you dont have a public routable address, have a look at <a href="https://ngrok.com">ngrok</a></li>
</ul>


<p>Once you are set, you should be able to see the slash command integration in your slack workspace, head over to slacks <a href="https://api.slack.com/docs">documentation</a> if you run into any trouble.</p>

<h2>Test your Slack App</h2>

<p>Now that everything is good to go, its time to test your slack app running on OpenFaas!</p>

<p>Head over to slack and run your command <code>/&lt;your-slack-slash-command&gt;</code>. You should see this output:</p>

<p><img src="https://user-images.githubusercontent.com/567298/53206700-56932e00-363a-11e9-8d44-dfd27f005ab0.png" alt="" /></p>

<p>When you select one of the buttons, you will get a new message:</p>

<p><img src="https://user-images.githubusercontent.com/567298/53206764-74f92980-363a-11e9-91cb-6cfc30c74457.png" alt="" /></p>

<p>This is a real basic example of slack apps, but slack apps are really powerful. You can for example create a slack app that deploys ephemeral environments on swarm, or create change management approval workflows etc.</p>

<p>I hope this was informative, I am really enjoying OpenFaas at the moment and if your have not tested it, I encourage you to try it out, its really, really amazing!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a 3 Node Kubernetes Cluster on Ubuntu]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/12/11/setup-a-3-node-kubernetes-cluster-on-ubuntu/"/>
    <updated>2017-12-11T16:31:47+02:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/12/11/setup-a-3-node-kubernetes-cluster-on-ubuntu</id>
    <content type="html"><![CDATA[<p><img src="https://kumorilabs.com/img/blog/kubernetes-logo.png" alt="" /></p>

<p>Setup a 3 Node Kubernetes Cluster on Ubuntu 16.04</p>

<h2>What is Kubernetes?</h2>

<p>As referenced from their <a href="https://kubernetes.io/">website</a>:</p>

<ul>
<li>&ldquo;Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.&rdquo;</li>
</ul>


<h2>Our Setup:</h2>

<p>For this setup I will be using 3 AWS EC2 Instances with Ubuntu 16.04. One node will act as the master node, and the other 2 nodes, will act as nodes, previously named minions.</p>

<p>We will deploy Kubernetes on all 3 nodes, the master will be the node where we will initialize our cluster, deploy our weave network, applications and we will execute the join command on the worker nodes to join the master to form the cluster.</p>

<h2>Deploy Kubernetes: Master</h2>

<p>The following commands will be used to install Kubernetes, it will be executed with root permissions:</p>

<pre><code class="bash">$ apt update &amp;&amp; sudo apt upgrade -y
$ sudo apt install docker.io apt-transport-https -qy
$ sudo apt update
$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
$ sudo su -c 'echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" &gt; /etc/apt/sources.list.d/app' root
$ apt update
$ sudo apt install kubelet kubeadm kubernetes-cni -y
</code></pre>

<p>Now we would like to set up the master by initializing the cluster:</p>

<pre><code class="bash">$ sudo kubeadm init --kubernetes-version stable-1.8
</code></pre>

<p>The output will provide you with instructions to setup the configurations for the master node, and provide you with a join token for your worker nodes, remember to make not of this token string, as we will need it later for our worker nodes. As your normal user, run the following to setup the config:</p>

<p>Remember to not run this as root, and as the normal user:</p>

<pre><code class="bash">$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>

<p>Now we need to deploy a network for our pods:</p>

<pre><code class="bash">$ kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
</code></pre>

<p>Lets confirm if all our resources are in its desired state, a small snippet of the output will look like the one below:</p>

<pre><code class="bash">$ kubectl get all -n kube-system

...
NAME                                          READY     STATUS    RESTARTS   AGE
po/etcd-ip-172-31-40-211                      1/1       Running   0          6h
po/kube-apiserver-ip-172-31-40-211            1/1       Running   0          6h
</code></pre>

<p>Once all of the resources are in its desired state, we can head along to our worker nodes, to join them to the cluster</p>

<h2>Deploy Kubernetes: Worker Nodes</h2>

<p>As I have 2 worker nodes, we will need to deploy the following on both of our worker nodes, first to deploy Kubernetes on our nodes with root permission:</p>

<pre><code class="bash">$ apt update &amp;&amp; sudo apt upgrade -y
$ sudo apt install docker.io apt-transport-https -qy
$ sudo apt update
$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
$ sudo su -c 'echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" &gt; /etc/apt/sources.list.d/app' root
$ apt update
$ sudo apt install kubelet kubeadm kubernetes-cni -y
</code></pre>

<p>Once Kubernetes is installed, join the Master node by executing the join command:</p>

<pre><code class="bash">$ sudo kubeadm join --token 49abf7.247d663db97f8504 172.31.40.211:6443 --discovery-token-ca-cert-hash sha256:3a3b301cfbac0995c69a0115989ea384230470d6836ae0e13e71dbdf15ffbb48
</code></pre>

<p>Do the 2 steps on the other node, then head back to the master node.</p>

<h2>Verifying if All Nodes are Checked In</h2>

<p>To verify if all nodes are available and reachable in the cluster:</p>

<pre><code class="bash">$ kubectl get nodes
NAME               STATUS    ROLES     AGE       VERSION
ip-172-31-36-68    Ready     &lt;none&gt;    6h        v1.8.5
ip-172-31-40-211   Ready     master    6h        v1.8.5
ip-172-31-44-80    Ready     &lt;none&gt;    6h        v1.8.5
</code></pre>

<h2>Deploy Services to Kubernetes:</h2>

<p>Kubernetes has Awesome Examples on their <a href="https://github.com/kubernetes/kubernetes/tree/master/examples">Github Repository</a>.</p>

<p>Since the awesomeness of <a href="https://github.com/openfaas">OpenFaas</a>, I will deploy OpenFaas on Kubernetes:</p>

<pre><code class="bash">$ git clone https://github.com/openfaas/faas-netes
$ cd faas-netes
$ kubectl apply -f faas.yml,monitoring.yml,rbac.yml
</code></pre>

<p>Give it about a minute or so, then you should see the pods running in their desired state:</p>

<pre><code class="bash">$ kubectl get pods
NAME                           READY     STATUS    RESTARTS   AGE
alertmanager-77b4b476b-zxtcz   1/1       Running   0          4h
crypto-7d8b7f999c-7l85k        1/1       Running   0          1h
faas-netesd-64fb9b4dfb-hc8gh   1/1       Running   0          4h
gateway-69c9d949f-q57zh        1/1       Running   0          4h
prometheus-7fbfd8bfb8-d4cft    1/1       Running   0          4h
</code></pre>

<p>When we have the desired state, head over to the OpenFaas Gateway WebUI: <code>http://master-public-ip:31112/ui/</code>, select &ldquo;Deploy New Function&rdquo;, you can use your own function or select one from the store.</p>

<p>I am going to use Figlet from the store, once the pod has been deployed, select the function, enter any text into the request body and select invoke. I have used my name and surname, and turns out into:</p>

<pre><code class="bash"> ____                      ____       _    _             
|  _ \ _   _  __ _ _ __   | __ )  ___| | _| | _____ _ __ 
| |_) | | | |/ _` | '_ \  |  _ \ / _ \ |/ / |/ / _ \ '__|
|  _ &lt;| |_| | (_| | | | | | |_) |  __/   &lt;|   &lt;  __/ |   
|_| \_\\__,_|\__,_|_| |_| |____/ \___|_|\_\_|\_\___|_|   
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">Kubernetes Overview</a></li>
<li><a href="https://kubernetes.io/docs/concepts/">Kubernetes Concepts</a></li>
<li><a href="https://blog.alexellis.io/tag/kubernetes/">Kubernetes Blogs</a></li>
<li><a href="https://blog.alexellis.io/tag/openfaas/">OpenFaas Blogs</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
