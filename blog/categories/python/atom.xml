<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/python/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2021-03-10T00:47:36-05:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Visualize Weather Data With Grafana and the DHT22 Sensor]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/03/10/visualize-weather-data-with-grafana-and-the-dht22-sensor/"/>
    <updated>2021-03-10T00:06:31-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/03/10/visualize-weather-data-with-grafana-and-the-dht22-sensor</id>
    <content type="html"><![CDATA[<p>In this tutorial, we will connect the <a href="https://learn.adafruit.com/dht">DHT22</a> sensor to the Raspberry Pi Zero via the GPIO pins to measure temperature and humidity and visualize it with Grafana.</p>

<p><em>Note</em>: This post was originally posted on my <a href="https://blog.pistack.co.za/monitor-temperature-with-the-dht22-sensor-on-the-raspberry-pi/">RaspberryPi Blog</a></p>

<p>Then we will write a Python exporter for prometheus to expose our metrics so that we can visualize it in Grafana.</p>

<h2>The Endgoal</h2>

<p><img src="https://user-images.githubusercontent.com/30043398/104296987-fd9d3f00-54ca-11eb-8623-f3fd4a63e3cc.png" alt="image" /></p>

<h2>The Hardware</h2>

<p>This is how the sensor looks like (I got it from <a href="https://www.communica.co.za/products/bmt-temp-humd-snsr-dht22-on-pcb">Communica</a>)</p>

<p><img src="https://user-images.githubusercontent.com/567298/103872941-ba605c00-50d7-11eb-9f60-531995a185e6.png" alt="image" /></p>

<h2>Connecting the Sensor</h2>

<p>You can use the following graphic to connect your sensor to your raspberry pi:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103873892-27c0bc80-50d9-11eb-9c41-3f3b2ff5aee2.png" alt="image" /></p>

<h2>Installing Software</h2>

<p>To install the required software, we will be using pip:</p>

<pre><code>$ pip3 install Adafruit_DHT --user
</code></pre>

<p>Once we installed the software we can configure it</p>

<h2>Interact with the Sensor</h2>

<p>Enter your python interpreter:</p>

<pre><code>$ python3
&gt;&gt;&gt;
</code></pre>

<p>Then import the library, and get the current temperature and humidity:</p>

<pre><code>&gt;&gt;&gt; import Adafruit_DHT as dht
&gt;&gt;&gt; humidity, temperature = dht.read_retry(dht.DHT22, 4)
&gt;&gt;&gt; humidity = format(humidity, ".2f") + "%"
&gt;&gt;&gt; humidity
'47.20%'
&gt;&gt;&gt; temperature = format(temperature, ".2f") + "C"
&gt;&gt;&gt; temperature
'29.10C'
</code></pre>

<p>Let&rsquo;s create a python script for it:</p>

<pre><code>$ cat temps.py
#!/usr/bin/env python3

import Adafruit_DHT as dht_sensor
import time

def get_temperature_readings():
    humidity, temperature = dht_sensor.read_retry(dht_sensor.DHT22, 4)
    humidity = format(humidity, ".2f") + "%"
    temperature = format(temperature, ".2f") + "C"
    return {"temperature": temperature, "humidity": humidity}

while True:
    print(get_temperature_readings())
    time.sleep(30)
</code></pre>

<p>And run it:</p>

<pre><code>$ python3 temps.py
{'temperature': '28.00C', 'humidity': '47.40%'}
{'temperature': '28.00C', 'humidity': '47.30%'}
{'temperature': '28.00C', 'humidity': '47.70%'}
{'temperature': '28.00C', 'humidity': '47.40%'}
{'temperature': '28.00C', 'humidity': '47.60%'}
</code></pre>

<h2>Visualize with Grafana</h2>

<p>Let&rsquo;s visualize our data with Grafana. For this, we need to write an exporter so that Prometheus can scrape the data.</p>

<p>Let&rsquo;s create a python flask application with the prometheus client library for python to expose the metrics to prometheus with a <code>/metrics</code> endpoint.</p>

<p>Note: I have used <a href="https://openweathermap.org/api">OpenWeatherMap</a>&rsquo;s API to get the outside temperature for my location.</p>

<pre><code>$ cat flask_temps.py
#!/usr/bin/env python3

import Adafruit_DHT as dht_sensor
import time
from flask import Flask, Response
from prometheus_client import Counter, Gauge, start_http_server, generate_latest
import requests

params = {"lat": "-xx.xxxxx", "lon": "xx.xxxx", "units": "metric", "appid": "your-api-key"}
baseurl = "https://api.openweathermap.org/data/2.5/weather"
content_type = str('text/plain; version=0.0.4; charset=utf-8')

def get_temperature_readings():
    humidity, temperature = dht_sensor.read_retry(dht_sensor.DHT22, 4)
    humidity = format(humidity, ".2f")
    temperature = format(temperature, ".2f")
    outside_temp = get_outside_weather()
    if all(v is not None for v in [humidity, temperature, outside_temp]):
        response = {"temperature": temperature, "humidity": humidity, "outside_temp": outside_temp}
        return response
    else:
        time.sleep(0.2)
        humidity, temperature = dht_sensor.read_retry(dht_sensor.DHT22, 4)
        humidity = format(humidity, ".2f")
        temperature = format(temperature, ".2f")
        outside_temp = get_outside_weather()
        response = {"temperature": temperature, "humidity": humidity, "outside_temp": outside_temp}
        return response

def get_outside_weather():
    response = requests.get(baseurl, params=params)
    temp = response.json()['main']['temp']
    return temp

app = Flask(__name__)

current_humidity = Gauge(
        'current_humidity',
        'the current humidity percentage, this is a gauge as the value can increase or decrease',
        ['room']
)

current_temperature = Gauge(
        'current_temperature',
        'the current temperature in celsius, this is a gauge as the value can increase or decrease',
        ['room']
)

current_temperature_outside = Gauge(
        'current_temperature_outside',
        'the current outside temperature in celsius, this is a gauge as the value can increase or decrease',
        ['location']
)

@app.route('/metrics')
def metrics():
    metrics = get_temperature_readings()
    current_humidity.labels('study').set(metrics['humidity'])
    current_temperature.labels('study').set(metrics['temperature'])
    current_temperature_outside.labels('za_ct').set(metrics['outside_temp'])
    return Response(generate_latest(), mimetype=content_type)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
</code></pre>

<p>Then install the flask and prometheus_client package:</p>

<pre><code>$ python3 -m pip install flask prometheus_client --user
</code></pre>

<p>When you run the program, you should be able to retrieve metrics from the exporter by making a request on port 5000 on the <code>/metrics</code> request path:</p>

<pre><code>$ curl http://localhost:5000/metrics
# HELP python_gc_objects_collected_total Objects collected during gc
# TYPE python_gc_objects_collected_total counter
python_gc_objects_collected_total{generation="0"} 646.0
python_gc_objects_collected_total{generation="1"} 129.0
python_gc_objects_collected_total{generation="2"} 0.0
# HELP python_gc_objects_uncollectable_total Uncollectable object found during GC
# TYPE python_gc_objects_uncollectable_total counter
python_gc_objects_uncollectable_total{generation="0"} 0.0
python_gc_objects_uncollectable_total{generation="1"} 0.0
python_gc_objects_uncollectable_total{generation="2"} 0.0
# HELP python_gc_collections_total Number of times this generation was collected
# TYPE python_gc_collections_total counter
python_gc_collections_total{generation="0"} 104.0
python_gc_collections_total{generation="1"} 9.0
python_gc_collections_total{generation="2"} 0.0
# HELP python_info Python platform information
# TYPE python_info gauge
python_info{implementation="CPython",major="3",minor="7",patchlevel="3",version="3.7.3"} 1.0
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 4.4761088e+07
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 2.7267072e+07
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.61044381853e+09
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 5.86
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 6.0
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1024.0
# HELP current_humidity the current humidity percentage, this is a gauge as the value can increase or decrease
# TYPE current_humidity gauge
current_humidity{room="study"} 47.0
# HELP current_temperature the current temperature in celsius, this is a gauge as the value can increase or decrease
# TYPE current_temperature gauge
current_temperature{room="study"} 25.7
# HELP current_temperature_outside the current outside temperature in celsius, this is a gauge as the value can increase or decrease
# TYPE current_temperature_outside gauge
current_temperature_outside{location="za_ct"} 27.97
</code></pre>

<p>Now to configure our prometheus scrape config to scrape our endpoint:</p>

<pre><code>$ cat /etc/prometheus/prometheus.yml
...
scrape_configs:
  - job_name: 'temperature-exporter'
    scrape_interval: 15s
    static_configs:
    - targets: ['192.168.0.5:5000']
      labels:
        instance: 'pi-zero'
        room: 'study'
</code></pre>

<p>Then restart prometheus and head over to Grafana.</p>

<p>We will be adding a new panel with a graph visualization, and from our prometheus datasource, we will be referencing the 2 metrics (different from the screenshot):</p>

<pre><code>current_humidity{room="study"} 47.0
current_temperature{room="study"} 25.7
current_temperature_outside{location="za_ct"} 27.97
</code></pre>

<p>As can be seen below:</p>

<p><img src="https://user-images.githubusercontent.com/567298/103987136-a169b080-5194-11eb-8a61-6d36f45caf5c.png" alt="image" /></p>

<p>After a bit of customization, you can get something more or less like this:</p>

<p><img src="https://user-images.githubusercontent.com/30043398/104296987-fd9d3f00-54ca-11eb-8623-f3fd4a63e3cc.png" alt="image" /></p>

<h2>Thank You</h2>

<p>Thanks for reading, if you like my content feel free to visit my website <strong><a href="https://ruan.dev">ruan.dev</a></strong> or follow me on Twitter <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sending Slack Messages With Python]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/11/06/sending-slack-messages-with-python/"/>
    <updated>2020-11-06T13:58:50+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/11/06/sending-slack-messages-with-python</id>
    <content type="html"><![CDATA[<p>In this post I will demonstrate how to send messages to slack using python based on the status of an event.</p>

<p>We will keep it basic, that when something is down or up, it should send a slack message with the status, message, color and embed your grafana dashboard links inside the alert (or any links that you would like).</p>

<h2>Create a Webhook</h2>

<p>From a previous post on <a href="https://blog.ruanbekker.com/blog/2019/04/18/setup-a-slack-webhook-for-sending-messages-from-applications/">how to use curl to send slack messages</a> I showed how to create your webhook, so you can just follow that post if you want to follow along.</p>

<p>Once you have a webhook, which will look like <code>https://hooks.slack.com/services/xx/yy/zz</code>, you are good to follow to the next step.</p>

<h2>Creating the Script</h2>

<p>First we need requests:</p>

<pre><code>$ pip install requests
</code></pre>

<p>Then we will create the <code>slack_notifier.py</code>, just ensure that you replace your slack webhook url and slack channel to yours:</p>

<pre><code class="python">import requests
import sys
import os

SLACK_WEBHOOK_URL = 'https://hooks.slack.com/&lt;your&gt;/&lt;slack&gt;/&lt;webhook&gt;'
SLACK_CHANNEL = "#your-slack-channel"
ALERT_STATE = sys.argv[1]

alert_map = {
    "emoji": {
        "up": ":white_check_mark:",
        "down": ":fire:"
    },
    "text": {
        "up": "RESOLVED",
        "down": "FIRING"
    },
    "message": {
        "up": "Everything is good!",
        "down": "Stuff is burning!"
    },
    "color": {
        "up": "#32a852",
        "down": "#ad1721"
    }
}

def alert_to_slack(status, log_url, metric_url):
    data = {
        "text": "AlertManager",
        "username": "Notifications",
        "channel": SLACK_CHANNEL,
        "attachments": [
        {
            "text": "{emoji} [*{state}*] Status Checker\n {message}".format(
                emoji=alert_map["emoji"][status],
                state=alert_map["text"][status],
                message=alert_map["message"][status]
            ),
            "color": alert_map["color"][status],
            "attachment_type": "default",
            "actions": [
                {
                    "name": "Logs",
                    "text": "Logs",
                    "type": "button",
                    "style": "primary",
                    "url": log_url
                },
                {
                    "name": "Metrics",
                    "text": "Metrics",
                    "type": "button",
                    "style": "primary",
                    "url": metric_url
                }
            ]
        }]
    }
    r = requests.post(SLACK_WEBHOOK_URL, json=data)
    return r.status_code

alert_to_slack(ALERT_STATE, "https://grafana-logs.dashboard.local", "https://grafana-metrics.dashboard.local")
</code></pre>

<h2>Testing it out</h2>

<p>Time to test it out, so let&rsquo;s assume something is down, then we can react on that event and action the following:</p>

<pre><code>$ python slack_notifier.py down
</code></pre>

<p>Which will look like the following on slack:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98374881-fdf00880-2049-11eb-9d7f-7599665871db.png" alt="image" /></p>

<p>And when recovery is in place, we can action the following:</p>

<pre><code>$ python slack_notifier.py up
</code></pre>

<p>Which will look like this:</p>

<p><img src="https://user-images.githubusercontent.com/567298/98374958-1eb85e00-204a-11eb-8ab0-c6a8a0640752.png" alt="image" /></p>

<h2>Thanks</h2>

<p>That was a basic example on how you can use python to send slack messages.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running SSH Commands on AWS EC2 Instances With Python]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/11/02/running-ssh-commands-on-aws-ec2-instances-with-python/"/>
    <updated>2020-11-02T09:55:43+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/11/02/running-ssh-commands-on-aws-ec2-instances-with-python</id>
    <content type="html"><![CDATA[<p>In this quick post I will demonstrate how to discover a EC2 Instance&rsquo;s Private IP Address using the AWS API by using Tags then use Paramiko in Python to SSH to the EC2 instance and run SSH commands on the target instance.</p>

<p>Install the required dependencies:</p>

<pre><code>$ virtualenv -p python3 .venv
$ source .venve/bin/activate
$ pip install boto3 paramiko
</code></pre>

<p>I have my development profile for aws configured under <code>dev</code> as can seen below:</p>

<pre><code>$ aws --profile dev configure list
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                      dev           manual    --profile
access_key     ****************xxxx      assume-role
secret_key     ****************xxxx      assume-role
    region                eu-west-1      config-file    ~/.aws/config
</code></pre>

<p>First we need to discover the private ip address from the api by referencing tags, and in this example we will use the <code>Name</code> tag:</p>

<pre><code>import boto3
ec2 = boto3.Session(profile_name='dev', region_name='eu-west-1').client('ec2')

target_instances = ec2.describe_instances(
    Filters=[{'Name':'tag:Name','Values':['my-demo-ec2-instance']}]
)

ec2_instances = []
for each_instance in target_instances['Reservations']:
    for found_instance in each_instance['Instances']:
        ec2_instances.append(found_instance['PrivateIpAddress'])

# ec2_instances
# ['172.31.2.89']
</code></pre>

<p>So we are instantiating a ec2 instance with our configured dev profile, then we describe all our instances using the tag key <code>Name</code> and value <code>my-demo-ec2-instance</code> and then access the private ip address and append it to our <code>ec2_instances</code> list.</p>

<p>Next we want to define the commands that we want to run on the target ec2 instance:</p>

<pre><code>commands = [
    "echo hi",
    "whoami",
    "hostname"
]
</code></pre>

<p>In my case I only have 1 ec2 instance with the name <code>my-demo-ec2-instance</code>, but if you have more you can just loop through the list and perform the actions.</p>

<p>Next we want to establish the SSH connection:</p>

<pre><code>k = paramiko.RSAKey.from_private_key_file("/Users/ruan/.ssh/id_rsa")
c = paramiko.SSHClient()
c.set_missing_host_key_policy(paramiko.AutoAddPolicy())
c.connect(hostname=ec2_instances[0], username="ruan", pkey=k, allow_agent=False, look_for_keys=False)
</code></pre>

<p>Once our SSH connection has established, we can loop through our commands and execute them:</p>

<pre><code>for command in commands:
    print("running command: {}".format(command))
    stdin , stdout, stderr = c.exec_command(command)
    print(stdout.read())
    print(stderr.read())
</code></pre>

<p>Which will output the folling:</p>

<pre><code>running command: echo hi
b'hi\n'
b''
running command: whoami
b'ruan\n'
b''
running command: hostname
b'ip-172-31-2-89\n'
b''
</code></pre>

<p>And then close the SSH connection:</p>

<pre><code>c.close()
</code></pre>

<p>And the full script will look like this:</p>

<pre><code class="python">import boto3
ssh_username = "ruan"
ssh_key_file = "/Users/ruan/.ssh/id_rsa"

ec2 = boto3.Session(profile_name='dev', region_name='eu-west-1').client('ec2')

target_instances = ec2.describe_instances(
    Filters=[{'Name':'tag:Name','Values':['my-demo-ec2-instance']}]
)

ec2_instances = []
for each_instance in target_instances['Reservations']:
    for found_instance in each_instance['Instances']:
        ec2_instances.append(found_instance['PrivateIpAddress'])

commands = [
    "echo hi",
    "whoami",
    "hostname"
]

k = paramiko.RSAKey.from_private_key_file(ssh_key_file)
c = paramiko.SSHClient()
c.set_missing_host_key_policy(paramiko.AutoAddPolicy())
c.connect(hostname=ec2_instances[0], username=ssh_username, pkey=k, allow_agent=False, look_for_keys=False)

for command in commands:
    print("running command: {}".format(command))
    stdin , stdout, stderr = c.exec_command(command)
    print(stdout.read())
    print(stderr.read())

c.close()
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Get the Top 10 Items on Hackernews in Python]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/06/13/get-the-top-10-items-on-hackernews-in-python/"/>
    <updated>2020-06-13T19:53:20+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/06/13/get-the-top-10-items-on-hackernews-in-python</id>
    <content type="html"><![CDATA[<p>This is a quick post on how to use python to get the 10 latest items from hacker<a href="news:">news:</a></p>

<pre><code>import requests
import json

def get_top_ten():
    ids = requests.get('https://hacker-news.firebaseio.com/v0/topstories.json?print=pretty').json()[0:10]
    for id in ids:
        postresponse = requests.get('https://hacker-news.firebaseio.com/v0/item/{postid}.json?print=pretty'.format(postid=id)).json()
        formatted = {"title": postresponse["title"], "type": postresponse["type"], "url": postresponse["url"], "by": postresponse["by"]}
        print(json.dumps(formatted, indent=2))
</code></pre>

<p>When running it:</p>

<pre><code>&gt;&gt;&gt; get_top_ten()
..
{
  "title": "Play Counter-Strike 1.6 in your browser",
  "type": "story",
  "url": "http://cs-online.club",
  "by": "m0ck"
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improve MySQL Write Performance Using Batch Writes]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/06/13/improve-mysql-write-performance-using-batch-writes/"/>
    <updated>2020-06-13T19:31:32+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/06/13/improve-mysql-write-performance-using-batch-writes</id>
    <content type="html"><![CDATA[<p><img src="https://img.sysadmins.co.za/wngib2.png" alt="mysql-python-performance" /></p>

<p>I am no DBA, but I got curious when I noticed sluggish write performance on a mysql database, and I remembered somewhere that you should always use batch writes over sequential writes. So I decided to test it out, using a python script and a mysql server.</p>

<h2>What will we be doing</h2>

<p>I wrote a python script that writes 100,000 records to a database and keeps time of how long the writes took, 2 examples which I will compare:</p>

<ul>
<li>One script writing each record to the database</li>
<li>One script writing all the records as batch</li>
</ul>


<h2>Sequential Writes</h2>

<p>It took 48 seconds to write 100,000 records into a database using sequential writes:</p>

<pre><code class="python">...
for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    cur.execute(
        """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
        (userid, name, job, age, credit_card_num, status)
    )
...
</code></pre>

<p>Running that shows us this:</p>

<pre><code>$ python3 mysql_seq_writes.py
start
writing customers to database
finish
inserted 100000 records in 48s
</code></pre>

<h2>Batch Writes</h2>

<p>It took 3 seconds to write to write 100,000 records using batch writes:</p>

<pre><code class="python">...
for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    bunch_users.append((userid, name, job, age, credit_card_num, status))

cur.executemany(
    """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
    bunch_users
)
...
</code></pre>

<p>Running that shows us this:</p>

<pre><code>$ python3 mysql_batch_writes.py
start
writing customers to database
finish
inserted 100000 records in 3s
</code></pre>

<h2>Looking at the Scripts</h2>

<p>The script used for sequential writes:</p>

<pre><code class="python">import datetime
import random
import MySQLdb
from datetime import datetime as dt

host="172.18.0.1"
user="root"
password="password"
dbname="shopdb"
records=100000

db = MySQLdb.connect(host, user, password, dbname)

names = ['ruan', 'donovan', 'james', 'warren', 'angie', 'nicole', 'jenny', 'penny', 'amber']
job = ['doctor', 'scientist', 'teacher', 'police officer', 'waiter', 'banker', 'it']

cur = db.cursor()
cur.execute("DROP TABLE IF EXISTS customers")
cur.execute("CREATE TABLE customers(userid VARCHAR(50), name VARCHAR(50), surname VARCHAR(50), job VARCHAR(50), age INT(2), credit_card_num VARCHAR(50), status VARCHAR(10))")

bunch_users = []
userids = []

print("start")

def gen_id():
    return str(random.randint(0,9999)).zfill(4)

def gen_user(username):
    ccnum = '{0}-{1}-{2}-{3}'.format(gen_id(), gen_id(), gen_id(), gen_id())
    userid = username + '_' + ccnum.split('-')[0] + ccnum.split('-')[2]
    return {"uid": userid, "ccnum": ccnum}

for name in range(records):
    userids.append(gen_user(random.choice(names)))

print("writing customers to database")

timestart = int(dt.now().strftime("%s"))

for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    #bunch_users.append((userid, name, job, age, credit_card_num, status))

    cur.execute(
        """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
        (userid, name, job, age, credit_card_num, status)
    )

db.commit()
db.close()
timefinish = int(dt.now().strftime("%s"))
print("finish")
print("inserted {} records in {}s".format(records, timefinish-timestart))
</code></pre>

<p>The script used for the batch writes:</p>

<pre><code class="python">import datetime
import random
import MySQLdb
from datetime import datetime as dt

host="172.18.0.1"
user="root"
password="password"
dbname="shopdb"
records=100000

db = MySQLdb.connect(host, user, password, dbname)

names = ['ruan', 'donovan', 'james', 'warren', 'angie', 'nicole', 'jenny', 'penny', 'amber']
job = ['doctor', 'scientist', 'teacher', 'police officer', 'waiter', 'banker', 'it']

cur = db.cursor()
cur.execute("DROP TABLE IF EXISTS customers")
cur.execute("CREATE TABLE customers(userid VARCHAR(50), name VARCHAR(50), surname VARCHAR(50), job VARCHAR(50), age INT(2), credit_card_num VARCHAR(50), status VARCHAR(10))")

bunch_users = []
userids = []

print("start")

def gen_id():
    return str(random.randint(0,9999)).zfill(4)

def gen_user(username):
    ccnum = '{0}-{1}-{2}-{3}'.format(gen_id(), gen_id(), gen_id(), gen_id())
    userid = username + '_' + ccnum.split('-')[0] + ccnum.split('-')[2]
    return {"uid": userid, "ccnum": ccnum}

for name in range(records):
    userids.append(gen_user(random.choice(names)))

for user in userids:
    userid = user["uid"]
    name = user["uid"].split('_')[0]
    job = random.choice(job)
    age = random.randint(24,49)
    credit_card_num = user["ccnum"]
    status = random.choice(["active", "inactive", "disabled"])

    bunch_users.append((userid, name, job, age, credit_card_num, status))

timestart = int(dt.now().strftime("%s"))

print("writing customers to database")
cur.executemany(
    """INSERT INTO customers(userid, name, job, age, credit_card_num, status) VALUES(%s, %s, %s, %s, %s, %s)""",
    bunch_users
)

db.commit()
db.close()
timefinish = int(dt.now().strftime("%s"))
print("finish")
print("inserted {} records in {}s".format(records, timefinish-timestart))
</code></pre>

<h2>Thanks</h2>

<p>Thanks for reading, so this was kind of interesting to see to never do sequential writes but write them in bulk when you have large amount of writes.</p>
]]></content>
  </entry>
  
</feed>
