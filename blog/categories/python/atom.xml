<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-08-29T15:44:48-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Improving Performance From Your Lambda Function From the Use of Global Variables]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/27/improving-performance-from-your-lambda-function-from-the-use-of-global-variables/"/>
    <updated>2018-08-27T08:30:30-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/27/improving-performance-from-your-lambda-function-from-the-use-of-global-variables</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/aws-logo.png" alt="" /></p>

<p>When using Lambda and DynamoDB, you can use global variables to gain performance when your data from DynamoDB does not get updated that often, and you would like to use caching to prevent a API call to DynamoDB everytime your Lambda Function gets invoked.</p>

<p>You can use external services like Redis or Memcached when you would like to verify that each invocation is as true as your source of truth which will be DynamoDB. Then your application logic can work with caching.</p>

<p>But in this case we just want a simple piece of code that can keep the state for the remaining time that the function is running on that underlying container. I am not 100% sure, but I have seen that the data can be cached for up to 60 minutes. This can be a total mess when your data gets updated regularly, then I would set all my calls in functions, as the global variables keeps their state for some time.</p>

<h2>Example Function:</h2>

<p>This function gets data from DynamoDB, iterates through a small dataset (10 Items), and appends each group name to my list which is the value of my <code>groups</code> key inside my dictionary.</p>

<p>Due to my global variable <code>mydata</code>, you will see that the first invocation will result in a API call to DynamoDB as the length of my <code>mydata["groups"]</code> being 0, the second invocation, the data will exist inside my global variable, therefore I am returning the data directly from my variable.</p>

<pre><code class="python">import boto3, json

client = boto3.resource('dynamodb', region_name='eu-west-1')
tbl = client.Table('my-dynamo-table')

mydata = {}
mydata["groups"] = []

def lambda_handler(event, context):
    if len(mydata["groups"]) == 0:
        # data is not cached, make call to dynamo
        data = tbl.scan()
        group_data = data['Items']

        for group in group_data:
            mydata["groups"].append(group['name'])
        return mydata

    else:
        # return cached content
        return mydata
</code></pre>

<h2>Results of my Invocations:</h2>

<p>The first call that I made:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/lambda-caching-miss.png" alt="" /></p>

<p>The second call that I made:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/lambda-caching-hit.png" alt="" /></p>

<p>If you need a small layer of caching that can improve your latency, this can be used. But if you need your data to be accurate from every call, rather looking into a different approach and external caching services.</p>

<h2>Resources:</h2>

<p><em>Take advantage of Execution Context reuse to improve the performance of your function.</em>:</p>

<p>&ldquo;Make sure any externalized configuration or dependencies that your code retrieves are stored and referenced locally after initial execution. Limit the re-initialization of variables/objects on every invocation. Instead use static initialization/constructor, global/static variables and singletons. Keep alive and reuse connections (HTTP, database, etc.) that were established during a previous invocation.&rdquo;</p>

<ul>
<li><a href="https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html">https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html</a></li>
<li><a href="https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/">https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Send Emails Using Python and Sendgrid Using SMTPlib]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/21/send-emails-using-python-and-sendgrid-using-smtplib/"/>
    <updated>2018-08-21T11:30:08-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/21/send-emails-using-python-and-sendgrid-using-smtplib</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/sendgrid-logo.png" alt="" /></p>

<p>Quick tutorial on how to send emails using Python and smtplib.</p>

<h2>Sendgrid</h2>

<p>Sendgrid offers 100 free outbound emails per day, sign up with them via <a href="https://sendgrid.com/free/">sendgrid.com/free</a>, create a API Key and save your credentials in a safe place.</p>

<p>You first need to verify your account by sending a mail using their API, but it&rsquo;s step by step so won&rsquo;t take more than 2 minutes to complete.</p>

<h2>Python Code</h2>

<p>Once the verification is completed, our Python Code:</p>

<pre><code class="python">import smtplib
from email.MIMEMultipart import MIMEMultipart
from email.MIMEText import MIMEText

mail_from = 'Ruan Bekker &lt;ruan@ruanbekker.com&gt;'
mail_to = 'Ruan Bekker &lt;xxxx@gmail.com&gt;'

msg = MIMEMultipart()
msg['From'] = mail_from
msg['To'] = mail_to
msg['Subject'] = 'Sending mails with Python'
mail_body = """
Hey,

This is a test.

Regards,\nRuan

"""
msg.attach(MIMEText(mail_body))

try:
    server = smtplib.SMTP_SSL('smtp.sendgrid.net', 465)
    server.ehlo()
    server.login('apikey', 'your-api-key')
    server.sendmail(mail_from, mail_to, msg.as_string())
    server.close()
    print("mail sent")
except:
    print("issue")
</code></pre>

<p>When I ran the code, I received the mail, and when you inspect the headers you can see that the mail came via sendgrid:</p>

<pre><code>Received: from xx.xx.s2shared.sendgrid.net (xx.xx.s2shared.sendgrid.net. [xx.xx.xx.xx])
</code></pre>

<h2>Resources:</h2>

<p>Great post on SSL / TLS:
- <a href="https://stackabuse.com/how-to-send-emails-with-gmail-using-python/">https://stackabuse.com/how-to-send-emails-with-gmail-using-python/</a></p>

<p>Enjoy :D</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using IAM Authentication With Amazon Elasticsearch Service]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/20/using-iam-authentication-with-amazon-elasticsearch-service/"/>
    <updated>2018-08-20T04:12:21-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/20/using-iam-authentication-with-amazon-elasticsearch-service</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/aws-logo.png" alt="" /></p>

<p>Today I will demonstrate how to allow access to Amazons Elasticsearch Service using IAM Authenticationi using AWS Signature Version4.</p>

<h2>Elasticsearch Service Authentication Support:</h2>

<p>When it comes to security, Amazons Elasticsearch Service supports three types of access policies:</p>

<ul>
<li>Resource Based</li>
<li>Identity Based</li>
<li>IP Access Based</li>
</ul>


<p>More information on this can be found below:
- <a href="https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-ac.html">https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-ac.html</a></p>

<h2>Securing your Amazon Elasticsearch Search Domain:</h2>

<p>To secure your domain with IAM Based Authentication, the following steps will be neeed:</p>

<ul>
<li>Create IAM Policy to be associated with a IAM User or Role</li>
<li>On Elasticsearch Access Policy, associate the ARN to the Resource</li>
<li>Use the AWS4Auth package to sign the requests as AWS supports Signature Version 4</li>
</ul>


<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "es:*"
            ],
            "Resource": "arn:aws:es:eu-west-1:&lt;ACCOUNT-ID&gt;:domain/&lt;ES-DOMAIN&gt;"
        }
    ]
}
</code></pre>

<p>Create the IAM Role with EC2 Identity Provider as a Trusted Relationship eg. es-role and associate the IAM Policy es-policy to the role.</p>

<p>Create/Moodify the Elasticsearch Access Policy, in this example we will be using a combination of IAM Role, IAM User and IP Based access:</p>

<ul>
<li>IAM Role for EC2 Role Based Services</li>
<li>IAM User for User/System Account</li>
<li>IP Based for cients that needs to be whitelisted via IP (ip-based just for demonstration, as the tests will be used only for IAM)</li>
</ul>


<pre><code class="json">{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": [
          "arn:aws:iam::&lt;ACCOUNT-ID&gt;:role/&lt;IAM-ROLE-NAME&gt;",
          "arn:aws:iam::&lt;ACCOUNT-ID&gt;:user/&lt;IAM-USER-NAME&gt;"
        ]
      },
      "Action": "es:*",
      "Resource": "arn:aws:es:eu-west-1:&lt;ACCOUNT-ID&gt;:domain/&lt;ES-DOMAIN&gt;/*"
    },
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "*"
      },
      "Action": "es:*",
      "Resource": "arn:aws:es:eu-west-1:&lt;ACCOUNT-ID&gt;:domain/&lt;ES-DOMAIN&gt;/*",
      "Condition": {
        "IpAddress": {
          "aws:SourceIp": [
            "x.x.x.x",
            "x.x.x.x"
          ]
        }
      }
    }
  ]
}
</code></pre>

<p>After the Access Policy has been updated, the Elasticsearch Domain Status will show <code>Active</code></p>

<h2>Testing from EC2 using IAM Instance Profile:</h2>

<p>Launch a EC2 Instance with the IAM Role eg. es-role, then using Python, we will make a request to our Elasticsearch Domain using boto3, aws4auth and the native elasticsearch client for python via our IAM Role, which we will get the temporary credentials from boto3.Session.</p>

<p>Installing the dependencies:</p>

<pre><code class="bash">$ pip install virtualenv
$ virtualenv .venv
$ source .venv/bin/activate
$ pip install boto3 elasticsearch requests_aws4auth
</code></pre>

<p>Our code:</p>

<pre><code class="python">import boto3, json
from elasticsearch import Elasticsearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth

my_region = 'eu-west-1'
my_service = 'es'
my_eshost = 'search-replaceme.eu-west-1.es.amazonaws.com'

session = boto3.Session(region_name=my_region) # thanks Leon
credentials = session.get_credentials()
credentials = credentials.get_frozen_credentials()
access_key = credentials.access_key
secret_key = credentials.secret_key
token = credentials.token

aws_auth = AWS4Auth(
    access_key,
    secret_key,
    my_region,
    my_service,
    session_token=token
)

es = Elasticsearch(
    hosts = [{'host': my_eshost, 'port': 443}],
    http_auth=aws_auth,
    use_ssl=True,
    verify_certs=True,
    connection_class=RequestsHttpConnection
)

print(json.dumps(es.info(), indent=2))
</code></pre>

<p>Running our piece of code, will result in this:</p>

<pre><code class="bash">$ python get-info-from-role.py
{
  "cluster_name": "&lt;ACCOUNT-ID&gt;:&lt;ES-DOMAIN&gt;",
  "cluster_uuid": "sLUnqFSsQdCMlBLrn7BTUA",
  "version": {
    "lucene_version": "6.6.0",
    "build_hash": "Unknown",
    "build_snapshot": false,
    "number": "5.5.2",
    "build_date": "2017-10-18T04:35:01.381Z"
  },
  "name": "KXSwBvT",
  "tagline": "You Know, for Search"
}
</code></pre>

<h2>Testing using IAM Credentials from Credentials Provider:</h2>

<p>Configure your credentials provider:</p>

<pre><code class="bash">$ pip install awscli
$ aws configure --profile ruan
AWS Access Key ID [None]: xxxxxxxxx
AWS Secret Access Key [None]: xxxxxx
Default region name [None]: eu-west-1
Default output format [None]: json
</code></pre>

<p>Using Python, we will get the credentials from the Credential Provider, using our profile name:</p>

<pre><code class="python">import boto3, json
from elasticsearch import Elasticsearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth

my_service = 'es'
my_region = 'eu-west-1'
my_eshost = 'search-replaceme.eu-west-1.es.amazonaws.com'

session = boto3.Session(
    region_name=my_region,
    profile_name='ruan'
)

credentials = session.get_credentials()
access_key = credentials.access_key
secret_key = credentials.secret_key

aws_auth = AWS4Auth(
    access_key,
    secret_key,
    my_region,
    my_service
)

es = Elasticsearch(
    hosts = [{'host': my_eshost, 'port': 443}],
    http_auth=aws_auth,
    use_ssl=True,
    verify_certs=True,
    connection_class=RequestsHttpConnection
)

print(json.dumps(es.info(), indent=2))
</code></pre>

<p>Running it will result in:</p>

<pre><code class="bash">$ python get-info-from-user.py
{
  "cluster_name": "&lt;ACCOUNT-ID&gt;:&lt;ES-DOMAIN&gt;",
  "cluster_uuid": "sLUnqFSsQdCMlBLrn7BTUA",
  "version": {
    "lucene_version": "6.6.0",
    "build_hash": "Unknown",
    "build_snapshot": false,
    "number": "5.5.2",
    "build_date": "2017-10-18T04:37:21.381Z"
  },
  "name": "KXSwBvT",
  "tagline": "You Know, for Search"
}
</code></pre>

<p>For more blog posts on Elasticsearch have a look at:
- <a href="http://blog.ruanbekker.com/blog/categories/elasticsearch">blog.ruanbekker.com:elasticsearch</a>
- <a href="https://sysadmins.co.za/tags/elasticsearch">sysadmins.co.za:elasticsearch</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Get Blogpost Titles Links and Tags From a RSS Link Using Python Feedparser]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/08/15/get-blogpost-titles-links-and-tags-from-a-rss-link-using-python-feedparser/"/>
    <updated>2018-08-15T18:14:54-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/08/15/get-blogpost-titles-links-and-tags-from-a-rss-link-using-python-feedparser</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/python-logo.png" alt="" /></p>

<p>I wanted to get metadata from my other blog <a href="https://sysadmins.co.za">sysadmins.co.za</a>, such as each post&rsquo;s title, link and tags using the RSS link. I stumbled upon <code>feedparser</code>, where I will use it to scrape all the posts details from the link and append it to a list, which I can then use to ingest it into a database or something like that.</p>

<h2>Installing Dependencies:</h2>

<p>Install feedparser and requests:</p>

<pre><code class="bash">$ pip install feedparser requests
</code></pre>

<h2>The Python Code:</h2>

<p>I&rsquo;m not too sure at this point how to get pagination going, so I&rsquo;ve set a range to check, and if a status code of <code>200</code> is received, it will check if the title is in the list that I defined, if not, it will append it to the list.</p>

<p>At the end of the loop, the script will return the list that was defined, which will provide the info mentioned earlier:</p>

<pre><code class="python">import feedparser
import time
import requests

rss_url = "https://sysadmins.co.za/rss"

posts = []

def get_posts_for_ghost(rss_url):
    response = feedparser.parse(rss_url)
    for each in response['entries']:
        if each['title'] in [x['title'] for x in posts]:
            pass
        else:
            posts.append({
                "title": each['title'],
                "link": each['links'][0]['href'],
                "tags": [x['term'] for x in each['tags']],
                "date": time.strftime('%Y-%m-%d', each['published_parsed'])
            })
    return posts

count = 12

for x in range(count):
    if requests.get("{0}/{1}/".format(rss_url, count)).status_code == 200:
        print("get succeeded, count at: {}".format(count))
        get_posts_for_ghost("{0}/{1}/".format(rss_url, count))
        count -= 1
    else:
        print("got 404, count at: {}".format(count))
        count -= 1

    get_posts_for_ghost(rss_url)

print(posts)
</code></pre>

<h2>Running the script:</h2>

<p>Running the script will look something like this:</p>

<pre><code class="bash">$ python rssfeed.py
got 404, count at: 12
got 404, count at: 11
got 404, count at: 10
get succeeded, count at: 9
get succeeded, count at: 8
get succeeded, count at: 7
get succeeded, count at: 6
get succeeded, count at: 5
get succeeded, count at: 4
get succeeded, count at: 3
get succeeded, count at: 2
get succeeded, count at: 1
[
  {
    'title': 'Tutorial on DynamoDB using Bash and the AWS CLI Tools to Interact with a Music Dataset', 
    'link': 'https://sysadmins.co.za/tutorial-on-dynamodb-using-bash-and-the-aws-cli-tools-to-interact-with-a-music-dataset/',
    'tags': ['DynamoDB', 'Bash', 'AWS'], 
    'date': '2018-08-15'
  },
  {
    'title': 'Setup a PPTP VPN on Ubuntu 16', 
    'link': 'https://sysadmins.co.za/setup-a-pptp-vpn-on-ubuntu-16/', 
    'tags': ['Networking', 'VPN'], 
    'date': '2018-06-27'
  },
  ...
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Capture Geo Location Data With Python Flask and PyGeoIP]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/07/16/capture-geo-location-data-with-python-flask-and-pygeoip/"/>
    <updated>2018-07-16T17:46:01-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/07/16/capture-geo-location-data-with-python-flask-and-pygeoip</id>
    <content type="html"><![CDATA[<p>With the PyGeoIP package you can capture geo location data, which is pretty cool, for example, when you have IOT devices pushing location data to elasticsearch and visualizing the data with Kibana. That will be one example, but the possibilites are endless.</p>

<h2>Dependencies:</h2>

<p>Get the Maxmind Geo Database:</p>

<pre><code class="bash">$ wget -N http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz
$ gunzip GeoLiteCity.dat.gz
</code></pre>

<p>Install Python Flask and PyGeoIP:</p>

<pre><code class="bash">$ pip install flask pygeoip
</code></pre>

<h2>Getting Started with PyGeoIP:</h2>

<p>Let&rsquo;s run through a couple of examples on how to get:</p>

<ul>
<li>Country Name by IP Address and DNS</li>
<li>Country Code by IP Address and DNS</li>
<li>GeoData by IP Address</li>
</ul>


<pre><code class="python">&gt;&gt;&gt; import pygeoip, json
&gt;&gt;&gt; gi = pygeoip.GeoIP('GeoLiteCity.dat')

&gt;&gt;&gt; gi.country_name_by_addr('8.8.8.8')
'United States'
&gt;&gt;&gt; gi.country_code_by_addr('8.8.8.8')
'US'

&gt;&gt;&gt; gi.country_name_by_name('scaleway.com')
'France'
&gt;&gt;&gt; gi.country_code_by_name('scaleway.com')
'FR'

&gt;&gt;&gt; gi.region_by_name('scaleway.com')
{'region_code': None, 'country_code': 'FR'}

&gt;&gt;&gt; data = gi.record_by_addr('104.244.42.193')
&gt;&gt;&gt; print(json.dumps(data, indent=2))
{
  "city": "San Francisco",
  "region_code": "CA",
  "area_code": 415,
  "time_zone": "America/Los_Angeles",
  "dma_code": 807,
  "metro_code": "San Francisco, CA",
  "country_code3": "USA",
  "latitude": 37.775800000000004,
  "postal_code": "94103",
  "longitude": -122.4128,
  "country_code": "US",
  "country_name": "United States",
  "continent": "NA"
}

&gt;&gt;&gt; data = gi.record_by_name('twitter.com')
&gt;&gt;&gt; print(json.dumps(data, indent=2))
{
  "city": "San Francisco",
  "region_code": "CA",
  "area_code": 415,
  "time_zone": "America/Los_Angeles",
  "dma_code": 807,
  "metro_code": "San Francisco, CA",
  "country_code3": "USA",
  "latitude": 37.775800000000004,
  "postal_code": "94103",
  "longitude": -122.4128,
  "country_code": "US",
  "country_name": "United States",
  "continent": "NA"
}
</code></pre>

<h2>Python Flask Web App to Capture Data</h2>

<p>Let&rsquo;s create a basic Flask App that will capture the data from the client making the request to the server. In this example we will just return the data, but we can filter the data and ingest it into a database like elasticsearch, etc.</p>

<pre><code class="python">from flask import Flask, request, jsonify
import pygeoip, json

app = Flask(__name__)

geo = pygeoip.GeoIP('GeoLiteCity.dat', pygeoip.MEMORY_CACHE)

@app.route('/')
def index():
    client_ip = request.remote_addr
    geo_data = geo.record_by_addr(client_ip)
    return json.dumps(geo_data, indent=2) + '\n'

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=80, debug=False)
</code></pre>

<p>Run the Server:</p>

<pre><code class="bash">$ python app.py
</code></pre>

<p>Make a request from the client over a remote connection:</p>

<pre><code class="bash">$ curl http://remote-endpoint.com
{
  "city": "Cape Town",
  "region_code": "11",
  "area_code": 0,
  "time_zone": "Africa/Johannesburg",
  "dma_code": 0,
  "metro_code": null,
  "country_code3": "ZAF",
  "latitude": -01.12345,
  "postal_code": "8000",
  "longitude": 02.123456789,
  "country_code": "ZA",
  "country_name": "South Africa",
  "continent": "AF"
}
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="http://pygeoip.readthedocs.io/en/latest/getting-started.html">PyGeoIP</a></li>
<li><a href="https://dev.maxmind.com/geoip/legacy/install/city/">MaxMind</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
