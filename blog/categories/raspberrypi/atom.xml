<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Raspberrypi | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/raspberrypi/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-10-23T17:24:12-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Building a Raspberry Pi Nginx Image With Caching on Alpine for Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm/"/>
    <updated>2018-10-23T17:00:02-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/building-a-raspberry-pi-nginx-image-with-caching-on-alpine-for-docker-swarm</id>
    <content type="html"><![CDATA[<p>In this guide, we will be creating a nginx reverse proxy with the ability to cache static content using a alpine image.</p>

<p>We will then push the image to gitlab&rsquo;s private registry, and then run the service on docker swarm.</p>

<h2>Create the backend service:</h2>

<p>We will upstream to our blog using ghost, which you can deploy using:</p>

<pre><code class="bash">$ docker service create --name blog --network docknet rbekker87/armhf-ghost:2.0.3
</code></pre>

<h2>Current File Structure:</h2>

<p>Our file structure for the assets we need to build the reverse proxy:</p>

<pre><code>$ find .
./conf.d
./conf.d/blog.conf
./Dockerfile
./nginx.conf
</code></pre>

<ul>
<li><code>Dockerfile</code></li>
</ul>


<pre><code>FROM hypriot/rpi-alpine-scratch
MAINTAINER Ruan Bekker

RUN apk update &amp;&amp; \
    apk add nginx &amp;&amp; \
    rm -rf /etc/nginx/nginx.conf &amp;&amp; \
    chown -R nginx:nginx /var/lib/nginx &amp;&amp; \
    rm -rf /var/cache/apk/*

ADD nginx.conf /etc/nginx/
ADD conf.d/blog.conf /etc/nginx/conf.d/

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
</code></pre>

<ul>
<li><code>nginx.conf</code></li>
</ul>


<pre><code>user nginx;
worker_processes 1;

events {
    worker_connections 1024;
    }

error_log  /var/log/nginx/nginx_error.log warn;

http {

    sendfile          on;
    tcp_nodelay       on;

    gzip              on;
    gzip_http_version 1.0;
    gzip_proxied      any;
    gzip_min_length   500;
    gzip_disable      "MSIE [1-6]\.";
    gzip_types        text/plain text/xml text/css
                      text/comma-separated-values
                      text/javascript
                      application/x-javascript
                      application/atom+xml;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;
    error_log   /var/log/nginx/error.log;

    proxy_cache_path /var/cache/nginx/ levels=1:2 keys_zone=nginx_cache:5m max_size=128m inactive=60m;

    keepalive_timeout  60;
    server_tokens      off;

    include /etc/nginx/conf.d/*.conf;

}
</code></pre>

<p>Hostname resolution to our Ghost Blog Service: In our swarm we have a service called blog which is associated to the docknet network, so the dns resolution will resolve to the vip of the service. As seen in the figure below:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
nq42a6jfwx3d        blog                replicated          1/1                 rbekker87/armhf-ghost:2.0.3
</code></pre>

<ul>
<li><code>conf.d/blog.conf</code></li>
</ul>


<pre><code>upstream ghost_blog {
    server blog:2368;
    }

server {
    listen 80;
    server_name blog.yourdomain.com;

    access_log  /var/log/nginx/blog_access.log  main;
    error_log   /var/log/nginx/blog_error.log;

    location / {

        proxy_cache                 nginx_cache;
        add_header                  X-Proxy-Cache $upstream_cache_status;
        proxy_ignore_headers        Cache-Control;
        proxy_cache_valid any       10m;
        proxy_cache_use_stale       error timeout http_500 http_502 http_503 http_504;

        proxy_pass                  http://ghost_blog;
        proxy_redirect              off;

        proxy_set_header            Host $host;
        proxy_set_header            X-Real-IP $remote_addr;
        proxy_set_header            X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header            X-Forwarded-Host $server_name;
    }
}
</code></pre>

<h2>Building the Image and Pushing to Gitlab</h2>

<p>I&rsquo;m using Gitlab in this demonstration, but you can use the registry of your choice:</p>

<pre><code>$ docker login registry.gitlab.com
$ docker build -t registry.gitlab.com/user/docker/arm-nginx:caching .
$ docker tag registry.gitlab.com/user/docker/arm-nginx:caching registry.gitlab.com/user/docker/arm-nginx:caching
$ docker push registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<h2>Deploy</h2>

<p>Create the Nginx Reverse Proxy Service on Docker Swarm:</p>

<pre><code>$ docker service create --name nginx_proxy \
--network docknet \
--publish 80:80 \
--replicas 1 \
--with-registry-auth registry.gitlab.com/user/docker/arm-nginx:caching
</code></pre>

<p>Listing our Services:</p>

<pre><code>$ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
je7x21l7egoh        nginx_proxy         replicated          1/1                 registry.gitlab.com/user/docker/arm-nginx:caching   *:80-&gt;80/tcp
nq42a6jfwx3d        blog                replicated          1/1                 alexellis2/ghost-on-docker:armv7
</code></pre>

<p>Once you access your proxy on port 80, you should see your Ghost Blog Homepage like below:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/ghost-blog-main.png" alt="" /></p>

<p>Have a look at the <a href="https://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/">benchmark performance</a> when using Nginx with caching enabled</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/r/rbekker87/armhf-ghost/">https://hub.docker.com/r/rbekker87/armhf-ghost/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx Caching Performance for Static Content on Docker Swarm With RaspberryPi]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi/"/>
    <updated>2018-10-23T16:41:41-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/nginx-caching-performance-for-static-content-on-docker-swarm-with-raspberrypi</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/nginx-logo.png" alt="" /></p>

<h2>The Environment:</h2>

<p>I had my Ghost Blog listening on port 2368 and exposing port 80 on Docker so that the port translation directs port 80 traffic to port 2368 on Ghost directly.</p>

<p>Alex responded on my tweet and introduced Nginx Caching:</p>

<ul>
<li><a href="https://twitter.com/alexellisuk/status/882347698636165121">https://twitter.com/alexellisuk/status/882347698636165121</a></li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/tweet-alexellis-04072017.png" alt="" /></p>

<p>With this approach benchmarking results was not so great in terms of requests per second, and as this hostname will be only used for a blog, its a great idea to cache the content, this was achieved with the help from Alex&rsquo;s blog: <a href="https://blog.alexellis.io/save-and-boost-with-nginx/">blog.alexellis.io/save-and-boost-with-nginx/</a></p>

<h2>How Nginx was Configured:</h2>

<p>I have a <a href="http://rbkr.ddns.net/building-nginx-on-alpine-image-for-docker-swarm-with-caching-enabled-config/">blogpost</a> on how I setup Nginx on an Alpine Image, where I setup caching and proxy-pass the connections through to my ghost blog.</p>

<h2>Benchmarking: Before Nginx with Caching was Implemented:</h2>

<p>When doing an apache benchmark I got <b>9.31 requests per second</b> performing the test on my LAN:</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://rbkr.ddns.net/

This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking rbkr.ddns.net (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   53.725 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2863000 bytes
HTML transferred:       2735000 bytes
Requests per second:    9.31 [#/sec] (mean)
Time per request:       1074.501 [ms] (mean)
Time per request:       107.450 [ms] (mean, across all concurrent requests)
Transfer rate:          52.04 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        1    2   0.5      2       6
Processing:   685 1068  68.7   1057    1306
Waiting:      683 1067  68.6   1056    1306
Total:        689 1070  68.7   1058    1312

Percentage of the requests served within a certain time (ms)
  50%   1058
  66%   1088
  75%   1102
  80%   1110
  90%   1163
  95%   1218
  98%   1240
  99%   1247
 100%   1312 (longest request)
</code></pre>

<h2>Benchmarking: After Nginx Caching was Implemented:</h2>

<p>After Nginx Caching was Implemented, I got <b>1067.73 requests per second</b> using apache benchmark over a LAN connection! Absolutely awesome!</p>

<pre><code class="bash">$ ab -n 500 -c 10 http://blog.pistack.co.za/
This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking blog.pistack.co.za (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Finished 500 requests


Server Software:        nginx
Server Hostname:        blog.pistack.co.za
Server Port:            80

Document Path:          /
Document Length:        5470 bytes

Concurrency Level:      10
Time taken for tests:   0.468 seconds
Complete requests:      500
Failed requests:        0
Total transferred:      2880500 bytes
HTML transferred:       2735000 bytes
Requests per second:    1067.73 [#/sec] (mean)
Time per request:       9.366 [ms] (mean)
Time per request:       0.937 [ms] (mean, across all concurrent requests)
Transfer rate:          6007.05 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        3    4   1.4      4      10
Processing:     3    5   1.6      4      10
Waiting:        2    4   1.6      4      10
Total:          6    9   2.7      8      17

Percentage of the requests served within a certain time (ms)
  50%      8
  66%      8
  75%      9
  80%      9
  90%     15
  95%     15
  98%     15
  99%     16
 100%     17 (longest request)
</code></pre>

<h2>Resources:</h2>

<p>Thanks to Alex Ellis for the suggestion on this, and definitely have a look at <a href="https://blog.alexellis.io/tag/nginx/">blog.alexellis.io</a> as he has some epic content on his blog!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting Up a Docker Swarm Cluster on 3 RaspberryPi Nodes]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes/"/>
    <updated>2018-10-23T16:24:00-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/rpi-docker-swarm.png" alt="" /></p>

<p>As the curious person that I am, I like to play around with new stuff that I stumble upon, and one of them was having a docker swarm cluster running on 3 Raspberry Pi&rsquo;s on my LAN.</p>

<p>The idea is to have 3 Raspberry Pi&rsquo;s (Model 3 B), a Manager Node, and 2 Worker Nodes, each with a 32 GB SanDisk SD Card, which I will also be part of a 3x Replicated GlusterFS Volume that will come in handy later for some data that needs persistent data.</p>

<p>More Inforamtion on: <a href="https://docs.docker.com/engine/swarm/">Docker Swarm</a></p>

<h2>Provision Raspbian on each RaspberryPi</h2>

<p>Grab the <a href="https://downloads.raspberrypi.org/raspbian_lite_latest">Latest Raspbian Lite ISO</a> and the following <a href="https://www.raspberrypi.org/documentation/installation/installing-images/">source</a> will help provisioning your RaspberryPi with Raspbian.</p>

<h2>Installing Docker on Raspberry PI</h2>

<p>On each node, run the following to install docker, and also add your user to the docker group, so that you can run docker commands with a normal user:</p>

<pre><code class="bash">$ apt-get update &amp;&amp; sudo apt-get upgrade -y
$ sudo apt-get remove docker.io
$ curl https://get.docker.com | sudo bash
$ sudo usermod -aG docker pi
</code></pre>

<p>If you have an internal DNS Server, set an A Record for each node, or for simplicity, set your hosts file on each node so that your hostname for each node responds to it&rsquo;s provisioned IP Address:</p>

<pre><code class="bash">$ cat /etc/hosts
192.168.0.2   rpi-01
192.168.0.3   rpi-02
192.168.0.4   rpi-03
</code></pre>

<p>Also, to have passwordless SSH, from each node:</p>

<pre><code class="bash">$ ssh-keygen -t rsa
$ ssh-copy-id rpi-01
$ ssh-copy-id rpi-02
$ ssh-copy-id rpi-03
</code></pre>

<h2>Initialize the Swarm</h2>

<p>Time to set up our swarm. As we have more than one network interface, we will need to setup our swarm by specifying the IP Address of our network interface that is accessible from our LAN:</p>

<pre><code class="bash">$ ifconfig eth0
eth0      Link encap:Ethernet  HWaddr a1:12:bc:d3:cd:4d
          inet addr:192.168.0.2  Bcast:192.168.0.255  Mask:255.255.255.0
</code></pre>

<p>Now that we have our IP Address, initialize the swarm on the manager node:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker swarm init --advertise-addr 192.168.0.2
Swarm initialized: current node (siqyf3yricsvjkzvej00a9b8h) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 \
    192.168.0.2:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.  
</code></pre>

<p>Then from <code>rpi-02</code> join the manager node of the swarm:</p>

<pre><code class="bash">pi@rpi-02:~ $ docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.168.0.2:2377
This node joined a swarm as a worker.  
</code></pre>

<p>Then from <code>rpi-03</code> join the manager node of the swarm:</p>

<pre><code class="bash">pi@rpi-03:~ $ docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.168.0.2:2377
This node joined a swarm as a worker.  
</code></pre>

<p>Then from the manager node: <code>rpi-01</code>, ensure that the nodes are checked in:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS
62s7gx1xdm2e3gp5qoca2ru0d     rpi-03              Ready               Active
6fhyfy9yt761ar9pl84dkxck3 *   rpi-01              Ready               Active              Leader
pg0nyy9l27mtfc13qnv9kywe7     rpi-02              Ready               Active
</code></pre>

<h2>Setting Up a Replicated GlusterFS Volume</h2>

<p>I have decided to setup a replicated glusterfs volume to have data replicated throughout the cluster if I would like to have some persistent data. From each node, install the GlusterFS Client and Server:</p>

<pre><code class="bash">$ sudo apt install glusterfs-server glusterfs-client -y &amp;&amp; sudo systemctl enable glusterfs-server
</code></pre>

<p>Probe the other nodes from the manager node:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster peer probe rpi-02
peer probe: success.

pi@rpi-01:~ $ sudo gluster peer probe rpi-03
peer probe: success.
</code></pre>

<p>Ensure that we can see all 3 nodes in our GlusterFS Pool:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster pool list
UUID                                    Hostname        State
778c7463-ba48-43de-9f97-83a960bba99e    rpi-02          Connected
00a20a3c-5902-477e-a8fe-da35aa955b5e    rpi-03          Connected
d82fb688-c50b-405d-a26f-9cb2922cce75    localhost       Connected
</code></pre>

<p>From each node, create the directory where GlusterFS will store the data for the bricks that we will specify when creating the volume:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo mkdir -p /gluster/brick 
pi@rpi-02:~ $ sudo mkdir -p /gluster/brick
pi@rpi-03:~ $ sudo mkdir -p /gluster/brick
</code></pre>

<p>Next, create a 3 Way Replicated GlusterFS Volume:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster volume create rpi-gfs replica 3 \
rpi-01:/gluster/brick \
rpi-02:/gluster/brick \
rpi-03:/gluster/brick \
force

volume create: rpi-gfs: success: please start the volume to access data
</code></pre>

<p>Start the GlusterFS Volume:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster volume start rpi-gfs
volume start: rpi-gfs: success
</code></pre>

<p>Verify the GlusterFS Volume Info, and from the below output you will see that the volume is replicated 3 ways from the 3 bricks that we specified</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo gluster volume info

Volume Name: rpi-gfs
Type: Replicate
Volume ID: b879db15-63e9-44ca-ad76-eeaa3e247623
Status: Started
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: rpi-01:/gluster/brick
Brick2: rpi-02:/gluster/brick
Brick3: rpi-03:/gluster/brick
</code></pre>

<p>Mount the GlusterFS Volume on each Node, first on <code>rpi-01</code>:</p>

<pre><code class="bash">pi@rpi-01:~ $ sudo umount /mnt
pi@rpi-01:~ $ sudo echo 'localhost:/rpi-gfs /mnt glusterfs defaults,_netdev,backupvolfile-server=localhost 0 0' &gt;&gt; /etc/fstab
pi@rpi-01:~ $ sudo mount.glusterfs localhost:/rpi-gfs /mnt
pi@rpi-01:~ $ sudo chown -R pi:docker /mnt
</code></pre>

<p>Then on <code>rpi-02</code>:</p>

<pre><code class="bash">pi@rpi-02:~ $ sudo umount /mnt
pi@rpi-02:~ $ sudo echo 'localhost:/rpi-gfs /mnt glusterfs defaults,_netdev,backupvolfile-server=localhost 0 0' &gt;&gt; /etc/fstab
pi@rpi-02:~ $ sudo mount.glusterfs localhost:/rpi-gfs /mnt
pi@rpi-02:~ $ sudo chown -R pi:docker /mnt
</code></pre>

<p>And lastly on <code>rpi-03</code>:</p>

<pre><code class="bash">pi@rpi-03:~ $ sudo umount /mnt
pi@rpi-03:~ $ sudo echo 'localhost:/rpi-gfs /mnt glusterfs defaults,_netdev,backupvolfile-server=localhost 0 0' &gt;&gt; /etc/fstab
pi@rpi-03:~ $ sudo mount.glusterfs localhost:/rpi-gfs /mnt
pi@rpi-03:~ $ sudo chown -R pi:docker /mnt
</code></pre>

<p>Then your GlusterFS Volume will be mounted on all the nodes, and when a file is written to the <code>/mnt/</code> partition, data will be replicated to all the nodes in the Cluster:</p>

<pre><code class="bash">pi@rpi-01:~ $ df -h
Filesystem          Size  Used Avail Use% Mounted on
/dev/root            30G  4.5G   24G  16% /
localhost:/rpi-gfs   30G  4.5G   24G  16% /mnt
</code></pre>

<h2>Create a Web Service on Docker Swarm:</h2>

<p>Let&rsquo;s create a Web Service in our Swarm, called <code>web</code> and by specifying <code>1</code> replica and publishing the exposed port <code>80</code> to our containers port <code>80</code>:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service create --name web --replicas 1 --publish 80:80 hypriot/rpi-busybox-httpd
vsvyanuw6q6yf4jr52m5z7vr1
</code></pre>

<p>Verifying that our Service is Started and equals to the desired replica count:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
vsvyanuw6q6y        web                 replicated          1/1                 hypriot/rpi-busybox-httpd:latest                         *:891-&gt;80/tcp
</code></pre>

<p>Inspecting the Service:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service inspect web
[
    {
        "ID": "vsvyanuw6q6yf4jr52m5z7vr1",
        "Version": {
            "Index": 2493
        },
        "CreatedAt": "2017-07-16T21:20:00.017836646Z",
        "UpdatedAt": "2017-07-16T21:20:00.026359794Z",
        "Spec": {
            "Name": "web",
            "Labels": {},
            "TaskTemplate": {
                "ContainerSpec": {
                    "Image": "hypriot/rpi-busybox-httpd:latest@sha256:c00342f952d97628bf5dda457d3b409c37df687c859df82b9424f61264f54cd1",
                    "StopGracePeriod": 10000000000,
                    "DNSConfig": {}
                },
                "Resources": {
                    "Limits": {},
                    "Reservations": {}
                },
                "RestartPolicy": {
                    "Condition": "any",
                    "Delay": 5000000000,
                    "MaxAttempts": 0
                },
                "Placement": {},
                "ForceUpdate": 0
            },
            "Mode": {
                "Replicated": {
                    "Replicas": 1
                }
            },
            "UpdateConfig": {
                "Parallelism": 1,
                "FailureAction": "pause",
                "Monitor": 5000000000,
                "MaxFailureRatio": 0,
                "Order": "stop-first"
            },
            "RollbackConfig": {
                "Parallelism": 1,
                "FailureAction": "pause",
                "Monitor": 5000000000,
                "MaxFailureRatio": 0,
                "Order": "stop-first"
            },
            "EndpointSpec": {
                "Mode": "vip",
                "Ports": [
                    {
                        "Protocol": "tcp",
                        "TargetPort": 80,
                        "PublishedPort": 80,
                        "PublishMode": "ingress"
                    }
                ]
            }
        },
        "Endpoint": {
            "Spec": {
                "Mode": "vip",
                "Ports": [
                    {
                        "Protocol": "tcp",
                        "TargetPort": 80,
                        "PublishedPort": 80,
                        "PublishMode": "ingress"
                    }
                ]
            },
            "Ports": [
                {
                    "Protocol": "tcp",
                    "TargetPort": 80,
                    "PublishedPort": 80,
                    "PublishMode": "ingress"
                }
            ],
            "VirtualIPs": [
                {
                    "NetworkID": "zjerz0xsw39icnh24enja4cgk",
                    "Addr": "10.255.0.13/16"
                }
            ]
        }
    }
]
</code></pre>

<p>Docker Swarm&rsquo;s Routing mesh takes care of the internal routing, so requests will respond even if the container is not running on the node that you are making the request against.</p>

<p>With that said, verifying on which node our service is running:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ps web
ID                  NAME                IMAGE                              NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS
sd67cd18s5m0        web.1               hypriot/rpi-busybox-httpd:latest   rpi-02              Running             Running 2 minutes ago
</code></pre>

<p>When we make a HTTP Request to one of these Nodes IP Addresses, our request will be responded with this awesome static page:</p>

<p><img src="https://objects.ruanbekker.com/assets/images/armed-with-hypriot.jpg" alt="" /></p>

<p>We can see we only have one container in our swarm, let&rsquo;s scale that up to <code>3</code> containers:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service scale web01=3
web01 scaled to 3
</code></pre>

<p>Now that the service is scaled to 3 containers, requests will be handled using the round-robin algorithm. To ensured that the service scaled, we will see that we will have 3 replicas:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE                                                    PORTS
vsvyanuw6q6y        web                 replicated          3/3                 hypriot/rpi-busybox-httpd:latest                         *:891-&gt;80/tcp
</code></pre>

<p>Verifying where these containers are running on:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service ps web01
ID                  NAME                IMAGE                              NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
sd67cd18s5m0        web.1               hypriot/rpi-busybox-httpd:latest   rpi-02              Running             Running 2 minutes ago
ope3ya7hh9j4        web.2               hypriot/rpi-busybox-httpd:latest   rpi-03              Running             Running 30 seconds ago
07m1ww7ptxro        web.3               hypriot/rpi-busybox-httpd:latest   rpi-01              Running             Running 28 seconds ago
</code></pre>

<p>Lastly, removing the service from our swarm:</p>

<pre><code class="bash">pi@rpi-01:~ $ docker service rm web01
web01
</code></pre>

<h2>Massive Thanks:</h2>

<p>a Massive thanks to <a href="https://twitter.com/alexellisuk">Alex Ellis</a> for mentioning me on one of his blogposts:</p>

<ul>
<li><a href="https://blog.alexellis.io/blog-community-inspiration/">https://blog.alexellis.io/blog-community-inspiration/</a></li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/tweet-alexellis-21072017.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My PiStack Blog Proudly Hosted on My RaspberryPi Swarm Cluster]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/my-pistack-blog-proudly-hosted-on-my-raspberrypi-swarm-cluster/"/>
    <updated>2018-10-23T16:11:19-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/my-pistack-blog-proudly-hosted-on-my-raspberrypi-swarm-cluster</id>
    <content type="html"><![CDATA[<p>This is a repost of my <a href="http://blog.pistack.co.za/my-blog-proudly-hosted-on-my-raspberrypi-cluster/">first blogpost which is hosted on my Raspberry Pi Cluster (04 July 2017)</a>, that runs Docker Swarm and is served from my Home in South Africa, and can be accessed on <a href="http://blog.pistack.co.za">http://blog.pistack.co.za</a></p>

<h2>Just Look at It!</h2>

<ul>
<li>3x Raspberry Pi 3 Model B</li>
<li>Quad Core 1.2GHz Broadcom BCM2837 64bit CPU</li>
<li>1GB RAM</li>
<li>BCM43438 wireless LAN and Bluetooth Low Energy (BLE) on board</li>
<li>3x 32GB Sandisk SD Cards (Replicated GlusterFS Volume for <code>/gluster</code> partition)</li>
<li>Upgraded switched Micro USB power source up to 2.5A</li>
</ul>


<p><img src="https://objects.ruanbekker.com/assets/images/rpi-cluster.jpg" alt="" /></p>

<h2>My Setup:</h2>

<p>I have 3x <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberrypi 3&rsquo;s</a>, each with a <a href="https://www.sandisk.com/home/memory-cards/sd-cards/ultra-sd">32GB SanDisk SD Card</a>, formatted with <a href="https://www.raspberrypi.org/downloads/raspbian/">Raspbian Jessie Lite</a>, powered by a <a href="https://www.pishop.co.za/store/rpi-power/anid%C3%A9es-6-port-50w-high-power-usb-hub-25aport">6 Port USB Hub</a> and networked with a <a href="https://m.takealot.com/#product_1?id=35258721">Totolink 5 Port Gigabit Switch</a>, but note that: <em>the Rpi does not support Gigabit Networking</em></p>

<p>For persistent storage I have setup a Replicated GlusterFS Volume across the 3 nodes.</p>

<p>More details on how I did the setup, can be found from the <a href="http://blog.pistack.co.za/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes/">Setting Up a Docker Swarm Cluster on RaspberryPi Nodes</a> blog post.</p>

<h2>Thanks!</h2>

<p>Thanks for the visit, I will blog about awesome Docker and RaspberryPi related stuff as my mind stumble along awesome ideas :)</p>
]]></content>
  </entry>
  
</feed>
