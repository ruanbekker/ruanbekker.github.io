<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: S3 | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/s3/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2019-04-02T05:24:10-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Python Boto3 and DreamHosts DreamObjects to Interact With Their Object Storage Offering]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/04/03/using-python-boto3-and-dreamhosts-dreamobjects-to-interact-with-their-object-storage-offering/"/>
    <updated>2018-04-03T07:19:27-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/04/03/using-python-boto3-and-dreamhosts-dreamobjects-to-interact-with-their-object-storage-offering</id>
    <content type="html"><![CDATA[<p><img src="https://i.snag.gy/uxK5qy.jpg" alt="" /></p>

<p>In this post I will demonstrate how to interact with Dreamhost&rsquo;s Object Storage Service Offering called DreamObjects using Python Boto3 library. Dreamhost offers Object Storage at great pricing, for more information have a look at their <a href="https://goo.gl/N7Xws8">Documentation</a></p>

<h2>Whats on the Menu:</h2>

<p>We will do the following:</p>

<ul>
<li>List Buckets</li>
<li>List Objects</li>
<li>Put Object</li>
<li>Get Object</li>
<li>Upload Object</li>
<li>Download Object</li>
<li>Delete Object(s)</li>
</ul>


<h2>Configuration</h2>

<p>First we need to configure credentials, by providing the access key and access secret key, that is provided by DreamHost:</p>

<pre><code class="bash">$ pip install awscli
$ aws configure --profile dreamhost
</code></pre>

<p>After your credentials is set to your profile, we will need to import boto3 and instantiate the s3 client with our profile name, region name and endpoint url:</p>

<pre><code class="python">&gt;&gt;&gt; import boto3
&gt;&gt;&gt; session = boto3.Session(region_name='us-west-2', profile_name='dreamhost')
&gt;&gt;&gt; s3 = session.client('s3', endpoint_url='https://objects-us-west-1.dream.io')
</code></pre>

<h2>List Buckets:</h2>

<p>To list our Buckets:</p>

<pre><code>&gt;&gt;&gt; response = s3.list_buckets()
&gt;&gt;&gt; print(response)
{u'Owner': {u'DisplayName': 'foobar', u'ID': 'foobar'}, u'Buckets': [{u'CreationDate': datetime.datetime(2017, 4, 15, 21, 51, 3, 921000, tzinfo=tzutc()), u'Name': 'ruanbucket'}], 'ResponseMetadata': {'HTTPStatusCode': 200, 'RetryAttempts': 0, 'HostId': '', 'RequestId': 'tx00000000000000003cd88-005ac361f5-foobar-default', 'HTTPHeaders': {'date': 'Tue, 03 Apr 2018 11:13:57 GMT', 'content-length': '306', 'x-amz-request-id': 'tx00000000000000003cd88-005ac361f5-foobar-default', 'content-type': 'application/xml'}}}

&gt;&gt;&gt; for bucket in response['Buckets']:
...     print(bucket['Name'])
...
ruanbucket
</code></pre>

<h2>List Objects:</h2>

<p>List all the Objects, after the given prefix:</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.list_objects(Bucket='ruanbucket', Prefix='logs/sysadmins.co.za/access/')
&gt;&gt;&gt; for obj in response['Contents']:
...     print obj['Key']
...
logs/sysadmins.co.za/access/access.log-2017-10-10.gz
logs/sysadmins.co.za/access/access.log-2017-10-11.gz
logs/sysadmins.co.za/access/access.log-2017-10-12.gz
</code></pre>

<h2>Put Object:</h2>

<p>Write text as the body to the destination key on the Bucket:</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.put_object(Bucket='ruanbucket', Body='My Name is Ruan\n', Key='uploads/docs/file.txt')
&gt;&gt;&gt; print(response)
{u'Body': &lt;botocore.response.StreamingBody object at 0x13cde10&gt;, u'AcceptRanges': 'bytes', u'ContentType': 'binary/octet-stream', 'ResponseMetadata': {'HTTPStatusCode': 200, 'RetryAttempts': 0, 'HostId': '', 'RequestId': 'tx0000000000000000053f2-005ac3e0db-foobar-default', 'HTTPHeaders': {'content-length': '16', 'accept-ranges': 'bytes', 'last-modified': 'Tue, 03 Apr 2018 20:14:54 GMT', 'etag': '"292edceea84d1234465f725c3921fc2a"', 'x-amz-request-id': 'tx0000000000000000053f2-005ac3e0db-foobar-default', 'date': 'Tue, 03 Apr 2018 20:15:23 GMT', 'content-type': 'binary/octet-stream'}}, u'LastModified': datetime.datetime(2018, 4, 3, 20, 14, 54, tzinfo=tzutc()), u'ContentLength': 16, u'ETag': '"292edceea84d1234465f725c3921fc2a"', u'Metadata': {}}
</code></pre>

<p>List the Object that we have created in the Bucket::</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.list_objects(Bucket='ruanbucket', Prefix='uploads/')
&gt;&gt;&gt; for obj in response['Contents']:
...     print obj['Key']
...
uploads/docs/file.txt
</code></pre>

<h2>Get Object:</h2>

<p>Read the value from the key that was uploaded:</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.get_object(Bucket='ruanbucket', Key='uploads/docs/file.txt')
&gt;&gt;&gt; print(response['Body'].read())
My Name is Ruan
</code></pre>

<h2>Upload Files:</h2>

<p>Upload the file from disk to the Bucket:</p>

<pre><code class="python">&gt;&gt;&gt; with open('myfile.txt', 'rb') as data:
...     s3.upload_fileobj(Fileobj=data, Bucket='ruanbucket', Key='uploads/docs/uploadobj.txt')
...
</code></pre>

<p>Read the contents from the uploaded file:</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.get_object(Bucket='ruanbucket', Key='uploads/docs/uploadobj.txt')
&gt;&gt;&gt; print(response['Body'].read())
This is some text
</code></pre>

<h2>Download File:</h2>

<p>Download the file from the Bucket to the local disk:</p>

<pre><code class="python">&gt;&gt;&gt; with open('downloaded.txt', 'wb') as data:
...     s3.download_fileobj(Bucket='ruanbucket', Key='uploads/docs/uploadobj.txt', Fileobj=data)
...
</code></pre>

<p>Read the file&rsquo;s content from disk:</p>

<pre><code class="python">&gt;&gt;&gt; print(open('downloaded.txt').read())
This is some text
</code></pre>

<h2>Delete Object:</h2>

<p>Delete one object:</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.delete_object(Bucket='ruanbucket', Key='uploads/docs/uploadobj.txt')
&gt;&gt;&gt; print(response)
{'ResponseMetadata': {'HTTPStatusCode': 204, 'RetryAttempts': 0, 'HostId': '', 'RequestId': 'tx00000000000000000be5a-005ac3e61a-foobar-default', 'HTTPHeaders': {'date': 'Tue, 03 Apr 2018 20:37:46 GMT', 'x-amz-request-id': 'tx00000000000000000be5a-005ac3e61a-foobar-default'}}}
</code></pre>

<h2>Delete Objects:</h2>

<p>Delete more than one object with a single API call:</p>

<pre><code class="python">&gt;&gt;&gt; response = s3.delete_objects(Bucket='ruanbucket', Delete={'Objects': [{'Key': 'uploads/docs/file.txt'}, {'Key': 'uploads/docs/file2.txt'}, {'Key': 'uploads/docs/file3.txt'}]})
&gt;&gt;&gt; print(response)
{u'Deleted': [{u'Key': 'uploads/docs/file.txt'}, {u'Key': 'uploads/docs/file2.txt'}, {u'Key': 'uploads/docs/file3.txt'}], 'ResponseMetadata': {'HTTPStatusCode': 200, 'RetryAttempts': 0, 'HostId': '', 'RequestId': 'tx000000000000000011008-005ac3e951-foobar-default', 'HTTPHeaders': {'date': 'Tue, 03 Apr 2018 20:51:29 GMT', 'content-length': '270', 'x-amz-request-id': 'tx000000000000000011008-005ac3e951-217c0ac5-default', 'content-type': 'application/xml'}}}
</code></pre>

<p>For more information on the above, have a look at <a href="http://boto3.readthedocs.io/en/latest/guide/quickstart.html">Boto&rsquo;s Documentation</a> and <a href="https://www.dreamhost.com/">DreamHost&rsquo;s Website</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS: IAM S3 Policy for Cyberduck to Allow Listing Buckets and Access to One Bucket]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/15/aws-iam-s3-policy-for-cyberduck-to-allow-listing-buckets-and-access-to-one-bucket/"/>
    <updated>2017-09-15T11:18:17-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/15/aws-iam-s3-policy-for-cyberduck-to-allow-listing-buckets-and-access-to-one-bucket</id>
    <content type="html"><![CDATA[<p>When using Cyberduck to access S3, and a account has restrictive policies, you may find error <code>Listing Directory: /</code> failed.</p>

<p>If you have restrictive IAM Policies in your account, this may be due to the fact that <code>S3:ListMyBuckets</code> is not allowed.</p>

<p>In this post we want to allow a user to list all buckets, so that Cyberduck can do the initial list after configuration / launch, and we would like to give the user access to their designated bucket.</p>

<h2>Creating the IAM Policy:</h2>

<p>We will create this IAM Policy and associate the policy to the user&rsquo;s account:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "Stmt1480515305000",
            "Effect": "Allow",
            "Action": [
                "s3:ListAllMyBuckets",
                "s3:GetBucketLocation"
            ],
            "Resource": [
                "arn:aws:s3:::*"
            ]
        },
        {
            "Sid": "Stmt1480515305002",
            "Effect": "Allow",
            "Action": [
                "s3:List*",
                "s3:GetObject",
                "s3:PutObject",
                "s3:DeleteObject"
            ],
            "Resource": [
                "arn:aws:s3:::allowed-bucket",
                "arn:aws:s3:::allowed-bucket/*"
            ]
        }
    ]
}
</code></pre>

<p>So here we should be able to list the buckets:</p>

<pre><code class="bash">$ aws --profile cyberduck s3 ls /
2017-06-08 08:27:01 allowed-bucket
2017-05-21 13:39:21 private-bucket
2016-12-21 08:23:45 confidential-bucket
2017-08-10 14:18:19 test-bucket
2016-08-03 12:38:29 datalake-bucket
</code></pre>

<p>Able to list inside the bucket, as well as Get, Put etc.</p>

<pre><code class="bash">$ aws --profile cyberduck s3 ls allowed-bucket/
                           PRE data/
</code></pre>

<p>Unable to list the buckets content which is expected, as we did not mention in the policy:</p>

<pre><code class="bash">$ aws --profile cyberduck s3 ls confidential-bucket/

An error occurred (AccessDenied) when calling the ListObjects operation: Access Denied
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://aws.amazon.com/blogs/security/writing-iam-policies-how-to-grant-access-to-an-amazon-s3-bucket/">https://aws.amazon.com/blogs/security/writing-iam-policies-how-to-grant-access-to-an-amazon-s3-bucket/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Minios Python SDK to Interact With a Minio S3 Bucket]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/08/using-minios-python-sdk-to-interact-with-a-minio-s3-bucket/"/>
    <updated>2017-09-08T16:15:52-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/08/using-minios-python-sdk-to-interact-with-a-minio-s3-bucket</id>
    <content type="html"><![CDATA[<p>In our previous post, we have <a href="http://blog.ruanbekker.com/blog/2017/09/08/run-your-self-hosted-s3-service-with-minio-on-docker-swarm/">Setup Minio Server</a> which is a self-hosted alternative to Amazon&rsquo;s S3 Service.</p>

<p>We will go through some basic examples on working with the Python SDK, to interact with Minio.</p>

<h2>Installing the Minio Python Library:</h2>

<p>Ensure that Python and Pip is installed, the install the Python Minio Library:</p>

<pre><code class="bash">$ virtualenv -p /usr/local/bin/python2.7 .venv
$ source .venv/bin/activate
(.venv)$ pip install minio
</code></pre>

<h2>Create a Bucket:</h2>

<p>Enter the Python Interpreter and Create a S3 Bucket on your Minio Server:</p>

<pre><code class="python">&gt;&gt;&gt; from minio import Minio
&gt;&gt;&gt; client = Minio('10.0.0.2:9000', access_key='ASDASDASD', secret_key='ASDASDASD', secure=False)
&gt;&gt;&gt; client.make_bucket('pythonbucket', location='us-west-1')
</code></pre>

<h2>List Buckets:</h2>

<p>I have also created a bucket from my previous post, so we should have 2 buckets:</p>

<pre><code class="python">&gt;&gt;&gt; buckets = client.list_buckets()
&gt;&gt;&gt; for bucket in buckets:
...     print(bucket).name
...
news3bucket
pythonbucket
</code></pre>

<h2>Put Objects to your Bucket:</h2>

<p>Write a string to a file, then upload the file to 2 different destination objects. The arguments is: BucketName, Destination, Source.</p>

<pre><code class="python">&gt;&gt;&gt; data = open('file.txt', 'w')
&gt;&gt;&gt; data.write('This is some text' + '\n')
&gt;&gt;&gt; data.close()

&gt;&gt;&gt; client.fput_object('pythonbucket', 'bucket/contents/file.txt', 'file.txt')
'6b8c327f0fc6f470c030a5b6c71154c5'
&gt;&gt;&gt; client.fput_object('pythonbucket', 'bucket/contents/file2.txt', 'file.txt')
'6b8c327f0fc6f470c030a5b6c71154c5'
</code></pre>

<h2>List Objects in your Bucket:</h2>

<p>List the objects in your bucket:</p>

<pre><code class="python">&gt;&gt;&gt; objects = client.list_objects('pythonbucket', prefix='bucket/contents/', recursive=True)
&gt;&gt;&gt; for obj in objects:
&gt;&gt;&gt; for obj in objects:
...     print(obj.object_name, obj.size)
...
('bucket/contents/file.txt', 18)
('bucket/contents/file2.txt', 18)
</code></pre>

<h2>Remove Objects from your Bucket:</h2>

<p>Remove the objects from your Bucket, the list your bucket to verify that they are removed:</p>

<pre><code class="python">&gt;&gt;&gt; client.remove_object('pythonbucket', 'bucket/contents/file.txt')
&gt;&gt;&gt; client.remove_object('pythonbucket', 'bucket/contents/file2.txt')

&gt;&gt;&gt; for obj in objects:
...     print(obj.object_name, obj.size)
...
&gt;&gt;&gt;
</code></pre>

<h2>Remove the Bucket:</h2>

<p>Remove the Bucket that we created:</p>

<pre><code class="python">&gt;&gt;&gt; client.remove_bucket('pythonbucket')
&gt;&gt;&gt; exit()
</code></pre>

<h2>Resources:</h2>

<p>Minio has some great documentation, for more information on their SDK:</p>

<ul>
<li><a href="https://docs.minio.io/docs/python-client-api-reference">https://docs.minio.io/docs/python-client-api-reference</a></li>
</ul>


<center>
    <script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script> 
</center>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Run Your Self-Hosted S3 Service With Minio on Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/08/run-your-self-hosted-s3-service-with-minio-on-docker-swarm/"/>
    <updated>2017-09-08T15:29:29-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/08/run-your-self-hosted-s3-service-with-minio-on-docker-swarm</id>
    <content type="html"><![CDATA[<p>Minio is a distributed object storage server built for cloud applications, which is similar to Amazon&rsquo;s S3 Service.</p>

<p>Today, we will create the server on docker swarm, as I don&rsquo;t currently have a external data store like GlusterFS / NFS etc, I will host the data on the manager node, and set a constraint for the service so that the service can only run on the manager node.</p>

<h2>Prepare the Data Directory:</h2>

<p>I will only rely on the manager node for my data, so on my manager node:</p>

<pre><code>$ mkdir -p /mnt/data
</code></pre>

<h2>Create the Service:</h2>

<p>If you have a Replicated Gluster Volume or NFS which is mounted throughout your docker swarm, you can create the directory path for it, and the update your <code>--mount</code> source path to your external data store. In my case, I will just point it to my manager node&rsquo;s <code>/mnt/data</code> path as I have setup the service to only run on the one manager node in my swarm:</p>

<pre><code>$ docker service create \
--name minio \
--network appnet \
--replicas 1 \
--publish 9000:9000 \
--constraint 'node.role==manager' \
-e "MINIO_ACCESS_KEY=AKIAASDKJASDL" \
-e "MINIO_SECRET_KEY=AKIAASDKJASDL" \
--mount "type=bind,source=/mnt/data,target=/data" \
minio/minio server /data
</code></pre>

<h2>Install the AWS CLI Tools:</h2>

<p>We will use the awscli tools to interact with our Minio Server:</p>

<pre><code>$ pip install awscli
</code></pre>

<h2>Configure the Client:</h2>

<p>Configure the awscli client with the access details that we passed in our docker service:</p>

<pre><code>$ aws configure --profile minio
AWS Access Key ID []: AKIAASDKJASDL
AWS Secret Access Key []: ASLDKJASDLKJASDLKJ
Default region name []: us-west-1
Default output format []: json
</code></pre>

<h2>Create the Bucket:</h2>

<p>Create a New Bucket, in this case <code>news3bucket</code></p>

<pre><code>aws --profile minio --endpoint-url http://MINIO-IP:9000 s3 mb s3://news3bucket
make_bucket: news3bucket
</code></pre>

<h2>List Buckets:</h2>

<p>List our endpoint, to see the buckets on our server:</p>

<pre><code>$ aws --profile minio --endpoint-url http://MINIO-IP:9000 s3 ls /
2017-09-08 15:01:40 news3bucket
</code></pre>

<h2>Upload an Object to your Bucket:</h2>

<p>We will upload an image <code>awsddb-1.png</code> to our new bucket:</p>

<pre><code>$ aws --profile minio --endpoint-url http://MINIO-IP:9000 s3 cp awsddb-1.png s3://news3bucket/
upload: ./awsddb-1.png to s3://news3bucket/awsddb-1.png
</code></pre>

<h2>List Bucket:</h2>

<p>List your bucket, to see the uploaded object:</p>

<pre><code>$ aws --profile minio --endpoint-url http://MINIO-IP:9000 s3 ls s3://news3bucket
2017-09-08 15:03:11      19851 awsddb-1.png
</code></pre>

<h2>Download Object:</h2>

<p>Download the image from your Bucket, and set the local file to <code>file.png</code>:</p>

<pre><code>$ aws --profile minio --endpoint-url http://MINIO-IP:9000 s3 cp s3://news3bucket/awsddb-1.png file.png
download: s3://news3bucket/awsddb-1.png to ./file.png
</code></pre>

<h2>Web Access:</h2>

<p>You can also access Minio&rsquo;s Web Interface on the port that you have exposed, in my case: <code>http://MINIO-IP:9000/minio/</code></p>

<h2>Resources:</h2>

<ul>
<li><a href="https://www.minio.io/">https://www.minio.io/</a></li>
<li><a href="https://docs.minio.io/docs/minio-docker-quickstart-guide">https://docs.minio.io/docs/minio-docker-quickstart-guide</a></li>
<li><a href="https://github.com/minio/minio/blob/master/README.md">https://github.com/minio/minio/blob/master/README.md</a></li>
<li><a href="https://github.com/arschles/minio-howto/blob/master/aws-cli-with-minio-server.md">https://github.com/arschles/minio-howto/blob/master/aws-cli-with-minio-server.md</a></li>
</ul>


<center>
    <script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script> 
</center>

]]></content>
  </entry>
  
</feed>
