<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Security | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/security/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2022-03-20T17:52:20-04:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Difference With ECS Task and Execution IAM Roles on AWS]]></title>
    <link href="https://blog.ruanbekker.com/blog/2021/07/31/difference-with-ecs-task-and-execution-iam-roles-on-aws/"/>
    <updated>2021-07-31T03:37:34-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2021/07/31/difference-with-ecs-task-and-execution-iam-roles-on-aws</id>
    <content type="html"><![CDATA[<p><img src="https://blog.ruanbekker.com/images/ruanbekker-header-photo.png" alt="" /></p>

<p>In this post we will look at what the difference is between the <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task-iam-roles.html">AWS ECS Task Execution IAM Role</a> and the <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task-iam-roles.html">IAM Role for Tasks</a> and give a example policy to demonstrate.</p>

<h2>ECS Task Execution Role</h2>

<p>The ECS Execution Role is used by the ecs-agent which runs on ECS and is responsible for:
- Pulling down docker images from ECR
- Fetching the SSM Parameters from SSM for your Task (Secrets and LogConfigurations)
- Writing Logs to CloudWatch</p>

<p>The IAM Role has been configured that the Trusted Identity is ecs so only ECS is allowed to assume credentials from the IAM Policy that is associated to the Role.</p>

<p>The trusted identity in the IAM Role to be ecs:</p>

<pre><code class="json">{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": "ecs-tasks.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
</code></pre>

<p>and the policy will look like this more or less for a example service, I am demonstrating my-dev-service:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ecr:GetAuthorizationToken",
                "ecr:BatchCheckLayerAvailability",
                "ecr:GetDownloadUrlForLayer",
                "ecr:BatchGetImage",
                "logs:CreateLogStream",
                "logs:PutLogEvents"
            ],
            "Resource": "*"
        },
        {
            "Sid": "SSMGetParameters",
            "Effect": "Allow",
            "Action": [
                "ssm:GetParameter"
            ],
            "Resource": "arn:aws:ssm:eu-west-1:*:parameter/my-service/dev/*"
        },
        {
            "Sid": "KMSDecryptParametersWithKey",
            "Effect": "Allow",
            "Action": [
                "kms:GetPublicKey",
                "kms:Decrypt",
                "kms:GenerateDataKey",
                "kms:DescribeKey"
            ],
            "Resource": "*"
        }
    ]
}
</code></pre>

<p>In the ECS Task Definition the role arn is specified as <code>"executionRoleArn"</code> in:</p>

<pre><code class="json">{
  "family": "my-dev-service",
  "executionRoleArn":"arn:aws:iam::000000000000:role/ecs-exec-role",
  "taskRoleArn":"arn:aws:iam::000000000000:role/ecs-task-role",
  "containerDefinitions": []
}
</code></pre>

<h2>ECS Task Role</h2>

<p>The ECS Task Role is used by the service that is deployed to ECS, so this will be your application requiring access to SQS as an example</p>

<p>Same as before, we set the trusted identity in the IAM Role to be ecs:</p>

<pre><code class="json">{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": "ecs-tasks.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
</code></pre>

<p>So only the ECS tasks using the role is allowed to assume credentials from the IAM Role, and the policy associated to the role, can look something like this:</p>

<pre><code class="json">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowDevSQS",
            "Effect": "Allow",
            "Action": [
                "sqs:GetQueueUrl",
                "sqs:ReceiveMessage",
                "sqs:SendMessage",
                "sqs:ChangeMessageVisibility"
            ],
            "Resource": [
                "arn:aws:sqs:eu-west-1:000000000000:dev-pending-queue",
                "arn:aws:sqs:eu-west-1:000000000000:dev-confirmed-queue"
            ]
        }
    ]
}
</code></pre>

<p>The role arn will be specified in <code>"taskRoleArn"</code> from the following in the ECS Task Definition:</p>

<pre><code class="json">{
  "family": "my-dev-service",
  "executionRoleArn":"arn:aws:iam::000000000000:role/ecs-exec-role",
  "taskRoleArn":"arn:aws:iam::000000000000:role/ecs-task-role",
  "containerDefinitions": []
}
</code></pre>

<h2>Application Code</h2>

<p>In your application you donâ€™t need to reference any aws access keys as the role will assume credentials for you by the SDK, with python a short example will be:</p>

<pre><code class="python">import boto3
sqs = boto3.Session(region_name='eu-west-1').client('sqs')
</code></pre>

<h2>Thanks</h2>

<p>Thanks for reading, if you like my content, check out my <strong><a href="https://ruan.dev">website</a></strong> or follow me at <strong><a href="https://twitter.com/ruanbekker">@ruanbekker</a></strong> on Twitter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Harden Your SSH Security on Linux Servers]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/12/18/harden-your-ssh-security-on-linux-servers/"/>
    <updated>2020-12-18T13:32:18+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/12/18/harden-your-ssh-security-on-linux-servers</id>
    <content type="html"><![CDATA[<p>In this post we wil be focusing on increasing / hardening our security by adjusting our ssh configuration and applying some iptables firewall rules.</p>

<p>This will be the list of things that we will do:</p>

<pre><code>  - Change the SSH Port
  - Don't allow root to SSH
  - Disable password based authentication
  - Enable key based authentication and only for a singular user
  - Allow our user to sudo
  - Use iptables to block sources trying to DDoS your server
</code></pre>

<h2>Packages</h2>

<p>First let&rsquo;s install the packages that we need, I&rsquo;m using Debian so I will be using the <code>apt</code> package manager:</p>

<pre><code>$ apt update &amp;&amp; apt upgrade -y
$ apt install sudo -y
</code></pre>

<h2>Dedicated User</h2>

<p>Let&rsquo;s create our user james:</p>

<pre><code>$ useradd -m -s /bin/bash james
</code></pre>

<p>Allow our user to sudo without a password, by running <code>visudo</code> then append the following line:</p>

<pre><code>james ALL=(ALL:ALL) NOPASSWD: ALL
</code></pre>

<h2>SSH Authorized Keys</h2>

<p>If you don&rsquo;t already have a private SSH key, generate one on your client side:</p>

<pre><code>$ ssh-keygen -f ~/.ssh/james -t rsa -C "james" -q -N ""
</code></pre>

<p>Then copy the public key:</p>

<pre><code>$ cat ~/.ssh/james.pub | pbcopy
</code></pre>

<p>On your server create the SSH directories:</p>

<pre><code>$ mkdir /home/james/.ssh
</code></pre>

<p>Now paste your public key into <code>/home/james/.ssh/authorized_keys</code></p>

<p>Then change the ownership:</p>

<pre><code>$ chmod 700 /home/james/.ssh
$ chmod 644 /home/james/.ssh/authorized_keys
$ chown -R james:james /home/james
</code></pre>

<h2>SSH Config</h2>

<p>Backup your SSH config:</p>

<pre><code>$ cp /etc/ssh/sshd_config /etc/ssh_sshd_config.bak
</code></pre>

<p>We will be using the SSH port <code>2914</code>, replace your SSH config with the following and make your adjustments where you need to:</p>

<pre><code># /etc/ssh/sshd_config
Port 2914
HostKey /etc/ssh/ssh_host_rsa_key
HostKey /etc/ssh/ssh_host_ecdsa_key
HostKey /etc/ssh/ssh_host_ed25519_key
LoginGraceTime 1m
PermitRootLogin no
MaxAuthTries 3
MaxSessions 5
AuthenticationMethods publickey
PubkeyAuthentication yes
AuthorizedKeysFile      /home/james/.ssh/authorized_keys
PasswordAuthentication no
PermitEmptyPasswords no
ChallengeResponseAuthentication no
UsePAM yes
AllowUsers james
DenyUsers root
X11Forwarding yes
PrintMotd no
UseDNS no
PidFile /var/run/sshd.pid
AcceptEnv LANG LC_*
Subsystem       sftp    /usr/lib/openssh/sftp-server
</code></pre>

<p>Then save the file and restart SSH:</p>

<pre><code>$ systemctl restart sshd
</code></pre>

<p>While you are still connected to the shell session, open up a new terminal and try to connect with your new user and private SSH key to ensure that you can connect to your server.</p>

<h2>Iptables</h2>

<p>We want to drop incoming connections which make more than 10 connection attempts to SSH within 60 seconds.</p>

<p>The tokens get refilled into buckets at 3 per minute and maximum of 3 tokens that can be filled into the bucket.</p>

<p>Let&rsquo;s create our script:</p>

<pre><code>$ mkdir -p /opt/scripts
$ touch /opt/scripts/fw.sh
</code></pre>

<p>In our script we will place the following content:</p>

<pre><code>#!/usr/bin/env bash
INTERFACE=eth0 # check ifconfig to determine the correct interface
SSH_PORT=2914
CONNECTION_ATTEMPTS=10
CONNECTION_TIME=60
#WHITELIST_IP=x.x.x.x/32 # replace ip and uncomment if you want to whitelist a ip
#iptables -I INPUT -s ${WHITELIST_IP} -p tcp --dport ${SSH_PORT} -i ${INTERFACE} -j ACCEPT # uncomment if you want to use whitelisting
iptables -A INPUT -p tcp --dport ${SSH_PORT} -i ${INTERFACE} -m state --state NEW -m recent  --set
iptables -A INPUT -p tcp --dport ${SSH_PORT} -i ${INTERFACE} -m state --state NEW -m recent  --update --seconds ${CONNECTION_TIME} --hitcount ${CONNECTION_ATTEMPTS} -j DROP
iptables -A INPUT  -i ${INTERFACE} -p tcp --dport ${SSH_PORT} -m state --state NEW -m limit --limit 3/min --limit-burst 3 -j ACCEPT
iptables -A INPUT  -i ${INTERFACE} -p tcp --dport ${SSH_PORT} -m state --state ESTABLISHED -j ACCEPT
iptables -A OUTPUT -o ${INTERFACE} -p tcp --sport ${SSH_PORT} -m state --state ESTABLISHED -j ACCEPT
</code></pre>

<p>Now we want to execute this script whenever the server boots, open up <code>/etc/rc.local</code> and append the following line, so that the file looks more or less like:</p>

<pre><code>#!/bin/bash
/opt/scripts/fw.sh
exit 0
</code></pre>

<p>Ensure both files are executable:</p>

<pre><code>$ chmod +x /opt/scripts/fw.sh
$ chmod +x /etc/rc.local
</code></pre>

<p>When you are sure everything is in place, reboot:</p>

<pre><code>$ reboot
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Encrypt and Decrypt Files With Ccrypt]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/11/20/encrypt-and-decrypt-files-with-ccrypt/"/>
    <updated>2020-11-20T06:27:01+00:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/11/20/encrypt-and-decrypt-files-with-ccrypt</id>
    <content type="html"><![CDATA[<p>This is a quick post to demonstrate how to encrypt and decrypt files with <strong>ccrypt</strong></p>

<h2>About</h2>

<p>Ccrypt&rsquo;s description from its project page:</p>

<p><em>Encryption and decryption depends on a keyword (or key phrase) supplied by the user. By default, the user is prompted to enter a keyword from the terminal. Keywords can consist of any number of characters, and all characters are significant (although ccrypt internally hashes the key to 256 bits). Longer keywords provide better security than short ones, since they are less likely to be discovered by exhaustive search.</em></p>

<p>Ref: <a href="http://ccrypt.sourceforge.net/">http://ccrypt.sourceforge.net/</a></p>

<h2>Install</h2>

<p>For debian based systems, to install ccrypt:</p>

<pre><code>$ sudo apt-get install ccrypt
</code></pre>

<h2>Usage</h2>

<p>To encrypt files, write a file to disk:</p>

<pre><code>$ echo "ok" &gt; file.txt
</code></pre>

<p>Then encrypt the file by providing a password:</p>

<pre><code>$ ccencrypt file.txt
Enter encryption key:
Enter encryption key: (repeat)
</code></pre>

<p>It encrypts and only the encrypted file can be found:</p>

<pre><code>$ ls
file.txt.cpt
</code></pre>

<p>Decrypt the file, by providing your password that you encrypted it with:</p>

<pre><code>$ ccdecrypt file.txt.cpt
Enter decryption key:
</code></pre>

<p>View the decrypted file:</p>

<pre><code>$ cat file.txt
ok
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Secure Your Elasticsearch Cluster With Basic Auth Using Nginx and SSL From Letsencrypt]]></title>
    <link href="https://blog.ruanbekker.com/blog/2019/04/02/secure-your-elasticsearch-cluster-with-basic-auth-using-nginx/"/>
    <updated>2019-04-02T14:55:58-04:00</updated>
    <id>https://blog.ruanbekker.com/blog/2019/04/02/secure-your-elasticsearch-cluster-with-basic-auth-using-nginx</id>
    <content type="html"><![CDATA[<p>In this tutorial we will setup a reverse proxy using nginx to translate and load balance traffic through to our elasticsearch nodes. We will also protect our elasticsearch cluster with basic auth and use letsencrypt to retrieve free ssl certificates.</p>

<p>We want to allow certain requests to be bypassed from authentication such as getting status from the cluster and certain requests we want to enforce authentication, such as indexing and deleting data.</p>

<h2>Install Nginx:</h2>

<p>Install nginx and the dependency package to create basic auth:</p>

<pre><code class="bash">$ apt install nginx apache2-utils -y
</code></pre>

<h2>Configure Nginx for Reverse Proxy</h2>

<p>We want to access our nginx proxy on port 80: <code>0.0.0.0:80</code> and the requests should be proxied through to elasticsearch private addresses: <code>10.0.0.10:9200</code> and <code>10.0.0.11:9200</code>. Traffic will be load balanced between our 2 nodes.</p>

<p>Edit the main nginx configuration:</p>

<pre><code>$ vim /etc/nginx/nginx.conf
</code></pre>

<p>and populate the information as shown below:</p>

<pre><code>user www-data;
worker_processes auto;
pid /run/nginx.pid;

events {
    worker_connections 1024;
    # multi_accept on;
}

http {

    # basic Settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # ssl settings
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;

    # logging settings
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # gzip settings
    gzip on;
    gzip_disable "msie6";

    # virtual host configs
    include /etc/nginx/conf.d/*.conf;
}
</code></pre>

<p>Next, edit the virtual host config:</p>

<pre><code>$ vim /etc/nginx/conf.d/elasticsearch.conf
</code></pre>

<p>And populate the following config:</p>

<pre><code># https://gist.github.com/sahilsk/b16cb51387847e6c3329

upstream elasticsearch {
    # define your es nodes
    server 10.0.0.10:9200;
    server 10.0.0.11:9200;
    # persistent http connections
    # https://www.elastic.co/blog/playing-http-tricks-nginx
    keepalive 15;
}

server {
  listen 80;
  server_name elasticsearch.domain.com;

  auth_basic "server auth";
  auth_basic_user_file /etc/nginx/passwords;

  location / {

    # deny node shutdown api
    if ($request_filename ~ "_shutdown") {
      return 403;
      break;
    }

    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_redirect off;
  }

  location = / {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_redirect off;
    auth_basic "off";
  }

  location ~* ^(/_cluster/health|/_cat/health) {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_redirect off;
    auth_basic "off";
  }
}
</code></pre>

<p>Set your username and password to protect your endpoint:</p>

<pre><code class="bash">$ htpasswd -c /etc/nginx/passwords admin
</code></pre>

<p>Enable nginx on boot and restart the process:</p>

<pre><code class="bash">$ systemctl enable nginx
$ systemctl restart nginx
</code></pre>

<h2>Test it</h2>

<p>Now make requests to elasticsearch via your nginx reverse proxy:</p>

<pre><code class="bash">$ curl -H 'Content-Type: application/json' -u 'admin:admin' http://myproxy.domain.com/_cat/indices?v
health status index       uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   first-index 1o6yM7tCSqagqoeihKM7_g   5   1          3            0     40.6kb         20.3kb
</code></pre>

<h2>Letsencrypt SSL Certificates</h2>

<p>Add free SSL Certificates to your reverse proxy. Install certbot:</p>

<pre><code class="bash">$ apt-get update
$ apt-get install software-properties-common -y
$ add-apt-repository universe
$ add-apt-repository ppa:certbot/certbot
$ apt-get update
$ apt-get install certbot python-certbot-nginx -y
</code></pre>

<p>Request a Certificate for your domain:</p>

<pre><code class="bash">$ certbot --manual certonly -d myproxy.domain.com -m my@email.com --preferred-challenges dns --agree-tos

Obtaining a new certificate
Performing the following challenges:
dns-01 challenge for myproxy.domain.com
</code></pre>

<p>You will be prompted to make a dns change, since we requested the dns challenge. While this screen is here, we can go our dns provider and make the TXT record change as shown below:</p>

<pre><code>Please deploy a DNS TXT record under the name
_acme-challenge.myproxy.domain.com with the following value:

xLP4y_YJvdAK7_aZMJ50gkudTDeIC3rX0x83aNJctGw

Before continuing, verify the record is deployed.
Press Enter to Continue
Waiting for verification...
Cleaning up challenges

IMPORTANT NOTES:
 - Congratulations! Your certificate and chain have been saved at:
   /etc/letsencrypt/live/myproxy.domain.com/fullchain.pem
   Your key file has been saved at:
   /etc/letsencrypt/live/myproxy.domain.com/privkey.pem
   Your cert will expire on 2019-07-01. To obtain a new or tweaked
   version of this certificate in the future, simply run certbot
   again. To non-interactively renew *all* of your certificates, run
   "certbot renew"
 - If you like Certbot, please consider supporting our work by:

   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate
   Donating to EFF:                    https://eff.org/donate-le
</code></pre>

<h2>Update Nginx Config</h2>

<p>Now that we have our ssl certificates, we need to update our nginx config to enable ssl, redirect http to https and point the ssl certificates and ssl private keys to the certificates that we retrieved from letsencrypt.</p>

<p>Open up the virtual host nginx configuration:</p>

<pre><code class="bash">$ vim /etc/nginx/conf.d/elasticsearch.conf
</code></pre>

<p>Update the config like the one below:</p>

<pre><code>upstream elasticsearch {
    server 10.0.0.10:9200;
    server 10.0.0.11:9200;
    keepalive 15;
}

server {
  listen 80;
  server_name myproxy.domain.com;
  return 301 https://$host$request_uri;
}

server {
  listen 443 ssl;
  server_name myproxy.domain.com;

  ssl_certificate /etc/letsencrypt/live/myproxy.domain.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/myproxy.domain.com/privkey.pem;

  auth_basic "server auth";
  auth_basic_user_file /etc/nginx/passwords;

  location ^~ /.well-known/acme-challenge/ {
    auth_basic off;
  }

  location / {

    # deny node shutdown api
    if ($request_filename ~ "_shutdown") {
      return 403;
      break;
    }

    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $http_host;
    proxy_redirect off;
  }

  location = / {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $http_host;
    proxy_redirect off;
    auth_basic "off";
  }

  location ~* ^(/_cluster/health|/_cat/health) {
    proxy_pass http://elasticsearch;
    proxy_http_version 1.1;
    proxy_set_header Connection "Keep-Alive";
    proxy_set_header Proxy-Connection "Keep-Alive";
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $http_host;
    proxy_redirect off;
    auth_basic "off";
  }
}
</code></pre>

<p>Restart the nginx process:</p>

<pre><code class="bash">$ systemctl restart nginx
</code></pre>

<h2>Test the Nginx Proxy with SSL</h2>

<p>Test the proxy with HTTP so that we can see that our nginx config redirects us to <a href="HTTPS:">HTTPS:</a></p>

<pre><code class="bash">$ curl -iL -u 'admin:admin' http://myproxy.domain.com/_cat/nodes?v
HTTP/1.1 301 Moved Permanently
Server: nginx/1.14.0 (Ubuntu)
Date: Tue, 02 Apr 2019 21:40:09 GMT
Content-Type: text/html
Content-Length: 194
Connection: keep-alive
Location: https://myproxy.domain.com/_cat/nodes?v

HTTP/1.1 200 OK
Server: nginx/1.14.0 (Ubuntu)
Date: Tue, 02 Apr 2019 21:40:10 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 276
Connection: keep-alive

ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.0.0.10               40          97   3    0.15    0.10     0.08 mdi       -      Lq9P7eP
10.0.0.11               44          96   3    0.21    0.10     0.09 mdi       *      F5edOwK
</code></pre>

<p>Test the proxy with <a href="HTTPS:">HTTPS:</a></p>

<pre><code class="bash">$ curl -i -u 'admin:admin' https://myproxy.domain.com/_cat/nodes?v
HTTP/1.1 200 OK
Server: nginx/1.14.0 (Ubuntu)
Date: Tue, 02 Apr 2019 21:40:22 GMT
Content-Type: text/plain; charset=UTF-8
Content-Length: 276
Connection: keep-alive

ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.0.0.10               44          96   4    0.18    0.10     0.09 mdi       *      F5edOwK
10.0.0.11               39          97   5    0.13    0.09     0.08 mdi       -      Lq9P7eP
</code></pre>

<p>Setup a cronjob to auto renew the certificates:</p>

<pre><code class="bash">$ crontab -e
</code></pre>

<p>Populate the following line:</p>

<pre><code class="bash">6 1,13 * * * /usr/bin/certbot renew --post-hook "systemctl restart nginx" --quiet
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://certbot.eff.org/lets-encrypt/ubuntuxenial-nginx.html">https://certbot.eff.org/lets-encrypt/ubuntuxenial-nginx.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create Read Only Users in MongoDB]]></title>
    <link href="https://blog.ruanbekker.com/blog/2018/11/12/create-read-only-users-in-mongodb/"/>
    <updated>2018-11-12T17:02:53-05:00</updated>
    <id>https://blog.ruanbekker.com/blog/2018/11/12/create-read-only-users-in-mongodb</id>
    <content type="html"><![CDATA[<p>In this post I will demonstrate how to setup 2 read only users in MongoDB, one user that will have access to one MongoDB Database and all the Collections, and one user with access to one MongoDB Database and only one Collection.</p>

<script id="mNCC" language="javascript">
    medianet_width = "728";
    medianet_height = "90";
    medianet_crid = "218284798";
    medianet_versionId = "3111299";
  </script>


<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>


<h2>First Method: Creating and Assigning the User</h2>

<p>The first method we will create the user and assign it the read permissions that he needs. In this case read only access to the mytest db.</p>

<p>First logon to mongodb and switch to the admin database:</p>

<pre><code class="bash">$ mongo -u dbadmin -p --authenticationDatabase admin
&gt; use admin
switched to db admin
</code></pre>

<p>Now list the dbs:</p>

<pre><code class="bash">&gt; show dbs
admin       0.000GB
mytest      0.000GB
</code></pre>

<p>List the collections and read the data from it for demonstration purposes:</p>

<pre><code class="bash">&gt; use mytest
&gt; show collections;
col1
col2
&gt; db.col1.find()
{ "_id" : ObjectId("5be3d377b54849bb738e3b6b"), "name" : "ruan" }
&gt; db.col2.find()
{ "_id" : ObjectId("5be3d383b54849bb738e3b6c"), "name" : "stefan" }
</code></pre>

<p>Now create the user collectionreader that will have access to read all the collections from the database:</p>

<pre><code class="bash">$ &gt; db.createUser({user: "collectionreader", pwd: "secretpass", roles: [{role: "read", db: "mytest"}]})
Successfully added user: {
  "user" : "collectionreader",
  "roles" : [
    {
      "role" : "read",
      "db" : "mytest"
    }
  ]
}
</code></pre>

<p>Exit and log out and log in with the new user to test the permissions:</p>

<pre><code class="bash">$ mongo -u collectionreader -p --authenticationDatabase mytest
&gt; use mytest
switched to db mytest

&gt; show collections
col1
col2

&gt; db.col1.find()
{ "_id" : ObjectId("5be3d377b54849bb738e3b6b"), "name" : "ruan" }
</code></pre>

<p>Now lets try to write to a collection:</p>

<pre><code class="bash">&gt; db.col1.insert({"name": "james"})
WriteResult({
  "writeError" : {
    "code" : 13,
    "errmsg" : "not authorized on mytest to execute command { insert: \"col1\", documents: [ { _id: ObjectId('5be3d6c0492818b2c966d61a'), name: \"james\" } ], ordered: true }"
  }
})
</code></pre>

<p>So we can see it works as expected.</p>

<h2>Second Method: Create Roles and Assign Users to the Roles</h2>

<p>In the second method, we will create the roles then assign the users to the roles. And in this scenario, we will only grant a user <code>reader</code> access to one collection on a database. Login with the admin user:</p>

<pre><code class="bash">$ mongo -u dbadmin -p --authenticationDatabase admin
&gt; use admin
</code></pre>

<p>First create the read only role <code>myReadOnlyRole</code>:</p>

<pre><code class="bash">&gt; db.createRole({ role: "myReadOnlyRole", privileges: [{ resource: { db: "mytest", collection: "col2"}, actions: ["find"]}], roles: []})
</code></pre>

<p>Now create the user and assign it to the role:</p>

<pre><code class="bash">&gt; db.createUser({ user: "reader", pwd: "secretpass", roles: [{ role: "myReadOnlyRole", db: "mytest"}]})
</code></pre>

<p>Similarly, if we had an existing user that we also would like to add to that role, we can do that by doing this:</p>

<pre><code class="bash">&gt; db.grantRolesToUser("anotheruser", [ { role: "myReadOnlyRole", db: "mytest" } ])
</code></pre>

<p>Logout and login with the reader user:</p>

<pre><code class="bash">$ mongo -u reader -p --authenticationDatabase mytest
&gt; use mytest
</code></pre>

<p>Now try to list the collections:</p>

<pre><code class="bash">&gt; show collections
2018-11-08T07:42:39.907+0100 E QUERY    [thread1] Error: listCollections failed: {
  "ok" : 0,
  "errmsg" : "not authorized on mytest to execute command { listCollections: 1.0, filter: {} }",
  "code" : 13,
  "codeName" : "Unauthorized"
}
</code></pre>

<p>As we only have read (find) access on col2, lets try to read data from collection col1:</p>

<pre><code class="bash">&gt; db.col1.find()
Error: error: {
  "ok" : 0,
  "errmsg" : "not authorized on mytest to execute command { find: \"col1\", filter: {} }",
  "code" : 13,
  "codeName" : "Unauthorized"
}
</code></pre>

<p>And finally try to read data from the collection we are allowed to read from:</p>

<pre><code class="bash">&gt; db.col2.find()
{ "_id" : ObjectId("5be3d383b54849bb738e3b6c"), "name" : "stefan" }
</code></pre>

<p>And also making sure we cant write to that collection:</p>

<pre><code>&gt; db.col2.insert({"name": "frank"})
WriteResult({
  "writeError" : {
    "code" : 13,
    "errmsg" : "not authorized on mytest to execute command { insert: \"col2\", documents: [ { _id: ObjectId('5be3db1530a86d900c361465'), name: \"frank\" } ], ordered: true }"
  }
})
</code></pre>

<h2>Assigning Permissions to Roles</h2>

<p>If you later on want to add more permissions to the role, this can easily be done by using <code>grantPrivilegesToRole()</code>:</p>

<pre><code class="bash">$ mongo -u dbadmin -p --authenticationDatabase admin
&gt; use mytest
&gt; db.grantPrivilegesToRole("myReadOnlyRole", [{ resource: { db : "mytest", collection : "col1"}, actions : ["find"] }])
</code></pre>

<p>To view the permissions for that role:</p>

<pre><code class="bash">&gt; db.getRole("myReadOnlyRole", { showPrivileges : true })
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="https://docs.mongodb.com/manual/tutorial/create-users/">https://docs.mongodb.com/manual/tutorial/create-users/</a></li>
<li><a href="https://docs.mongodb.com/manual/core/collection-level-access-control/">https://docs.mongodb.com/manual/core/collection-level-access-control/</a></li>
<li><a href="https://docs.mongodb.com/manual/reference/privilege-actions/">https://docs.mongodb.com/manual/reference/privilege-actions/</a></li>
<li><a href="https://sanderknape.com/2018/07/manage-custom-secrets-aws-secrets-manager/">https://sanderknape.com/2018/07/manage-custom-secrets-aws-secrets-manager/</a></li>
<li><a href="https://blog.mlab.com/2016/07/mongodb-tips-tricks-collection-level-access-control/">https://blog.mlab.com/2016/07/mongodb-tips-tricks-collection-level-access-control/</a></li>
<li><a href="https://studio3t.com/knowledge-base/articles/mongodb-users-roles-explained-part-1/">https://studio3t.com/knowledge-base/articles/mongodb-users-roles-explained-part-1/</a></li>
</ul>


<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>

]]></content>
  </entry>
  
</feed>
