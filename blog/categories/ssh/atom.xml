<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ssh | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/ssh/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2019-02-19T09:22:22-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Capturing 54 Million Passwords With a Docker SSH Honeypot]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/11/capturing-54-million-passwords-with-a-docker-ssh-honeypot/"/>
    <updated>2018-10-11T16:38:52-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/11/capturing-54-million-passwords-with-a-docker-ssh-honeypot</id>
    <content type="html"><![CDATA[<p><img src="https://res.cloudinary.com/rbekker/image/upload/v1539291851/ssh-docker-honeypot_eyhzc7.png" alt="" /></p>

<p>The last couple of days I picked up on my ELK Stack a couple thousands of SSH Brute Force Attacks, so I decided I will just revisit my SSH Server configuration, and change my SSH Port to something else for the interim. The dashboard that showed me the results at that point in time:</p>

<p><img src="https://res.cloudinary.com/rbekker/image/upload/v1539292443/kibana-failed-ssh-auth_udkxkl.png" alt="" /></p>

<p>Then I decided I actually would like to setup a SSH Honeypot to listen on Port 22 and change my SSH Server to listen on 222 and capture their IP Addresses, Usernames and Passwords that they are trying to use and dump it all in a file so that I can build up my own password dictionary :D</p>

<h2>SSH Configuration:</h2>

<p>Changing the SSH Port:</p>

<pre><code class="bash">$ sudo vim /etc/ssh/sshd_config
</code></pre>

<p>Change the port to 222:</p>

<pre><code class="bash">Port 222
</code></pre>

<p>Restart the SSH Server:</p>

<pre><code class="bash">$ sudo /etc/init.d/ssh restart
</code></pre>

<p>Verify that the SSH Server is running on the new port:</p>

<pre><code class="bash">$ sudo netstat -tulpn | grep sshd
tcp        0      0 0.0.0.0:222            0.0.0.0:*               LISTEN      28838/sshd
</code></pre>

<h2>Docker SSH Honeypot:</h2>

<p>Thanks to <a href="https://github.com/random-robbie/docker-ssh-honey">random-robbie</a>, as he had everything I was looking for on Github.</p>

<p>Setup the SSH Honeypot:</p>

<pre><code class="bash">$ git clone https://github.com/random-robbie/docker-ssh-honey
$ cd docker-ssh-honey/
$ docker build . -t local:ssh-honepot
$ docker run -itd --name ssh-honeypot -p 22:22 local:ssh-honepot
</code></pre>

<p>Once people attempt to ssh, you will get the output to stdout:</p>

<pre><code class="bash">$ docker logs -f $(docker ps -f name=ssh-honeypot -q) | grep -v 'Error exchanging' | head -10
[Tue Jul 31 01:13:41 2018] ssh-honeypot 0.0.8 by Daniel Roberson started on port 22. PID 5
[Tue Jul 31 01:19:49 2018] 1xx.1xx.1xx.1x gambaa gambaa
[Tue Jul 31 01:23:26 2018] 1xx.9x.1xx.1xx root toor
[Tue Jul 31 01:25:57 2018] 1xx.2xx.1xx.1xx root Passw0rd1234
[Tue Jul 31 01:26:00 2018] 1xx.2xx.1xx.1xx root Qwer1234
[Tue Jul 31 01:26:00 2018] 1xx.2xx.1xx.1xx root Abcd1234
[Tue Jul 31 01:26:08 2018] 1xx.2xx.1xx.1xx root ubuntu
[Tue Jul 31 01:26:09 2018] 1xx.2xx.1xx.1xx root PassWord
[Tue Jul 31 01:26:10 2018] 1xx.2xx.1xx.1xx root password321
[Tue Jul 31 01:26:15 2018] 1xx.2xx.1xx.1xx root zxcvbnm
</code></pre>

<h2>Saving results to disk:</h2>

<p>Redirecting the output to a log file, running in the foreground as a screen session:</p>

<pre><code class="bash">$ screen -S honeypot
$ docker logs -f f6cb | grep -v 'Error exchanging' | awk '{print $6, $7, $8}' &gt;&gt; /var/log/ssh-honeypot.log
</code></pre>

<p>Detach from your screen session:</p>

<pre><code class="bash">Ctrl + a; d
</code></pre>

<p>Checking out the logs</p>

<pre><code class="bash">$ head -3 /var/log/ssh-honeypot.log
2.7.2x.1x root jiefan
4x.7.2x.1x root HowAreYou
4x.7.2x.1x root Sqladmin
</code></pre>

<p>Leaving this running for a couple of months, and I have a massive password database:</p>

<pre><code class="bash">$ wc -l /var/log/honeypot/ssh.log
54184260 /var/log/honeypot/ssh.log
</code></pre>

<p>That is correct, 54 million password attempts. 5372 Unique IPs, 4082 Unique Usernames, 88829 Unique Passwords.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH Tools That Comes in Handy When Dealing With Multiple Servers]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/05/31/ssh-tools-that-comes-in-handy-when-dealing-with-multiple-servers/"/>
    <updated>2018-05-31T05:18:11-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/05/31/ssh-tools-that-comes-in-handy-when-dealing-with-multiple-servers</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/header-ssh-tips.png" alt="" /></p>

<p>When dealing with a lot of servers where you need to ssh to different servers and especially if they require different authentication from different private ssh keys, it kinda gets annoying specifying the private key you need, when you want to SSH to them.</p>

<h2>SSH Config</h2>

<p>SSH Config: <code>~/.ssh/config</code> is powerful!</p>

<p>In this config file, you can specify the remote host, the key, user and the alias, so that when you want to SSH to it, you dont have to use the fully qualified domain name or IP address.</p>

<p>Let&rsquo;s take for example our server-a with the following details:</p>

<ul>
<li>FQDN: host1.eu.compute.domain.coom</li>
<li>User: james</li>
<li>PrivateKeyFile: /path/to/key.pem</li>
<li>Disable Strict Host Checking</li>
</ul>


<p>So to access that host, you would use the following command (without ssh config):</p>

<pre><code class="bash">$ ssh -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -i /path/to/key.pem james@host1.eu.compute.domain.com
</code></pre>

<p>Now with SSH Config, open up the config file:</p>

<pre><code class="">$ vim ~/.ssh/config
</code></pre>

<p>and declare the host details:</p>

<pre><code>Host host1
  Hostname host1.eu.compute.domain.com
  User james
  IdentityFile /path/to/key.pem
  StrictHostKeyChecking no
  UserKnownHostsFile /dev/null
</code></pre>

<p>Now, if we need to SSH to it, we can do it as simply as:</p>

<pre><code class="bash">$ ssh host1
</code></pre>

<p>as it will pull in the configs from the config that is described from the host alias that you calling from the argument of the ssh binary.</p>

<h2>SSH Timeout</h2>

<p>Appending to our SSH Config, we can configure either our client or server to prevent SSH Timeouts due to inactivity.</p>

<ul>
<li>SSH Timeout on our Client:</li>
</ul>


<pre><code class="bash">$ vim ~/.ssh/config
</code></pre>

<p>Here we can set how often a NULL Packet is sent to the SSH Connections to keep the connection alive, in this case every 120 seconds:</p>

<pre><code>ServerAliveInterval 120
</code></pre>

<ul>
<li>SSH Timeout on the Servers:</li>
</ul>


<pre><code class="bash">$ vim /etc/ssh/sshd_config
</code></pre>

<p>Below we have 2 properties, the interval of how often to instruct the client connected to send a NULL packet to keep the connection alive and the max number of intervals, so for a idle connection to timeout in 24 hours, we will take 86400 seconds which is 24 hours, divide into 120 second intervals, which gives as 720 intervals.</p>

<p>So the config will look like this:</p>

<pre><code>ClientAliveInterval 120
ClientAliveCountMax 720
</code></pre>

<p>The restart the sshd service:</p>

<pre><code class="bash">$ /etc/init.d/sshd restart
</code></pre>

<h2>SSH Agent</h2>

<p>Another handy tool is <code>ssh-agent</code>, if you have password encryption on your key, everytime you need to ssh, a password will be prompted. A way to get around this is to use the ssh-agent.</p>

<p>We also want to set a TTL to the ssh-agent, as we don&rsquo;t want it to run forever (unless you want it to). In this case I will let the ssh-agent exit after 2 hours. It will also only run in the shell session from where you execute it. Lets start up our ssh-agent:</p>

<pre><code class="bash">$ eval $(ssh-agent -t 7200)
Agent pid 88760 
</code></pre>

<p>Now add the private key to the ssh-agent. If your private key is password protected, it will prompt you for the password and after successful verification the key will be added:</p>

<pre><code>$ ssh-add /path/to/key.pem
Identity added: /path/to/key.pem (/path/to/key.pem)
</code></pre>

<h2>Multiple Github Accounts:</h2>

<p>Here is a great post on how to work with different GitHub Accounts:
- <a href="https://gist.github.com/jexchan/2351996">https://gist.github.com/jexchan/2351996</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Forwarding the Docker Socket via a SSH Tunnel to Execute Docker Commands Locally]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/04/30/forwarding-the-docker-socket-via-a-ssh-tunnel-to-execute-docker-commands-locally/"/>
    <updated>2018-04-30T08:30:23-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/04/30/forwarding-the-docker-socket-via-a-ssh-tunnel-to-execute-docker-commands-locally</id>
    <content type="html"><![CDATA[<p>With automation in mind, when you want to execute docker commands remotely, you want to do it in a secure manner, as you don&rsquo;t want to expose your Docker port to the whole world.</p>

<p>One way in doing that, is forwarding the remote docker socket via a local port over a SSH Tunnel. With this way, you can execute docker commands locally on your workstation, as if the swarm is running on your workstation/laptop/node/bastion host etc.</p>

<p>Without the tunnel, I have a swarm on my laptop with no running services:</p>

<pre><code class="bash">$ docker service ls
ID                  NAME                   MODE                REPLICAS            IMAGE                                                               PORTS
</code></pre>

<p>As you can see, we have no services running, but the remote swarm has a couple, so after forwarding the connection, we should see our remote services.</p>

<script id="mNCC" language="javascript">
    medianet_width = "728";
    medianet_height = "90";
    medianet_crid = "218284798";
    medianet_versionId = "3111299"; 
  </script>


<script src="//contextual.media.net/nmedianet.js?cid=8CUD78FSV"></script>


<h2>Setting up the SSH Tunnel:</h2>

<p>Here we will forward the remote docker socket: <code>/var/run/docker.sock</code> to a local port bound to localhost: <code>localhost:2377</code>:</p>

<pre><code class="bash">$ screen -S docker
$ ssh -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -i ~/path/to/key.pem -NL localhost:2377:/var/run/docker.sock root@docker-managers.mydomain.com
</code></pre>

<p>Now the SSH Tunnel will be established, and you can detach your screen session, or open a new shell session. To detach your screen session: <code>'ctrl + a' then d</code></p>

<h2>Verifying that the tunnel is established:</h2>

<p>You can use netstat to verify that the port is listening:</p>

<pre><code class="bash">$ netstat -ant | grep 2377
tcp4       0      0  127.0.0.1.2377         *.*                    LISTEN
</code></pre>

<h2>Inform the Docker Client to use the Port:</h2>

<p>Now we need to inform the docker client, to use the new port to talk to the docker daemon. We do that by setting the <code>DOCKER_HOST</code> environment variable to point to <code>localhost:2377</code>:</p>

<pre><code class="bash">$ export DOCKER_HOST="localhost:2377"
</code></pre>

<p>This will remain for the lifetime of the shell session.</p>

<h2>Testing it Out:</h2>

<p>Now we can run our commands locally, and we should see the output of our remote swarm:</p>

<pre><code class="bash">$ docker service ls
ID                  NAME                   MODE                REPLICAS            IMAGE                                                               PORTS
xjta8e3ek2u2        apps_flask_reminders   replicated          3/3                 rbekker87/flask-reminders:debian
0l7ruktbqj99        apps_kibana            replicated          1/1                 kibana:latest
...
</code></pre>

<h2>Terminating our SSH Tunnel:</h2>

<p>To terminate our SSH Tunnel, reconnect to your shell session, and hit <code>ctrl + c</code>:</p>

<pre><code class="bash">$ screen -ls 
There is a screen on:
    50413.docker    (Detached)
$ screen -r 50413
</code></pre>

<p>Hit <code>ctrl + c</code> :</p>

<pre><code class="bash">CKilled by signal 2.
</code></pre>

<p>And exit the screen session:</p>

<pre><code class="bash">$ exit
</code></pre>

<p>With this way, you can do lots of automation with docker swarm, not limited to swarm, but one of them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Paramiko Module in Python to Execute Remote Bash Commands]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/04/23/using-paramiko-module-in-python-to-execute-remote-bash-commands/"/>
    <updated>2018-04-23T12:16:59-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/04/23/using-paramiko-module-in-python-to-execute-remote-bash-commands</id>
    <content type="html"><![CDATA[<p>Paramiko is a python implementation of the sshv2 protocol.</p>

<h2>Paramiko to execute Remote Commands:</h2>

<p>We will use paramiko module in python to execute a command on our remote server.</p>

<p>Client side will be referenced as (side-a) and Server side will be referenced as (side-b)</p>

<h2>Getting the Dependencies:</h2>

<p>Install Paramiko via pip on side-a:</p>

<pre><code class="bash">$ pip install paramiko --user
</code></pre>

<h2>Using Paramiko in our Code:</h2>

<p>Our Python Code:</p>

<pre><code class="python">import paramiko

ssh = paramiko.SSHClient()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
ssh.connect(hostname='192.168.10.10', username='ubuntu', key_filename='/home/ubuntu/.ssh/mykey.pem')

stdin, stdout, stderr = ssh.exec_command('lsb_release -a')

for line in stdout.read().splitlines():
    print(line)

ssh.close()
</code></pre>

<h2>Execute our Command Remotely:</h2>

<p>Now we will attempt to establish the ssh connection from side-a, then run <code>lsb_release -a</code> on our remote server, side-b:</p>

<pre><code class="bash">$ python execute.py

Distributor ID: Ubuntu
Description:    Ubuntu 16.04.4 LTS
Release:    16.04
Codename:   xenial
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a SSH Tunnel With the Sshtunnel Module in Python]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/04/23/setup-a-ssh-tunnel-with-the-sshtunnel-module-in-python/"/>
    <updated>2018-04-23T11:56:46-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/04/23/setup-a-ssh-tunnel-with-the-sshtunnel-module-in-python</id>
    <content type="html"><![CDATA[<p>Sometimes we need to restrict access to a port, where a port should listen on localhost, but you want to access that port from a remote source. One secure way of doing that, is to establish a SSH Tunnel to the remote side, and forward to port via the SSH Tunnel.</p>

<p>Today we will setup a Flask Web Service on our Remote Server (Side B) which will be listening on <code>127.0.0.1:5000</code> and setup the SSH Tunnel with the <code>sshtunnel</code> module in Python from our client side (Side A). Then we will make a GET request on our client side to the port that we are forwarding via the tunnel to our remote side.</p>

<h2>Remote Side:</h2>

<p>Our Demo Python Flask Application:</p>

<pre><code class="python">from flask import Flask

app = Flask(__name__)

@app.route('/')
def index():
    return 'OK'

if __name__ == '__main__':
    app.run(host='127.0.0.1', port=5000)
</code></pre>

<p>Run the server:</p>

<pre><code class="bash">$ python app.py
Listening on 127.0.0.1:5000
</code></pre>

<h2>Client Side:</h2>

<p>From our client side we first need to install sshtunnel via pip:</p>

<pre><code class="bash">$ pip install sshtunnel requests --user
</code></pre>

<p>Our code for our client that will establish the tunnel and do the GET request:</p>

<pre><code class="python">from sshtunnel import SSHTunnelForwarder
import requests

remote_user = 'ubuntu'
remote_host = '192.168.10.10'
remote_port = 22
local_host = '127.0.0.1'
local_port = 5000

server = SSHTunnelForwarder(
   (remote_host, remote_port),
   ssh_username=remote_user,
   ssh_private_key='/home/ubuntu/.ssh/mykey.pem',
   remote_bind_address=(local_host, local_port),
   local_bind_address=(local_host, local_port),
   )

server.start()

headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0'}
r = requests.get('http://127.0.0.1:5000', headers=headers).content
print(r)
server.stop()
</code></pre>

<p>Running our app:</p>

<pre><code class="bash">$ python ssh_tunnel.py
OK
</code></pre>

<p>So we have sucessfully established our ssh tunnel to our remote side, and able to access the network restricted port via the tunnel.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://pypi.org/project/sshtunnel/">SSHTunnel</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
