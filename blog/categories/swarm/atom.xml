<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Swarm | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/swarm/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2019-03-09T18:06:15-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Container Persistent Storage for Docker Swarm Using a GlusterFS Volume Plugin]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/03/05/container-persistent-storage-for-docker-swarm-using-a-glusterfs-volume-plugin/"/>
    <updated>2019-03-05T13:18:30-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/03/05/container-persistent-storage-for-docker-swarm-using-a-glusterfs-volume-plugin</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53351889-85572000-392a-11e9-9720-464e9318206e.jpg" alt="" /></p>

<p>From one of my previous posts I demonstrated how to provide persistent storage for your containers by using a <a href="https://blog.ruanbekker.com/blog/2018/02/16/guide-to-setup-docker-convoy-volume-driver-for-docker-swarm-with-nfs/">Convoy NFS Plugin</a>.</p>

<p>I&rsquo;ve stumbled upon one AWESOME GlusterFS Volume Plugin for Docker by <a href="https://github.com/trajano/docker-volume-plugins/tree/master/glusterfs-volume-plugin">@trajano</a>, please have a look at his repository. I&rsquo;ve been waiting for some time for one solid glusterfs volume plugin, and it works great.</p>

<h2>What we will be doing today</h2>

<p>We will setup a 3 node replicated glusterfs volume and show how easy it is to install the volume plugin and then demonstrate how storage from our swarms containers are persisted.</p>

<p>Our servers that we will be using will have the private ip&rsquo;s as shown below:</p>

<pre><code>10.22.125.101
10.22.125.102
10.22.125.103
</code></pre>

<h2>Setup GlusterFS</h2>

<p>Have a look at <a href="https://blog.ruanbekker.com/blog/2019/03/05/setup-a-3-node-replicated-storage-volume-with-glusterfs/?referral=github.com">this</a> post to setup the glusterfs volume.</p>

<h2>Install the GlusterFS Volume Plugin</h2>

<p>Below I&rsquo;m installing the plugin and setting the alias name as <code>glusterfs</code>, granting all permissions and keeping the plugin in a disabled state.</p>

<pre><code class="bash">$ docker plugin install --alias glusterfs trajano/glusterfs-volume-plugin --grant-all-permissions --disable
</code></pre>

<p>Set the glusterfs servers:</p>

<pre><code>$ docker plugin set glusterfs SERVERS=10.22.125.101,10.22.125.102,10.22.125.103
</code></pre>

<p>Enable the glusterfs plugin:</p>

<pre><code>$ docker plugin enable glusterfs
</code></pre>

<h2>Create a Service in Docker Swarm</h2>

<p>Deploy a sample service on docker swarm with a volume backed by glusterfs. Note that my glusterfs volume is called <code>gfs</code></p>

<pre><code class="yaml">version: "3.4"

services:
  foo:
    image: alpine
    command: ping localhost
    networks:
      - net
    volumes:
      - vol1:/tmp

networks:
  net:
    driver: overlay

volumes:
  vol1:
    driver: glusterfs
    name: "gfs/vol1"
</code></pre>

<p>Deploy the stack:</p>

<pre><code class="bash">$ docker stack deploy -c docker-compose.yml test
Creating service test_foo
</code></pre>

<p>Have a look on which node is your container running:</p>

<pre><code class="bash">$ docker service ps test_foo
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
jfwzb7yxnrxx        test_foo.1          alpine:latest       swarm-worker-1      Running             Running 37 seconds ago
</code></pre>

<p>Now jump to the <code>swarm-worker-1</code> node and verify that the container is running on that node:</p>

<pre><code class="bash">$ docker ps
CONTAINER ID        IMAGE                                          COMMAND                  CREATED             STATUS                  PORTS               NAMES
d469f341d836        alpine:latest                                  "ping localhost"           59 seconds ago      Up 57 seconds                               test_foo.1.jfwzb7yxnrxxnd0qxtcjex8lu
</code></pre>

<p>Now since the container is running on this node, we will also see that the volume defined in our task configuration will also be present:</p>

<pre><code class="bash">$ docker volume ls
DRIVER                       VOLUME NAME
glusterfs:latest             gfs/vol1
</code></pre>

<p>Exec into the container and look at the disk layout:</p>

<pre><code class="bash">$ docker exec -it d469f341d836 sh
/ # df -h
Filesystem                Size      Used Available Use% Mounted on
overlay                  45.6G      3.2G     40.0G   7% /
10.22.125.101:gfs/vol1   45.6G      3.3G     40.0G   8% /tmp
</code></pre>

<p>While you are in the container, write the hostname&rsquo;s value into a file which is mapped to the glusterfs volume:</p>

<pre><code class="bash">$ echo $HOSTNAME &gt; /tmp/data.txt
$ cat /tmp/data.txt
d469f341d836
</code></pre>

<h2>Testing Data Persistence</h2>

<p>Time to test the data persistence. Scale the service to 3 replicas, then hop onto a new node where a replica resides and check if the data was persisted.</p>

<pre><code class="bash">$ docker service scale test_foo=3
test_foo scaled to 3
overall progress: 3 out of 3 tasks
1/3: running   [==================================================&gt;]
2/3: running   [==================================================&gt;]
3/3: running   [==================================================&gt;]
verify: Service converged
</code></pre>

<p>Check where the containers are running:</p>

<pre><code class="bash">$ docker service ps test_foo
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTS
jfwzb7yxnrxx        test_foo.1          alpine:latest       swarm-worker-1      Running             Running 2 minutes ago
mdsg6c5b2nqb        test_foo.2          alpine:latest       swarm-worker-3      Running             Running 15 seconds ago
iybat57t4lha        test_foo.3          alpine:latest       swarm-worker-2      Running             Running 15 seconds ago
</code></pre>

<p>Hop onto the <code>swarm-worker-2</code> node and check if the data is persisted from our previous write:</p>

<pre><code class="bash">$ docker exec -it 4228529aba29 sh
$ cat /tmp/data.txt
d469f341d836
</code></pre>

<p>Now let&rsquo;s append data to that file, then delete the stack and recreate to test if the data is still persisted:</p>

<pre><code class="bash">$ echo $HOSTNAME &gt;&gt; /tmp/data.txt
$ cat /tmp/data.txt
d469f341d836
4228529aba29
</code></pre>

<p>On the manager delete the stack:</p>

<pre><code class="bash">$ docker stack rm test
Removing service test_foo
</code></pre>

<p>The deploy the stack again:</p>

<pre><code class="bash">$ docker stack deploy -c docker-compose.yml test
Creating service test_foo
</code></pre>

<p>Check where the container is running:</p>

<pre><code class="bash">$ docker service ps test_foo
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS
9d6z02m123jk        test_foo.1          alpine:latest       swarm-worker-1      Running             Running 2 seconds ago
</code></pre>

<p>Exec into the container and read the data:</p>

<pre><code class="bash">$ docker exec -it 3008b1e1bba1 cat /tmp/data.txt
d469f341d836
4228529aba29
</code></pre>

<p>And as you can see the data is persisted.</p>

<h2>Resources</h2>

<p>Please have a look and star <a href="https://github.com/trajano/docker-volume-plugins">@trajano&rsquo;s</a> repository:</p>

<ul>
<li><a href="https://github.com/trajano/docker-volume-plugins">https://github.com/trajano/docker-volume-plugins</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Use Swarm Managed Configs in Docker Swarm to Store Your Application Configs]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/02/28/use-swarm-managed-configs-in-docker-swarm-to-store-your-application-configs/"/>
    <updated>2019-02-28T09:48:28-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/02/28/use-swarm-managed-configs-in-docker-swarm-to-store-your-application-configs</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53351889-85572000-392a-11e9-9720-464e9318206e.jpg" alt="" /></p>

<p>Docker version 17.06 introduced Swarm Service Configs, which allows you to store data like configuration files, note that this is for non-sensitive information.</p>

<p>In this tutorial we will store the data of our <code>index.html</code> in a service config, then attach the config to our service.</p>

<h2>Creating the Config</h2>

<p>Create the <code>index.html</code> file and store it as a config:</p>

<pre><code class="bash">$ cat &gt; index.html &lt;&lt; EOF
&lt;html&gt;
  &lt;body&gt;
    Hello, World!
  &lt;/body&gt;
&lt;/html&gt;
EOF
</code></pre>

<p>Store the config as <code>nginx_root_doc</code>:</p>

<pre><code class="bash">$ docker config create nginx_root_doc index.html
</code></pre>

<h2>Create the Service</h2>

<p>Create the swarm service and associate the config with the service and set the target path where the config will reside:</p>

<pre><code class="bash">$ docker service create --name web \
  --config source=nginx_root_doc,target=/usr/share/nginx/html/index.html \
  --publish 8080:80 nginx:alpine
</code></pre>

<p>Once the service is up, test it:</p>

<pre><code class="bash">$ curl -i http://localhost:8080/
&lt;html&gt;
HTTP/1.1 200 OK
Server: nginx/1.15.9
Date: Thu, 28 Feb 2019 12:00:19 GMT
Content-Type: text/html
Content-Length: 52
Last-Modified: Thu, 28 Feb 2019 11:59:37 GMT
Connection: keep-alive
ETag: "5c77cd29-34"
Accept-Ranges: bytes

&lt;html&gt;
  &lt;body&gt;
    Hello, World!
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Delete the service:</p>

<pre><code class="bash">$ docker service rm web
</code></pre>

<p>Delete the config:</p>

<pre><code class="bash">$ docker config rm nginx_root_doc
</code></pre>

<h2>Create the Service using Compose:</h2>

<p>Doing the same with a docker-compose file, will look like the following. The first example will be where we will explicitly define our path of our secret, and will create on deploy time. Our compose file:</p>

<pre><code class="yaml">services:
  web:
    image: nginx:alpine
    ports:
      - 8080:80
    networks:
      - net
    configs:
      - source: nginx_root_doc
        target: /usr/share/nginx/html/index.html

configs:
  nginx_root_doc:
    file: ./index.html

networks:
  net:
    driver: overlay
</code></pre>

<p>Deploying our stack:</p>

<pre><code class="bash">$ docker stack deploy -c docker-compose.yml apps
Creating network apps_net
Creating config apps_nginx_root_doc
Creating service apps_web
</code></pre>

<p>Testing our our service:</p>

<pre><code class="bash">$ curl -i http://localhost:8080/
HTTP/1.1 200 OK
Server: nginx/1.15.9
Date: Thu, 28 Feb 2019 12:20:52 GMT
Content-Type: text/html
Content-Length: 56
Last-Modified: Thu, 28 Feb 2019 12:20:47 GMT
Connection: keep-alive
ETag: "5c77d21f-38"
Accept-Ranges: bytes

&lt;html&gt;
  &lt;body&gt;
    Hello, World!
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Note, that configs cant be updated, if you want to rotate a config you will create a new config and update the target in your task definition to point to your new config.</p>

<p>Delete the stack:</p>

<pre><code class="bash">$ docker stack rm apps
Removing service apps_web
Removing config apps_nginx_root_doc
Removing network apps_net
</code></pre>

<p>Another example will be to point to a external config which already exists in swarm. The only change will be that we need to set the config as a external type.</p>

<p>Create the config:</p>

<pre><code class="bash">$ docker config create nginx_root_doc index.html
</code></pre>

<p>Now that the config exists, create this compose file:</p>

<pre><code class="yaml">version: "3.3"

services:
  web:
    image: nginx:alpine
    ports:
      - 8080:80
    networks:
      - net
    configs:
      - source: nginx_root_doc
        target: /usr/share/nginx/html/index.html

configs:
  nginx_root_doc:
    external: true

networks:
  net:
    driver: overlay
</code></pre>

<p>Then deploy the stack:</p>

<pre><code class="bash">$ docker stack deploy -c docker-compose.yml apps
Creating network apps_net
Creating service apps_web
</code></pre>

<p>Then testing:</p>

<pre><code class="bash">$ curl -i http://localhost:8080/
HTTP/1.1 200 OK
Server: nginx/1.15.9
Date: Thu, 28 Feb 2019 12:28:11 GMT
Content-Type: text/html
Content-Length: 56
Last-Modified: Thu, 28 Feb 2019 12:28:09 GMT
Connection: keep-alive
ETag: "5c77d3d9-38"
Accept-Ranges: bytes

&lt;html&gt;
  &lt;body&gt;
    Hello, World!
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<h2>Resources:</h2>

<p>For more information on docker swarm configs have a look at <a href="https://docs.docker.com/engine/swarm/configs/#example-rotate-a-config">docker&rsquo;s documentation</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup a 3 Node Docker Swarm Cluster on Ubuntu 16.04]]></title>
    <link href="http://blog.ruanbekker.com/blog/2019/01/10/setup-a-3-node-docker-swarm-cluster-on-ubuntu-16-dot-04/"/>
    <updated>2019-01-10T09:52:07-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2019/01/10/setup-a-3-node-docker-swarm-cluster-on-ubuntu-16-dot-04</id>
    <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/567298/53351889-85572000-392a-11e9-9720-464e9318206e.jpg" alt="" /></p>

<p>Docker Swarm is a Clustering and Orchestration Framework for the Docker ecosystem. Have a look at their <a href="https://docs.docker.com/engine/swarm/">official documentation</a> for detailed information.</p>

<p>In this Tutorial we will Setup a 3 Node Docker Swarm Cluster and to Demonstrate How Easy it is to Deploy a Web Application with 2 Replicas from a Docker Image.</p>

<p><br></p>

<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>


<p><br></p>

<h2>Overview of What we will be Doing</h2>

<ul>
<li>Install Docker on 3 Servers with Ubuntu 16.04</li>
<li>Initialize the Swarm and Join the Worker Nodes</li>
<li>Create a Nginx Service with 2 Replicas</li>
<li>Do some Inspection: View some info on the Service</li>
</ul>


<h2>Prerequisites</h2>

<p>3 Fresh Deployed Ubuntu 16.04 Servers. ( 1GB Memory Servers will be good for development )</p>

<h2>What is Docker</h2>

<p>Docker is a Open Source Technology that allows you to create lightweight, isolated, reproducible application instances which is called Containers. Docker is built on top of the LXC technology, so it uses Linux Containers and as mentioned, it&rsquo;s lightweight compared to a traditional VM.</p>

<p>A Container is isolated and uses the Kernel of the Docker host, it also utilizes Kernel features such as cgroups and namespaces in order to make them isolated.</p>

<h2>Installing Docker Community Edition</h2>

<p>Remove any older versions of Docker that might be present and install the dependencies:</p>

<pre><code class="bash">$ sudo apt remove docker docker-engine -y
$ sudo apt install linux-image-extra-$(uname -r) linux-image-extra-virtual python-setuptools -y
$ sudo apt install apt-transport-https ca-certificates curl software-properties-common -y
</code></pre>

<p>Get the needed repository to setup Docker Community Edition:</p>

<pre><code class="bash">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo apt-key fingerprint 0EBFCD88
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
</code></pre>

<p>Update the repository index and Install Docker Community Edition:</p>

<pre><code class="bash">$ sudo apt update
$ sudo apt install docker-ce -y
$ sudo easy_install pip
$ sudo pip install docker-compose
</code></pre>

<p>Enable Docker on Startup and Start the Docker Engine:</p>

<pre><code class="bash">$ sudo systemctl enable docker
$ sudo systemctl restart docker
</code></pre>

<p>If you would like to execute your docker commands without sudo, add your user to the docker group:</p>

<pre><code class="bash">$ sudo usermod -aG docker $(whoami)
</code></pre>

<p>Test your Setup by Running a Hello World Container. You will see that if the image is not in the local docker image cache, it will pull the image from docker hub (or the respective docker registry), then once the image is saved locally, docker will then instantiate the container from that image:</p>

<pre><code class="bash">$ docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
78445dd45222: Pull complete
Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.
</code></pre>

<h2>DNS Configuration</h2>

<p>If you have a DNS Server you can configure the A Records for these hosts on DNS, but for simplicity, I will add the noted IP Addresses from the previous step into my <code>/etc/hosts</code> file so we can resolve names to IP&rsquo;s</p>

<p>Open up the the hosts file:</p>

<pre><code class="bash">$ sudo vim /etc/hosts
</code></pre>

<p>In my example, my IP Addresses:</p>

<pre><code>192.0.2.41  manager
192.0.2.42  worker-1
192.0.2.43  worker-2
</code></pre>

<p>Repeat the above steps on the other 2 Servers and make note of the IP Addresses of each node. You should be able to ping and reach the nodes that was configured. Make sure to allow all traffic between these nodes.</p>

<h2>Initialize the Swarm:</h2>

<p>Now we will initialize the swarm on the manager node and as we have more than one network interface, we will specify the &ndash;advertise-addr option:</p>

<pre><code class="bash">$ docker swarm init --advertise-addr 192.0.2.41
Swarm initialized: current node (siqyf3yricsvjkzvej00a9b8h) is now a manager.

    To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 \
    192.0.2.41:2377

    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
</code></pre>

<p>From the response above, we received the join token that allows the workers to register with the manager node. If its a scenario where you want to have more than one manager node, you can run <code>docker swarm join-token manager</code> to receive the join token for additional manager.</p>

<p>Let&rsquo;s add the two worker nodes to the manager:</p>

<pre><code class="bash">$ [worker-1] docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.0.2.41:2377
This node joined a swarm as a worker.
</code></pre>

<pre><code class="bash">$ [worker-2] docker swarm join --token SWMTKN-1-0eith07xkcg93lzftuhjmxaxwfa6mbkjsmjzb3d3sx9cobc2zp-97s6xzdt27y2gk3kpm0cgo6y2 192.0.2.41:2377
This node joined a swarm as a worker.
</code></pre>

<p>To see the node status, so that we can determine if the nodes are active/available etc, from the manager node, list all the nodes in the swarm:</p>

<pre><code class="bash">[manager] $ docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
j14mte3v1jhtbm3pb2qrpgwp6    worker-1  Ready   Active 
siqyf3yricsvjkzvej00a9b8h *  master    Ready   Active        Leader
srl5yzme5hxnzxal2t1efmwje    worker-2  Ready   Active
</code></pre>

<h2>Reobtaining the Join Tokens</h2>

<p>If at any time, you lost your join token, it can be retrieved by running the following for the manager token:</p>

<pre><code class="bash">$ docker swarm join-token manager -q SWMTKN-1-67chzvi4epx28ii18gizcia8idfar5hokojz660igeavnrltf0-09ijujbnnh4v960b8xel58pmj
</code></pre>

<p>And the following to retrieve the worker token:</p>

<pre><code class="bash">$ docker swarm join-token worker -q SWMTKN-1-67chzvi4epx28ii18gizcia8idfar5hokojz660igeavnrltf0-acs21nn28v17uwhw0oqg5ibwx
</code></pre>

<p>Swarm Services in Docker uses a declarative model which means that you define the desired state of the service, and rely on Docker to maintain this state. More information on this can be found on their <a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/">Documentation</a></p>

<p>At this moment, we will see that we have no services running in our swarm:</p>

<pre><code class="bash">[manager] $ docker service ls
ID  NAME  MODE  REPLICAS  IMAGE
</code></pre>

<h2>Deploying our First Service</h2>

<p>Now onto the creation of a standard nginx service with 2 replicas, which means that there will be 2 containers of nginx running in our swarm.</p>

<p>But first, we need to create a overlay network, which is a network driver that creates a distributed network among multiple Docker daemon hosts. Swarm takes care of the routing automatically, which is routed via the port mappings. So you can have that your container sits on worker-2, when you hit your manager node on the published port, it will route the request to the desired application that resides on the respective container.</p>

<p>To create a overlay network called mynet:</p>

<pre><code class="bash">[manager] $ docker network create --driver overlay mynet
</code></pre>

<p>Now onto creating the Service. If any of these containers fail, they will handled by the manager node and will be spawned again to have the desired number that we set on the replica option:</p>

<pre><code class="bash">[manager] $ docker service create --name my-web --publish 8080:80 --replicas 2 --network mynet nginx
</code></pre>

<p>Let&rsquo;s have a look at our nginx service:</p>

<pre><code class="bash">[manager] $ docker service ls
ID            NAME    MODE        REPLICAS  IMAGE
1okycpshfusq  my-web  replicated  2/2       nginx:latest
</code></pre>

<p>After we see that the replica count is 2/2 our service is ready.</p>

<p>To see on which nodes our containers are running that makes up our service:</p>

<pre><code class="bash">[manager] $ docker service ps my-web
ID            NAME      IMAGE         NODE      DESIRED STATE  CURRENT STATE           ERROR  PORTS
k0qqrh8s0c2d  my-web.1  nginx:latest  worker-1  Running        Running 30 seconds ago
nku9wer6tmll  my-web.2  nginx:latest  worker-2  Running        Running 30 seconds ago
</code></pre>

<p>From the above output, we can see that worker-1 and worker-2 are serving our containers for our service. We can also retrieve more information of our service by using the inspect option, which will give you a detailed response in json format of the service:</p>

<pre><code class="bash">[manager] $ docker service inspect my-web
</code></pre>

<p>We can get the Endpoint Port info by using inspect and using the &ndash;format parameter to filter the output:</p>

<pre><code class="bash">[manager] $ docker service inspect --format="" my-web  | python -m json.tool
</code></pre>

<p>From the output we will find the PublishedPort is the Port that we Expose, which will be the listener. Our TargetPort will be the port that is listening on the container:</p>

<pre><code class="json">[
    {
        "Protocol": "tcp",
        "PublishMode": "ingress",
        "PublishedPort": 8080,
        "TargetPort": 80
    }
]
</code></pre>

<p>Now that we went through the inspection of our service, its time to test our base nginx service.</p>

<h2>Testing Nginx in our Swarm</h2>

<p>Make a request against your docker node manager address on the port that was exposed, in this case 8080:</p>

<pre><code class="bash">$ curl -I http://docker-node-manager-ip:8080

HTTP/1.1 200 OK
Server: nginx/1.15.5
Date: Thu, 10 Jan 2019 14:48:40 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 02 Oct 2018 14:49:27 GMT
Connection: keep-alive
ETag: "5bb38577-264"
Accept-Ranges: bytes
</code></pre>

<p>Now we have successfull setup a 3 node docker swarm cluster and deployed a basic nginx service to our swarm. Please have a look at my other <a href="https://blog.ruanbekker.com/blog/categories/docker/">Docker Swarm Tutorials</a> for other content.</p>

<h2>Thank You</h2>

<p>Please feel free to show support by, <strong>sharing</strong> this post, making a <strong>donation</strong>, <strong>subscribing</strong> or <strong>reach out to me</strong> if you want me to demo and write up on any specific tech topic.</p>

<center>
<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick" />
<input type="hidden" name="hosted_button_id" value="W7CBGYTCWGANQ" />
<input type="image" src="https://user-images.githubusercontent.com/567298/49853901-461c3700-fdf1-11e8-9d80-8a424a3173af.png" border="0" name="submit" title="PayPal - The safer, easier way to pay online!" alt="Donate with PayPal button" />
</form>
</center>




<p><p></p>

<p>Thanks for reading!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Ghost Version 2 Blog for the RaspberryPi]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/building-ghost-version-2-blog-for-the-raspberrypi/"/>
    <updated>2018-10-23T17:37:49-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/building-ghost-version-2-blog-for-the-raspberrypi</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/ghost-blog-main.png" alt="" /></p>

<p>In this post we will setup Ghost 2.0.3 for the Raspberry Pi on Docker Swarm</p>

<h2>Dockerfile</h2>

<p>Our dockerfile:</p>

<pre><code>FROM rbekker87/armhf-node:8.11

RUN apk add --no-cache 'su-exec&gt;=0.2' &amp;&amp; apk --update add bash gcc g++ make python &amp;&amp; npm install sqlite3 --build-from-source

ENV NODE_ENV production
ENV GHOST_CLI_VERSION 1.9.1
ENV GHOST_VERSION 2.0.3
ENV GHOST_INSTALL /var/lib/ghost
ENV GHOST_CONTENT /var/lib/ghost/content

RUN npm install -g "ghost-cli@$GHOST_CLI_VERSION"

RUN set -ex; \
        mkdir -p "$GHOST_INSTALL" \
        &amp;&amp; adduser -s /bin/sh -D node \
        &amp;&amp; chown node:node "$GHOST_INSTALL" \
        &amp;&amp; su-exec node ghost install "$GHOST_VERSION" --db sqlite3 --no-prompt --no-stack --no-setup --dir "$GHOST_INSTALL" \
        &amp;&amp; cd "$GHOST_INSTALL" \
        &amp;&amp; su-exec node ghost config --ip 0.0.0.0 --port 2368 --no-prompt --db sqlite3 --url http://localhost:2368 --dbpath "$GHOST_CONTENT/data/ghost.db" \
        &amp;&amp; su-exec node ghost config paths.contentPath "$GHOST_CONTENT" \
        &amp;&amp; su-exec node ln -s config.production.json "$GHOST_INSTALL/config.development.json" \
        &amp;&amp; readlink -f "$GHOST_INSTALL/config.development.json" \
        &amp;&amp; mv "$GHOST_CONTENT" "$GHOST_INSTALL/content.orig" \
        &amp;&amp; mkdir -p "$GHOST_CONTENT" &amp;&amp; chown node:node "$GHOST_CONTENT" \
        &amp;&amp; "$GHOST_INSTALL/current/node_modules/knex-migrator/bin/knex-migrator" --version

ENV PATH $PATH:$GHOST_INSTALL/current/node_modules/knex-migrator/bin

WORKDIR $GHOST_INSTALL

COPY docker-entrypoint.sh /usr/local/bin
RUN chmod +x /usr/local/bin/docker-entrypoint.sh

ENTRYPOINT ["docker-entrypoint.sh"]

CMD ["node", "current/index.js"]
</code></pre>

<h2>Our Boot Script</h2>

<p>Our entrypoint script <code>docker-entrypoint.sh</code>:</p>

<pre><code>#!/bin/bash
set -e

if [[ "$*" == node*current/index.js* ]] &amp;&amp; [ "$(id -u)" = '0' ];
  then
    chown -R node "$GHOST_CONTENT"
    exec su-exec node "$BASH_SOURCE" "$@"
fi

if [[ "$*" == node*current/index.js* ]];
  then
    baseDir="$GHOST_INSTALL/content.orig"
    for src in "$baseDir"/*/ "$baseDir"/themes/*;
      do
        src="${src%/}"
        target="$GHOST_CONTENT/${src#$baseDir/}"
        mkdir -p "$(dirname "$target")"
        if [ ! -e "$target" ];
          then
            tar -cC "$(dirname "$src")" "$(basename "$src")" | tar -xC "$(dirname "$target")"
        fi
      done

    knex-migrator-migrate --init --mgpath "$GHOST_INSTALL/current"
fi

prod() {
cat &gt; /var/lib/ghost/config.development.json &lt;&lt; EOF
{
  "url": "http://${SERVER_URL:-localhost}:${SERVER_PORT:-2368}",
  "server": {
    "port": ${SERVER_PORT:-2368},
    "host": "0.0.0.0"
  },
  "database": {
    "client": "sqlite3",
    "connection": {
      "filename": "/var/lib/ghost/content/data/ghost.db"
    }
  },
  "mail": {
    "transport": "SMTP",
    "from": "${FROM_NAME:-MyBlog} &lt;${FROM_EMAIL:-ghost-blog@localhost}&gt;",
    "options": {
      "service": "Mailgun",
      "host": "${SMTP_HOST:-localhost}",
      "port": ${SMTP_PORT:-25},
      "auth": {
        "user": "${SMTP_AUTH_USERNAME:-root}",
        "pass": "${SMTP_AUTH_PASSWORD:-password}"
      }
    }
  },
  "logging": {
    "transports": [
      "file",
      "stdout"
    ]
  },
  "process": "systemd",
  "paths": {
    "contentPath": "/var/lib/ghost/content"
  }
}
EOF
}

dev() {
cat &gt; /var/lib/ghost/config.development.json &lt;&lt; EOF
{
  "url": "http://${SERVER_URL:-localhost}:${SERVER_PORT:-2368}",
  "server": {
    "port": ${SERVER_PORT:-2368},
    "host": "0.0.0.0"
  },
  "database": {
    "client": "sqlite3",
    "connection": {
      "filename": "/var/lib/ghost/content/data/ghost.db"
    }
  },
  "mail": {
    "transport": "Direct"
  },
  "logging": {
    "transports": [
      "file",
      "stdout"
    ]
  },
  "process": "systemd",
  "paths": {
    "contentPath": "/var/lib/ghost/content"
  }
}
EOF
}

test(){
cat &gt; /var/lib/ghost/config.development.json &lt;&lt; EOF
{
  "url": "http://localhost:2368",
  "server": {
    "port": 2368,
    "host": "0.0.0.0"
  },
  "database": {
    "client": "sqlite3",
    "connection": {
      "filename": "/var/lib/ghost/content/data/ghost.db"
    }
  },
  "mail": {
    "transport": "Direct"
  },
  "logging": {
    "transports": [
      "file",
      "stdout"
    ]
  },
  "process": "systemd",
  "paths": {
    "contentPath": "/var/lib/ghost/content"
  }
}
EOF
}

if  [ "${ENV_TYPE}" = "PROD" ]
  then prod

elif [ "${ENV_TYPE}" = "DEV" ]
  then dev
  else test

fi

exec "$@"
</code></pre>

<p>The entrypoint script takes a couple of environment variables, as you can see if they are not defined, defaults will be inherited.</p>

<p>Configurable Environment Variables:</p>

<pre><code>      - ENV_TYPE=PROD
      - SERVER_PORT=2368
      - SERVER_URL=myblog.pistack.co.za
      - FROM_NAME=MyName
      - SMTP_HOST=mail.mydomain.co.za
      - SMTP_PORT=587
      - SMTP_AUTH_USERNAME=me@mydomain.co.za
      - SMTP_AUTH_PASSWORD=secret
</code></pre>

<h2>Building our Ghost Image</h2>

<p>I have a public image available if you dont want to build/push, but for building:</p>

<pre><code>$ docker build -t your-name/repo:tag
</code></pre>

<h2>Deploy Ghost with Traefik</h2>

<p>Our <code>ghost-compose.yml</code> with traefik will look like the following, note that I mounted the source path to the container&rsquo;s path, the source path is running on a replicated glusterfs volume, which can be setup following <a href="https://blog.ruanbekker.com/blog/2018/10/23/setting-up-a-docker-swarm-cluster-on-3-raspberrypi-nodes/">this post</a></p>

<p>Also for this demonstration I was using the domain pistack.co.za, where you need to utilize the domain of your choice.</p>

<pre><code>version: "3.4"

services:
  ghost:
    image: rbekker87/armhf-ghost:2.0.3
    networks:
      - appnet
    volumes:
      - type: bind
        source: /mnt/volumes/myblog/content/data
        target: /var/www/ghost/content/data
    environment:
      - ENV_TYPE=PROD
      - SERVER_PORT=2368
      - SERVER_URL=myblog.pistack.co.za
      - FROM_NAME=MyName
      - SMTP_HOST=mail.mydomain.co.za
      - SMTP_PORT=587
      - SMTP_AUTH_USERNAME=me@mydomain.co.za
      - SMTP_AUTH_PASSWORD=secret
    deploy:
      replicas: 1
      labels:
        - "traefik.enable=true"
        - "traefik.backend=ghost"
        - "traefik.backend.loadbalancer.swarm=true"
        - "traefik.docker.network=appnet"
        - "traefik.port=2368"
        - "traefik.frontend.passHostHeader=true"
        - "traefik.frontend.rule=Host:myblog.pistack.co.za"
      replicas: 3
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints: [node.role == worker]

networks:
  appnet:
    external: true
</code></pre>

<p>Deploy the stack:</p>

<pre><code>$ docker stack deploy -c ghost-compose.yml web
</code></pre>

<p>Once the service is up, you will be able to reach your blog on the provided <code>traefik.frontend.rule</code>. If you don&rsquo;t have traefik running, you can follow <a href="https://blog.ruanbekker.com/blog/2018/10/23/build-a-traefik-proxy-image-for-your-raspberry-pi-on-docker-swarm/">this post</a> to get traefik up and running.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/r/rbekker87/armhf-ghost/">https://hub.docker.com/r/rbekker87/armhf-ghost/</a></li>
<li><a href="https://github.com/ruanbekker/ghost-armhf">https://github.com/ruanbekker/ghost-armhf</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build a Traefik Proxy Image for Your Raspberry Pi on Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/10/23/build-a-traefik-proxy-image-for-your-raspberry-pi-on-docker-swarm/"/>
    <updated>2018-10-23T17:31:02-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/10/23/build-a-traefik-proxy-image-for-your-raspberry-pi-on-docker-swarm</id>
    <content type="html"><![CDATA[<p><img src="https://objects.ruanbekker.com/assets/images/traefik-logo-routing.png" alt="" /></p>

<p>In this post we will setup a Docker Image for Traefik Proxy on the ARM Architecture, specifically on the Raspberry Pi, which we will deploy to our Raspberry Pi Docker Swarm.</p>

<p>Then we will build and push our image to a registry, then setup traefik and also setup a web application that sits behind our Traefik Proxy.</p>

<h2>What is Traefik</h2>

<p><a href="https://traefik.io/">Traefik</a> is a modern load balancer and reverse proxy built for micro services.</p>

<h2>Dockerfile</h2>

<p>We will be running Traefik on Alpine 3.8:</p>

<pre><code class="dockerfile">FROM rbekker87/armhf-alpine:3.8

ENV TRAEFIK_VERSION 1.7.0-rc3
ENV ARCH arm

ADD https://github.com/containous/traefik/releases/download/v${TRAEFIK_VERSION}/traefik_linux-${ARCH} /traefik

RUN apk add --no-cache ca-certificates \
    &amp;&amp; chmod +x /traefik \
    &amp;&amp; rm -rf /var/cache/apk/*

EXPOSE 80 8080 443

ENTRYPOINT ["/traefik"]
</code></pre>

<h2>Build and Push</h2>

<p>Build and Push your image to your registry of choice:</p>

<pre><code class="bash">$ docker build -t your-user/repo:tag .
$ docker push your-user/repo:tag
</code></pre>

<p>If you do not want to push to a registry, I have a public image available at <a href="https://hub.docker.com/r/rbekker87/armhf-traefik/">https://hub.docker.com/r/rbekker87/armhf-traefik/</a>, the image itself is <code>rbekker87/armhf-traefik:1.7.0-rc3</code></p>

<h2>Deploy Traefik to the Swarm</h2>

<p>From our <code>traefik-compose.yml</code>, you will notice that I have set that our network is external, so the network should exist prior to deploying the stack.</p>

<p>Let&rsquo;s create the overlay network:</p>

<pre><code class="bash">$ docker network create --driver overlay appnet
</code></pre>

<p>Below, the <code>traefik-compose.yml</code>, note that I&rsquo;m using pistack.co.za as my domain:</p>

<pre><code class="yml">version: "3.4"

services:
  traefik: 
    image: rbekker87/armhf-traefik:1.7.0-rc3
    command:
      - "--api"
      - "--docker"
      - "--docker.swarmmode"
      - "--docker.domain=pistack.co.za"
      - "--docker.watch"
      - "--logLevel=DEBUG"
      - "--web"
    networks:
      - appnet
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 80:80
      - 8080:8080
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
      placement:
        constraints: [node.role == manager]

networks:
  appnet:
    external: true
</code></pre>

<p>Deploy the stack:</p>

<pre><code class="bash">$ docker stack deploy -c traefik-compose.yml proxy
</code></pre>

<p>List the stacks:</p>

<pre><code class="bash">$ docker stack ls
NAME                SERVICES
proxy               1
</code></pre>

<p>Check if the services in your stack is running. Since our deploy mode was global, there will be a replica running on each node, and in my swarm I&rsquo;ve got 3 nodes:</p>

<pre><code class="bash">$ docker stack services proxy
ID                  NAME                MODE                REPLICAS            IMAGE                    PORTS
16x31j7o0f0r        proxy_traefik       global              3/3                 rbekker87/armhf-traefik:1.7.0-rc3   *:80-&gt;80/tcp,*:8080-&gt;8080/tcp
</code></pre>

<h2>Deploy a Web Service hooked up to Traefik</h2>

<p>Pre-Requirement:</p>

<p>To register subdomains on the fly, set you DNS for your domain to the following (im using pistack.co.za in this example):</p>

<ul>
<li><code>pistack.co.za</code> <code>A</code> <code>x.x.x.x</code></li>
<li><code>*.pistack.co.za</code> <code>A</code> <code>x.x.x.x</code></li>
</ul>


<p>Next, we will deploy we app that will be associated to our Traefik service domain, so we will inform Traefik that our web app fqdn and port that will be registered with the proxy.</p>

<p>Our <code>app-compose.yml</code> file for our webapp:</p>

<pre><code class="yml">version: "3.4"

services:
  whoami:
    image: rbekker87/golang-whoami:alpine-amrhf
    networks:
      - appnet
    deploy:
      replicas: 3
      labels:
        - "traefik.backend=whoami"
        - "traefik.port=80"
        - "traefik.frontend.rule=Host:whoami.pistack.co.za"
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
      placement:
        constraints: [node.role == worker]
    healthcheck:
      test: nc -vz 127.0.0.1 80 || exit 1
      interval: 60s
      timeout: 3s
      retries: 3

networks:
  appnet:
    external: true
</code></pre>

<p>In the above compose, you will notice that our traefik backend is set to our service name, our port is the port that the proxy will forward requests to the containers port, since the proxy and the whoami container is in the same network, they will be able to communicate with each other. Then we also have our frontend rule which will be the endpoint we will reach our application on.</p>

<p>Deploy the stack:</p>

<pre><code class="bash">$ docker stack deploy -c whoami.yml web
Creating service web_whoami
</code></pre>

<p>List the tasks running in our web stack:</p>

<pre><code class="bash">$ docker stack services web
ID                  NAME                MODE                REPLICAS            IMAGE                                  PORTS
31ylfcfb7uyw        web_whoami          replicated          3/3                 rbekker87/golang-whoami:alpine-amrhf
</code></pre>

<p>Once all the replicas is running, move along to test the application</p>

<h2>Testing our Application:</h2>

<p>I have 3 replicas each running on their own container, so each container will respond with its own hostname:</p>

<pre><code class="bash">$ docker service ps web_whoami
ID                  NAME                IMAGE                                  NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTS
ivn8fgfosvgd        web_whoami.1        rbekker87/golang-whoami:alpine-amrhf   rpi-01              Running             Running 26 minutes ago
rze6u6z56aop        web_whoami.2        rbekker87/golang-whoami:alpine-amrhf   rpi-02              Running             Running 26 minutes ago
6fjua869r498        web_whoami.3        rbekker87/golang-whoami:alpine-amrhf   rpi-04              Running             Running 23 minutes ago
</code></pre>

<p>Making our 1st GET request:</p>

<pre><code class="bash">$ $ curl http://whoami.pistack.co.za/
Hostname: 43f5f0a6682f
IP: 127.0.0.1
IP: 10.0.0.138
IP: 10.0.0.218
IP: 172.18.0.4
GET / HTTP/1.1
Host: whoami.pistack.co.za
User-Agent: curl/7.38.0
Accept: */*
Accept-Encoding: gzip
X-Forwarded-For: 165.73.96.95, 10.255.0.2
X-Forwarded-Host: whoami.pistack.co.za
X-Forwarded-Port: 80
X-Forwarded-Proto: http
X-Forwarded-Server: 31b37f9714d3
X-Real-Ip: 10.255.0.2
</code></pre>

<p>Our 2nd GET Request:</p>

<pre><code class="bash">$ curl http://whoami.pistack.co.za/
Hostname: d1c17a476414
IP: 127.0.0.1
IP: 10.0.0.138
IP: 10.0.0.71
IP: 172.19.0.5
GET / HTTP/1.1
Host: whoami.pistack.co.za
User-Agent: curl/7.38.0
Accept: */*
Accept-Encoding: gzip
X-Forwarded-For: 165.73.96.95, 10.255.0.2
X-Forwarded-Host: whoami.pistack.co.za
X-Forwarded-Port: 80
X-Forwarded-Proto: http
X-Forwarded-Server: 02b0ff6eab73
X-Real-Ip: 10.255.0.2
</code></pre>

<p>And our 3rd GET Request:</p>

<pre><code>$ curl http://whoami.pistack.co.za/
Hostname: 17c817a1813b
IP: 172.18.0.6
IP: 127.0.0.1
IP: 10.0.0.138
IP: 10.0.0.73
GET / HTTP/1.1
Host: whoami.pistack.co.za
User-Agent: curl/7.38.0
Accept: */*
Accept-Encoding: gzip
X-Forwarded-For: 165.73.96.95, 10.255.0.2
X-Forwarded-Host: whoami.pistack.co.za
X-Forwarded-Port: 80
X-Forwarded-Proto: http
X-Forwarded-Server: 31b37f9714d3
X-Real-Ip: 10.255.0.2
</code></pre>

<p>Hope this was useful.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://hub.docker.com/r/rbekker87/armhf-traefik/tags/">https://hub.docker.com/r/rbekker87/armhf-traefik/tags/</a></li>
<li><a href="https://github.com/containous/traefik/releases">https://github.com/containous/traefik/releases</a></li>
<li><a href="https://github.com/ruanbekker/traefik-armhf/blob/master/Dockerfile">https://github.com/ruanbekker/traefik-armhf/blob/master/Dockerfile</a></li>
</ul>


<script type="text/javascript">
  ( function() {
    if (window.CHITIKA === undefined) { window.CHITIKA = { 'units' : [] }; };
    var unit = {"calltype":"async[2]","publisher":"rbekker87","width":728,"height":90,"sid":"Chitika Default"};
    var placement_id = window.CHITIKA.units.length;
    window.CHITIKA.units.push(unit);
    document.write('<div id="chitikaAdBlock-' + placement_id + '"></div>');
}());
</script>


<script type="text/javascript" src="//cdn.chitika.net/getads.js" async></script>


<p></p>
]]></content>
  </entry>
  
</feed>
