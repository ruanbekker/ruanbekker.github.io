<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Swarm | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/swarm/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2018-06-01T03:40:21-04:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Clearing Up Disk Space on Docker Swarm by Removing Unused Data With Prune]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/06/01/clearing-up-disk-space-on-docker-swarm-by-removing-unused-data-with-prune/"/>
    <updated>2018-06-01T02:19:21-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/06/01/clearing-up-disk-space-on-docker-swarm-by-removing-unused-data-with-prune</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/docker-logo.png" alt="" /></p>

<p>After some time, your system can run out of disk space when running a lot of containers / volumes etc. You will find that at times, you will have a lot of unused containers, stopped containers, unused images, unused networks that is just sitting there, which consumes data on your nodes.</p>

<p>One way to clean them is by using <code>docker system prune</code>.</p>

<h2>Check Docker Disk Space</h2>

<p>The command below will show the amount of disk space consumed, and how much is reclaimable:</p>

<pre><code class="bash">$ docker system df
TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE
Images              229                 125                 23.94GB             14.65GB (61%)
Containers          322                 16                  8.229GB             8.222GB (99%)
Local Volumes       77                  41                  698MB               19.13MB (2%)
Build Cache                                                 0B                  0B
</code></pre>

<h2>Removing Unsued Data:</h2>

<p>By using Prune, we can remove the unused resources that is consuming data:</p>

<pre><code class="bash">$ docker system prune

WARNING! This will remove:
        - all stopped containers
        - all networks not used by at least one container
        - all dangling images
        - all build cache
Are you sure you want to continue? [y/N] y

Deleted Containers:
a3d7db158e065d0c86160fd5d688875f8b7435848ea91db57ed007
47890dcfea4a105f43e790dd8ad3c6d7c4ad7e738186c034d7a46b

Deleted Networks:
traefik-net
app_appnet

Deleted Images:
deleted: sha256:5b9909c10e93afec
deleted: sha256:d81eesdfihweo3rk

Total reclaimed space: 14.18GB
</code></pre>

<p>For related <a href="https://goo.gl/L2NYxU">Docker</a> posts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Wildcard SSL Certificate With Letsencrypt on Docker Swarm Using Traefik]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/05/28/wildcard-ssl-certificate-with-letsencrypt-on-docker-swarm-using-traefik/"/>
    <updated>2018-05-28T17:36:17-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/05/28/wildcard-ssl-certificate-with-letsencrypt-on-docker-swarm-using-traefik</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/traefik.png" alt="" /></p>

<p>With Letsencrypt supporting Wildcard certificates is really awesome. Now, we can setup traefik to listen on 443, acting as a reverse proxy and is doing HTTPS Termination to our Applications thats running in our Swarm.</p>

<h2>Architectural Design:</h2>

<p>At the moment we have 3 Manager Nodes, and 5 Worker Nodes:</p>

<ul>
<li>Using a Dummy Domain example.com which is set to the 3 Public IP&rsquo;s of our Manager Nodes</li>
<li>DNS is set for: <code>example.com</code> A Record to: <code>52.10.1.10</code>, <code>52.10.1.11</code>, <code>52.10.1.12</code></li>
<li>DNS is set for: <code>*.example.com</code> CNAME to <code>example.com</code></li>
<li>Any application that is spawned into our Swarm, will be labeled with a <code>traefik.frontend.rule</code> which will be routed to the service and redirected from HTTP to HTTPS</li>
</ul>


<h2>Create the Overlay Network:</h2>

<p>Create the overlay network that will be used for our stack:</p>

<pre><code class="bash">$ docker network create --driver overlay appnet
</code></pre>

<h2>Create the Compose Files for our Stacks:</h2>

<p>Create the Traefik Service Compose file, we will deploy it in Global Mode, constraint to our Manager Nodes, so that every manager node has a copy of traefik running.</p>

<pre><code class="bash">$ cat &gt; traefik-compose.yml &lt;&lt; EOF

version: "3.4"
services:
  proxy:
    image: traefik:latest
    command:
      - "--api"
      - "--entrypoints=Name:http Address::80 Redirect.EntryPoint:https"
      - "--entrypoints=Name:https Address::443 TLS"
      - "--defaultentrypoints=http,https"
      - "--acme"
      - "--acme.storage=/etc/traefik/acme/acme.json"
      - "--acme.entryPoint=https"
      - "--acme.httpChallenge.entryPoint=http"
      - "--acme.onHostRule=true"
      - "--acme.onDemand=false"
      - "--acme.email=me@example.com"
      - "--docker"
      - "--docker.swarmMode"
      - "--docker.domain=example.com"
      - "--docker.watch"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /mnt/traefik/acme.json:/etc/traefik/acme/acme.json
    networks:
      - appnet
    ports:
      - target: 80
        published: 80
        mode: host
      - target: 443
        published: 443
        mode: host
      - target: 8080
        published: 8080
        mode: host
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
networks:
  appnet:
    external: true

EOF
</code></pre>

<p>Create the Application Compose file, in this example we will be deploying a Ghost Blog:</p>

<pre><code class="bash">$ cat &gt; ghost-compose.yml &lt;&lt; EOF

version: '3.4'

services:
  blog:
    image: ghost:1.22.7-alpine
    networks:
      - appnet
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: 
          - node.role == worker
      labels:
        - "traefik.backend.loadbalancer.sticky=false"
        - "traefik.backend.loadbalancer.swarm=true"
        - "traefik.backend=blog-1"
        - "traefik.docker.network=appnet"
        - "traefik.entrypoints=https"
        - "traefik.frontend.passHostHeader=true"
        - "traefik.frontend.rule=Host:blog.example.com"
        - "traefik.port=2368"

networks:
  appnet:
    external: true

EOF
</code></pre>

<h2>Prepare the Path for Traefik:</h2>

<p>We have a <a href="https://sysadmins.co.za/tag/glusterfs/">replicated volume</a> under our <code>/mnt</code> partition, so that all our managers can read from that path, create the file and provide the sufficient permissions:</p>

<pre><code class="bash">$ mkdir -p /mnt/traefik
$ touch /mnt/traefik/acme.json
$ chmod 600 /mnt/traefik/acme.json
</code></pre>

<h2>Deploy the Stacks:</h2>

<p>Deploy the Traefik Stack:</p>

<pre><code class="bash">$ docker stack deploy -c traefik-compose.yml traefik
</code></pre>

<p>Wait until the services are deployed:</p>

<pre><code class="bash">$ docker stack services traefik
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
f8ru5gbcgd2v        traefik_proxy       global              3/3                 traefik:latest
</code></pre>

<p>Deploy the Application Stack:</p>

<pre><code class="bash">$ docker stack deploy -c ghost-compose.yml apps
</code></pre>

<p>Verify that the Application Stack has been deployed:</p>

<pre><code class="bash">$ docker stack services apps
ID                  NAME                MODE                REPLICAS            IMAGE                          PORTS
516zlfs2cfdv        apps_blog           replicated          1/1                 ghost:1.22.7-alpine
</code></pre>

<p>At the moment we will have 2 stacks in our Swarm:</p>

<pre><code class="bash">$ docker stack ls
NAME                SERVICES
apps                1
traefik             1
</code></pre>

<h2>Test the Application:</h2>

<p>Let&rsquo;s test our blog to see if we get redirected to <a href="HTTPS:">HTTPS:</a></p>

<pre><code class="bash">$ curl -iL http://blog.example.com
HTTP/1.1 302 Found
Location: https://blog.example.com:443/
Date: Mon, 28 May 2018 22:02:41 GMT
Content-Length: 5
Content-Type: text/plain; charset=utf-8

HTTP/1.1 200 OK
Cache-Control: public, max-age=0
Content-Type: text/html; charset=utf-8
Date: Mon, 28 May 2018 22:02:42 GMT
Etag: W/"4166-J2ooSIa8gtTkYjbnr7vnPUFlRJI"
Vary: Accept-Encoding
X-Powered-By: Express
Transfer-Encoding: chunked
</code></pre>

<p>Works like a charm! Traefik FTW!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Populate Environment Variables From Docker Secrets With a Flask Demo App]]></title>
    <link href="http://blog.ruanbekker.com/blog/2018/03/12/populate-environment-variables-from-docker-secrets-with-a-flask-demo-app/"/>
    <updated>2018-03-12T18:16:42-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2018/03/12/populate-environment-variables-from-docker-secrets-with-a-flask-demo-app</id>
    <content type="html"><![CDATA[<p><img src="http://obj-cache.cloud.ruanbekker.com/docker-logo.png" alt="" /></p>

<p>In this post we will create a basic Python Flask WebApp on Docker Swarm, but we will read our Flask Host, and Flask Port from Environment Variables, which will be populated from Docker Secrets, which we will read in from a python script.</p>

<h2>Our Directory Setup:</h2>

<p>This can be retrieved from <a href="https://github.com/ruanbekker/docker-swarm-apps/tree/master/tools-secrets-env-exporter">github.com/ruanbekker/docker-swarm-apps/tool-secrets-env-exporter</a>, but I will place the code in here as well.</p>

<pre><code class="bash Dockerfile:">FROM alpine:edge
RUN apk add --no-cache python2 py2-pip &amp;&amp; pip install flask
ADD exporter.py /exporter.py
ADD boot.sh /boot.sh
ADD app.py /app.py
CMD ["/bin/sh", "/boot.sh"]
</code></pre>

<pre><code class="python exporter.py">import os
from glob import glob

for var in glob('/run/secrets/*'):
    k=var.split('/')[-1]
    v=open(var).read().rstrip('\n')
    os.environ[k] = v
    print("export {key}={value}".format(key=k,value=v))
</code></pre>

<pre><code class="python app.py">import os
from flask import Flask

flask_host = str(os.environ['flask_host'])
flask_port = int(os.environ['flask_port'])

app = Flask(__name__)

@app.route('/')
def index():
    return 'ok\n'

if __name__ == '__main__':
    app.run(host=flask_host, port=flask_port)
</code></pre>

<pre><code class="bash boot.sh">#!/bin/sh
set -e
eval $(python /exporter.py)
python /app.py
</code></pre>

<h2>Flow Information:</h2>

<p>The exporter script checks all the secrets that is mounted to the container, then formats the secrets to a key/value pair, which then exports the environment variables to the current shell, which thereafter gets read by the flask application.</p>

<h2>Usage:</h2>

<p>Create Docker Secrets:</p>

<pre><code>$ echo 5001 | docker secret create flask_port -
$ echo 0.0.0.0 | docker secret create flask_host -
</code></pre>

<p>Build and Push the Image:</p>

<pre><code>$ docker build -t registry.gitlab.com/&lt;user&gt;/&lt;repo&gt;/&lt;image&gt;:&lt;tag&gt;
$ docker push registry.gitlab.com/&lt;user&gt;/&lt;repo&gt;/&lt;image&gt;:&lt;tag&gt;
</code></pre>

<p>Create the Service, and specify the secrets that we created earlier:</p>

<pre><code>$ docker service create --name webapp \
--secret source=flask_host,target=flask_host \
--secret source=flask_port,target=flask_port \
registry.gitlab.com/&lt;user&gt;/&lt;repo&gt;/&lt;image&gt;:&lt;tag&gt;
</code></pre>

<p>Exec into the container, list to see where the secrets got populated:</p>

<pre><code>$ ls /run/secrets/
flask_host  flask_port
</code></pre>

<p>Do a netstat, to see that the value from the created secret is listening:</p>

<pre><code>$ netstat -tulpn
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 0.0.0.0:5001            0.0.0.0:*               LISTEN      7/python
</code></pre>

<p>Do a GET request on the Flask Application:</p>

<pre><code>$ curl http://0.0.0.0:5001/
ok
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create a 3 Node Elasticsearch Stack With HAProxy on Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/24/create-a-3-node-elasticsearch-stack-with-haproxy-on-docker-swarm/"/>
    <updated>2017-09-24T15:40:19-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/24/create-a-3-node-elasticsearch-stack-with-haproxy-on-docker-swarm</id>
    <content type="html"><![CDATA[<p>Tried out creating a 3 node elasticsearch stack on docker swarm using docker-compose, that sits behind a haproxy service.</p>

<h2>Environment:</h2>

<p>Images:</p>

<ul>
<li><a href="https://hub.docker.com/r/dockercloud/haproxy/">dockercloud/haproxy</a></li>
<li><a href="https://github.com/ruanbekker/docker-elasticsearch">rbekker87/elasticsearch:master-5.6-alpine</a></li>
</ul>


<p>Stack:</p>

<ul>
<li>1 x haproxy</li>
<li>1 x elasticsearch master (haproxy wont send requests to this one)</li>
<li>2 x elasticsearch master/data</li>
<li>1 x esnet overlay network</li>
</ul>


<h2>Defining our Stack</h2>

<p>First we will create our compose file, which we will call <code>es-compose.yml</code>:</p>

<pre><code class="yaml">version: '3'

services:
  es-master:
    image: rbekker87/elasticsearch:master-5.6-alpine
    networks:
      - esnet
    deploy:
      replicas: 1

  es-data-1:
    image: rbekker87/elasticsearch:master-5.6-alpine
    environment:
     - SERVICE_PORTS=9200
    networks:
      - esnet
    deploy:
      replicas: 2

  es-data-2:
    image: rbekker87/elasticsearch:master-5.6-alpine
    environment:
     - SERVICE_PORTS=9200
    networks:
      - esnet
    deploy:
      replicas: 2

  loadbalancer:
    image: dockercloud/haproxy:latest
    depends_on:
      - es-data-1
      - es-data-2
    environment:
      - BALANCE=leastconn
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 9200:80
    networks:
      - esnet
    deploy:
      placement:
        constraints: [node.role == manager]

networks:
  esnet:
    driver: overlay
</code></pre>

<p>The above compose file defines that we want a overlay network, which we will associate with all our services, 3 elasticsearch services, haproxy service which will expose port 9200, then from haproxy it has a container port of 80, which sends to the backend <code>SERVICE_PORTS</code> of each elasticsearch service.</p>

<p>We have only defined <code>SERVICE_PORTS=9200</code> on our es-data services, as I just want to proxy client connections to them.</p>

<h2>Creating our Elasticsearch Stack</h2>

<p>Now that we have our compose file ready, let&rsquo;s create our stack using <code>docker stack deploy</code>:</p>

<pre><code class="bash Create the Stack">$ docker stack deploy -c es-compose.yml analytics

Creating network analytics_esnet
Creating service analytics_loadbalancer
Creating service analytics_es-master
Creating service analytics_es-data-1
Creating service analytics_es-data-2
</code></pre>

<p>Let&rsquo;s have a look at our stack:</p>

<pre><code class="bash Docker Stack Status ">$ docker stack ps analytics
ID                  NAME                       IMAGE                                       NODE                  DESIRED STATE       CURRENT STATE            ERROR               PORTS
4t3ukxl2kch3        analytics_loadbalancer.1   dockercloud/haproxy:latest                  scw-swarm-master-01   Running             Running 27 seconds ago
jgbxtgqkg9jp        analytics_es-data-2.1      rbekker87/elasticsearch:master-5.6-alpine   scw-swarm-master-01   Running             Running 33 seconds ago
x5cq6pm7u7mn        analytics_es-data-1.1      rbekker87/elasticsearch:master-5.6-alpine   scw-swarm-master-01   Running             Running 36 seconds ago
5v22w1hvtdvm        analytics_es-master.1      rbekker87/elasticsearch:master-5.6-alpine   scw-swarm-master-01   Running             Running 38 seconds ago
</code></pre>

<p>View the logs of our haproxy service:</p>

<pre><code class="bash HAProxy Service Logs">$ docker service logs -f analytics_loadbalancer
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:dockercloud/haproxy 1.6.7 is running outside Docker Cloud
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:Haproxy is running in SwarmMode, loading HAProxy definition through docker api
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:dockercloud/haproxy PID: 7
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:=&gt; Add task: Initial start - Swarm Mode
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:=&gt; Executing task: Initial start - Swarm Mode
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:==========BEGIN==========
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:Linked service: analytics_es-data-1, analytics_es-data-2, analytics_es-master
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:Linked container: analytics_es-data-1.1.u641c5bq5vkjklk8sb1scnnlc, analytics_es-data-2.1.ic9an6bzj6aejs0lx0vzfpia6, analytics_es-master.1.h4erlgwzit509p0zehzmozy3u
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:HAProxy configuration:
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | global
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   log 127.0.0.1 local0
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   log 127.0.0.1 local1 notice
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   log-send-hostname
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   maxconn 4096
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   pidfile /var/run/haproxy.pid
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   user haproxy
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   group haproxy
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   daemon
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   stats socket /var/run/haproxy.stats level admin
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   ssl-default-bind-options no-sslv3
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   ssl-default-bind-ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:DHE-DSS-AES128-SHA:DES-CBC3-SHA
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | defaults
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   balance leastconn
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   log global
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   mode http
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   option redispatch
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   option httplog
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   option dontlognull
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   option forwardfor
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   timeout connect 5000
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   timeout client 50000
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   timeout server 50000
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | listen stats
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   bind :1936
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   mode http
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   stats enable
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   timeout connect 10s
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   timeout client 1m
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   timeout server 1m
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   stats hide-version
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   stats realm Haproxy\ Statistics
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   stats uri /
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   stats auth stats:stats
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | frontend default_port_80
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   bind :80
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   reqadd X-Forwarded-Proto:\ http
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   maxconn 4096
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   default_backend default_service
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | backend default_service
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   server analytics_es-data-1.1.u641c5bq5vkjklk8sb1scnnlc 10.0.7.5:9200 check inter 2000 rise 2 fall 3
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    |   server analytics_es-data-2.1.ic9an6bzj6aejs0lx0vzfpia6 10.0.7.7:9200 check inter 2000 rise 2 fall 3
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:Launching HAProxy
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:HAProxy has been launched(PID: 10)
analytics_loadbalancer.1.lcpgiz0ooeas@scw-swarm-master-01    | INFO:haproxy:===========END===========
</code></pre>

<h2>Testing Elasticsearch:</h2>

<p>Do a GET request on our HAProxy&rsquo;s Expose port: 9200</p>

<pre><code class="bash Test Elasticsearch on port 9200">$ curl -XGET http://127.0.0.1:9200
{
  "name" : "5306a0c2ee24",
  "cluster_name" : "es-cluster",
  "cluster_uuid" : "FUJmMekFQVq6zXofPCin2A",
  "version" : {
    "number" : "5.6.0",
    "build_hash" : "781a835",
    "build_date" : "2017-09-07T03:09:58.087Z",
    "build_snapshot" : false,
    "lucene_version" : "6.6.0"
  },
  "tagline" : "You Know, for Search"
}
</code></pre>

<p>Have a look at the <code>/_cat/nodes</code> API:</p>

<pre><code class="bash Get the Node Info">$  curl -XGET http://127.0.0.1:9200/_cat/nodes?v
ip       heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.0.7.6           28          84  14    3.09    2.28     1.49 mdi       -      56c1b0aebc5f
10.0.7.2           27          84  15    3.09    2.28     1.49 mdi       *      572c68bca904
10.0.7.4           29          84  15    3.09    2.28     1.49 mdi       -      5306a0c2ee24
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup RocketChat on Docker Swarm]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/09/10/setup-rocketchat-on-docker-swarm/"/>
    <updated>2017-09-10T18:45:12-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/09/10/setup-rocketchat-on-docker-swarm</id>
    <content type="html"><![CDATA[<p>Rocket Chat, a Self Hosted Alternative, which is very similar to Slack.</p>

<p>We will setup a RocketChat Server which is hosted on Docker Swarm. In future posts, I will also go through the steps on working with the API, Custom Emoji&rsquo;s etc.</p>

<h2>Requirements:</h2>

<p>RocketChat uses MongoDB as its Database, we will keep the database outside of our swarm, if you don&rsquo;t already have a MongoDB Server in place, follow the <a href="http://blog.ruanbekker.com/blog/2017/09/02/setup-a-3-node-mongodb-replica-set-on-ubuntu-16/">Setup a 3 Node MongoDB</a> post to get that sorted.</p>

<p>Another requirement is to have docker swarm running, alternatively, you can also follow <a href="https://rocket.chat/docs/installation/">RocketChat&rsquo;s Documentation</a> if you prefer setting it up elsewhere.</p>

<h2>Setup Rocket Chat</h2>

<p>We will assume MongoDB is accessible via <code>mongodb.domain.com</code> on port <code>27017</code>, with a username and password.</p>

<p>Creating the RocketChat service and associate it to our <code>appnet</code> overlay network:</p>

<pre><code class="bash">docker service create --name rocketchat \
--replicas 1 \
--network appnet \
--env DEPLOY_METHOD=docker \
--env NODE_ENV=production \
--env PORT=3000 \
--env MONGO_URL="mongodb://mongoadmin:mongopass@mongodb.domain.com:27017/rocketchat?authSource=admin" \
--env ROOT_URL=http://rocketchat.domain.com \
--env ADMIN_USERNAME=myadmin \
--env ADMIN_PASS=secret \
--env ADMIN_EMAIL=mail@domain.com \
--env Accounts_AvatarStorePath=/app/uploads \
--secret rocketchat_secret \
rocketchat/rocket.chat
</code></pre>

<h2>View the RocketChat Service Logs</h2>

<p>Lets monitor the docker service logs for our rocketchat service:</p>

<pre><code class="bash">$ docker service logs -f rocketchat

rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | Using GridFS for custom sounds storage
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | Using GridFS for custom emoji storage
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | ufs: temp directory created at "/tmp/ufs"
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | System startup
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | +--------------------------------------------------------------+
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |                        SERVER RUNNING                        |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | +--------------------------------------------------------------+
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |                                                              |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |  Rocket.Chat Version: 0.58.2                                 |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |       NodeJS Version: 4.8.4 - x64                            |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |             Platform: linux                                  |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |         Process Port: 3000                                   |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |             Site URL: http://rocketchat.domain.com           |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |     ReplicaSet OpLog: Disabled                               |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |          Commit Hash: 988103d449                             |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |        Commit Branch: HEAD                                   |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | |                                                              |
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | +--------------------------------------------------------------+
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | Inserting admin user:
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | Name: Administrator
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | Email: mail@domain.com
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | Username: myadmin
rocketchat.1.lnbyfjiotqpz@docker-swarm-worker-03    | Password: secret
</code></pre>

<p>Now you should be able to access Rocket Chat on the <code>ROOT_URL</code> that you have specified.</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://rocket.chat/docs/installation/">https://rocket.chat/docs/installation/</a></li>
<li><a href="https://github.com/RocketChat/Docker.Official.Image">https://github.com/RocketChat/Docker.Official.Image</a></li>
<li><a href="https://rocket.chat/docs/installation/docker-containers">https://rocket.chat/docs/installation/docker-containers</a></li>
</ul>


<center>
        <script type='text/javascript' src='https://ko-fi.com/widgets/widget_2.js'></script><script type='text/javascript'>kofiwidget2.init('Buy Me a Coffee', '#46b798', 'A6423ZIQ');kofiwidget2.draw();</script>
</center>



]]></content>
  </entry>
  
</feed>
