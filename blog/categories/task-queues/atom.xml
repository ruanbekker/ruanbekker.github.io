<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Task-queues | Ruan Bekker's Blog]]></title>
  <link href="https://blog.ruanbekker.com/blog/categories/task-queues/atom.xml" rel="self"/>
  <link href="https://blog.ruanbekker.com/"/>
  <updated>2020-05-22T00:01:53+02:00</updated>
  <id>https://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Python RQ for Task Queues in Python]]></title>
    <link href="https://blog.ruanbekker.com/blog/2020/05/16/using-python-rq-for-task-queues-in-python/"/>
    <updated>2020-05-16T21:12:36+02:00</updated>
    <id>https://blog.ruanbekker.com/blog/2020/05/16/using-python-rq-for-task-queues-in-python</id>
    <content type="html"><![CDATA[<p>This is a getting started on python-rq tutorial and I will demonstrate how to work with asynchronous tasks using python redis queue (python-rq).</p>

<h2>What will we be doing</h2>

<p>We want a client to submit 1000&rsquo;s of tasks in a non-blocking asynchronous fashion, and then we will have workers which will consume these tasks from our redis queue, and process them at the rate of what our consumer can handle.</p>

<p>The nice thing about this is that, if our consumer is unavailable for processing the tasks will remain in the queue and once the consumer is ready to consume, the tasks will be executed. It&rsquo;s also nice that its asynchronous, so the client don&rsquo;t have to wait until the task has finished.</p>

<p>We will run a redis server using docker, which will be used to queue all our tasks, then we will go through the basics in python and python-rq such as:</p>

<ul>
<li>Writing a Task</li>
<li>Enqueueing a Job</li>
<li>Getting information from our queue, listing jobs, job statuses</li>
<li>Running our workers to consume from the queue and action our tasks</li>
<li>Basic application which queues jobs to the queue, consumes and action them and monitors the queue</li>
</ul>


<h2>Redis Server</h2>

<p>You will require docker for this next step, to start the redis server:</p>

<pre><code>$ docker run --rm -itd --name redis -p 6379:6379 redis:alpine
</code></pre>

<h2>Python RQ</h2>

<p>Install python-rq:</p>

<pre><code>$ pip install rq
</code></pre>
]]></content>
  </entry>
  
</feed>
