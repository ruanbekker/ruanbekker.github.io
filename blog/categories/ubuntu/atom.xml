<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ubuntu | Ruan Bekker's Blog]]></title>
  <link href="http://blog.ruanbekker.com/blog/categories/ubuntu/atom.xml" rel="self"/>
  <link href="http://blog.ruanbekker.com/"/>
  <updated>2017-11-22T17:45:40-05:00</updated>
  <id>http://blog.ruanbekker.com/</id>
  <author>
    <name><![CDATA[Ruan]]></name>
    <email><![CDATA[ruan@ruanbekker.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setup a Concourse-CI Server on Ubuntu 16]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/11/07/setup-a-concourse-ci-server-on-ubuntu-16/"/>
    <updated>2017-11-07T17:55:46-05:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/11/07/setup-a-concourse-ci-server-on-ubuntu-16</id>
    <content type="html"><![CDATA[<p>Concourse is a Pipeline Based Continious Integration system written in Go</p>

<h2>Resources:</h2>

<ul>
<li><a href="https://concourse.ci/">https://concourse.ci/</a></li>
<li><a href="https://github.com/concourse/concourse">https://github.com/concourse/concourse</a></li>
<li><a href="https://concourse.ci/hello-world.html">https://concourse.ci/hello-world.html</a></li>
<li><a href="https://github.com/starkandwayne/concourse-tutorial">https://github.com/starkandwayne/concourse-tutorial</a></li>
</ul>


<h2>What will we be doing today</h2>

<p>We will setup a Concourse Server on Ubuntu 16.04 and run the traditional <code>Hello, World</code> pipeline</p>

<h2>Setup the Server:</h2>

<p>Concourse needs <code>PostgresSQL 9.3+</code></p>

<pre><code class="bash">$ apt update &amp;&amp; apt upgrade -y
$ apt install postgresql postgresql-contrib -y
$ systemctl enable postgresql
</code></pre>

<p>Create the Database and User for Concourse on Postgres:</p>

<pre><code class="bash">$ sudo -u postgres createuser concourse
$ sudo -u postgres createdb --owner=concourse atc
</code></pre>

<p>Download the Concourse and Fly Cli Binaries:</p>

<pre><code class="bash">$ wget https://github.com/concourse/concourse/releases/download/v3.6.0/concourse_linux_amd64
$ wget https://github.com/concourse/concourse/releases/download/v3.6.0/fly_linux_amd64
$ chmod +x concourse_linux_amd64 fly_linux_amd64
$ mv concourse_linux_amd64 /usr/bin/concourse
$ mv fly_linux_amd64 /usr/bin/fly
</code></pre>

<p>Create the Encryption Keys:</p>

<pre><code class="bash">$ mkdir /etc/concourse
$ ssh-keygen -t rsa -q -N '' -f /etc/concourse/tsa_host_key
$ ssh-keygen -t rsa -q -N '' -f /etc/concourse/worker_key
$ ssh-keygen -t rsa -q -N '' -f /etc/concourse/session_signing_key
$ cp /etc/concourse/worker_key.pub /etc/concourse/authorized_worker_keys
</code></pre>

<p>Concourse Web Process Configuration:</p>

<pre><code class="bash">$ cat /etc/concourse/web_environment

CONCOURSE_SESSION_SIGNING_KEY=/etc/concourse/session_signing_key
CONCOURSE_TSA_HOST_KEY=/etc/concourse/tsa_host_key
CONCOURSE_TSA_AUTHORIZED_KEYS=/etc/concourse/authorized_worker_keys
CONCOURSE_POSTGRES_SOCKET=/var/run/postgresql

CONCOURSE_BASIC_AUTH_USERNAME=admin
CONCOURSE_BASIC_AUTH_PASSWORD=secret
CONCOURSE_EXTERNAL_URL=http://10.20.30.40:8080
</code></pre>

<p>Concourse Worker Process Configuration:</p>

<pre><code class="bash">$ cat /etc/concourse/worker_environment

CONCOURSE_WORK_DIR=/var/lib/concourse
CONCOURSE_TSA_WORKER_PRIVATE_KEY=/etc/concourse/worker_key
CONCOURSE_TSA_PUBLIC_KEY=/etc/concourse/tsa_host_key.pub
CONCOURSE_TSA_HOST=127.0.0.1
</code></pre>

<p>Create a Concourse user:</p>

<pre><code class="bash">$ sudo adduser --system --group concourse
$ sudo chown -R concourse:concourse /etc/concourse
$ sudo chmod 600 /etc/concourse/*_environment
</code></pre>

<p>Create SystemD Unit Files, first for the Web Service:</p>

<pre><code class="bash">$ cat /etc/systemd/system/concourse-web.service

[Unit]
Description=Concourse CI web process (ATC and TSA)
After=postgresql.service

[Service]
User=concourse
Restart=on-failure
EnvironmentFile=/etc/concourse/web_environment
ExecStart=/usr/bin/concourse web

[Install]
WantedBy=multi-user.target
</code></pre>

<p>Then the SystemD Unit File for the Worker Service:</p>

<pre><code class="bash">$ cat /etc/systemd/system/concourse-worker.service

[Unit]
Description=Concourse CI worker process
After=concourse-web.service

[Service]
User=root
Restart=on-failure
EnvironmentFile=/etc/concourse/worker_environment
ExecStart=/usr/bin/concourse worker

[Install]
WantedBy=multi-user.target
</code></pre>

<p>Start and Enable the Services:</p>

<pre><code class="bash">$ systemctl start concourse-web concourse-worker
$ systemctl enable concourse-web concourse-worker
$ systemctl status concourse-web concourse-worker

$ systemctl is-active concourse-worker concourse-web
active
active
</code></pre>

<p>The listening ports should more or less look like the following:</p>

<pre><code class="bash">$ netstat -tulpn

Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 127.0.0.1:7777          0.0.0.0:*               LISTEN      4530/concourse
tcp        0      0 127.0.0.1:7788          0.0.0.0:*               LISTEN      4530/concourse
tcp        0      0 127.0.0.1:8079          0.0.0.0:*               LISTEN      4525/concourse
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1283/sshd
tcp        0      0 127.0.0.1:5432          0.0.0.0:*               LISTEN      4047/postgres
tcp6       0      0 :::36159                :::*                    LISTEN      4525/concourse
tcp6       0      0 :::46829                :::*                    LISTEN      4525/concourse
tcp6       0      0 :::2222                 :::*                    LISTEN      4525/concourse
tcp6       0      0 :::8080                 :::*                    LISTEN      4525/concourse
tcp6       0      0 :::22                   :::*                    LISTEN      1283/sshd
udp        0      0 0.0.0.0:68              0.0.0.0:*                           918/dhclient
udp        0      0 0.0.0.0:42165           0.0.0.0:*                           4530/concourse
</code></pre>

<h2>Client Side:</h2>

<p>I will be using a the Fly cli from a Mac, so first we need to download the fly-cli for Mac:</p>

<pre><code class="bash">$ wget https://github.com/concourse/concourse/releases/download/v3.6.0/fly_darwin_amd64
$ chmod +x fly_darwin_amd64
$ alias fly='./fly_darwin_amd64'
</code></pre>

<p>Next, we need to setup our Concourse Target by Authenticating against our Concourse Endpoint, lets setup our target with the name <code>ci</code>:</p>

<pre><code class="bash">$ fly -t ci login -c http://10.20.30.40:8080
logging in to team 'main'

username: admin
password:

target saved
</code></pre>

<p>Lets list our targets:</p>

<pre><code class="bash">$ fly targets
name  url                        team  expiry
ci    http://10.20.30.40:8080    main  Wed, 08 Nov 2017 15:32:59 UTC
</code></pre>

<p>Listing Registered Workers:</p>

<pre><code class="bash">$ fly -t ci workers
name              containers  platform  tags  team  state    version
ip-172-31-12-134  0           linux     none  none  running  1.2
</code></pre>

<p>Listing Active Containers:</p>

<pre><code class="bash">$ fly -t ci containers
handle                                worker            pipeline     job            build #  build id  type   name                  attempt
</code></pre>

<h2>Hello World Pipeline:</h2>

<p>Let&rsquo;s create a basic pipeline, that will print out <code>Hello, World!</code>:</p>

<p>Our <code>hello-world.yml</code></p>

<pre><code class="yml">jobs:
- name: my-job
  plan:
  - task: say-hello
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: alpine
          tag: edge
      run:
        path: /bin/sh
        args:
        - -c
        - |
          echo "============="
          echo "Hello, World!"
          echo "============="
</code></pre>

<p>Applying the configuration to our pipeline:</p>

<pre><code class="bash">$ fly -t ci set-pipeline -p yeeehaa -c hello-world.yml
jobs:
  job my-job has been added:
    name: my-job
    plan:
    - task: say-hello
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: alpine
            tag: edge
        run:
          path: /bin/sh
          args:
          - -c
          - |
            echo "============="
            echo "Hello, World!"
            echo "============="

apply configuration? [yN]: y
pipeline created!
you can view your pipeline here: http://10.20.30.40:8080/teams/main/pipelines/yeeehaa

the pipeline is currently paused. to unpause, either:
  - run the unpause-pipeline command
  - click play next to the pipeline in the web ui
</code></pre>

<p>We can browse to the WebUI to unpause the pipeline, but since I like to do everything on cli as far as possible, I will unpause the pipeline via cli:</p>

<pre><code class="bash">$ fly -t ci unpause-pipeline -p yeeehaa
unpaused 'yeeehaa'
</code></pre>

<p>Now our Pipeline is unpaused, but since we did not specify any triggers, we need to manually trigger the pipeline to run, you can either via the WebUI, select your pipeline which in this case will be named <code>yeeehaa</code> and then select the job, which will be <code>my-job</code> then hit the <code>+</code> sign, which will trigger the pipeline.</p>

<p>I will be using the cli:</p>

<pre><code class="bash">$ fly -t ci trigger-job --job yeeehaa/my-job
started yeeehaa/my-job #1
</code></pre>

<p>Via the WebUI on <code>http://10.20.30.40:8080/teams/main/pipelines/yeeehaa/jobs/my-job/builds/1</code> you should see the <code>Hello, World!</code> output, or via the cli, we also have the option to see the output, so let&rsquo;s trigger it again, but this time passing the <code>--watch</code> flag:</p>

<pre><code class="bash">$ fly -t ci trigger-job --job yeeehaa/my-job --watch
started yeeehaa/my-job #2

initializing
running /bin/sh -c echo "============="
echo "Hello, World!"
echo "============="

=============
Hello, World!
=============
succeeded
</code></pre>

<p>Listing our Workers and Containers again:</p>

<pre><code class="bash">$ fly -t ci workers
name              containers  platform  tags  team  state    version
ip-172-31-12-134  2           linux     none  none  running  1.2

$ fly -t ci containers
handle                                worker            pipeline     job         build #  build id  type   name           attempt
36982955-54fd-4c1b-57b8-216486c58db8  ip-172-31-12-134  yeeehaa      my-job      2        729       task   say-hello      n/a
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup Kerberos Server and Client on Ubuntu]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/10/18/setup-kerberos-server-and-client-on-ubuntu/"/>
    <updated>2017-10-18T18:25:11-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/10/18/setup-kerberos-server-and-client-on-ubuntu</id>
    <content type="html"><![CDATA[<p>Kerberos is a authentication protocol that provides a centralized authentication server, that works with the concepts of tickets that are encrypted.</p>

<p>Today we will setup a Kerberos Server (KDC) and setup and Kerberos Enabled Client, and then testing our setup by obtaining a Kerberos Ticket from our server.</p>

<h2>Setup the Server:</h2>

<p>Install Kerberos KDC and Admin Server:</p>

<pre><code class="bash">$ apt update &amp;&amp; apt upgrade -y
$ apt install krb5-kdc krb5-admin-server krb5-config -y
$ krb5_newrealm
</code></pre>

<p>You will be prompted for realm, and hostnames, in my case I have setup the following:</p>

<ul>
<li>REALM: <code>LAN.RUANBEKER.COM</code></li>
<li>HOST: <code>localhost</code></li>
<li>ADMIN_SERVER: <code>localhost</code></li>
</ul>


<p>Then our master password:</p>

<pre><code class="bash">This script should be run on the master KDC/admin server to initialize
a Kerberos realm.  It will ask you to type in a master key password.
This password will be used to generate a key that is stored in
/etc/krb5kdc/stash.  You should try to remember this password, but it
is much more important that it be a strong password than that it be
remembered.  However, if you lose the password and /etc/krb5kdc/stash,
you cannot decrypt your Kerberos database.
Loading random data
Initializing database '/var/lib/krb5kdc/principal' for realm 'LAN.RUANBEKKER.COM',
master key name 'K/M@LAN.RUANBEKKER.COM'
You will be prompted for the database Master Password.
It is important that you NOT FORGET this password.
Enter KDC database master key: 
Re-enter KDC database master key to verify: 
</code></pre>

<p>The output:</p>

<pre><code class="bash">Now that your realm is set up you may wish to create an administrative
principal using the addprinc subcommand of the kadmin.local program.
Then, this principal can be added to /etc/krb5kdc/kadm5.acl so that
you can use the kadmin program on other computers.  Kerberos admin
principals usually belong to a single user and end in /admin.  For
example, if jruser is a Kerberos administrator, then in addition to
the normal jruser principal, a jruser/admin principal should be
created.

Don't forget to set up DNS information so your clients can find your
KDC and admin servers.  Doing so is documented in the administration
guide.
</code></pre>

<p>Uncomment the last line which contains <code>admin</code>:</p>

<pre><code class="bash">$ vi /etc/krb5kdc/kadm5.acl
</code></pre>

<p>a Kerberos principal is a unique identity to which Kerberos can assign tickets, lets add our first principal, <code>james</code>:</p>

<pre><code class="bash">$ kadmin.local 
Authenticating as principal root/admin@LAN.RUANBEKKER.COM with password.
kadmin.local:  addprinc james

WARNING: no policy specified for james@LAN.RUANBEKKER.COM; defaulting to no policy
Enter password for principal "james@LAN.RUANBEKKER.COM": 
Re-enter password for principal "james@LAN.RUANBEKKER.COM": 
Principal "james@LAN.RUANBEKKER.COM" created.
kadmin.local:  exit
</code></pre>

<h2>Setup the Client:</h2>

<p>Setup a Host Entry:</p>

<pre><code class="bash">$ echo '10.1.1.1 kdc.lan.ruanbekker.com kdc' &gt;&gt; /etc/hosts
</code></pre>

<p>Setup Kerberos Client:</p>

<pre><code class="bash">$ apt install krb5-user -y
- realm
- hostname
- hostname
</code></pre>

<p>Obtain a Ticket from the Server:</p>

<pre><code class="bash">$ kinit -p james
Password for james@LAN.RUANBEKKER.COM: 

$ klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: james@LAN.RUANBEKKER.COM

Valid starting     Expires            Service principal
10/18/17 22:13:34  10/19/17 08:13:34  krbtgt/LAN.RUANBEKKER.COM@LAN.RUANBEKKER.COM
    renew until 10/19/17 22:13:30
</code></pre>

<h2>Resources:</h2>

<ul>
<li><a href="http://csetutorials.com/setup-kerberos-ubuntu.html">http://csetutorials.com/setup-kerberos-ubuntu.html</a></li>
<li><a href="https://www.rootusers.com/how-to-configure-linux-to-authenticate-using-kerberos/">https://www.rootusers.com/how-to-configure-linux-to-authenticate-using-kerberos/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Customize Ubuntu 16 Desktop With Arc Dark Theme]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/10/11/customize-ubuntu-16-desktop-with-arc-dark-theme/"/>
    <updated>2017-10-11T15:56:10-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/10/11/customize-ubuntu-16-desktop-with-arc-dark-theme</id>
    <content type="html"><![CDATA[<p><img src="https://i.snag.gy/g1ryLn.jpg" alt="" /></p>

<p>So I was running ApricityOS for quite some time, which is a Arch Distibution. But a couple of hours before PyConZa I was trying to do a update and found that their repositories were reporting 404 errors, and turns out they have stopped their project :( . I quite liked ApricityOS, as it&rsquo;s what you will expect when installing Arch with the basic applications and the numix icon/theme pack.</p>

<p>So I decided to use Ubuntu for a change.</p>

<h2>Customizations:</h2>

<p>For the Operating System, I am Ubuntu 16:</p>

<ul>
<li><a href="https://www.ubuntu.com/download/desktop">Ubuntu 16.04 (Operating System)</a></li>
</ul>


<p>For my theme I am using Arc Dark:</p>

<ul>
<li><a href="https://github.com/horst3180/arc-theme">Arch Teme</a> - <a href="https://askubuntu.com/questions/265471/autoreconf-not-found-error-during-making-qemu-1-4-0/490839">autoconf dependency required</a></li>
</ul>


<p><img src="https://i.snag.gy/u5fP4w.jpg" alt="" /></p>

<p>Moka Icon pack for my Icons:</p>

<ul>
<li><a href="https://snwh.org/moka/download">Moka Icon Themes</a></li>
</ul>


<p><img src="https://i.snag.gy/3JPi9W.jpg?nocache=1507753731895" alt="" /></p>

<p>Terminator for my terminal of choice:</p>

<ul>
<li><a href="http://www.linuxandubuntu.com/home/10-best-linux-terminals-for-ubuntu-and-fedora">Terminator Terminal</a></li>
</ul>


<p><img src="https://i.snag.gy/xqgXMc.jpg" alt="" /></p>

<p>And my config:</p>

<p><code>bash ~/.config/terminator/config
[global_config]
  enabled_plugins = LaunchpadCodeURLHandler, APTURLHandler, LaunchpadBugURLHandler
  sticky = True
  window_state = maximise
[keybindings]
[layouts]
  [[default]]
    [[[child1]]]
      parent = window0
      profile = default
      type = Terminal
    [[[window0]]]
      parent = ""
      type = Window
  [[multi]]
    foreground_color = "#ffffff"
    palette = "#62b9d6:#cc0000:#4e9a06:#c4a000:#3465a4:#75507b:#06989a:#d3d7cf:#77c529:#ef2929:#8ae234:#fce94f:#729fcf:#ad7fa8:#34e2e2:#eeeeec"
    [[[child0]]]
      order = 0
      parent = ""
      position = 0:25
      size = 1366, 768
      type = Window
    [[[child1]]]
      order = 0
      parent = child0
      position = 632
      type = HPaned
    [[[child2]]]
      order = 0
      parent = child1
      position = 354
      type = VPaned
    [[[child5]]]
      order = 1
      parent = child1
      position = 354
      type = VPaned
    [[[terminal3]]]
      command = top; bash
      order = 0
      parent = child2
      profile = default
      type = Terminal
    [[[terminal4]]]
      command = uptime; bash
      order = 1
      parent = child2
      profile = default
      type = Terminal
    [[[terminal6]]]
      command = cd ~/workspace; bash
      order = 0
      parent = child5
      profile = default
      type = Terminal
    [[[terminal7]]]
      command = cd ~/workspace; bash
      order = 1
      parent = child5
      profile = default
      type = Terminal
  [[simples]]
    [[[child0]]]
      order = 0
      parent = ""
      position = 0:25
      size = 715, 694
      type = Window
    [[[child1]]]
      order = 0
      parent = child0
      position = 348
      type = VPaned
    [[[terminal2]]]
      command = cd ~/workspace; bash
      order = 0
      parent = child1
      profile = default
      type = Terminal
    [[[terminal3]]]
      command = cd ~/workspace; bash
      order = 1
      parent = child1
      profile = default
      type = Terminal
[plugins]
[profiles]
  [[default]]
    background_image = None
    icon_bell = False
    scrollback_infinite = True
</code></p>

<p>And to force color prompts:</p>

<p><code>bash ~/.bashrc
force_color_prompt=yes
</code></p>

<p>And my Wallpaper:</p>

<ul>
<li><a href="https://www.pixelstalk.net/wp-content/uploads/2016/03/Black-lamborghini-wallpaper-HD.jpg">Lamborghini Wallpaper</a></li>
</ul>


<h2>Other Preferred Applications:</h2>

<ul>
<li><a href="https://www.docker.com/docker-ubuntu">Docker</a> &lt;&ndash; Of course! :D</li>
<li><a href="https://linuxcontainers.org/lxd/getting-started-cli/">LXD</a></li>
<li><a href="https://www.dropbox.com/">Cloud Storage: Dropbox</a></li>
<li><a href="https://www.sublimetext.com/">Text Editor: Sublime Text</a></li>
<li><a href="https://boostnote.io/">Note Taking: Boostnote</a></li>
<li><a href="https://www.nylas.com/nylas-mail/">Mail Client: Nylas</a> and <a href="https://wiki.gnome.org/Apps/Geary">Geary</a></li>
<li><a href="https://www.jetbrains.com/pycharm/">Python IDE: PyCharm</a> (however, I prefer to use VIM :D )</li>
<li><p><a href="https://netbeans.org/">Java IDE: Netbeans</a></p></li>
<li><p>Sysadmin Tools: (htop, netstat, tcpdump, nmap, vnstat, mysql-client, mongo-client, curl, nload, etc)</p></li>
</ul>


<p>I will update this page as I&rsquo;m getting new apps or modifications</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create a ZFS Raidz1 Volume Pool on Ubuntu 16]]></title>
    <link href="http://blog.ruanbekker.com/blog/2017/08/24/create-a-zfs-raidz1-volume-pool-on-ubuntu-16/"/>
    <updated>2017-08-24T09:16:34-04:00</updated>
    <id>http://blog.ruanbekker.com/blog/2017/08/24/create-a-zfs-raidz1-volume-pool-on-ubuntu-16</id>
    <content type="html"><![CDATA[<p>Setting up ZFS Volume Pool on Ubuntu 16.04</p>

<h2>Installation</h2>

<pre><code>$ sudo apt-get install zfsutils-linux -y
</code></pre>

<h2>Creating the ZFS Storage Pool</h2>

<p>We will create a RAIDZ(1) Volume which is like Raid5 with Single Parity, so we can lose one of the Physical Disks before Raid failure.</p>

<p>Let&rsquo;s first have a look at our disks that we have on our server:</p>

<pre><code>$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
└─xvda1 202:1    0   8G  0 part /
xvdf    202:80   0 100G  0 disk 
xvdg    202:80   0 100G  0 disk 
</code></pre>

<p>So we will be creating the volume consisting of <code>/dev/xvdf</code> and <code>/dev/xvdg</code> and we will name our pool: <code>storage-pool</code></p>

<pre><code>$ zpool create storage-pool raidz1 xvdf xvdg -f
</code></pre>

<h2>Listing Pools</h2>

<pre><code>$ zpool list
NAME           SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
storage-pool   199G   125K   199G         -     0%     0%  1.00x  ONLINE  -
</code></pre>

<p>We can also list the volume with <code>zfs</code>:</p>

<pre><code>$ zfs list
NAME            USED  AVAIL  REFER  MOUNTPOINT
storage-pool    125K  199G   19K    /storage-pool
</code></pre>

<h2>Mounting the Volume:</h2>

<p>You will find that the volume is already mounted:</p>

<pre><code>$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/xvda1      7.7G  1.1G  6.7G  14% /
pool            199G  125K  198G   1% /pool
</code></pre>

<h2>Resources:</h2>

<p>See how Brett Kelly from 45 Drives tried to break a Storage Cluster with GlusterFS and ZFS:</p>

<center><iframe width="740" height="400" src="https://www.youtube.com/embed/A0wV4k58RIs" frameborder="1" allowfullscreen></iframe></center>


<p>Great ZFS Performance Comparison:</p>

<ul>
<li><a href="https://calomel.org/zfs_raid_speed_capacity.html">https://calomel.org/zfs_raid_speed_capacity.html</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
